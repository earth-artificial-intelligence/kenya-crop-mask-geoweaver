[{
  "history_id" : "0dutrif2397",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1666167825336,
  "history_end_time" : 1666167825336,
  "history_notes" : null,
  "history_process" : "mw544v",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "q1isbv958t1",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1666167772295,
  "history_end_time" : 1666167772295,
  "history_notes" : null,
  "history_process" : "mw544v",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "aruj20bzgjb",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1666166465572,
  "history_end_time" : 1666166465572,
  "history_notes" : null,
  "history_process" : "mw544v",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "zc9ubvwpk8a",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1666166410232,
  "history_end_time" : 1666166419926,
  "history_notes" : null,
  "history_process" : "mw544v",
  "host_id" : "100001",
  "indicator" : "Stopped"
},{
  "history_id" : "sqrh6cr32y5",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1666164233049,
  "history_end_time" : 1666164233049,
  "history_notes" : null,
  "history_process" : "mw544v",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "5i6taaazsjq",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1666163607247,
  "history_end_time" : 1666163607247,
  "history_notes" : null,
  "history_process" : "mw544v",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "4hkyf9z86qi",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1666137012926,
  "history_end_time" : 1666137012926,
  "history_notes" : null,
  "history_process" : "mw544v",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "0eepc9svp4w",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1666136593461,
  "history_end_time" : 1666136593461,
  "history_notes" : null,
  "history_process" : "mw544v",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "lhm7kb0dhb4",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1666136435742,
  "history_end_time" : 1666136435742,
  "history_notes" : null,
  "history_process" : "mw544v",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "0vx3m29v2q3",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1666134110722,
  "history_end_time" : 1666134110722,
  "history_notes" : null,
  "history_process" : "mw544v",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "zvrjmgjcqom",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1666134036873,
  "history_end_time" : 1666134036873,
  "history_notes" : null,
  "history_process" : "mw544v",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "jsmyx3mmm2u",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1666134008927,
  "history_end_time" : 1666134008927,
  "history_notes" : null,
  "history_process" : "mw544v",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "ovfmw20d814",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1666131993119,
  "history_end_time" : 1666131993119,
  "history_notes" : null,
  "history_process" : "mw544v",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "wocp9qqbzi9",
  "history_input" : "import pandas as pd\nimport xarray as xr\nfrom datetime import date\nfrom tqdm import tqdm\n\nfrom src_exporters_sentinel_base import BaseSentinelExporter\nfrom src_exporters_geowiki import GeoWikiExporter\nfrom src_exporters_sentinel_utils import EEBoundingBox, bounding_box_from_centre\n\nfrom typing import Optional, List\n\n\nclass GeoWikiSentinelExporter(BaseSentinelExporter):\n\n    dataset = \"earth_engine_geowiki\"\n\n    def load_labels(self) -> pd.DataFrame:\n        # right now, this just loads geowiki data. In the future,\n        # it would be neat to merge all labels together\n        geowiki = self.data_folder / \"processed\" / GeoWikiExporter.dataset / \"data.nc\"\n        assert geowiki.exists(), \"GeoWiki processor must be run to load labels\"\n        return xr.open_dataset(geowiki).to_dataframe().dropna().reset_index()\n\n    def labels_to_bounding_boxes(\n        self, num_labelled_points: Optional[int], surrounding_metres: int\n    ) -> List[EEBoundingBox]:\n\n        output: List[EEBoundingBox] = []\n\n        for idx, row in tqdm(self.labels.iterrows()):\n            output.append(\n                bounding_box_from_centre(\n                    mid_lat=row[\"lat\"], mid_lon=row[\"lon\"], surrounding_metres=surrounding_metres,\n                )\n            )\n\n            if num_labelled_points is not None:\n                if len(output) >= num_labelled_points:\n                    return output\n        return output\n\n    def export_for_labels(\n        self,\n        days_per_timestep: int = 30,\n        start_date: date = date(2017, 3, 28),\n        end_date: date = date(2018, 3, 28),\n        num_labelled_points: Optional[int] = None,\n        surrounding_metres: int = 80,\n        checkpoint: bool = True,\n        monitor: bool = False,\n        fast: bool = True,\n    ) -> None:\n        r\"\"\"\n        Run the GeoWiki exporter. For each label, the exporter will export\n        int( (end_date - start_date).days / days_per_timestep) timesteps of data,\n        where each timestep consists of a mosaic of all available images within the\n        days_per_timestep of that timestep.\n        :param days_per_timestep: The number of days of data to use for each mosaiced image.\n        :param start_date: The start data of the data export\n        :param end_date: The end date of the data export\n        :param num_labelled_points: (Optional) The number of labelled points to export.\n        :param surrounding_metres: The number of metres surrounding each labelled point to export\n        :param checkpoint: Whether or not to check in self.data_folder to see if the file has\n            already been exported. If it has, skip it\n        :param monitor: Whether to monitor each task until it has been run\n        :param fast: Whether to use the faster cloudfree exporter. This function is considerably\n            faster, but cloud artefacts can be more pronounced. Default = True\n        \"\"\"\n        assert start_date >= self.min_date, f\"Sentinel data does not exist before {self.min_date}\"\n\n        bounding_boxes_to_download = self.labels_to_bounding_boxes(\n            num_labelled_points=num_labelled_points, surrounding_metres=surrounding_metres,\n        )\n\n        for idx, bounding_box in enumerate(bounding_boxes_to_download):\n            self._export_for_polygon(\n                polygon=bounding_box.to_ee_polygon(),\n                polygon_identifier=idx,\n                start_date=start_date,\n                end_date=end_date,\n                days_per_timestep=days_per_timestep,\n                checkpoint=checkpoint,\n                monitor=monitor,\n                fast=fast,\n            )\n",
  "history_output" : "",
  "history_begin_time" : 1666118275946,
  "history_end_time" : 1666118282371,
  "history_notes" : null,
  "history_process" : "mw544v",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "08pil51ge54",
  "history_input" : "import pandas as pd\nimport xarray as xr\nfrom datetime import date\nfrom tqdm import tqdm\n\nfrom src_exporters_sentinel_base import BaseSentinelExporter\nfrom src_exporters_geowiki import GeoWikiExporter\nfrom src_exporters_sentinel_utils import EEBoundingBox, bounding_box_from_centre\n\nfrom typing import Optional, List\n\n\nclass GeoWikiSentinelExporter(BaseSentinelExporter):\n\n    dataset = \"earth_engine_geowiki\"\n\n    def load_labels(self) -> pd.DataFrame:\n        # right now, this just loads geowiki data. In the future,\n        # it would be neat to merge all labels together\n        geowiki = self.data_folder / \"processed\" / GeoWikiExporter.dataset / \"data.nc\"\n        assert geowiki.exists(), \"GeoWiki processor must be run to load labels\"\n        return xr.open_dataset(geowiki).to_dataframe().dropna().reset_index()\n\n    def labels_to_bounding_boxes(\n        self, num_labelled_points: Optional[int], surrounding_metres: int\n    ) -> List[EEBoundingBox]:\n\n        output: List[EEBoundingBox] = []\n\n        for idx, row in tqdm(self.labels.iterrows()):\n            output.append(\n                bounding_box_from_centre(\n                    mid_lat=row[\"lat\"], mid_lon=row[\"lon\"], surrounding_metres=surrounding_metres,\n                )\n            )\n\n            if num_labelled_points is not None:\n                if len(output) >= num_labelled_points:\n                    return output\n        return output\n\n    def export_for_labels(\n        self,\n        days_per_timestep: int = 30,\n        start_date: date = date(2017, 3, 28),\n        end_date: date = date(2018, 3, 28),\n        num_labelled_points: Optional[int] = None,\n        surrounding_metres: int = 80,\n        checkpoint: bool = True,\n        monitor: bool = False,\n        fast: bool = True,\n    ) -> None:\n        r\"\"\"\n        Run the GeoWiki exporter. For each label, the exporter will export\n        int( (end_date - start_date).days / days_per_timestep) timesteps of data,\n        where each timestep consists of a mosaic of all available images within the\n        days_per_timestep of that timestep.\n        :param days_per_timestep: The number of days of data to use for each mosaiced image.\n        :param start_date: The start data of the data export\n        :param end_date: The end date of the data export\n        :param num_labelled_points: (Optional) The number of labelled points to export.\n        :param surrounding_metres: The number of metres surrounding each labelled point to export\n        :param checkpoint: Whether or not to check in self.data_folder to see if the file has\n            already been exported. If it has, skip it\n        :param monitor: Whether to monitor each task until it has been run\n        :param fast: Whether to use the faster cloudfree exporter. This function is considerably\n            faster, but cloud artefacts can be more pronounced. Default = True\n        \"\"\"\n        assert start_date >= self.min_date, f\"Sentinel data does not exist before {self.min_date}\"\n\n        bounding_boxes_to_download = self.labels_to_bounding_boxes(\n            num_labelled_points=num_labelled_points, surrounding_metres=surrounding_metres,\n        )\n\n        for idx, bounding_box in enumerate(bounding_boxes_to_download):\n            self._export_for_polygon(\n                polygon=bounding_box.to_ee_polygon(),\n                polygon_identifier=idx,\n                start_date=start_date,\n                end_date=end_date,\n                days_per_timestep=days_per_timestep,\n                checkpoint=checkpoint,\n                monitor=monitor,\n                fast=fast,\n            )\n",
  "history_output" : "",
  "history_begin_time" : 1655909874141,
  "history_end_time" : 1655909877808,
  "history_notes" : null,
  "history_process" : "mw544v",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "97rw6mm0ldv",
  "history_input" : "import pandas as pd\nimport xarray as xr\nfrom datetime import date\nfrom tqdm import tqdm\n\nfrom src_exporters_sentinel_base import BaseSentinelExporter\nfrom src_exporters_geowiki import GeoWikiExporter\nfrom src_exporters_sentinel_utils import EEBoundingBox, bounding_box_from_centre\n\nfrom typing import Optional, List\n\n\nclass GeoWikiSentinelExporter(BaseSentinelExporter):\n\n    dataset = \"earth_engine_geowiki\"\n\n    def load_labels(self) -> pd.DataFrame:\n        # right now, this just loads geowiki data. In the future,\n        # it would be neat to merge all labels together\n        geowiki = self.data_folder / \"processed\" / GeoWikiExporter.dataset / \"data.nc\"\n        assert geowiki.exists(), \"GeoWiki processor must be run to load labels\"\n        return xr.open_dataset(geowiki).to_dataframe().dropna().reset_index()\n\n    def labels_to_bounding_boxes(\n        self, num_labelled_points: Optional[int], surrounding_metres: int\n    ) -> List[EEBoundingBox]:\n\n        output: List[EEBoundingBox] = []\n\n        for idx, row in tqdm(self.labels.iterrows()):\n            output.append(\n                bounding_box_from_centre(\n                    mid_lat=row[\"lat\"], mid_lon=row[\"lon\"], surrounding_metres=surrounding_metres,\n                )\n            )\n\n            if num_labelled_points is not None:\n                if len(output) >= num_labelled_points:\n                    return output\n        return output\n\n    def export_for_labels(\n        self,\n        days_per_timestep: int = 30,\n        start_date: date = date(2017, 3, 28),\n        end_date: date = date(2018, 3, 28),\n        num_labelled_points: Optional[int] = None,\n        surrounding_metres: int = 80,\n        checkpoint: bool = True,\n        monitor: bool = False,\n        fast: bool = True,\n    ) -> None:\n        r\"\"\"\n        Run the GeoWiki exporter. For each label, the exporter will export\n        int( (end_date - start_date).days / days_per_timestep) timesteps of data,\n        where each timestep consists of a mosaic of all available images within the\n        days_per_timestep of that timestep.\n        :param days_per_timestep: The number of days of data to use for each mosaiced image.\n        :param start_date: The start data of the data export\n        :param end_date: The end date of the data export\n        :param num_labelled_points: (Optional) The number of labelled points to export.\n        :param surrounding_metres: The number of metres surrounding each labelled point to export\n        :param checkpoint: Whether or not to check in self.data_folder to see if the file has\n            already been exported. If it has, skip it\n        :param monitor: Whether to monitor each task until it has been run\n        :param fast: Whether to use the faster cloudfree exporter. This function is considerably\n            faster, but cloud artefacts can be more pronounced. Default = True\n        \"\"\"\n        assert start_date >= self.min_date, f\"Sentinel data does not exist before {self.min_date}\"\n\n        bounding_boxes_to_download = self.labels_to_bounding_boxes(\n            num_labelled_points=num_labelled_points, surrounding_metres=surrounding_metres,\n        )\n\n        for idx, bounding_box in enumerate(bounding_boxes_to_download):\n            self._export_for_polygon(\n                polygon=bounding_box.to_ee_polygon(),\n                polygon_identifier=idx,\n                start_date=start_date,\n                end_date=end_date,\n                days_per_timestep=days_per_timestep,\n                checkpoint=checkpoint,\n                monitor=monitor,\n                fast=fast,\n            )\n",
  "history_output" : "",
  "history_begin_time" : 1655908832468,
  "history_end_time" : 1655908835639,
  "history_notes" : null,
  "history_process" : "mw544v",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "abura1j64z8",
  "history_input" : "import pandas as pd\nimport xarray as xr\nfrom datetime import date\nfrom tqdm import tqdm\n\nfrom src_exporters_sentinel_base import BaseSentinelExporter\nfrom src_exporters_geowiki import GeoWikiExporter\nfrom src_exporters_sentinel_utils import EEBoundingBox, bounding_box_from_centre\n\nfrom typing import Optional, List\n\n\nclass GeoWikiSentinelExporter(BaseSentinelExporter):\n\n    dataset = \"earth_engine_geowiki\"\n\n    def load_labels(self) -> pd.DataFrame:\n        # right now, this just loads geowiki data. In the future,\n        # it would be neat to merge all labels together\n        geowiki = self.data_folder / \"processed\" / GeoWikiExporter.dataset / \"data.nc\"\n        assert geowiki.exists(), \"GeoWiki processor must be run to load labels\"\n        return xr.open_dataset(geowiki).to_dataframe().dropna().reset_index()\n\n    def labels_to_bounding_boxes(\n        self, num_labelled_points: Optional[int], surrounding_metres: int\n    ) -> List[EEBoundingBox]:\n\n        output: List[EEBoundingBox] = []\n\n        for idx, row in tqdm(self.labels.iterrows()):\n            output.append(\n                bounding_box_from_centre(\n                    mid_lat=row[\"lat\"], mid_lon=row[\"lon\"], surrounding_metres=surrounding_metres,\n                )\n            )\n\n            if num_labelled_points is not None:\n                if len(output) >= num_labelled_points:\n                    return output\n        return output\n\n    def export_for_labels(\n        self,\n        days_per_timestep: int = 30,\n        start_date: date = date(2017, 3, 28),\n        end_date: date = date(2018, 3, 28),\n        num_labelled_points: Optional[int] = None,\n        surrounding_metres: int = 80,\n        checkpoint: bool = True,\n        monitor: bool = False,\n        fast: bool = True,\n    ) -> None:\n        r\"\"\"\n        Run the GeoWiki exporter. For each label, the exporter will export\n        int( (end_date - start_date).days / days_per_timestep) timesteps of data,\n        where each timestep consists of a mosaic of all available images within the\n        days_per_timestep of that timestep.\n        :param days_per_timestep: The number of days of data to use for each mosaiced image.\n        :param start_date: The start data of the data export\n        :param end_date: The end date of the data export\n        :param num_labelled_points: (Optional) The number of labelled points to export.\n        :param surrounding_metres: The number of metres surrounding each labelled point to export\n        :param checkpoint: Whether or not to check in self.data_folder to see if the file has\n            already been exported. If it has, skip it\n        :param monitor: Whether to monitor each task until it has been run\n        :param fast: Whether to use the faster cloudfree exporter. This function is considerably\n            faster, but cloud artefacts can be more pronounced. Default = True\n        \"\"\"\n        assert start_date >= self.min_date, f\"Sentinel data does not exist before {self.min_date}\"\n\n        bounding_boxes_to_download = self.labels_to_bounding_boxes(\n            num_labelled_points=num_labelled_points, surrounding_metres=surrounding_metres,\n        )\n\n        for idx, bounding_box in enumerate(bounding_boxes_to_download):\n            self._export_for_polygon(\n                polygon=bounding_box.to_ee_polygon(),\n                polygon_identifier=idx,\n                start_date=start_date,\n                end_date=end_date,\n                days_per_timestep=days_per_timestep,\n                checkpoint=checkpoint,\n                monitor=monitor,\n                fast=fast,\n            )\n",
  "history_output" : "",
  "history_begin_time" : 1655907428830,
  "history_end_time" : 1655907432776,
  "history_notes" : null,
  "history_process" : "mw544v",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "47vaaizr7qa",
  "history_input" : "import pandas as pd\nimport xarray as xr\nfrom datetime import date\nfrom tqdm import tqdm\n\nfrom src_exporters_sentinel_base import BaseSentinelExporter\nfrom src_exporters_geowiki import GeoWikiExporter\nfrom src_exporters_sentinel_utils import EEBoundingBox, bounding_box_from_centre\n\nfrom typing import Optional, List\n\n\nclass GeoWikiSentinelExporter(BaseSentinelExporter):\n\n    dataset = \"earth_engine_geowiki\"\n\n    def load_labels(self) -> pd.DataFrame:\n        # right now, this just loads geowiki data. In the future,\n        # it would be neat to merge all labels together\n        geowiki = self.data_folder / \"processed\" / GeoWikiExporter.dataset / \"data.nc\"\n        assert geowiki.exists(), \"GeoWiki processor must be run to load labels\"\n        return xr.open_dataset(geowiki).to_dataframe().dropna().reset_index()\n\n    def labels_to_bounding_boxes(\n        self, num_labelled_points: Optional[int], surrounding_metres: int\n    ) -> List[EEBoundingBox]:\n\n        output: List[EEBoundingBox] = []\n\n        for idx, row in tqdm(self.labels.iterrows()):\n            output.append(\n                bounding_box_from_centre(\n                    mid_lat=row[\"lat\"], mid_lon=row[\"lon\"], surrounding_metres=surrounding_metres,\n                )\n            )\n\n            if num_labelled_points is not None:\n                if len(output) >= num_labelled_points:\n                    return output\n        return output\n\n    def export_for_labels(\n        self,\n        days_per_timestep: int = 30,\n        start_date: date = date(2017, 3, 28),\n        end_date: date = date(2018, 3, 28),\n        num_labelled_points: Optional[int] = None,\n        surrounding_metres: int = 80,\n        checkpoint: bool = True,\n        monitor: bool = False,\n        fast: bool = True,\n    ) -> None:\n        r\"\"\"\n        Run the GeoWiki exporter. For each label, the exporter will export\n        int( (end_date - start_date).days / days_per_timestep) timesteps of data,\n        where each timestep consists of a mosaic of all available images within the\n        days_per_timestep of that timestep.\n        :param days_per_timestep: The number of days of data to use for each mosaiced image.\n        :param start_date: The start data of the data export\n        :param end_date: The end date of the data export\n        :param num_labelled_points: (Optional) The number of labelled points to export.\n        :param surrounding_metres: The number of metres surrounding each labelled point to export\n        :param checkpoint: Whether or not to check in self.data_folder to see if the file has\n            already been exported. If it has, skip it\n        :param monitor: Whether to monitor each task until it has been run\n        :param fast: Whether to use the faster cloudfree exporter. This function is considerably\n            faster, but cloud artefacts can be more pronounced. Default = True\n        \"\"\"\n        assert start_date >= self.min_date, f\"Sentinel data does not exist before {self.min_date}\"\n\n        bounding_boxes_to_download = self.labels_to_bounding_boxes(\n            num_labelled_points=num_labelled_points, surrounding_metres=surrounding_metres,\n        )\n\n        for idx, bounding_box in enumerate(bounding_boxes_to_download):\n            self._export_for_polygon(\n                polygon=bounding_box.to_ee_polygon(),\n                polygon_identifier=idx,\n                start_date=start_date,\n                end_date=end_date,\n                days_per_timestep=days_per_timestep,\n                checkpoint=checkpoint,\n                monitor=monitor,\n                fast=fast,\n            )\n",
  "history_output" : "Traceback (most recent call last):\n  File \"src_exporters_sentinel_geowiki.py\", line 1, in <module>\n    import pandas as pd\nModuleNotFoundError: No module named 'pandas'\n",
  "history_begin_time" : 1655907396276,
  "history_end_time" : 1655907403071,
  "history_notes" : null,
  "history_process" : "mw544v",
  "host_id" : "100001",
  "indicator" : "Stopped"
},{
  "history_id" : "zbvwi57pfre",
  "history_input" : "import pandas as pd\nimport xarray as xr\nfrom datetime import date\nfrom tqdm import tqdm\n\nfrom src_exporters_sentinel_base import BaseSentinelExporter\nfrom src_exporters_geowiki import GeoWikiExporter\nfrom src_exporters_sentinel_utils import EEBoundingBox, bounding_box_from_centre\n\nfrom typing import Optional, List\n\n\nclass GeoWikiSentinelExporter(BaseSentinelExporter):\n\n    dataset = \"earth_engine_geowiki\"\n\n    def load_labels(self) -> pd.DataFrame:\n        # right now, this just loads geowiki data. In the future,\n        # it would be neat to merge all labels together\n        geowiki = self.data_folder / \"processed\" / GeoWikiExporter.dataset / \"data.nc\"\n        assert geowiki.exists(), \"GeoWiki processor must be run to load labels\"\n        return xr.open_dataset(geowiki).to_dataframe().dropna().reset_index()\n\n    def labels_to_bounding_boxes(\n        self, num_labelled_points: Optional[int], surrounding_metres: int\n    ) -> List[EEBoundingBox]:\n\n        output: List[EEBoundingBox] = []\n\n        for idx, row in tqdm(self.labels.iterrows()):\n            output.append(\n                bounding_box_from_centre(\n                    mid_lat=row[\"lat\"], mid_lon=row[\"lon\"], surrounding_metres=surrounding_metres,\n                )\n            )\n\n            if num_labelled_points is not None:\n                if len(output) >= num_labelled_points:\n                    return output\n        return output\n\n    def export_for_labels(\n        self,\n        days_per_timestep: int = 30,\n        start_date: date = date(2017, 3, 28),\n        end_date: date = date(2018, 3, 28),\n        num_labelled_points: Optional[int] = None,\n        surrounding_metres: int = 80,\n        checkpoint: bool = True,\n        monitor: bool = False,\n        fast: bool = True,\n    ) -> None:\n        r\"\"\"\n        Run the GeoWiki exporter. For each label, the exporter will export\n        int( (end_date - start_date).days / days_per_timestep) timesteps of data,\n        where each timestep consists of a mosaic of all available images within the\n        days_per_timestep of that timestep.\n        :param days_per_timestep: The number of days of data to use for each mosaiced image.\n        :param start_date: The start data of the data export\n        :param end_date: The end date of the data export\n        :param num_labelled_points: (Optional) The number of labelled points to export.\n        :param surrounding_metres: The number of metres surrounding each labelled point to export\n        :param checkpoint: Whether or not to check in self.data_folder to see if the file has\n            already been exported. If it has, skip it\n        :param monitor: Whether to monitor each task until it has been run\n        :param fast: Whether to use the faster cloudfree exporter. This function is considerably\n            faster, but cloud artefacts can be more pronounced. Default = True\n        \"\"\"\n        assert start_date >= self.min_date, f\"Sentinel data does not exist before {self.min_date}\"\n\n        bounding_boxes_to_download = self.labels_to_bounding_boxes(\n            num_labelled_points=num_labelled_points, surrounding_metres=surrounding_metres,\n        )\n\n        for idx, bounding_box in enumerate(bounding_boxes_to_download):\n            self._export_for_polygon(\n                polygon=bounding_box.to_ee_polygon(),\n                polygon_identifier=idx,\n                start_date=start_date,\n                end_date=end_date,\n                days_per_timestep=days_per_timestep,\n                checkpoint=checkpoint,\n                monitor=monitor,\n                fast=fast,\n            )\n",
  "history_output" : "Traceback (most recent call last):\n  File \"src_exporters_sentinel_geowiki.py\", line 1, in <module>\n    import pandas as pd\nModuleNotFoundError: No module named 'pandas'\n",
  "history_begin_time" : 1655865871852,
  "history_end_time" : 1655865871970,
  "history_notes" : null,
  "history_process" : "mw544v",
  "host_id" : "100001",
  "indicator" : "Failed"
},{
  "history_id" : "orfzzzmbogk",
  "history_input" : "import pandas as pd\nimport xarray as xr\nfrom datetime import date\nfrom tqdm import tqdm\n\nfrom src_exporters_sentinel_base import BaseSentinelExporter\nfrom src_exporters_geowiki import GeoWikiExporter\nfrom src_exporters_sentinel_utils import EEBoundingBox, bounding_box_from_centre\n\nfrom typing import Optional, List\n\n\nclass GeoWikiSentinelExporter(BaseSentinelExporter):\n\n    dataset = \"earth_engine_geowiki\"\n\n    def load_labels(self) -> pd.DataFrame:\n        # right now, this just loads geowiki data. In the future,\n        # it would be neat to merge all labels together\n        geowiki = self.data_folder / \"processed\" / GeoWikiExporter.dataset / \"data.nc\"\n        assert geowiki.exists(), \"GeoWiki processor must be run to load labels\"\n        return xr.open_dataset(geowiki).to_dataframe().dropna().reset_index()\n\n    def labels_to_bounding_boxes(\n        self, num_labelled_points: Optional[int], surrounding_metres: int\n    ) -> List[EEBoundingBox]:\n\n        output: List[EEBoundingBox] = []\n\n        for idx, row in tqdm(self.labels.iterrows()):\n            output.append(\n                bounding_box_from_centre(\n                    mid_lat=row[\"lat\"], mid_lon=row[\"lon\"], surrounding_metres=surrounding_metres,\n                )\n            )\n\n            if num_labelled_points is not None:\n                if len(output) >= num_labelled_points:\n                    return output\n        return output\n\n    def export_for_labels(\n        self,\n        days_per_timestep: int = 30,\n        start_date: date = date(2017, 3, 28),\n        end_date: date = date(2018, 3, 28),\n        num_labelled_points: Optional[int] = None,\n        surrounding_metres: int = 80,\n        checkpoint: bool = True,\n        monitor: bool = False,\n        fast: bool = True,\n    ) -> None:\n        r\"\"\"\n        Run the GeoWiki exporter. For each label, the exporter will export\n        int( (end_date - start_date).days / days_per_timestep) timesteps of data,\n        where each timestep consists of a mosaic of all available images within the\n        days_per_timestep of that timestep.\n        :param days_per_timestep: The number of days of data to use for each mosaiced image.\n        :param start_date: The start data of the data export\n        :param end_date: The end date of the data export\n        :param num_labelled_points: (Optional) The number of labelled points to export.\n        :param surrounding_metres: The number of metres surrounding each labelled point to export\n        :param checkpoint: Whether or not to check in self.data_folder to see if the file has\n            already been exported. If it has, skip it\n        :param monitor: Whether to monitor each task until it has been run\n        :param fast: Whether to use the faster cloudfree exporter. This function is considerably\n            faster, but cloud artefacts can be more pronounced. Default = True\n        \"\"\"\n        assert start_date >= self.min_date, f\"Sentinel data does not exist before {self.min_date}\"\n\n        bounding_boxes_to_download = self.labels_to_bounding_boxes(\n            num_labelled_points=num_labelled_points, surrounding_metres=surrounding_metres,\n        )\n\n        for idx, bounding_box in enumerate(bounding_boxes_to_download):\n            self._export_for_polygon(\n                polygon=bounding_box.to_ee_polygon(),\n                polygon_identifier=idx,\n                start_date=start_date,\n                end_date=end_date,\n                days_per_timestep=days_per_timestep,\n                checkpoint=checkpoint,\n                monitor=monitor,\n                fast=fast,\n            )\n",
  "history_output" : "",
  "history_begin_time" : 1655865082105,
  "history_end_time" : 1655865086023,
  "history_notes" : null,
  "history_process" : "mw544v",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "ccmzzfafjpf",
  "history_input" : "import pandas as pd\nimport xarray as xr\nfrom datetime import date\nfrom tqdm import tqdm\n\nfrom src_exporters_sentinel_base import BaseSentinelExporter\nfrom src_exporters_geowiki import GeoWikiExporter\nfrom src_exporters_sentinel_utils import EEBoundingBox, bounding_box_from_centre\n\nfrom typing import Optional, List\n\n\nclass GeoWikiSentinelExporter(BaseSentinelExporter):\n\n    dataset = \"earth_engine_geowiki\"\n\n    def load_labels(self) -> pd.DataFrame:\n        # right now, this just loads geowiki data. In the future,\n        # it would be neat to merge all labels together\n        geowiki = self.data_folder / \"processed\" / GeoWikiExporter.dataset / \"data.nc\"\n        assert geowiki.exists(), \"GeoWiki processor must be run to load labels\"\n        return xr.open_dataset(geowiki).to_dataframe().dropna().reset_index()\n\n    def labels_to_bounding_boxes(\n        self, num_labelled_points: Optional[int], surrounding_metres: int\n    ) -> List[EEBoundingBox]:\n\n        output: List[EEBoundingBox] = []\n\n        for idx, row in tqdm(self.labels.iterrows()):\n            output.append(\n                bounding_box_from_centre(\n                    mid_lat=row[\"lat\"], mid_lon=row[\"lon\"], surrounding_metres=surrounding_metres,\n                )\n            )\n\n            if num_labelled_points is not None:\n                if len(output) >= num_labelled_points:\n                    return output\n        return output\n\n    def export_for_labels(\n        self,\n        days_per_timestep: int = 30,\n        start_date: date = date(2017, 3, 28),\n        end_date: date = date(2018, 3, 28),\n        num_labelled_points: Optional[int] = None,\n        surrounding_metres: int = 80,\n        checkpoint: bool = True,\n        monitor: bool = False,\n        fast: bool = True,\n    ) -> None:\n        r\"\"\"\n        Run the GeoWiki exporter. For each label, the exporter will export\n        int( (end_date - start_date).days / days_per_timestep) timesteps of data,\n        where each timestep consists of a mosaic of all available images within the\n        days_per_timestep of that timestep.\n        :param days_per_timestep: The number of days of data to use for each mosaiced image.\n        :param start_date: The start data of the data export\n        :param end_date: The end date of the data export\n        :param num_labelled_points: (Optional) The number of labelled points to export.\n        :param surrounding_metres: The number of metres surrounding each labelled point to export\n        :param checkpoint: Whether or not to check in self.data_folder to see if the file has\n            already been exported. If it has, skip it\n        :param monitor: Whether to monitor each task until it has been run\n        :param fast: Whether to use the faster cloudfree exporter. This function is considerably\n            faster, but cloud artefacts can be more pronounced. Default = True\n        \"\"\"\n        assert start_date >= self.min_date, f\"Sentinel data does not exist before {self.min_date}\"\n\n        bounding_boxes_to_download = self.labels_to_bounding_boxes(\n            num_labelled_points=num_labelled_points, surrounding_metres=surrounding_metres,\n        )\n\n        for idx, bounding_box in enumerate(bounding_boxes_to_download):\n            self._export_for_polygon(\n                polygon=bounding_box.to_ee_polygon(),\n                polygon_identifier=idx,\n                start_date=start_date,\n                end_date=end_date,\n                days_per_timestep=days_per_timestep,\n                checkpoint=checkpoint,\n                monitor=monitor,\n                fast=fast,\n            )\n",
  "history_output" : "",
  "history_begin_time" : 1647347431982,
  "history_end_time" : 1647347432600,
  "history_notes" : null,
  "history_process" : "mw544v",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "81v4koxebff",
  "history_input" : "import pandas as pd\nimport xarray as xr\nfrom datetime import date\nfrom tqdm import tqdm\n\nfrom src_exporters_sentinel_base import BaseSentinelExporter\nfrom src_exporters_geowiki import GeoWikiExporter\nfrom src_exporters_sentinel_utils import EEBoundingBox, bounding_box_from_centre\n\nfrom typing import Optional, List\n\n\nclass GeoWikiSentinelExporter(BaseSentinelExporter):\n\n    dataset = \"earth_engine_geowiki\"\n\n    def load_labels(self) -> pd.DataFrame:\n        # right now, this just loads geowiki data. In the future,\n        # it would be neat to merge all labels together\n        geowiki = self.data_folder / \"processed\" / GeoWikiExporter.dataset / \"data.nc\"\n        assert geowiki.exists(), \"GeoWiki processor must be run to load labels\"\n        return xr.open_dataset(geowiki).to_dataframe().dropna().reset_index()\n\n    def labels_to_bounding_boxes(\n        self, num_labelled_points: Optional[int], surrounding_metres: int\n    ) -> List[EEBoundingBox]:\n\n        output: List[EEBoundingBox] = []\n\n        for idx, row in tqdm(self.labels.iterrows()):\n            output.append(\n                bounding_box_from_centre(\n                    mid_lat=row[\"lat\"], mid_lon=row[\"lon\"], surrounding_metres=surrounding_metres,\n                )\n            )\n\n            if num_labelled_points is not None:\n                if len(output) >= num_labelled_points:\n                    return output\n        return output\n\n    def export_for_labels(\n        self,\n        days_per_timestep: int = 30,\n        start_date: date = date(2017, 3, 28),\n        end_date: date = date(2018, 3, 28),\n        num_labelled_points: Optional[int] = None,\n        surrounding_metres: int = 80,\n        checkpoint: bool = True,\n        monitor: bool = False,\n        fast: bool = True,\n    ) -> None:\n        r\"\"\"\n        Run the GeoWiki exporter. For each label, the exporter will export\n        int( (end_date - start_date).days / days_per_timestep) timesteps of data,\n        where each timestep consists of a mosaic of all available images within the\n        days_per_timestep of that timestep.\n        :param days_per_timestep: The number of days of data to use for each mosaiced image.\n        :param start_date: The start data of the data export\n        :param end_date: The end date of the data export\n        :param num_labelled_points: (Optional) The number of labelled points to export.\n        :param surrounding_metres: The number of metres surrounding each labelled point to export\n        :param checkpoint: Whether or not to check in self.data_folder to see if the file has\n            already been exported. If it has, skip it\n        :param monitor: Whether to monitor each task until it has been run\n        :param fast: Whether to use the faster cloudfree exporter. This function is considerably\n            faster, but cloud artefacts can be more pronounced. Default = True\n        \"\"\"\n        assert start_date >= self.min_date, f\"Sentinel data does not exist before {self.min_date}\"\n\n        bounding_boxes_to_download = self.labels_to_bounding_boxes(\n            num_labelled_points=num_labelled_points, surrounding_metres=surrounding_metres,\n        )\n\n        for idx, bounding_box in enumerate(bounding_boxes_to_download):\n            self._export_for_polygon(\n                polygon=bounding_box.to_ee_polygon(),\n                polygon_identifier=idx,\n                start_date=start_date,\n                end_date=end_date,\n                days_per_timestep=days_per_timestep,\n                checkpoint=checkpoint,\n                monitor=monitor,\n                fast=fast,\n            )\n",
  "history_output" : "",
  "history_begin_time" : 1647347337310,
  "history_end_time" : 1647347338007,
  "history_notes" : null,
  "history_process" : "mw544v",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "7e9r9gar55m",
  "history_input" : "import pandas as pd\nimport xarray as xr\nfrom datetime import date\nfrom tqdm import tqdm\n\nfrom src_exporters_sentinel_base import BaseSentinelExporter\nfrom src_exporters_geowiki import GeoWikiExporter\nfrom src_exporters_sentinel_utils import EEBoundingBox, bounding_box_from_centre\n\nfrom typing import Optional, List\n\n\nclass GeoWikiSentinelExporter(BaseSentinelExporter):\n\n    dataset = \"earth_engine_geowiki\"\n\n    def load_labels(self) -> pd.DataFrame:\n        # right now, this just loads geowiki data. In the future,\n        # it would be neat to merge all labels together\n        geowiki = self.data_folder / \"processed\" / GeoWikiExporter.dataset / \"data.nc\"\n        assert geowiki.exists(), \"GeoWiki processor must be run to load labels\"\n        return xr.open_dataset(geowiki).to_dataframe().dropna().reset_index()\n\n    def labels_to_bounding_boxes(\n        self, num_labelled_points: Optional[int], surrounding_metres: int\n    ) -> List[EEBoundingBox]:\n\n        output: List[EEBoundingBox] = []\n\n        for idx, row in tqdm(self.labels.iterrows()):\n            output.append(\n                bounding_box_from_centre(\n                    mid_lat=row[\"lat\"], mid_lon=row[\"lon\"], surrounding_metres=surrounding_metres,\n                )\n            )\n\n            if num_labelled_points is not None:\n                if len(output) >= num_labelled_points:\n                    return output\n        return output\n\n    def export_for_labels(\n        self,\n        days_per_timestep: int = 30,\n        start_date: date = date(2017, 3, 28),\n        end_date: date = date(2018, 3, 28),\n        num_labelled_points: Optional[int] = None,\n        surrounding_metres: int = 80,\n        checkpoint: bool = True,\n        monitor: bool = False,\n        fast: bool = True,\n    ) -> None:\n        r\"\"\"\n        Run the GeoWiki exporter. For each label, the exporter will export\n        int( (end_date - start_date).days / days_per_timestep) timesteps of data,\n        where each timestep consists of a mosaic of all available images within the\n        days_per_timestep of that timestep.\n        :param days_per_timestep: The number of days of data to use for each mosaiced image.\n        :param start_date: The start data of the data export\n        :param end_date: The end date of the data export\n        :param num_labelled_points: (Optional) The number of labelled points to export.\n        :param surrounding_metres: The number of metres surrounding each labelled point to export\n        :param checkpoint: Whether or not to check in self.data_folder to see if the file has\n            already been exported. If it has, skip it\n        :param monitor: Whether to monitor each task until it has been run\n        :param fast: Whether to use the faster cloudfree exporter. This function is considerably\n            faster, but cloud artefacts can be more pronounced. Default = True\n        \"\"\"\n        assert start_date >= self.min_date, f\"Sentinel data does not exist before {self.min_date}\"\n\n        bounding_boxes_to_download = self.labels_to_bounding_boxes(\n            num_labelled_points=num_labelled_points, surrounding_metres=surrounding_metres,\n        )\n\n        for idx, bounding_box in enumerate(bounding_boxes_to_download):\n            self._export_for_polygon(\n                polygon=bounding_box.to_ee_polygon(),\n                polygon_identifier=idx,\n                start_date=start_date,\n                end_date=end_date,\n                days_per_timestep=days_per_timestep,\n                checkpoint=checkpoint,\n                monitor=monitor,\n                fast=fast,\n            )\n",
  "history_output" : "",
  "history_begin_time" : 1647347270986,
  "history_end_time" : 1647347271559,
  "history_notes" : null,
  "history_process" : "mw544v",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "a70tjdhiq8e",
  "history_input" : "import pandas as pd\nimport xarray as xr\nfrom datetime import date\nfrom tqdm import tqdm\n\nfrom src_exporters_sentinel_base import BaseSentinelExporter\nfrom src_exporters_geowiki import GeoWikiExporter\nfrom src_exporters_sentinel_utils import EEBoundingBox, bounding_box_from_centre\n\nfrom typing import Optional, List\n\n\nclass GeoWikiSentinelExporter(BaseSentinelExporter):\n\n    dataset = \"earth_engine_geowiki\"\n\n    def load_labels(self) -> pd.DataFrame:\n        # right now, this just loads geowiki data. In the future,\n        # it would be neat to merge all labels together\n        geowiki = self.data_folder / \"processed\" / GeoWikiExporter.dataset / \"data.nc\"\n        assert geowiki.exists(), \"GeoWiki processor must be run to load labels\"\n        return xr.open_dataset(geowiki).to_dataframe().dropna().reset_index()\n\n    def labels_to_bounding_boxes(\n        self, num_labelled_points: Optional[int], surrounding_metres: int\n    ) -> List[EEBoundingBox]:\n\n        output: List[EEBoundingBox] = []\n\n        for idx, row in tqdm(self.labels.iterrows()):\n            output.append(\n                bounding_box_from_centre(\n                    mid_lat=row[\"lat\"], mid_lon=row[\"lon\"], surrounding_metres=surrounding_metres,\n                )\n            )\n\n            if num_labelled_points is not None:\n                if len(output) >= num_labelled_points:\n                    return output\n        return output\n\n    def export_for_labels(\n        self,\n        days_per_timestep: int = 30,\n        start_date: date = date(2017, 3, 28),\n        end_date: date = date(2018, 3, 28),\n        num_labelled_points: Optional[int] = None,\n        surrounding_metres: int = 80,\n        checkpoint: bool = True,\n        monitor: bool = False,\n        fast: bool = True,\n    ) -> None:\n        r\"\"\"\n        Run the GeoWiki exporter. For each label, the exporter will export\n        int( (end_date - start_date).days / days_per_timestep) timesteps of data,\n        where each timestep consists of a mosaic of all available images within the\n        days_per_timestep of that timestep.\n        :param days_per_timestep: The number of days of data to use for each mosaiced image.\n        :param start_date: The start data of the data export\n        :param end_date: The end date of the data export\n        :param num_labelled_points: (Optional) The number of labelled points to export.\n        :param surrounding_metres: The number of metres surrounding each labelled point to export\n        :param checkpoint: Whether or not to check in self.data_folder to see if the file has\n            already been exported. If it has, skip it\n        :param monitor: Whether to monitor each task until it has been run\n        :param fast: Whether to use the faster cloudfree exporter. This function is considerably\n            faster, but cloud artefacts can be more pronounced. Default = True\n        \"\"\"\n        assert start_date >= self.min_date, f\"Sentinel data does not exist before {self.min_date}\"\n\n        bounding_boxes_to_download = self.labels_to_bounding_boxes(\n            num_labelled_points=num_labelled_points, surrounding_metres=surrounding_metres,\n        )\n\n        for idx, bounding_box in enumerate(bounding_boxes_to_download):\n            self._export_for_polygon(\n                polygon=bounding_box.to_ee_polygon(),\n                polygon_identifier=idx,\n                start_date=start_date,\n                end_date=end_date,\n                days_per_timestep=days_per_timestep,\n                checkpoint=checkpoint,\n                monitor=monitor,\n                fast=fast,\n            )\n",
  "history_output" : "",
  "history_begin_time" : 1647347137581,
  "history_end_time" : 1647347138236,
  "history_notes" : null,
  "history_process" : "mw544v",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "a3y5wh2on80",
  "history_input" : "import pandas as pd\nimport xarray as xr\nfrom datetime import date\nfrom tqdm import tqdm\n\nfrom src_exporters_sentinel_base import BaseSentinelExporter\nfrom src_exporters_geowiki import GeoWikiExporter\nfrom src_exporters_sentinel_utils import EEBoundingBox, bounding_box_from_centre\n\nfrom typing import Optional, List\n\n\nclass GeoWikiSentinelExporter(BaseSentinelExporter):\n\n    dataset = \"earth_engine_geowiki\"\n\n    def load_labels(self) -> pd.DataFrame:\n        # right now, this just loads geowiki data. In the future,\n        # it would be neat to merge all labels together\n        geowiki = self.data_folder / \"processed\" / GeoWikiExporter.dataset / \"data.nc\"\n        assert geowiki.exists(), \"GeoWiki processor must be run to load labels\"\n        return xr.open_dataset(geowiki).to_dataframe().dropna().reset_index()\n\n    def labels_to_bounding_boxes(\n        self, num_labelled_points: Optional[int], surrounding_metres: int\n    ) -> List[EEBoundingBox]:\n\n        output: List[EEBoundingBox] = []\n\n        for idx, row in tqdm(self.labels.iterrows()):\n            output.append(\n                bounding_box_from_centre(\n                    mid_lat=row[\"lat\"], mid_lon=row[\"lon\"], surrounding_metres=surrounding_metres,\n                )\n            )\n\n            if num_labelled_points is not None:\n                if len(output) >= num_labelled_points:\n                    return output\n        return output\n\n    def export_for_labels(\n        self,\n        days_per_timestep: int = 30,\n        start_date: date = date(2017, 3, 28),\n        end_date: date = date(2018, 3, 28),\n        num_labelled_points: Optional[int] = None,\n        surrounding_metres: int = 80,\n        checkpoint: bool = True,\n        monitor: bool = False,\n        fast: bool = True,\n    ) -> None:\n        r\"\"\"\n        Run the GeoWiki exporter. For each label, the exporter will export\n        int( (end_date - start_date).days / days_per_timestep) timesteps of data,\n        where each timestep consists of a mosaic of all available images within the\n        days_per_timestep of that timestep.\n        :param days_per_timestep: The number of days of data to use for each mosaiced image.\n        :param start_date: The start data of the data export\n        :param end_date: The end date of the data export\n        :param num_labelled_points: (Optional) The number of labelled points to export.\n        :param surrounding_metres: The number of metres surrounding each labelled point to export\n        :param checkpoint: Whether or not to check in self.data_folder to see if the file has\n            already been exported. If it has, skip it\n        :param monitor: Whether to monitor each task until it has been run\n        :param fast: Whether to use the faster cloudfree exporter. This function is considerably\n            faster, but cloud artefacts can be more pronounced. Default = True\n        \"\"\"\n        assert start_date >= self.min_date, f\"Sentinel data does not exist before {self.min_date}\"\n\n        bounding_boxes_to_download = self.labels_to_bounding_boxes(\n            num_labelled_points=num_labelled_points, surrounding_metres=surrounding_metres,\n        )\n\n        for idx, bounding_box in enumerate(bounding_boxes_to_download):\n            self._export_for_polygon(\n                polygon=bounding_box.to_ee_polygon(),\n                polygon_identifier=idx,\n                start_date=start_date,\n                end_date=end_date,\n                days_per_timestep=days_per_timestep,\n                checkpoint=checkpoint,\n                monitor=monitor,\n                fast=fast,\n            )\n",
  "history_output" : "",
  "history_begin_time" : 1647346812666,
  "history_end_time" : 1647346815683,
  "history_notes" : null,
  "history_process" : "mw544v",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "gvaun02f4pr",
  "history_input" : "import pandas as pd\nimport xarray as xr\nfrom datetime import date\nfrom tqdm import tqdm\n\nfrom src_exporters_sentinel_base import BaseSentinelExporter\nfrom src_exporters_geowiki import GeoWikiExporter\nfrom src_exporters_sentinel_utils import EEBoundingBox, bounding_box_from_centre\n\nfrom typing import Optional, List\n\n\nclass GeoWikiSentinelExporter(BaseSentinelExporter):\n\n    dataset = \"earth_engine_geowiki\"\n\n    def load_labels(self) -> pd.DataFrame:\n        # right now, this just loads geowiki data. In the future,\n        # it would be neat to merge all labels together\n        geowiki = self.data_folder / \"processed\" / GeoWikiExporter.dataset / \"data.nc\"\n        assert geowiki.exists(), \"GeoWiki processor must be run to load labels\"\n        return xr.open_dataset(geowiki).to_dataframe().dropna().reset_index()\n\n    def labels_to_bounding_boxes(\n        self, num_labelled_points: Optional[int], surrounding_metres: int\n    ) -> List[EEBoundingBox]:\n\n        output: List[EEBoundingBox] = []\n\n        for idx, row in tqdm(self.labels.iterrows()):\n            output.append(\n                bounding_box_from_centre(\n                    mid_lat=row[\"lat\"], mid_lon=row[\"lon\"], surrounding_metres=surrounding_metres,\n                )\n            )\n\n            if num_labelled_points is not None:\n                if len(output) >= num_labelled_points:\n                    return output\n        return output\n\n    def export_for_labels(\n        self,\n        days_per_timestep: int = 30,\n        start_date: date = date(2017, 3, 28),\n        end_date: date = date(2018, 3, 28),\n        num_labelled_points: Optional[int] = None,\n        surrounding_metres: int = 80,\n        checkpoint: bool = True,\n        monitor: bool = False,\n        fast: bool = True,\n    ) -> None:\n        r\"\"\"\n        Run the GeoWiki exporter. For each label, the exporter will export\n        int( (end_date - start_date).days / days_per_timestep) timesteps of data,\n        where each timestep consists of a mosaic of all available images within the\n        days_per_timestep of that timestep.\n        :param days_per_timestep: The number of days of data to use for each mosaiced image.\n        :param start_date: The start data of the data export\n        :param end_date: The end date of the data export\n        :param num_labelled_points: (Optional) The number of labelled points to export.\n        :param surrounding_metres: The number of metres surrounding each labelled point to export\n        :param checkpoint: Whether or not to check in self.data_folder to see if the file has\n            already been exported. If it has, skip it\n        :param monitor: Whether to monitor each task until it has been run\n        :param fast: Whether to use the faster cloudfree exporter. This function is considerably\n            faster, but cloud artefacts can be more pronounced. Default = True\n        \"\"\"\n        assert start_date >= self.min_date, f\"Sentinel data does not exist before {self.min_date}\"\n\n        bounding_boxes_to_download = self.labels_to_bounding_boxes(\n            num_labelled_points=num_labelled_points, surrounding_metres=surrounding_metres,\n        )\n\n        for idx, bounding_box in enumerate(bounding_boxes_to_download):\n            self._export_for_polygon(\n                polygon=bounding_box.to_ee_polygon(),\n                polygon_identifier=idx,\n                start_date=start_date,\n                end_date=end_date,\n                days_per_timestep=days_per_timestep,\n                checkpoint=checkpoint,\n                monitor=monitor,\n                fast=fast,\n            )\n",
  "history_output" : "",
  "history_begin_time" : 1647346645910,
  "history_end_time" : 1647346649200,
  "history_notes" : null,
  "history_process" : "mw544v",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "l9javvbuve8",
  "history_input" : "import pandas as pd\nimport xarray as xr\nfrom datetime import date\nfrom tqdm import tqdm\n\nfrom src_exporters_sentinel_base import BaseSentinelExporter\nfrom src_exporters_geowiki import GeoWikiExporter\nfrom src_exporters_sentinel_utils import EEBoundingBox, bounding_box_from_centre\n\nfrom typing import Optional, List\n\n\nclass GeoWikiSentinelExporter(BaseSentinelExporter):\n\n    dataset = \"earth_engine_geowiki\"\n\n    def load_labels(self) -> pd.DataFrame:\n        # right now, this just loads geowiki data. In the future,\n        # it would be neat to merge all labels together\n        geowiki = self.data_folder / \"processed\" / GeoWikiExporter.dataset / \"data.nc\"\n        assert geowiki.exists(), \"GeoWiki processor must be run to load labels\"\n        return xr.open_dataset(geowiki).to_dataframe().dropna().reset_index()\n\n    def labels_to_bounding_boxes(\n        self, num_labelled_points: Optional[int], surrounding_metres: int\n    ) -> List[EEBoundingBox]:\n\n        output: List[EEBoundingBox] = []\n\n        for idx, row in tqdm(self.labels.iterrows()):\n            output.append(\n                bounding_box_from_centre(\n                    mid_lat=row[\"lat\"], mid_lon=row[\"lon\"], surrounding_metres=surrounding_metres,\n                )\n            )\n\n            if num_labelled_points is not None:\n                if len(output) >= num_labelled_points:\n                    return output\n        return output\n\n    def export_for_labels(\n        self,\n        days_per_timestep: int = 30,\n        start_date: date = date(2017, 3, 28),\n        end_date: date = date(2018, 3, 28),\n        num_labelled_points: Optional[int] = None,\n        surrounding_metres: int = 80,\n        checkpoint: bool = True,\n        monitor: bool = False,\n        fast: bool = True,\n    ) -> None:\n        r\"\"\"\n        Run the GeoWiki exporter. For each label, the exporter will export\n        int( (end_date - start_date).days / days_per_timestep) timesteps of data,\n        where each timestep consists of a mosaic of all available images within the\n        days_per_timestep of that timestep.\n        :param days_per_timestep: The number of days of data to use for each mosaiced image.\n        :param start_date: The start data of the data export\n        :param end_date: The end date of the data export\n        :param num_labelled_points: (Optional) The number of labelled points to export.\n        :param surrounding_metres: The number of metres surrounding each labelled point to export\n        :param checkpoint: Whether or not to check in self.data_folder to see if the file has\n            already been exported. If it has, skip it\n        :param monitor: Whether to monitor each task until it has been run\n        :param fast: Whether to use the faster cloudfree exporter. This function is considerably\n            faster, but cloud artefacts can be more pronounced. Default = True\n        \"\"\"\n        assert start_date >= self.min_date, f\"Sentinel data does not exist before {self.min_date}\"\n\n        bounding_boxes_to_download = self.labels_to_bounding_boxes(\n            num_labelled_points=num_labelled_points, surrounding_metres=surrounding_metres,\n        )\n\n        for idx, bounding_box in enumerate(bounding_boxes_to_download):\n            self._export_for_polygon(\n                polygon=bounding_box.to_ee_polygon(),\n                polygon_identifier=idx,\n                start_date=start_date,\n                end_date=end_date,\n                days_per_timestep=days_per_timestep,\n                checkpoint=checkpoint,\n                monitor=monitor,\n                fast=fast,\n            )\n",
  "history_output" : "",
  "history_begin_time" : 1647345841513,
  "history_end_time" : 1647345844949,
  "history_notes" : null,
  "history_process" : "mw544v",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "sadsq0mvcra",
  "history_input" : "import pandas as pd\nimport xarray as xr\nfrom datetime import date\nfrom tqdm import tqdm\n\nfrom src_exporters_sentinel_base import BaseSentinelExporter\nfrom src_exporters_geowiki import GeoWikiExporter\nfrom src_exporters_sentinel_utils import EEBoundingBox, bounding_box_from_centre\n\nfrom typing import Optional, List\n\n\nclass GeoWikiSentinelExporter(BaseSentinelExporter):\n\n    dataset = \"earth_engine_geowiki\"\n\n    def load_labels(self) -> pd.DataFrame:\n        # right now, this just loads geowiki data. In the future,\n        # it would be neat to merge all labels together\n        geowiki = self.data_folder / \"processed\" / GeoWikiExporter.dataset / \"data.nc\"\n        assert geowiki.exists(), \"GeoWiki processor must be run to load labels\"\n        return xr.open_dataset(geowiki).to_dataframe().dropna().reset_index()\n\n    def labels_to_bounding_boxes(\n        self, num_labelled_points: Optional[int], surrounding_metres: int\n    ) -> List[EEBoundingBox]:\n\n        output: List[EEBoundingBox] = []\n\n        for idx, row in tqdm(self.labels.iterrows()):\n            output.append(\n                bounding_box_from_centre(\n                    mid_lat=row[\"lat\"], mid_lon=row[\"lon\"], surrounding_metres=surrounding_metres,\n                )\n            )\n\n            if num_labelled_points is not None:\n                if len(output) >= num_labelled_points:\n                    return output\n        return output\n\n    def export_for_labels(\n        self,\n        days_per_timestep: int = 30,\n        start_date: date = date(2017, 3, 28),\n        end_date: date = date(2018, 3, 28),\n        num_labelled_points: Optional[int] = None,\n        surrounding_metres: int = 80,\n        checkpoint: bool = True,\n        monitor: bool = False,\n        fast: bool = True,\n    ) -> None:\n        r\"\"\"\n        Run the GeoWiki exporter. For each label, the exporter will export\n        int( (end_date - start_date).days / days_per_timestep) timesteps of data,\n        where each timestep consists of a mosaic of all available images within the\n        days_per_timestep of that timestep.\n        :param days_per_timestep: The number of days of data to use for each mosaiced image.\n        :param start_date: The start data of the data export\n        :param end_date: The end date of the data export\n        :param num_labelled_points: (Optional) The number of labelled points to export.\n        :param surrounding_metres: The number of metres surrounding each labelled point to export\n        :param checkpoint: Whether or not to check in self.data_folder to see if the file has\n            already been exported. If it has, skip it\n        :param monitor: Whether to monitor each task until it has been run\n        :param fast: Whether to use the faster cloudfree exporter. This function is considerably\n            faster, but cloud artefacts can be more pronounced. Default = True\n        \"\"\"\n        assert start_date >= self.min_date, f\"Sentinel data does not exist before {self.min_date}\"\n\n        bounding_boxes_to_download = self.labels_to_bounding_boxes(\n            num_labelled_points=num_labelled_points, surrounding_metres=surrounding_metres,\n        )\n\n        for idx, bounding_box in enumerate(bounding_boxes_to_download):\n            self._export_for_polygon(\n                polygon=bounding_box.to_ee_polygon(),\n                polygon_identifier=idx,\n                start_date=start_date,\n                end_date=end_date,\n                days_per_timestep=days_per_timestep,\n                checkpoint=checkpoint,\n                monitor=monitor,\n                fast=fast,\n            )\n",
  "history_output" : "",
  "history_begin_time" : 1647345657791,
  "history_end_time" : 1647345660862,
  "history_notes" : null,
  "history_process" : "mw544v",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "gxhcakv4651",
  "history_input" : "import pandas as pd\nimport xarray as xr\nfrom datetime import date\nfrom tqdm import tqdm\n\nfrom src_exporters_sentinel_base import BaseSentinelExporter\nfrom src_exporters_geowiki import GeoWikiExporter\nfrom src_exporters_sentinel_utils import EEBoundingBox, bounding_box_from_centre\n\nfrom typing import Optional, List\n\n\nclass GeoWikiSentinelExporter(BaseSentinelExporter):\n\n    dataset = \"earth_engine_geowiki\"\n\n    def load_labels(self) -> pd.DataFrame:\n        # right now, this just loads geowiki data. In the future,\n        # it would be neat to merge all labels together\n        geowiki = self.data_folder / \"processed\" / GeoWikiExporter.dataset / \"data.nc\"\n        assert geowiki.exists(), \"GeoWiki processor must be run to load labels\"\n        return xr.open_dataset(geowiki).to_dataframe().dropna().reset_index()\n\n    def labels_to_bounding_boxes(\n        self, num_labelled_points: Optional[int], surrounding_metres: int\n    ) -> List[EEBoundingBox]:\n\n        output: List[EEBoundingBox] = []\n\n        for idx, row in tqdm(self.labels.iterrows()):\n            output.append(\n                bounding_box_from_centre(\n                    mid_lat=row[\"lat\"], mid_lon=row[\"lon\"], surrounding_metres=surrounding_metres,\n                )\n            )\n\n            if num_labelled_points is not None:\n                if len(output) >= num_labelled_points:\n                    return output\n        return output\n\n    def export_for_labels(\n        self,\n        days_per_timestep: int = 30,\n        start_date: date = date(2017, 3, 28),\n        end_date: date = date(2018, 3, 28),\n        num_labelled_points: Optional[int] = None,\n        surrounding_metres: int = 80,\n        checkpoint: bool = True,\n        monitor: bool = False,\n        fast: bool = True,\n    ) -> None:\n        r\"\"\"\n        Run the GeoWiki exporter. For each label, the exporter will export\n        int( (end_date - start_date).days / days_per_timestep) timesteps of data,\n        where each timestep consists of a mosaic of all available images within the\n        days_per_timestep of that timestep.\n        :param days_per_timestep: The number of days of data to use for each mosaiced image.\n        :param start_date: The start data of the data export\n        :param end_date: The end date of the data export\n        :param num_labelled_points: (Optional) The number of labelled points to export.\n        :param surrounding_metres: The number of metres surrounding each labelled point to export\n        :param checkpoint: Whether or not to check in self.data_folder to see if the file has\n            already been exported. If it has, skip it\n        :param monitor: Whether to monitor each task until it has been run\n        :param fast: Whether to use the faster cloudfree exporter. This function is considerably\n            faster, but cloud artefacts can be more pronounced. Default = True\n        \"\"\"\n        assert start_date >= self.min_date, f\"Sentinel data does not exist before {self.min_date}\"\n\n        bounding_boxes_to_download = self.labels_to_bounding_boxes(\n            num_labelled_points=num_labelled_points, surrounding_metres=surrounding_metres,\n        )\n\n        for idx, bounding_box in enumerate(bounding_boxes_to_download):\n            self._export_for_polygon(\n                polygon=bounding_box.to_ee_polygon(),\n                polygon_identifier=idx,\n                start_date=start_date,\n                end_date=end_date,\n                days_per_timestep=days_per_timestep,\n                checkpoint=checkpoint,\n                monitor=monitor,\n                fast=fast,\n            )\n",
  "history_output" : "",
  "history_begin_time" : 1647340128551,
  "history_end_time" : 1647340129023,
  "history_notes" : null,
  "history_process" : "mw544v",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "yeohy25d76l",
  "history_input" : "import pandas as pd\nimport xarray as xr\nfrom datetime import date\nfrom tqdm import tqdm\n\nfrom src_exporters_sentinel_base import BaseSentinelExporter\nfrom src_exporters_geowiki import GeoWikiExporter\nfrom src_exporters_sentinel_utils import EEBoundingBox, bounding_box_from_centre\n\nfrom typing import Optional, List\n\n\nclass GeoWikiSentinelExporter(BaseSentinelExporter):\n\n    dataset = \"earth_engine_geowiki\"\n\n    def load_labels(self) -> pd.DataFrame:\n        # right now, this just loads geowiki data. In the future,\n        # it would be neat to merge all labels together\n        geowiki = self.data_folder / \"processed\" / GeoWikiExporter.dataset / \"data.nc\"\n        assert geowiki.exists(), \"GeoWiki processor must be run to load labels\"\n        return xr.open_dataset(geowiki).to_dataframe().dropna().reset_index()\n\n    def labels_to_bounding_boxes(\n        self, num_labelled_points: Optional[int], surrounding_metres: int\n    ) -> List[EEBoundingBox]:\n\n        output: List[EEBoundingBox] = []\n\n        for idx, row in tqdm(self.labels.iterrows()):\n            output.append(\n                bounding_box_from_centre(\n                    mid_lat=row[\"lat\"], mid_lon=row[\"lon\"], surrounding_metres=surrounding_metres,\n                )\n            )\n\n            if num_labelled_points is not None:\n                if len(output) >= num_labelled_points:\n                    return output\n        return output\n\n    def export_for_labels(\n        self,\n        days_per_timestep: int = 30,\n        start_date: date = date(2017, 3, 28),\n        end_date: date = date(2018, 3, 28),\n        num_labelled_points: Optional[int] = None,\n        surrounding_metres: int = 80,\n        checkpoint: bool = True,\n        monitor: bool = False,\n        fast: bool = True,\n    ) -> None:\n        r\"\"\"\n        Run the GeoWiki exporter. For each label, the exporter will export\n        int( (end_date - start_date).days / days_per_timestep) timesteps of data,\n        where each timestep consists of a mosaic of all available images within the\n        days_per_timestep of that timestep.\n        :param days_per_timestep: The number of days of data to use for each mosaiced image.\n        :param start_date: The start data of the data export\n        :param end_date: The end date of the data export\n        :param num_labelled_points: (Optional) The number of labelled points to export.\n        :param surrounding_metres: The number of metres surrounding each labelled point to export\n        :param checkpoint: Whether or not to check in self.data_folder to see if the file has\n            already been exported. If it has, skip it\n        :param monitor: Whether to monitor each task until it has been run\n        :param fast: Whether to use the faster cloudfree exporter. This function is considerably\n            faster, but cloud artefacts can be more pronounced. Default = True\n        \"\"\"\n        assert start_date >= self.min_date, f\"Sentinel data does not exist before {self.min_date}\"\n\n        bounding_boxes_to_download = self.labels_to_bounding_boxes(\n            num_labelled_points=num_labelled_points, surrounding_metres=surrounding_metres,\n        )\n\n        for idx, bounding_box in enumerate(bounding_boxes_to_download):\n            self._export_for_polygon(\n                polygon=bounding_box.to_ee_polygon(),\n                polygon_identifier=idx,\n                start_date=start_date,\n                end_date=end_date,\n                days_per_timestep=days_per_timestep,\n                checkpoint=checkpoint,\n                monitor=monitor,\n                fast=fast,\n            )\n",
  "history_output" : "",
  "history_begin_time" : 1646147717864,
  "history_end_time" : 1646147722197,
  "history_notes" : null,
  "history_process" : "mw544v",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "95ihv08w73t",
  "history_input" : "import pandas as pd\nimport xarray as xr\nfrom datetime import date\nfrom tqdm import tqdm\n\nfrom src_exporters_sentinel_base import BaseSentinelExporter\nfrom src_exporters_geowiki import GeoWikiExporter\nfrom src_exporters_sentinel_utils import EEBoundingBox, bounding_box_from_centre\n\nfrom typing import Optional, List\n\n\nclass GeoWikiSentinelExporter(BaseSentinelExporter):\n\n    dataset = \"earth_engine_geowiki\"\n\n    def load_labels(self) -> pd.DataFrame:\n        # right now, this just loads geowiki data. In the future,\n        # it would be neat to merge all labels together\n        geowiki = self.data_folder / \"processed\" / GeoWikiExporter.dataset / \"data.nc\"\n        assert geowiki.exists(), \"GeoWiki processor must be run to load labels\"\n        return xr.open_dataset(geowiki).to_dataframe().dropna().reset_index()\n\n    def labels_to_bounding_boxes(\n        self, num_labelled_points: Optional[int], surrounding_metres: int\n    ) -> List[EEBoundingBox]:\n\n        output: List[EEBoundingBox] = []\n\n        for idx, row in tqdm(self.labels.iterrows()):\n            output.append(\n                bounding_box_from_centre(\n                    mid_lat=row[\"lat\"], mid_lon=row[\"lon\"], surrounding_metres=surrounding_metres,\n                )\n            )\n\n            if num_labelled_points is not None:\n                if len(output) >= num_labelled_points:\n                    return output\n        return output\n\n    def export_for_labels(\n        self,\n        days_per_timestep: int = 30,\n        start_date: date = date(2017, 3, 28),\n        end_date: date = date(2018, 3, 28),\n        num_labelled_points: Optional[int] = None,\n        surrounding_metres: int = 80,\n        checkpoint: bool = True,\n        monitor: bool = False,\n        fast: bool = True,\n    ) -> None:\n        r\"\"\"\n        Run the GeoWiki exporter. For each label, the exporter will export\n        int( (end_date - start_date).days / days_per_timestep) timesteps of data,\n        where each timestep consists of a mosaic of all available images within the\n        days_per_timestep of that timestep.\n        :param days_per_timestep: The number of days of data to use for each mosaiced image.\n        :param start_date: The start data of the data export\n        :param end_date: The end date of the data export\n        :param num_labelled_points: (Optional) The number of labelled points to export.\n        :param surrounding_metres: The number of metres surrounding each labelled point to export\n        :param checkpoint: Whether or not to check in self.data_folder to see if the file has\n            already been exported. If it has, skip it\n        :param monitor: Whether to monitor each task until it has been run\n        :param fast: Whether to use the faster cloudfree exporter. This function is considerably\n            faster, but cloud artefacts can be more pronounced. Default = True\n        \"\"\"\n        assert start_date >= self.min_date, f\"Sentinel data does not exist before {self.min_date}\"\n\n        bounding_boxes_to_download = self.labels_to_bounding_boxes(\n            num_labelled_points=num_labelled_points, surrounding_metres=surrounding_metres,\n        )\n\n        for idx, bounding_box in enumerate(bounding_boxes_to_download):\n            self._export_for_polygon(\n                polygon=bounding_box.to_ee_polygon(),\n                polygon_identifier=idx,\n                start_date=start_date,\n                end_date=end_date,\n                days_per_timestep=days_per_timestep,\n                checkpoint=checkpoint,\n                monitor=monitor,\n                fast=fast,\n            )\n",
  "history_output" : "",
  "history_begin_time" : 1646145428136,
  "history_end_time" : 1646145431070,
  "history_notes" : null,
  "history_process" : "mw544v",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "loize29l28f",
  "history_input" : "import pandas as pd\nimport xarray as xr\nfrom datetime import date\nfrom tqdm import tqdm\n\nfrom src_exporters_sentinel_base import BaseSentinelExporter\nfrom src_exporters_geowiki import GeoWikiExporter\nfrom src_exporters_sentinel_utils import EEBoundingBox, bounding_box_from_centre\n\nfrom typing import Optional, List\n\n\nclass GeoWikiSentinelExporter(BaseSentinelExporter):\n\n    dataset = \"earth_engine_geowiki\"\n\n    def load_labels(self) -> pd.DataFrame:\n        # right now, this just loads geowiki data. In the future,\n        # it would be neat to merge all labels together\n        geowiki = self.data_folder / \"processed\" / GeoWikiExporter.dataset / \"data.nc\"\n        assert geowiki.exists(), \"GeoWiki processor must be run to load labels\"\n        return xr.open_dataset(geowiki).to_dataframe().dropna().reset_index()\n\n    def labels_to_bounding_boxes(\n        self, num_labelled_points: Optional[int], surrounding_metres: int\n    ) -> List[EEBoundingBox]:\n\n        output: List[EEBoundingBox] = []\n\n        for idx, row in tqdm(self.labels.iterrows()):\n            output.append(\n                bounding_box_from_centre(\n                    mid_lat=row[\"lat\"], mid_lon=row[\"lon\"], surrounding_metres=surrounding_metres,\n                )\n            )\n\n            if num_labelled_points is not None:\n                if len(output) >= num_labelled_points:\n                    return output\n        return output\n\n    def export_for_labels(\n        self,\n        days_per_timestep: int = 30,\n        start_date: date = date(2017, 3, 28),\n        end_date: date = date(2018, 3, 28),\n        num_labelled_points: Optional[int] = None,\n        surrounding_metres: int = 80,\n        checkpoint: bool = True,\n        monitor: bool = False,\n        fast: bool = True,\n    ) -> None:\n        r\"\"\"\n        Run the GeoWiki exporter. For each label, the exporter will export\n        int( (end_date - start_date).days / days_per_timestep) timesteps of data,\n        where each timestep consists of a mosaic of all available images within the\n        days_per_timestep of that timestep.\n        :param days_per_timestep: The number of days of data to use for each mosaiced image.\n        :param start_date: The start data of the data export\n        :param end_date: The end date of the data export\n        :param num_labelled_points: (Optional) The number of labelled points to export.\n        :param surrounding_metres: The number of metres surrounding each labelled point to export\n        :param checkpoint: Whether or not to check in self.data_folder to see if the file has\n            already been exported. If it has, skip it\n        :param monitor: Whether to monitor each task until it has been run\n        :param fast: Whether to use the faster cloudfree exporter. This function is considerably\n            faster, but cloud artefacts can be more pronounced. Default = True\n        \"\"\"\n        assert start_date >= self.min_date, f\"Sentinel data does not exist before {self.min_date}\"\n\n        bounding_boxes_to_download = self.labels_to_bounding_boxes(\n            num_labelled_points=num_labelled_points, surrounding_metres=surrounding_metres,\n        )\n\n        for idx, bounding_box in enumerate(bounding_boxes_to_download):\n            self._export_for_polygon(\n                polygon=bounding_box.to_ee_polygon(),\n                polygon_identifier=idx,\n                start_date=start_date,\n                end_date=end_date,\n                days_per_timestep=days_per_timestep,\n                checkpoint=checkpoint,\n                monitor=monitor,\n                fast=fast,\n            )\n",
  "history_output" : "",
  "history_begin_time" : 1646145218118,
  "history_end_time" : 1646145218408,
  "history_notes" : null,
  "history_process" : "mw544v",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "fb0lfwuj8n2",
  "history_input" : "import pandas as pd\nimport xarray as xr\nfrom datetime import date\nfrom tqdm import tqdm\n\nfrom src_exporters_sentinel_base import BaseSentinelExporter\nfrom src_exporters_geowiki import GeoWikiExporter\nfrom src_exporters_sentinel_utils import EEBoundingBox, bounding_box_from_centre\n\nfrom typing import Optional, List\n\n\nclass GeoWikiSentinelExporter(BaseSentinelExporter):\n\n    dataset = \"earth_engine_geowiki\"\n\n    def load_labels(self) -> pd.DataFrame:\n        # right now, this just loads geowiki data. In the future,\n        # it would be neat to merge all labels together\n        geowiki = self.data_folder / \"processed\" / GeoWikiExporter.dataset / \"data.nc\"\n        assert geowiki.exists(), \"GeoWiki processor must be run to load labels\"\n        return xr.open_dataset(geowiki).to_dataframe().dropna().reset_index()\n\n    def labels_to_bounding_boxes(\n        self, num_labelled_points: Optional[int], surrounding_metres: int\n    ) -> List[EEBoundingBox]:\n\n        output: List[EEBoundingBox] = []\n\n        for idx, row in tqdm(self.labels.iterrows()):\n            output.append(\n                bounding_box_from_centre(\n                    mid_lat=row[\"lat\"], mid_lon=row[\"lon\"], surrounding_metres=surrounding_metres,\n                )\n            )\n\n            if num_labelled_points is not None:\n                if len(output) >= num_labelled_points:\n                    return output\n        return output\n\n    def export_for_labels(\n        self,\n        days_per_timestep: int = 30,\n        start_date: date = date(2017, 3, 28),\n        end_date: date = date(2018, 3, 28),\n        num_labelled_points: Optional[int] = None,\n        surrounding_metres: int = 80,\n        checkpoint: bool = True,\n        monitor: bool = False,\n        fast: bool = True,\n    ) -> None:\n        r\"\"\"\n        Run the GeoWiki exporter. For each label, the exporter will export\n        int( (end_date - start_date).days / days_per_timestep) timesteps of data,\n        where each timestep consists of a mosaic of all available images within the\n        days_per_timestep of that timestep.\n        :param days_per_timestep: The number of days of data to use for each mosaiced image.\n        :param start_date: The start data of the data export\n        :param end_date: The end date of the data export\n        :param num_labelled_points: (Optional) The number of labelled points to export.\n        :param surrounding_metres: The number of metres surrounding each labelled point to export\n        :param checkpoint: Whether or not to check in self.data_folder to see if the file has\n            already been exported. If it has, skip it\n        :param monitor: Whether to monitor each task until it has been run\n        :param fast: Whether to use the faster cloudfree exporter. This function is considerably\n            faster, but cloud artefacts can be more pronounced. Default = True\n        \"\"\"\n        assert start_date >= self.min_date, f\"Sentinel data does not exist before {self.min_date}\"\n\n        bounding_boxes_to_download = self.labels_to_bounding_boxes(\n            num_labelled_points=num_labelled_points, surrounding_metres=surrounding_metres,\n        )\n\n        for idx, bounding_box in enumerate(bounding_boxes_to_download):\n            self._export_for_polygon(\n                polygon=bounding_box.to_ee_polygon(),\n                polygon_identifier=idx,\n                start_date=start_date,\n                end_date=end_date,\n                days_per_timestep=days_per_timestep,\n                checkpoint=checkpoint,\n                monitor=monitor,\n                fast=fast,\n            )\n",
  "history_output" : "",
  "history_begin_time" : 1646144601359,
  "history_end_time" : 1646144604460,
  "history_notes" : null,
  "history_process" : "mw544v",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "z5w1wuiw82w",
  "history_input" : "import pandas as pd\nimport xarray as xr\nfrom datetime import date\nfrom tqdm import tqdm\n\nfrom src_exporters_sentinel_base import BaseSentinelExporter\nfrom src_exporters_geowiki import GeoWikiExporter\nfrom src_exporters_sentinel_utils import EEBoundingBox, bounding_box_from_centre\n\nfrom typing import Optional, List\n\n\nclass GeoWikiSentinelExporter(BaseSentinelExporter):\n\n    dataset = \"earth_engine_geowiki\"\n\n    def load_labels(self) -> pd.DataFrame:\n        # right now, this just loads geowiki data. In the future,\n        # it would be neat to merge all labels together\n        geowiki = self.data_folder / \"processed\" / GeoWikiExporter.dataset / \"data.nc\"\n        assert geowiki.exists(), \"GeoWiki processor must be run to load labels\"\n        return xr.open_dataset(geowiki).to_dataframe().dropna().reset_index()\n\n    def labels_to_bounding_boxes(\n        self, num_labelled_points: Optional[int], surrounding_metres: int\n    ) -> List[EEBoundingBox]:\n\n        output: List[EEBoundingBox] = []\n\n        for idx, row in tqdm(self.labels.iterrows()):\n            output.append(\n                bounding_box_from_centre(\n                    mid_lat=row[\"lat\"], mid_lon=row[\"lon\"], surrounding_metres=surrounding_metres,\n                )\n            )\n\n            if num_labelled_points is not None:\n                if len(output) >= num_labelled_points:\n                    return output\n        return output\n\n    def export_for_labels(\n        self,\n        days_per_timestep: int = 30,\n        start_date: date = date(2017, 3, 28),\n        end_date: date = date(2018, 3, 28),\n        num_labelled_points: Optional[int] = None,\n        surrounding_metres: int = 80,\n        checkpoint: bool = True,\n        monitor: bool = False,\n        fast: bool = True,\n    ) -> None:\n        r\"\"\"\n        Run the GeoWiki exporter. For each label, the exporter will export\n        int( (end_date - start_date).days / days_per_timestep) timesteps of data,\n        where each timestep consists of a mosaic of all available images within the\n        days_per_timestep of that timestep.\n        :param days_per_timestep: The number of days of data to use for each mosaiced image.\n        :param start_date: The start data of the data export\n        :param end_date: The end date of the data export\n        :param num_labelled_points: (Optional) The number of labelled points to export.\n        :param surrounding_metres: The number of metres surrounding each labelled point to export\n        :param checkpoint: Whether or not to check in self.data_folder to see if the file has\n            already been exported. If it has, skip it\n        :param monitor: Whether to monitor each task until it has been run\n        :param fast: Whether to use the faster cloudfree exporter. This function is considerably\n            faster, but cloud artefacts can be more pronounced. Default = True\n        \"\"\"\n        assert start_date >= self.min_date, f\"Sentinel data does not exist before {self.min_date}\"\n\n        bounding_boxes_to_download = self.labels_to_bounding_boxes(\n            num_labelled_points=num_labelled_points, surrounding_metres=surrounding_metres,\n        )\n\n        for idx, bounding_box in enumerate(bounding_boxes_to_download):\n            self._export_for_polygon(\n                polygon=bounding_box.to_ee_polygon(),\n                polygon_identifier=idx,\n                start_date=start_date,\n                end_date=end_date,\n                days_per_timestep=days_per_timestep,\n                checkpoint=checkpoint,\n                monitor=monitor,\n                fast=fast,\n            )\n",
  "history_output" : "",
  "history_begin_time" : 1646144384065,
  "history_end_time" : 1646144384847,
  "history_notes" : null,
  "history_process" : "mw544v",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "c6civuen0y0",
  "history_input" : "import pandas as pd\nimport xarray as xr\nfrom datetime import date\nfrom tqdm import tqdm\n\nfrom src_exporters_sentinel_base import BaseSentinelExporter\nfrom src_exporters_geowiki import GeoWikiExporter\nfrom src_exporters_sentinel_utils import EEBoundingBox, bounding_box_from_centre\n\nfrom typing import Optional, List\n\n\nclass GeoWikiSentinelExporter(BaseSentinelExporter):\n\n    dataset = \"earth_engine_geowiki\"\n\n    def load_labels(self) -> pd.DataFrame:\n        # right now, this just loads geowiki data. In the future,\n        # it would be neat to merge all labels together\n        geowiki = self.data_folder / \"processed\" / GeoWikiExporter.dataset / \"data.nc\"\n        assert geowiki.exists(), \"GeoWiki processor must be run to load labels\"\n        return xr.open_dataset(geowiki).to_dataframe().dropna().reset_index()\n\n    def labels_to_bounding_boxes(\n        self, num_labelled_points: Optional[int], surrounding_metres: int\n    ) -> List[EEBoundingBox]:\n\n        output: List[EEBoundingBox] = []\n\n        for idx, row in tqdm(self.labels.iterrows()):\n            output.append(\n                bounding_box_from_centre(\n                    mid_lat=row[\"lat\"], mid_lon=row[\"lon\"], surrounding_metres=surrounding_metres,\n                )\n            )\n\n            if num_labelled_points is not None:\n                if len(output) >= num_labelled_points:\n                    return output\n        return output\n\n    def export_for_labels(\n        self,\n        days_per_timestep: int = 30,\n        start_date: date = date(2017, 3, 28),\n        end_date: date = date(2018, 3, 28),\n        num_labelled_points: Optional[int] = None,\n        surrounding_metres: int = 80,\n        checkpoint: bool = True,\n        monitor: bool = False,\n        fast: bool = True,\n    ) -> None:\n        r\"\"\"\n        Run the GeoWiki exporter. For each label, the exporter will export\n        int( (end_date - start_date).days / days_per_timestep) timesteps of data,\n        where each timestep consists of a mosaic of all available images within the\n        days_per_timestep of that timestep.\n        :param days_per_timestep: The number of days of data to use for each mosaiced image.\n        :param start_date: The start data of the data export\n        :param end_date: The end date of the data export\n        :param num_labelled_points: (Optional) The number of labelled points to export.\n        :param surrounding_metres: The number of metres surrounding each labelled point to export\n        :param checkpoint: Whether or not to check in self.data_folder to see if the file has\n            already been exported. If it has, skip it\n        :param monitor: Whether to monitor each task until it has been run\n        :param fast: Whether to use the faster cloudfree exporter. This function is considerably\n            faster, but cloud artefacts can be more pronounced. Default = True\n        \"\"\"\n        assert start_date >= self.min_date, f\"Sentinel data does not exist before {self.min_date}\"\n\n        bounding_boxes_to_download = self.labels_to_bounding_boxes(\n            num_labelled_points=num_labelled_points, surrounding_metres=surrounding_metres,\n        )\n\n        for idx, bounding_box in enumerate(bounding_boxes_to_download):\n            self._export_for_polygon(\n                polygon=bounding_box.to_ee_polygon(),\n                polygon_identifier=idx,\n                start_date=start_date,\n                end_date=end_date,\n                days_per_timestep=days_per_timestep,\n                checkpoint=checkpoint,\n                monitor=monitor,\n                fast=fast,\n            )\n",
  "history_output" : "",
  "history_begin_time" : 1646144311443,
  "history_end_time" : 1646144314230,
  "history_notes" : null,
  "history_process" : "mw544v",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "vqg29h9em4v",
  "history_input" : "import pandas as pd\nimport xarray as xr\nfrom datetime import date\nfrom tqdm import tqdm\n\nfrom src_exporters_sentinel_base import BaseSentinelExporter\nfrom src_exporters_geowiki import GeoWikiExporter\nfrom src_exporters_sentinel_utils import EEBoundingBox, bounding_box_from_centre\n\nfrom typing import Optional, List\n\n\nclass GeoWikiSentinelExporter(BaseSentinelExporter):\n\n    dataset = \"earth_engine_geowiki\"\n\n    def load_labels(self) -> pd.DataFrame:\n        # right now, this just loads geowiki data. In the future,\n        # it would be neat to merge all labels together\n        geowiki = self.data_folder / \"processed\" / GeoWikiExporter.dataset / \"data.nc\"\n        assert geowiki.exists(), \"GeoWiki processor must be run to load labels\"\n        return xr.open_dataset(geowiki).to_dataframe().dropna().reset_index()\n\n    def labels_to_bounding_boxes(\n        self, num_labelled_points: Optional[int], surrounding_metres: int\n    ) -> List[EEBoundingBox]:\n\n        output: List[EEBoundingBox] = []\n\n        for idx, row in tqdm(self.labels.iterrows()):\n            output.append(\n                bounding_box_from_centre(\n                    mid_lat=row[\"lat\"], mid_lon=row[\"lon\"], surrounding_metres=surrounding_metres,\n                )\n            )\n\n            if num_labelled_points is not None:\n                if len(output) >= num_labelled_points:\n                    return output\n        return output\n\n    def export_for_labels(\n        self,\n        days_per_timestep: int = 30,\n        start_date: date = date(2017, 3, 28),\n        end_date: date = date(2018, 3, 28),\n        num_labelled_points: Optional[int] = None,\n        surrounding_metres: int = 80,\n        checkpoint: bool = True,\n        monitor: bool = False,\n        fast: bool = True,\n    ) -> None:\n        r\"\"\"\n        Run the GeoWiki exporter. For each label, the exporter will export\n        int( (end_date - start_date).days / days_per_timestep) timesteps of data,\n        where each timestep consists of a mosaic of all available images within the\n        days_per_timestep of that timestep.\n        :param days_per_timestep: The number of days of data to use for each mosaiced image.\n        :param start_date: The start data of the data export\n        :param end_date: The end date of the data export\n        :param num_labelled_points: (Optional) The number of labelled points to export.\n        :param surrounding_metres: The number of metres surrounding each labelled point to export\n        :param checkpoint: Whether or not to check in self.data_folder to see if the file has\n            already been exported. If it has, skip it\n        :param monitor: Whether to monitor each task until it has been run\n        :param fast: Whether to use the faster cloudfree exporter. This function is considerably\n            faster, but cloud artefacts can be more pronounced. Default = True\n        \"\"\"\n        assert start_date >= self.min_date, f\"Sentinel data does not exist before {self.min_date}\"\n\n        bounding_boxes_to_download = self.labels_to_bounding_boxes(\n            num_labelled_points=num_labelled_points, surrounding_metres=surrounding_metres,\n        )\n\n        for idx, bounding_box in enumerate(bounding_boxes_to_download):\n            self._export_for_polygon(\n                polygon=bounding_box.to_ee_polygon(),\n                polygon_identifier=idx,\n                start_date=start_date,\n                end_date=end_date,\n                days_per_timestep=days_per_timestep,\n                checkpoint=checkpoint,\n                monitor=monitor,\n                fast=fast,\n            )\n",
  "history_output" : "",
  "history_begin_time" : 1646143410542,
  "history_end_time" : 1646143412476,
  "history_notes" : null,
  "history_process" : "mw544v",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "5ypqxpy76h4",
  "history_input" : "import pandas as pd\nimport xarray as xr\nfrom datetime import date\nfrom tqdm import tqdm\n\nfrom src_exporters_sentinel_base import BaseSentinelExporter\nfrom src_exporters_geowiki import GeoWikiExporter\nfrom src_exporters_sentinel_utils import EEBoundingBox, bounding_box_from_centre\n\nfrom typing import Optional, List\n\n\nclass GeoWikiSentinelExporter(BaseSentinelExporter):\n\n    dataset = \"earth_engine_geowiki\"\n\n    def load_labels(self) -> pd.DataFrame:\n        # right now, this just loads geowiki data. In the future,\n        # it would be neat to merge all labels together\n        geowiki = self.data_folder / \"processed\" / GeoWikiExporter.dataset / \"data.nc\"\n        assert geowiki.exists(), \"GeoWiki processor must be run to load labels\"\n        return xr.open_dataset(geowiki).to_dataframe().dropna().reset_index()\n\n    def labels_to_bounding_boxes(\n        self, num_labelled_points: Optional[int], surrounding_metres: int\n    ) -> List[EEBoundingBox]:\n\n        output: List[EEBoundingBox] = []\n\n        for idx, row in tqdm(self.labels.iterrows()):\n            output.append(\n                bounding_box_from_centre(\n                    mid_lat=row[\"lat\"], mid_lon=row[\"lon\"], surrounding_metres=surrounding_metres,\n                )\n            )\n\n            if num_labelled_points is not None:\n                if len(output) >= num_labelled_points:\n                    return output\n        return output\n\n    def export_for_labels(\n        self,\n        days_per_timestep: int = 30,\n        start_date: date = date(2017, 3, 28),\n        end_date: date = date(2018, 3, 28),\n        num_labelled_points: Optional[int] = None,\n        surrounding_metres: int = 80,\n        checkpoint: bool = True,\n        monitor: bool = False,\n        fast: bool = True,\n    ) -> None:\n        r\"\"\"\n        Run the GeoWiki exporter. For each label, the exporter will export\n        int( (end_date - start_date).days / days_per_timestep) timesteps of data,\n        where each timestep consists of a mosaic of all available images within the\n        days_per_timestep of that timestep.\n        :param days_per_timestep: The number of days of data to use for each mosaiced image.\n        :param start_date: The start data of the data export\n        :param end_date: The end date of the data export\n        :param num_labelled_points: (Optional) The number of labelled points to export.\n        :param surrounding_metres: The number of metres surrounding each labelled point to export\n        :param checkpoint: Whether or not to check in self.data_folder to see if the file has\n            already been exported. If it has, skip it\n        :param monitor: Whether to monitor each task until it has been run\n        :param fast: Whether to use the faster cloudfree exporter. This function is considerably\n            faster, but cloud artefacts can be more pronounced. Default = True\n        \"\"\"\n        assert start_date >= self.min_date, f\"Sentinel data does not exist before {self.min_date}\"\n\n        bounding_boxes_to_download = self.labels_to_bounding_boxes(\n            num_labelled_points=num_labelled_points, surrounding_metres=surrounding_metres,\n        )\n\n        for idx, bounding_box in enumerate(bounding_boxes_to_download):\n            self._export_for_polygon(\n                polygon=bounding_box.to_ee_polygon(),\n                polygon_identifier=idx,\n                start_date=start_date,\n                end_date=end_date,\n                days_per_timestep=days_per_timestep,\n                checkpoint=checkpoint,\n                monitor=monitor,\n                fast=fast,\n            )\n",
  "history_output" : "",
  "history_begin_time" : 1646143257184,
  "history_end_time" : 1646143257869,
  "history_notes" : null,
  "history_process" : "mw544v",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "5ydvkrhovdb",
  "history_input" : "import pandas as pd\nimport xarray as xr\nfrom datetime import date\nfrom tqdm import tqdm\n\nfrom src_exporters_sentinel_base import BaseSentinelExporter\nfrom src_exporters_geowiki import GeoWikiExporter\nfrom src_exporters_sentinel_utils import EEBoundingBox, bounding_box_from_centre\n\nfrom typing import Optional, List\n\n\nclass GeoWikiSentinelExporter(BaseSentinelExporter):\n\n    dataset = \"earth_engine_geowiki\"\n\n    def load_labels(self) -> pd.DataFrame:\n        # right now, this just loads geowiki data. In the future,\n        # it would be neat to merge all labels together\n        geowiki = self.data_folder / \"processed\" / GeoWikiExporter.dataset / \"data.nc\"\n        assert geowiki.exists(), \"GeoWiki processor must be run to load labels\"\n        return xr.open_dataset(geowiki).to_dataframe().dropna().reset_index()\n\n    def labels_to_bounding_boxes(\n        self, num_labelled_points: Optional[int], surrounding_metres: int\n    ) -> List[EEBoundingBox]:\n\n        output: List[EEBoundingBox] = []\n\n        for idx, row in tqdm(self.labels.iterrows()):\n            output.append(\n                bounding_box_from_centre(\n                    mid_lat=row[\"lat\"], mid_lon=row[\"lon\"], surrounding_metres=surrounding_metres,\n                )\n            )\n\n            if num_labelled_points is not None:\n                if len(output) >= num_labelled_points:\n                    return output\n        return output\n\n    def export_for_labels(\n        self,\n        days_per_timestep: int = 30,\n        start_date: date = date(2017, 3, 28),\n        end_date: date = date(2018, 3, 28),\n        num_labelled_points: Optional[int] = None,\n        surrounding_metres: int = 80,\n        checkpoint: bool = True,\n        monitor: bool = False,\n        fast: bool = True,\n    ) -> None:\n        r\"\"\"\n        Run the GeoWiki exporter. For each label, the exporter will export\n        int( (end_date - start_date).days / days_per_timestep) timesteps of data,\n        where each timestep consists of a mosaic of all available images within the\n        days_per_timestep of that timestep.\n        :param days_per_timestep: The number of days of data to use for each mosaiced image.\n        :param start_date: The start data of the data export\n        :param end_date: The end date of the data export\n        :param num_labelled_points: (Optional) The number of labelled points to export.\n        :param surrounding_metres: The number of metres surrounding each labelled point to export\n        :param checkpoint: Whether or not to check in self.data_folder to see if the file has\n            already been exported. If it has, skip it\n        :param monitor: Whether to monitor each task until it has been run\n        :param fast: Whether to use the faster cloudfree exporter. This function is considerably\n            faster, but cloud artefacts can be more pronounced. Default = True\n        \"\"\"\n        assert start_date >= self.min_date, f\"Sentinel data does not exist before {self.min_date}\"\n\n        bounding_boxes_to_download = self.labels_to_bounding_boxes(\n            num_labelled_points=num_labelled_points, surrounding_metres=surrounding_metres,\n        )\n\n        for idx, bounding_box in enumerate(bounding_boxes_to_download):\n            self._export_for_polygon(\n                polygon=bounding_box.to_ee_polygon(),\n                polygon_identifier=idx,\n                start_date=start_date,\n                end_date=end_date,\n                days_per_timestep=days_per_timestep,\n                checkpoint=checkpoint,\n                monitor=monitor,\n                fast=fast,\n            )\n",
  "history_output" : "",
  "history_begin_time" : 1646143178979,
  "history_end_time" : 1646143179822,
  "history_notes" : null,
  "history_process" : "mw544v",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "n88rjnobhk4",
  "history_input" : "import pandas as pd\nimport xarray as xr\nfrom datetime import date\nfrom tqdm import tqdm\n\nfrom src_exporters_sentinel_base import BaseSentinelExporter\nfrom src_exporters_geowiki import GeoWikiExporter\nfrom src_exporters_sentinel_utils import EEBoundingBox, bounding_box_from_centre\n\nfrom typing import Optional, List\n\n\nclass GeoWikiSentinelExporter(BaseSentinelExporter):\n\n    dataset = \"earth_engine_geowiki\"\n\n    def load_labels(self) -> pd.DataFrame:\n        # right now, this just loads geowiki data. In the future,\n        # it would be neat to merge all labels together\n        geowiki = self.data_folder / \"processed\" / GeoWikiExporter.dataset / \"data.nc\"\n        assert geowiki.exists(), \"GeoWiki processor must be run to load labels\"\n        return xr.open_dataset(geowiki).to_dataframe().dropna().reset_index()\n\n    def labels_to_bounding_boxes(\n        self, num_labelled_points: Optional[int], surrounding_metres: int\n    ) -> List[EEBoundingBox]:\n\n        output: List[EEBoundingBox] = []\n\n        for idx, row in tqdm(self.labels.iterrows()):\n            output.append(\n                bounding_box_from_centre(\n                    mid_lat=row[\"lat\"], mid_lon=row[\"lon\"], surrounding_metres=surrounding_metres,\n                )\n            )\n\n            if num_labelled_points is not None:\n                if len(output) >= num_labelled_points:\n                    return output\n        return output\n\n    def export_for_labels(\n        self,\n        days_per_timestep: int = 30,\n        start_date: date = date(2017, 3, 28),\n        end_date: date = date(2018, 3, 28),\n        num_labelled_points: Optional[int] = None,\n        surrounding_metres: int = 80,\n        checkpoint: bool = True,\n        monitor: bool = False,\n        fast: bool = True,\n    ) -> None:\n        r\"\"\"\n        Run the GeoWiki exporter. For each label, the exporter will export\n        int( (end_date - start_date).days / days_per_timestep) timesteps of data,\n        where each timestep consists of a mosaic of all available images within the\n        days_per_timestep of that timestep.\n        :param days_per_timestep: The number of days of data to use for each mosaiced image.\n        :param start_date: The start data of the data export\n        :param end_date: The end date of the data export\n        :param num_labelled_points: (Optional) The number of labelled points to export.\n        :param surrounding_metres: The number of metres surrounding each labelled point to export\n        :param checkpoint: Whether or not to check in self.data_folder to see if the file has\n            already been exported. If it has, skip it\n        :param monitor: Whether to monitor each task until it has been run\n        :param fast: Whether to use the faster cloudfree exporter. This function is considerably\n            faster, but cloud artefacts can be more pronounced. Default = True\n        \"\"\"\n        assert start_date >= self.min_date, f\"Sentinel data does not exist before {self.min_date}\"\n\n        bounding_boxes_to_download = self.labels_to_bounding_boxes(\n            num_labelled_points=num_labelled_points, surrounding_metres=surrounding_metres,\n        )\n\n        for idx, bounding_box in enumerate(bounding_boxes_to_download):\n            self._export_for_polygon(\n                polygon=bounding_box.to_ee_polygon(),\n                polygon_identifier=idx,\n                start_date=start_date,\n                end_date=end_date,\n                days_per_timestep=days_per_timestep,\n                checkpoint=checkpoint,\n                monitor=monitor,\n                fast=fast,\n            )\n",
  "history_output" : "",
  "history_begin_time" : 1646143141867,
  "history_end_time" : 1646143144948,
  "history_notes" : null,
  "history_process" : "mw544v",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "j8y183jg5d8",
  "history_input" : "import pandas as pd\nimport xarray as xr\nfrom datetime import date\nfrom tqdm import tqdm\n\nfrom src_exporters_sentinel_base import BaseSentinelExporter\nfrom src_exporters_geowiki import GeoWikiExporter\nfrom src_exporters_sentinel_utils import EEBoundingBox, bounding_box_from_centre\n\nfrom typing import Optional, List\n\n\nclass GeoWikiSentinelExporter(BaseSentinelExporter):\n\n    dataset = \"earth_engine_geowiki\"\n\n    def load_labels(self) -> pd.DataFrame:\n        # right now, this just loads geowiki data. In the future,\n        # it would be neat to merge all labels together\n        geowiki = self.data_folder / \"processed\" / GeoWikiExporter.dataset / \"data.nc\"\n        assert geowiki.exists(), \"GeoWiki processor must be run to load labels\"\n        return xr.open_dataset(geowiki).to_dataframe().dropna().reset_index()\n\n    def labels_to_bounding_boxes(\n        self, num_labelled_points: Optional[int], surrounding_metres: int\n    ) -> List[EEBoundingBox]:\n\n        output: List[EEBoundingBox] = []\n\n        for idx, row in tqdm(self.labels.iterrows()):\n            output.append(\n                bounding_box_from_centre(\n                    mid_lat=row[\"lat\"], mid_lon=row[\"lon\"], surrounding_metres=surrounding_metres,\n                )\n            )\n\n            if num_labelled_points is not None:\n                if len(output) >= num_labelled_points:\n                    return output\n        return output\n\n    def export_for_labels(\n        self,\n        days_per_timestep: int = 30,\n        start_date: date = date(2017, 3, 28),\n        end_date: date = date(2018, 3, 28),\n        num_labelled_points: Optional[int] = None,\n        surrounding_metres: int = 80,\n        checkpoint: bool = True,\n        monitor: bool = False,\n        fast: bool = True,\n    ) -> None:\n        r\"\"\"\n        Run the GeoWiki exporter. For each label, the exporter will export\n        int( (end_date - start_date).days / days_per_timestep) timesteps of data,\n        where each timestep consists of a mosaic of all available images within the\n        days_per_timestep of that timestep.\n        :param days_per_timestep: The number of days of data to use for each mosaiced image.\n        :param start_date: The start data of the data export\n        :param end_date: The end date of the data export\n        :param num_labelled_points: (Optional) The number of labelled points to export.\n        :param surrounding_metres: The number of metres surrounding each labelled point to export\n        :param checkpoint: Whether or not to check in self.data_folder to see if the file has\n            already been exported. If it has, skip it\n        :param monitor: Whether to monitor each task until it has been run\n        :param fast: Whether to use the faster cloudfree exporter. This function is considerably\n            faster, but cloud artefacts can be more pronounced. Default = True\n        \"\"\"\n        assert start_date >= self.min_date, f\"Sentinel data does not exist before {self.min_date}\"\n\n        bounding_boxes_to_download = self.labels_to_bounding_boxes(\n            num_labelled_points=num_labelled_points, surrounding_metres=surrounding_metres,\n        )\n\n        for idx, bounding_box in enumerate(bounding_boxes_to_download):\n            self._export_for_polygon(\n                polygon=bounding_box.to_ee_polygon(),\n                polygon_identifier=idx,\n                start_date=start_date,\n                end_date=end_date,\n                days_per_timestep=days_per_timestep,\n                checkpoint=checkpoint,\n                monitor=monitor,\n                fast=fast,\n            )\n",
  "history_output" : "",
  "history_begin_time" : 1646143111807,
  "history_end_time" : 1646143115040,
  "history_notes" : null,
  "history_process" : "mw544v",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "uynjovnxkqz",
  "history_input" : "import pandas as pd\nimport xarray as xr\nfrom datetime import date\nfrom tqdm import tqdm\n\nfrom src_exporters_sentinel_base import BaseSentinelExporter\nfrom src_exporters_geowiki import GeoWikiExporter\nfrom src_exporters_sentinel_utils import EEBoundingBox, bounding_box_from_centre\n\nfrom typing import Optional, List\n\n\nclass GeoWikiSentinelExporter(BaseSentinelExporter):\n\n    dataset = \"earth_engine_geowiki\"\n\n    def load_labels(self) -> pd.DataFrame:\n        # right now, this just loads geowiki data. In the future,\n        # it would be neat to merge all labels together\n        geowiki = self.data_folder / \"processed\" / GeoWikiExporter.dataset / \"data.nc\"\n        assert geowiki.exists(), \"GeoWiki processor must be run to load labels\"\n        return xr.open_dataset(geowiki).to_dataframe().dropna().reset_index()\n\n    def labels_to_bounding_boxes(\n        self, num_labelled_points: Optional[int], surrounding_metres: int\n    ) -> List[EEBoundingBox]:\n\n        output: List[EEBoundingBox] = []\n\n        for idx, row in tqdm(self.labels.iterrows()):\n            output.append(\n                bounding_box_from_centre(\n                    mid_lat=row[\"lat\"], mid_lon=row[\"lon\"], surrounding_metres=surrounding_metres,\n                )\n            )\n\n            if num_labelled_points is not None:\n                if len(output) >= num_labelled_points:\n                    return output\n        return output\n\n    def export_for_labels(\n        self,\n        days_per_timestep: int = 30,\n        start_date: date = date(2017, 3, 28),\n        end_date: date = date(2018, 3, 28),\n        num_labelled_points: Optional[int] = None,\n        surrounding_metres: int = 80,\n        checkpoint: bool = True,\n        monitor: bool = False,\n        fast: bool = True,\n    ) -> None:\n        r\"\"\"\n        Run the GeoWiki exporter. For each label, the exporter will export\n        int( (end_date - start_date).days / days_per_timestep) timesteps of data,\n        where each timestep consists of a mosaic of all available images within the\n        days_per_timestep of that timestep.\n        :param days_per_timestep: The number of days of data to use for each mosaiced image.\n        :param start_date: The start data of the data export\n        :param end_date: The end date of the data export\n        :param num_labelled_points: (Optional) The number of labelled points to export.\n        :param surrounding_metres: The number of metres surrounding each labelled point to export\n        :param checkpoint: Whether or not to check in self.data_folder to see if the file has\n            already been exported. If it has, skip it\n        :param monitor: Whether to monitor each task until it has been run\n        :param fast: Whether to use the faster cloudfree exporter. This function is considerably\n            faster, but cloud artefacts can be more pronounced. Default = True\n        \"\"\"\n        assert start_date >= self.min_date, f\"Sentinel data does not exist before {self.min_date}\"\n\n        bounding_boxes_to_download = self.labels_to_bounding_boxes(\n            num_labelled_points=num_labelled_points, surrounding_metres=surrounding_metres,\n        )\n\n        for idx, bounding_box in enumerate(bounding_boxes_to_download):\n            self._export_for_polygon(\n                polygon=bounding_box.to_ee_polygon(),\n                polygon_identifier=idx,\n                start_date=start_date,\n                end_date=end_date,\n                days_per_timestep=days_per_timestep,\n                checkpoint=checkpoint,\n                monitor=monitor,\n                fast=fast,\n            )\n",
  "history_output" : "",
  "history_begin_time" : 1646139378892,
  "history_end_time" : 1646139378950,
  "history_notes" : null,
  "history_process" : "mw544v",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "3epvrwqujsu",
  "history_input" : "import pandas as pd\nimport xarray as xr\nfrom datetime import date\nfrom tqdm import tqdm\n\nfrom src_exporters_sentinel_base import BaseSentinelExporter\nfrom src_exporters_geowiki import GeoWikiExporter\nfrom src_exporters_sentinel_utils import EEBoundingBox, bounding_box_from_centre\n\nfrom typing import Optional, List\n\n\nclass GeoWikiSentinelExporter(BaseSentinelExporter):\n\n    dataset = \"earth_engine_geowiki\"\n\n    def load_labels(self) -> pd.DataFrame:\n        # right now, this just loads geowiki data. In the future,\n        # it would be neat to merge all labels together\n        geowiki = self.data_folder / \"processed\" / GeoWikiExporter.dataset / \"data.nc\"\n        assert geowiki.exists(), \"GeoWiki processor must be run to load labels\"\n        return xr.open_dataset(geowiki).to_dataframe().dropna().reset_index()\n\n    def labels_to_bounding_boxes(\n        self, num_labelled_points: Optional[int], surrounding_metres: int\n    ) -> List[EEBoundingBox]:\n\n        output: List[EEBoundingBox] = []\n\n        for idx, row in tqdm(self.labels.iterrows()):\n            output.append(\n                bounding_box_from_centre(\n                    mid_lat=row[\"lat\"], mid_lon=row[\"lon\"], surrounding_metres=surrounding_metres,\n                )\n            )\n\n            if num_labelled_points is not None:\n                if len(output) >= num_labelled_points:\n                    return output\n        return output\n\n    def export_for_labels(\n        self,\n        days_per_timestep: int = 30,\n        start_date: date = date(2017, 3, 28),\n        end_date: date = date(2018, 3, 28),\n        num_labelled_points: Optional[int] = None,\n        surrounding_metres: int = 80,\n        checkpoint: bool = True,\n        monitor: bool = False,\n        fast: bool = True,\n    ) -> None:\n        r\"\"\"\n        Run the GeoWiki exporter. For each label, the exporter will export\n        int( (end_date - start_date).days / days_per_timestep) timesteps of data,\n        where each timestep consists of a mosaic of all available images within the\n        days_per_timestep of that timestep.\n        :param days_per_timestep: The number of days of data to use for each mosaiced image.\n        :param start_date: The start data of the data export\n        :param end_date: The end date of the data export\n        :param num_labelled_points: (Optional) The number of labelled points to export.\n        :param surrounding_metres: The number of metres surrounding each labelled point to export\n        :param checkpoint: Whether or not to check in self.data_folder to see if the file has\n            already been exported. If it has, skip it\n        :param monitor: Whether to monitor each task until it has been run\n        :param fast: Whether to use the faster cloudfree exporter. This function is considerably\n            faster, but cloud artefacts can be more pronounced. Default = True\n        \"\"\"\n        assert start_date >= self.min_date, f\"Sentinel data does not exist before {self.min_date}\"\n\n        bounding_boxes_to_download = self.labels_to_bounding_boxes(\n            num_labelled_points=num_labelled_points, surrounding_metres=surrounding_metres,\n        )\n\n        for idx, bounding_box in enumerate(bounding_boxes_to_download):\n            self._export_for_polygon(\n                polygon=bounding_box.to_ee_polygon(),\n                polygon_identifier=idx,\n                start_date=start_date,\n                end_date=end_date,\n                days_per_timestep=days_per_timestep,\n                checkpoint=checkpoint,\n                monitor=monitor,\n                fast=fast,\n            )\n",
  "history_output" : "",
  "history_begin_time" : 1646139286848,
  "history_end_time" : 1646139288485,
  "history_notes" : null,
  "history_process" : "mw544v",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "xaqcnqho2pr",
  "history_input" : "import pandas as pd\nimport xarray as xr\nfrom datetime import date\nfrom tqdm import tqdm\n\nfrom src_exporters_sentinel_base import BaseSentinelExporter\nfrom src_exporters_geowiki import GeoWikiExporter\nfrom src_exporters_sentinel_utils import EEBoundingBox, bounding_box_from_centre\n\nfrom typing import Optional, List\n\n\nclass GeoWikiSentinelExporter(BaseSentinelExporter):\n\n    dataset = \"earth_engine_geowiki\"\n\n    def load_labels(self) -> pd.DataFrame:\n        # right now, this just loads geowiki data. In the future,\n        # it would be neat to merge all labels together\n        geowiki = self.data_folder / \"processed\" / GeoWikiExporter.dataset / \"data.nc\"\n        assert geowiki.exists(), \"GeoWiki processor must be run to load labels\"\n        return xr.open_dataset(geowiki).to_dataframe().dropna().reset_index()\n\n    def labels_to_bounding_boxes(\n        self, num_labelled_points: Optional[int], surrounding_metres: int\n    ) -> List[EEBoundingBox]:\n\n        output: List[EEBoundingBox] = []\n\n        for idx, row in tqdm(self.labels.iterrows()):\n            output.append(\n                bounding_box_from_centre(\n                    mid_lat=row[\"lat\"], mid_lon=row[\"lon\"], surrounding_metres=surrounding_metres,\n                )\n            )\n\n            if num_labelled_points is not None:\n                if len(output) >= num_labelled_points:\n                    return output\n        return output\n\n    def export_for_labels(\n        self,\n        days_per_timestep: int = 30,\n        start_date: date = date(2017, 3, 28),\n        end_date: date = date(2018, 3, 28),\n        num_labelled_points: Optional[int] = None,\n        surrounding_metres: int = 80,\n        checkpoint: bool = True,\n        monitor: bool = False,\n        fast: bool = True,\n    ) -> None:\n        r\"\"\"\n        Run the GeoWiki exporter. For each label, the exporter will export\n        int( (end_date - start_date).days / days_per_timestep) timesteps of data,\n        where each timestep consists of a mosaic of all available images within the\n        days_per_timestep of that timestep.\n        :param days_per_timestep: The number of days of data to use for each mosaiced image.\n        :param start_date: The start data of the data export\n        :param end_date: The end date of the data export\n        :param num_labelled_points: (Optional) The number of labelled points to export.\n        :param surrounding_metres: The number of metres surrounding each labelled point to export\n        :param checkpoint: Whether or not to check in self.data_folder to see if the file has\n            already been exported. If it has, skip it\n        :param monitor: Whether to monitor each task until it has been run\n        :param fast: Whether to use the faster cloudfree exporter. This function is considerably\n            faster, but cloud artefacts can be more pronounced. Default = True\n        \"\"\"\n        assert start_date >= self.min_date, f\"Sentinel data does not exist before {self.min_date}\"\n\n        bounding_boxes_to_download = self.labels_to_bounding_boxes(\n            num_labelled_points=num_labelled_points, surrounding_metres=surrounding_metres,\n        )\n\n        for idx, bounding_box in enumerate(bounding_boxes_to_download):\n            self._export_for_polygon(\n                polygon=bounding_box.to_ee_polygon(),\n                polygon_identifier=idx,\n                start_date=start_date,\n                end_date=end_date,\n                days_per_timestep=days_per_timestep,\n                checkpoint=checkpoint,\n                monitor=monitor,\n                fast=fast,\n            )\n",
  "history_output" : "",
  "history_begin_time" : 1646139247177,
  "history_end_time" : 1646139250157,
  "history_notes" : null,
  "history_process" : "mw544v",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "wagyfftxolx",
  "history_input" : "import pandas as pd\nimport xarray as xr\nfrom datetime import date\nfrom tqdm import tqdm\n\nfrom src_exporters_sentinel_base import BaseSentinelExporter\nfrom src_exporters_geowiki import GeoWikiExporter\nfrom src_exporters_sentinel_utils import EEBoundingBox, bounding_box_from_centre\n\nfrom typing import Optional, List\n\n\nclass GeoWikiSentinelExporter(BaseSentinelExporter):\n\n    dataset = \"earth_engine_geowiki\"\n\n    def load_labels(self) -> pd.DataFrame:\n        # right now, this just loads geowiki data. In the future,\n        # it would be neat to merge all labels together\n        geowiki = self.data_folder / \"processed\" / GeoWikiExporter.dataset / \"data.nc\"\n        assert geowiki.exists(), \"GeoWiki processor must be run to load labels\"\n        return xr.open_dataset(geowiki).to_dataframe().dropna().reset_index()\n\n    def labels_to_bounding_boxes(\n        self, num_labelled_points: Optional[int], surrounding_metres: int\n    ) -> List[EEBoundingBox]:\n\n        output: List[EEBoundingBox] = []\n\n        for idx, row in tqdm(self.labels.iterrows()):\n            output.append(\n                bounding_box_from_centre(\n                    mid_lat=row[\"lat\"], mid_lon=row[\"lon\"], surrounding_metres=surrounding_metres,\n                )\n            )\n\n            if num_labelled_points is not None:\n                if len(output) >= num_labelled_points:\n                    return output\n        return output\n\n    def export_for_labels(\n        self,\n        days_per_timestep: int = 30,\n        start_date: date = date(2017, 3, 28),\n        end_date: date = date(2018, 3, 28),\n        num_labelled_points: Optional[int] = None,\n        surrounding_metres: int = 80,\n        checkpoint: bool = True,\n        monitor: bool = False,\n        fast: bool = True,\n    ) -> None:\n        r\"\"\"\n        Run the GeoWiki exporter. For each label, the exporter will export\n        int( (end_date - start_date).days / days_per_timestep) timesteps of data,\n        where each timestep consists of a mosaic of all available images within the\n        days_per_timestep of that timestep.\n        :param days_per_timestep: The number of days of data to use for each mosaiced image.\n        :param start_date: The start data of the data export\n        :param end_date: The end date of the data export\n        :param num_labelled_points: (Optional) The number of labelled points to export.\n        :param surrounding_metres: The number of metres surrounding each labelled point to export\n        :param checkpoint: Whether or not to check in self.data_folder to see if the file has\n            already been exported. If it has, skip it\n        :param monitor: Whether to monitor each task until it has been run\n        :param fast: Whether to use the faster cloudfree exporter. This function is considerably\n            faster, but cloud artefacts can be more pronounced. Default = True\n        \"\"\"\n        assert start_date >= self.min_date, f\"Sentinel data does not exist before {self.min_date}\"\n\n        bounding_boxes_to_download = self.labels_to_bounding_boxes(\n            num_labelled_points=num_labelled_points, surrounding_metres=surrounding_metres,\n        )\n\n        for idx, bounding_box in enumerate(bounding_boxes_to_download):\n            self._export_for_polygon(\n                polygon=bounding_box.to_ee_polygon(),\n                polygon_identifier=idx,\n                start_date=start_date,\n                end_date=end_date,\n                days_per_timestep=days_per_timestep,\n                checkpoint=checkpoint,\n                monitor=monitor,\n                fast=fast,\n            )\n",
  "history_output" : "",
  "history_begin_time" : 1646139195416,
  "history_end_time" : 1646139198677,
  "history_notes" : null,
  "history_process" : "mw544v",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "34s84wx7x4u",
  "history_input" : "import pandas as pd\nimport xarray as xr\nfrom datetime import date\nfrom tqdm import tqdm\n\nfrom src_exporters_sentinel_base import BaseSentinelExporter\nfrom src_exporters_geowiki import GeoWikiExporter\nfrom src_exporters_sentinel_utils import EEBoundingBox, bounding_box_from_centre\n\nfrom typing import Optional, List\n\n\nclass GeoWikiSentinelExporter(BaseSentinelExporter):\n\n    dataset = \"earth_engine_geowiki\"\n\n    def load_labels(self) -> pd.DataFrame:\n        # right now, this just loads geowiki data. In the future,\n        # it would be neat to merge all labels together\n        geowiki = self.data_folder / \"processed\" / GeoWikiExporter.dataset / \"data.nc\"\n        assert geowiki.exists(), \"GeoWiki processor must be run to load labels\"\n        return xr.open_dataset(geowiki).to_dataframe().dropna().reset_index()\n\n    def labels_to_bounding_boxes(\n        self, num_labelled_points: Optional[int], surrounding_metres: int\n    ) -> List[EEBoundingBox]:\n\n        output: List[EEBoundingBox] = []\n\n        for idx, row in tqdm(self.labels.iterrows()):\n            output.append(\n                bounding_box_from_centre(\n                    mid_lat=row[\"lat\"], mid_lon=row[\"lon\"], surrounding_metres=surrounding_metres,\n                )\n            )\n\n            if num_labelled_points is not None:\n                if len(output) >= num_labelled_points:\n                    return output\n        return output\n\n    def export_for_labels(\n        self,\n        days_per_timestep: int = 30,\n        start_date: date = date(2017, 3, 28),\n        end_date: date = date(2018, 3, 28),\n        num_labelled_points: Optional[int] = None,\n        surrounding_metres: int = 80,\n        checkpoint: bool = True,\n        monitor: bool = False,\n        fast: bool = True,\n    ) -> None:\n        r\"\"\"\n        Run the GeoWiki exporter. For each label, the exporter will export\n        int( (end_date - start_date).days / days_per_timestep) timesteps of data,\n        where each timestep consists of a mosaic of all available images within the\n        days_per_timestep of that timestep.\n        :param days_per_timestep: The number of days of data to use for each mosaiced image.\n        :param start_date: The start data of the data export\n        :param end_date: The end date of the data export\n        :param num_labelled_points: (Optional) The number of labelled points to export.\n        :param surrounding_metres: The number of metres surrounding each labelled point to export\n        :param checkpoint: Whether or not to check in self.data_folder to see if the file has\n            already been exported. If it has, skip it\n        :param monitor: Whether to monitor each task until it has been run\n        :param fast: Whether to use the faster cloudfree exporter. This function is considerably\n            faster, but cloud artefacts can be more pronounced. Default = True\n        \"\"\"\n        assert start_date >= self.min_date, f\"Sentinel data does not exist before {self.min_date}\"\n\n        bounding_boxes_to_download = self.labels_to_bounding_boxes(\n            num_labelled_points=num_labelled_points, surrounding_metres=surrounding_metres,\n        )\n\n        for idx, bounding_box in enumerate(bounding_boxes_to_download):\n            self._export_for_polygon(\n                polygon=bounding_box.to_ee_polygon(),\n                polygon_identifier=idx,\n                start_date=start_date,\n                end_date=end_date,\n                days_per_timestep=days_per_timestep,\n                checkpoint=checkpoint,\n                monitor=monitor,\n                fast=fast,\n            )\n",
  "history_output" : "",
  "history_begin_time" : 1646139160594,
  "history_end_time" : 1646139161003,
  "history_notes" : null,
  "history_process" : "mw544v",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "oyg7sdz72zm",
  "history_input" : "import pandas as pd\nimport xarray as xr\nfrom datetime import date\nfrom tqdm import tqdm\n\nfrom src_exporters_sentinel_base import BaseSentinelExporter\nfrom src_exporters_geowiki import GeoWikiExporter\nfrom src_exporters_sentinel_utils import EEBoundingBox, bounding_box_from_centre\n\nfrom typing import Optional, List\n\n\nclass GeoWikiSentinelExporter(BaseSentinelExporter):\n\n    dataset = \"earth_engine_geowiki\"\n\n    def load_labels(self) -> pd.DataFrame:\n        # right now, this just loads geowiki data. In the future,\n        # it would be neat to merge all labels together\n        geowiki = self.data_folder / \"processed\" / GeoWikiExporter.dataset / \"data.nc\"\n        assert geowiki.exists(), \"GeoWiki processor must be run to load labels\"\n        return xr.open_dataset(geowiki).to_dataframe().dropna().reset_index()\n\n    def labels_to_bounding_boxes(\n        self, num_labelled_points: Optional[int], surrounding_metres: int\n    ) -> List[EEBoundingBox]:\n\n        output: List[EEBoundingBox] = []\n\n        for idx, row in tqdm(self.labels.iterrows()):\n            output.append(\n                bounding_box_from_centre(\n                    mid_lat=row[\"lat\"], mid_lon=row[\"lon\"], surrounding_metres=surrounding_metres,\n                )\n            )\n\n            if num_labelled_points is not None:\n                if len(output) >= num_labelled_points:\n                    return output\n        return output\n\n    def export_for_labels(\n        self,\n        days_per_timestep: int = 30,\n        start_date: date = date(2017, 3, 28),\n        end_date: date = date(2018, 3, 28),\n        num_labelled_points: Optional[int] = None,\n        surrounding_metres: int = 80,\n        checkpoint: bool = True,\n        monitor: bool = False,\n        fast: bool = True,\n    ) -> None:\n        r\"\"\"\n        Run the GeoWiki exporter. For each label, the exporter will export\n        int( (end_date - start_date).days / days_per_timestep) timesteps of data,\n        where each timestep consists of a mosaic of all available images within the\n        days_per_timestep of that timestep.\n        :param days_per_timestep: The number of days of data to use for each mosaiced image.\n        :param start_date: The start data of the data export\n        :param end_date: The end date of the data export\n        :param num_labelled_points: (Optional) The number of labelled points to export.\n        :param surrounding_metres: The number of metres surrounding each labelled point to export\n        :param checkpoint: Whether or not to check in self.data_folder to see if the file has\n            already been exported. If it has, skip it\n        :param monitor: Whether to monitor each task until it has been run\n        :param fast: Whether to use the faster cloudfree exporter. This function is considerably\n            faster, but cloud artefacts can be more pronounced. Default = True\n        \"\"\"\n        assert start_date >= self.min_date, f\"Sentinel data does not exist before {self.min_date}\"\n\n        bounding_boxes_to_download = self.labels_to_bounding_boxes(\n            num_labelled_points=num_labelled_points, surrounding_metres=surrounding_metres,\n        )\n\n        for idx, bounding_box in enumerate(bounding_boxes_to_download):\n            self._export_for_polygon(\n                polygon=bounding_box.to_ee_polygon(),\n                polygon_identifier=idx,\n                start_date=start_date,\n                end_date=end_date,\n                days_per_timestep=days_per_timestep,\n                checkpoint=checkpoint,\n                monitor=monitor,\n                fast=fast,\n            )\n",
  "history_output" : "",
  "history_begin_time" : 1646138499472,
  "history_end_time" : 1646138502319,
  "history_notes" : null,
  "history_process" : "mw544v",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "1iuvo8w7m42",
  "history_input" : "import pandas as pd\nimport xarray as xr\nfrom datetime import date\nfrom tqdm import tqdm\n\nfrom src_exporters_sentinel_base import BaseSentinelExporter\nfrom src_exporters_geowiki import GeoWikiExporter\nfrom src_exporters_sentinel_utils import EEBoundingBox, bounding_box_from_centre\n\nfrom typing import Optional, List\n\n\nclass GeoWikiSentinelExporter(BaseSentinelExporter):\n\n    dataset = \"earth_engine_geowiki\"\n\n    def load_labels(self) -> pd.DataFrame:\n        # right now, this just loads geowiki data. In the future,\n        # it would be neat to merge all labels together\n        geowiki = self.data_folder / \"processed\" / GeoWikiExporter.dataset / \"data.nc\"\n        assert geowiki.exists(), \"GeoWiki processor must be run to load labels\"\n        return xr.open_dataset(geowiki).to_dataframe().dropna().reset_index()\n\n    def labels_to_bounding_boxes(\n        self, num_labelled_points: Optional[int], surrounding_metres: int\n    ) -> List[EEBoundingBox]:\n\n        output: List[EEBoundingBox] = []\n\n        for idx, row in tqdm(self.labels.iterrows()):\n            output.append(\n                bounding_box_from_centre(\n                    mid_lat=row[\"lat\"], mid_lon=row[\"lon\"], surrounding_metres=surrounding_metres,\n                )\n            )\n\n            if num_labelled_points is not None:\n                if len(output) >= num_labelled_points:\n                    return output\n        return output\n\n    def export_for_labels(\n        self,\n        days_per_timestep: int = 30,\n        start_date: date = date(2017, 3, 28),\n        end_date: date = date(2018, 3, 28),\n        num_labelled_points: Optional[int] = None,\n        surrounding_metres: int = 80,\n        checkpoint: bool = True,\n        monitor: bool = False,\n        fast: bool = True,\n    ) -> None:\n        r\"\"\"\n        Run the GeoWiki exporter. For each label, the exporter will export\n        int( (end_date - start_date).days / days_per_timestep) timesteps of data,\n        where each timestep consists of a mosaic of all available images within the\n        days_per_timestep of that timestep.\n        :param days_per_timestep: The number of days of data to use for each mosaiced image.\n        :param start_date: The start data of the data export\n        :param end_date: The end date of the data export\n        :param num_labelled_points: (Optional) The number of labelled points to export.\n        :param surrounding_metres: The number of metres surrounding each labelled point to export\n        :param checkpoint: Whether or not to check in self.data_folder to see if the file has\n            already been exported. If it has, skip it\n        :param monitor: Whether to monitor each task until it has been run\n        :param fast: Whether to use the faster cloudfree exporter. This function is considerably\n            faster, but cloud artefacts can be more pronounced. Default = True\n        \"\"\"\n        assert start_date >= self.min_date, f\"Sentinel data does not exist before {self.min_date}\"\n\n        bounding_boxes_to_download = self.labels_to_bounding_boxes(\n            num_labelled_points=num_labelled_points, surrounding_metres=surrounding_metres,\n        )\n\n        for idx, bounding_box in enumerate(bounding_boxes_to_download):\n            self._export_for_polygon(\n                polygon=bounding_box.to_ee_polygon(),\n                polygon_identifier=idx,\n                start_date=start_date,\n                end_date=end_date,\n                days_per_timestep=days_per_timestep,\n                checkpoint=checkpoint,\n                monitor=monitor,\n                fast=fast,\n            )\n",
  "history_output" : "",
  "history_begin_time" : 1646138451922,
  "history_end_time" : 1646138452178,
  "history_notes" : null,
  "history_process" : "mw544v",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "63483nyxidy",
  "history_input" : "import pandas as pd\nimport xarray as xr\nfrom datetime import date\nfrom tqdm import tqdm\n\nfrom src_exporters_sentinel_base import BaseSentinelExporter\nfrom src_exporters_geowiki import GeoWikiExporter\nfrom src_exporters_sentinel_utils import EEBoundingBox, bounding_box_from_centre\n\nfrom typing import Optional, List\n\n\nclass GeoWikiSentinelExporter(BaseSentinelExporter):\n\n    dataset = \"earth_engine_geowiki\"\n\n    def load_labels(self) -> pd.DataFrame:\n        # right now, this just loads geowiki data. In the future,\n        # it would be neat to merge all labels together\n        geowiki = self.data_folder / \"processed\" / GeoWikiExporter.dataset / \"data.nc\"\n        assert geowiki.exists(), \"GeoWiki processor must be run to load labels\"\n        return xr.open_dataset(geowiki).to_dataframe().dropna().reset_index()\n\n    def labels_to_bounding_boxes(\n        self, num_labelled_points: Optional[int], surrounding_metres: int\n    ) -> List[EEBoundingBox]:\n\n        output: List[EEBoundingBox] = []\n\n        for idx, row in tqdm(self.labels.iterrows()):\n            output.append(\n                bounding_box_from_centre(\n                    mid_lat=row[\"lat\"], mid_lon=row[\"lon\"], surrounding_metres=surrounding_metres,\n                )\n            )\n\n            if num_labelled_points is not None:\n                if len(output) >= num_labelled_points:\n                    return output\n        return output\n\n    def export_for_labels(\n        self,\n        days_per_timestep: int = 30,\n        start_date: date = date(2017, 3, 28),\n        end_date: date = date(2018, 3, 28),\n        num_labelled_points: Optional[int] = None,\n        surrounding_metres: int = 80,\n        checkpoint: bool = True,\n        monitor: bool = False,\n        fast: bool = True,\n    ) -> None:\n        r\"\"\"\n        Run the GeoWiki exporter. For each label, the exporter will export\n        int( (end_date - start_date).days / days_per_timestep) timesteps of data,\n        where each timestep consists of a mosaic of all available images within the\n        days_per_timestep of that timestep.\n        :param days_per_timestep: The number of days of data to use for each mosaiced image.\n        :param start_date: The start data of the data export\n        :param end_date: The end date of the data export\n        :param num_labelled_points: (Optional) The number of labelled points to export.\n        :param surrounding_metres: The number of metres surrounding each labelled point to export\n        :param checkpoint: Whether or not to check in self.data_folder to see if the file has\n            already been exported. If it has, skip it\n        :param monitor: Whether to monitor each task until it has been run\n        :param fast: Whether to use the faster cloudfree exporter. This function is considerably\n            faster, but cloud artefacts can be more pronounced. Default = True\n        \"\"\"\n        assert start_date >= self.min_date, f\"Sentinel data does not exist before {self.min_date}\"\n\n        bounding_boxes_to_download = self.labels_to_bounding_boxes(\n            num_labelled_points=num_labelled_points, surrounding_metres=surrounding_metres,\n        )\n\n        for idx, bounding_box in enumerate(bounding_boxes_to_download):\n            self._export_for_polygon(\n                polygon=bounding_box.to_ee_polygon(),\n                polygon_identifier=idx,\n                start_date=start_date,\n                end_date=end_date,\n                days_per_timestep=days_per_timestep,\n                checkpoint=checkpoint,\n                monitor=monitor,\n                fast=fast,\n            )\n",
  "history_output" : "",
  "history_begin_time" : 1646138399499,
  "history_end_time" : 1646138402467,
  "history_notes" : null,
  "history_process" : "mw544v",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "lecs7rt88jp",
  "history_input" : "import pandas as pd\nimport xarray as xr\nfrom datetime import date\nfrom tqdm import tqdm\n\nfrom src_exporters_sentinel_base import BaseSentinelExporter\nfrom src_exporters_geowiki import GeoWikiExporter\nfrom src_exporters_sentinel_utils import EEBoundingBox, bounding_box_from_centre\n\nfrom typing import Optional, List\n\n\nclass GeoWikiSentinelExporter(BaseSentinelExporter):\n\n    dataset = \"earth_engine_geowiki\"\n\n    def load_labels(self) -> pd.DataFrame:\n        # right now, this just loads geowiki data. In the future,\n        # it would be neat to merge all labels together\n        geowiki = self.data_folder / \"processed\" / GeoWikiExporter.dataset / \"data.nc\"\n        assert geowiki.exists(), \"GeoWiki processor must be run to load labels\"\n        return xr.open_dataset(geowiki).to_dataframe().dropna().reset_index()\n\n    def labels_to_bounding_boxes(\n        self, num_labelled_points: Optional[int], surrounding_metres: int\n    ) -> List[EEBoundingBox]:\n\n        output: List[EEBoundingBox] = []\n\n        for idx, row in tqdm(self.labels.iterrows()):\n            output.append(\n                bounding_box_from_centre(\n                    mid_lat=row[\"lat\"], mid_lon=row[\"lon\"], surrounding_metres=surrounding_metres,\n                )\n            )\n\n            if num_labelled_points is not None:\n                if len(output) >= num_labelled_points:\n                    return output\n        return output\n\n    def export_for_labels(\n        self,\n        days_per_timestep: int = 30,\n        start_date: date = date(2017, 3, 28),\n        end_date: date = date(2018, 3, 28),\n        num_labelled_points: Optional[int] = None,\n        surrounding_metres: int = 80,\n        checkpoint: bool = True,\n        monitor: bool = False,\n        fast: bool = True,\n    ) -> None:\n        r\"\"\"\n        Run the GeoWiki exporter. For each label, the exporter will export\n        int( (end_date - start_date).days / days_per_timestep) timesteps of data,\n        where each timestep consists of a mosaic of all available images within the\n        days_per_timestep of that timestep.\n        :param days_per_timestep: The number of days of data to use for each mosaiced image.\n        :param start_date: The start data of the data export\n        :param end_date: The end date of the data export\n        :param num_labelled_points: (Optional) The number of labelled points to export.\n        :param surrounding_metres: The number of metres surrounding each labelled point to export\n        :param checkpoint: Whether or not to check in self.data_folder to see if the file has\n            already been exported. If it has, skip it\n        :param monitor: Whether to monitor each task until it has been run\n        :param fast: Whether to use the faster cloudfree exporter. This function is considerably\n            faster, but cloud artefacts can be more pronounced. Default = True\n        \"\"\"\n        assert start_date >= self.min_date, f\"Sentinel data does not exist before {self.min_date}\"\n\n        bounding_boxes_to_download = self.labels_to_bounding_boxes(\n            num_labelled_points=num_labelled_points, surrounding_metres=surrounding_metres,\n        )\n\n        for idx, bounding_box in enumerate(bounding_boxes_to_download):\n            self._export_for_polygon(\n                polygon=bounding_box.to_ee_polygon(),\n                polygon_identifier=idx,\n                start_date=start_date,\n                end_date=end_date,\n                days_per_timestep=days_per_timestep,\n                checkpoint=checkpoint,\n                monitor=monitor,\n                fast=fast,\n            )\n",
  "history_output" : "",
  "history_begin_time" : 1646138272395,
  "history_end_time" : 1646138276464,
  "history_notes" : null,
  "history_process" : "mw544v",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "rfaugt171z2",
  "history_input" : "import pandas as pd\nimport xarray as xr\nfrom datetime import date\nfrom tqdm import tqdm\n\nfrom src_exporters_sentinel_base import BaseSentinelExporter\nfrom src_exporters_geowiki import GeoWikiExporter\nfrom src_exporters_sentinel_utils import EEBoundingBox, bounding_box_from_centre\n\nfrom typing import Optional, List\n\n\nclass GeoWikiSentinelExporter(BaseSentinelExporter):\n\n    dataset = \"earth_engine_geowiki\"\n\n    def load_labels(self) -> pd.DataFrame:\n        # right now, this just loads geowiki data. In the future,\n        # it would be neat to merge all labels together\n        geowiki = self.data_folder / \"processed\" / GeoWikiExporter.dataset / \"data.nc\"\n        assert geowiki.exists(), \"GeoWiki processor must be run to load labels\"\n        return xr.open_dataset(geowiki).to_dataframe().dropna().reset_index()\n\n    def labels_to_bounding_boxes(\n        self, num_labelled_points: Optional[int], surrounding_metres: int\n    ) -> List[EEBoundingBox]:\n\n        output: List[EEBoundingBox] = []\n\n        for idx, row in tqdm(self.labels.iterrows()):\n            output.append(\n                bounding_box_from_centre(\n                    mid_lat=row[\"lat\"], mid_lon=row[\"lon\"], surrounding_metres=surrounding_metres,\n                )\n            )\n\n            if num_labelled_points is not None:\n                if len(output) >= num_labelled_points:\n                    return output\n        return output\n\n    def export_for_labels(\n        self,\n        days_per_timestep: int = 30,\n        start_date: date = date(2017, 3, 28),\n        end_date: date = date(2018, 3, 28),\n        num_labelled_points: Optional[int] = None,\n        surrounding_metres: int = 80,\n        checkpoint: bool = True,\n        monitor: bool = False,\n        fast: bool = True,\n    ) -> None:\n        r\"\"\"\n        Run the GeoWiki exporter. For each label, the exporter will export\n        int( (end_date - start_date).days / days_per_timestep) timesteps of data,\n        where each timestep consists of a mosaic of all available images within the\n        days_per_timestep of that timestep.\n        :param days_per_timestep: The number of days of data to use for each mosaiced image.\n        :param start_date: The start data of the data export\n        :param end_date: The end date of the data export\n        :param num_labelled_points: (Optional) The number of labelled points to export.\n        :param surrounding_metres: The number of metres surrounding each labelled point to export\n        :param checkpoint: Whether or not to check in self.data_folder to see if the file has\n            already been exported. If it has, skip it\n        :param monitor: Whether to monitor each task until it has been run\n        :param fast: Whether to use the faster cloudfree exporter. This function is considerably\n            faster, but cloud artefacts can be more pronounced. Default = True\n        \"\"\"\n        assert start_date >= self.min_date, f\"Sentinel data does not exist before {self.min_date}\"\n\n        bounding_boxes_to_download = self.labels_to_bounding_boxes(\n            num_labelled_points=num_labelled_points, surrounding_metres=surrounding_metres,\n        )\n\n        for idx, bounding_box in enumerate(bounding_boxes_to_download):\n            self._export_for_polygon(\n                polygon=bounding_box.to_ee_polygon(),\n                polygon_identifier=idx,\n                start_date=start_date,\n                end_date=end_date,\n                days_per_timestep=days_per_timestep,\n                checkpoint=checkpoint,\n                monitor=monitor,\n                fast=fast,\n            )\n",
  "history_output" : "",
  "history_begin_time" : 1646138180482,
  "history_end_time" : 1646138183976,
  "history_notes" : null,
  "history_process" : "mw544v",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "2x9ugjs6jlh",
  "history_input" : "import pandas as pd\nimport xarray as xr\nfrom datetime import date\nfrom tqdm import tqdm\n\nfrom src_exporters_sentinel_base import BaseSentinelExporter\nfrom src_exporters_geowiki import GeoWikiExporter\nfrom src_exporters_sentinel_utils import EEBoundingBox, bounding_box_from_centre\n\nfrom typing import Optional, List\n\n\nclass GeoWikiSentinelExporter(BaseSentinelExporter):\n\n    dataset = \"earth_engine_geowiki\"\n\n    def load_labels(self) -> pd.DataFrame:\n        # right now, this just loads geowiki data. In the future,\n        # it would be neat to merge all labels together\n        geowiki = self.data_folder / \"processed\" / GeoWikiExporter.dataset / \"data.nc\"\n        assert geowiki.exists(), \"GeoWiki processor must be run to load labels\"\n        return xr.open_dataset(geowiki).to_dataframe().dropna().reset_index()\n\n    def labels_to_bounding_boxes(\n        self, num_labelled_points: Optional[int], surrounding_metres: int\n    ) -> List[EEBoundingBox]:\n\n        output: List[EEBoundingBox] = []\n\n        for idx, row in tqdm(self.labels.iterrows()):\n            output.append(\n                bounding_box_from_centre(\n                    mid_lat=row[\"lat\"], mid_lon=row[\"lon\"], surrounding_metres=surrounding_metres,\n                )\n            )\n\n            if num_labelled_points is not None:\n                if len(output) >= num_labelled_points:\n                    return output\n        return output\n\n    def export_for_labels(\n        self,\n        days_per_timestep: int = 30,\n        start_date: date = date(2017, 3, 28),\n        end_date: date = date(2018, 3, 28),\n        num_labelled_points: Optional[int] = None,\n        surrounding_metres: int = 80,\n        checkpoint: bool = True,\n        monitor: bool = False,\n        fast: bool = True,\n    ) -> None:\n        r\"\"\"\n        Run the GeoWiki exporter. For each label, the exporter will export\n        int( (end_date - start_date).days / days_per_timestep) timesteps of data,\n        where each timestep consists of a mosaic of all available images within the\n        days_per_timestep of that timestep.\n        :param days_per_timestep: The number of days of data to use for each mosaiced image.\n        :param start_date: The start data of the data export\n        :param end_date: The end date of the data export\n        :param num_labelled_points: (Optional) The number of labelled points to export.\n        :param surrounding_metres: The number of metres surrounding each labelled point to export\n        :param checkpoint: Whether or not to check in self.data_folder to see if the file has\n            already been exported. If it has, skip it\n        :param monitor: Whether to monitor each task until it has been run\n        :param fast: Whether to use the faster cloudfree exporter. This function is considerably\n            faster, but cloud artefacts can be more pronounced. Default = True\n        \"\"\"\n        assert start_date >= self.min_date, f\"Sentinel data does not exist before {self.min_date}\"\n\n        bounding_boxes_to_download = self.labels_to_bounding_boxes(\n            num_labelled_points=num_labelled_points, surrounding_metres=surrounding_metres,\n        )\n\n        for idx, bounding_box in enumerate(bounding_boxes_to_download):\n            self._export_for_polygon(\n                polygon=bounding_box.to_ee_polygon(),\n                polygon_identifier=idx,\n                start_date=start_date,\n                end_date=end_date,\n                days_per_timestep=days_per_timestep,\n                checkpoint=checkpoint,\n                monitor=monitor,\n                fast=fast,\n            )\n",
  "history_output" : "",
  "history_begin_time" : 1646138104378,
  "history_end_time" : 1646138107874,
  "history_notes" : null,
  "history_process" : "mw544v",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "n6ph1pf49lj",
  "history_input" : "import pandas as pd\nimport xarray as xr\nfrom datetime import date\nfrom tqdm import tqdm\n\nfrom src_exporters_sentinel_base import BaseSentinelExporter\nfrom src_exporters_geowiki import GeoWikiExporter\nfrom src_exporters_sentinel_utils import EEBoundingBox, bounding_box_from_centre\n\nfrom typing import Optional, List\n\n\nclass GeoWikiSentinelExporter(BaseSentinelExporter):\n\n    dataset = \"earth_engine_geowiki\"\n\n    def load_labels(self) -> pd.DataFrame:\n        # right now, this just loads geowiki data. In the future,\n        # it would be neat to merge all labels together\n        geowiki = self.data_folder / \"processed\" / GeoWikiExporter.dataset / \"data.nc\"\n        assert geowiki.exists(), \"GeoWiki processor must be run to load labels\"\n        return xr.open_dataset(geowiki).to_dataframe().dropna().reset_index()\n\n    def labels_to_bounding_boxes(\n        self, num_labelled_points: Optional[int], surrounding_metres: int\n    ) -> List[EEBoundingBox]:\n\n        output: List[EEBoundingBox] = []\n\n        for idx, row in tqdm(self.labels.iterrows()):\n            output.append(\n                bounding_box_from_centre(\n                    mid_lat=row[\"lat\"], mid_lon=row[\"lon\"], surrounding_metres=surrounding_metres,\n                )\n            )\n\n            if num_labelled_points is not None:\n                if len(output) >= num_labelled_points:\n                    return output\n        return output\n\n    def export_for_labels(\n        self,\n        days_per_timestep: int = 30,\n        start_date: date = date(2017, 3, 28),\n        end_date: date = date(2018, 3, 28),\n        num_labelled_points: Optional[int] = None,\n        surrounding_metres: int = 80,\n        checkpoint: bool = True,\n        monitor: bool = False,\n        fast: bool = True,\n    ) -> None:\n        r\"\"\"\n        Run the GeoWiki exporter. For each label, the exporter will export\n        int( (end_date - start_date).days / days_per_timestep) timesteps of data,\n        where each timestep consists of a mosaic of all available images within the\n        days_per_timestep of that timestep.\n        :param days_per_timestep: The number of days of data to use for each mosaiced image.\n        :param start_date: The start data of the data export\n        :param end_date: The end date of the data export\n        :param num_labelled_points: (Optional) The number of labelled points to export.\n        :param surrounding_metres: The number of metres surrounding each labelled point to export\n        :param checkpoint: Whether or not to check in self.data_folder to see if the file has\n            already been exported. If it has, skip it\n        :param monitor: Whether to monitor each task until it has been run\n        :param fast: Whether to use the faster cloudfree exporter. This function is considerably\n            faster, but cloud artefacts can be more pronounced. Default = True\n        \"\"\"\n        assert start_date >= self.min_date, f\"Sentinel data does not exist before {self.min_date}\"\n\n        bounding_boxes_to_download = self.labels_to_bounding_boxes(\n            num_labelled_points=num_labelled_points, surrounding_metres=surrounding_metres,\n        )\n\n        for idx, bounding_box in enumerate(bounding_boxes_to_download):\n            self._export_for_polygon(\n                polygon=bounding_box.to_ee_polygon(),\n                polygon_identifier=idx,\n                start_date=start_date,\n                end_date=end_date,\n                days_per_timestep=days_per_timestep,\n                checkpoint=checkpoint,\n                monitor=monitor,\n                fast=fast,\n            )\n",
  "history_output" : "",
  "history_begin_time" : 1646137788838,
  "history_end_time" : 1646137792655,
  "history_notes" : null,
  "history_process" : "mw544v",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "6q54f8gqsdt",
  "history_input" : "import pandas as pd\nimport xarray as xr\nfrom datetime import date\nfrom tqdm import tqdm\n\nfrom src_exporters_sentinel_base import BaseSentinelExporter\nfrom src_exporters_geowiki import GeoWikiExporter\nfrom src_exporters_sentinel_utils import EEBoundingBox, bounding_box_from_centre\n\nfrom typing import Optional, List\n\n\nclass GeoWikiSentinelExporter(BaseSentinelExporter):\n\n    dataset = \"earth_engine_geowiki\"\n\n    def load_labels(self) -> pd.DataFrame:\n        # right now, this just loads geowiki data. In the future,\n        # it would be neat to merge all labels together\n        geowiki = self.data_folder / \"processed\" / GeoWikiExporter.dataset / \"data.nc\"\n        assert geowiki.exists(), \"GeoWiki processor must be run to load labels\"\n        return xr.open_dataset(geowiki).to_dataframe().dropna().reset_index()\n\n    def labels_to_bounding_boxes(\n        self, num_labelled_points: Optional[int], surrounding_metres: int\n    ) -> List[EEBoundingBox]:\n\n        output: List[EEBoundingBox] = []\n\n        for idx, row in tqdm(self.labels.iterrows()):\n            output.append(\n                bounding_box_from_centre(\n                    mid_lat=row[\"lat\"], mid_lon=row[\"lon\"], surrounding_metres=surrounding_metres,\n                )\n            )\n\n            if num_labelled_points is not None:\n                if len(output) >= num_labelled_points:\n                    return output\n        return output\n\n    def export_for_labels(\n        self,\n        days_per_timestep: int = 30,\n        start_date: date = date(2017, 3, 28),\n        end_date: date = date(2018, 3, 28),\n        num_labelled_points: Optional[int] = None,\n        surrounding_metres: int = 80,\n        checkpoint: bool = True,\n        monitor: bool = False,\n        fast: bool = True,\n    ) -> None:\n        r\"\"\"\n        Run the GeoWiki exporter. For each label, the exporter will export\n        int( (end_date - start_date).days / days_per_timestep) timesteps of data,\n        where each timestep consists of a mosaic of all available images within the\n        days_per_timestep of that timestep.\n        :param days_per_timestep: The number of days of data to use for each mosaiced image.\n        :param start_date: The start data of the data export\n        :param end_date: The end date of the data export\n        :param num_labelled_points: (Optional) The number of labelled points to export.\n        :param surrounding_metres: The number of metres surrounding each labelled point to export\n        :param checkpoint: Whether or not to check in self.data_folder to see if the file has\n            already been exported. If it has, skip it\n        :param monitor: Whether to monitor each task until it has been run\n        :param fast: Whether to use the faster cloudfree exporter. This function is considerably\n            faster, but cloud artefacts can be more pronounced. Default = True\n        \"\"\"\n        assert start_date >= self.min_date, f\"Sentinel data does not exist before {self.min_date}\"\n\n        bounding_boxes_to_download = self.labels_to_bounding_boxes(\n            num_labelled_points=num_labelled_points, surrounding_metres=surrounding_metres,\n        )\n\n        for idx, bounding_box in enumerate(bounding_boxes_to_download):\n            self._export_for_polygon(\n                polygon=bounding_box.to_ee_polygon(),\n                polygon_identifier=idx,\n                start_date=start_date,\n                end_date=end_date,\n                days_per_timestep=days_per_timestep,\n                checkpoint=checkpoint,\n                monitor=monitor,\n                fast=fast,\n            )\n",
  "history_output" : "",
  "history_begin_time" : 1646137691972,
  "history_end_time" : 1646137694449,
  "history_notes" : null,
  "history_process" : "mw544v",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "x5j53vwpais",
  "history_input" : "import pandas as pd\nimport xarray as xr\nfrom datetime import date\nfrom tqdm import tqdm\n\nfrom src_exporters_sentinel_base import BaseSentinelExporter\nfrom src_exporters_geowiki import GeoWikiExporter\nfrom src_exporters_sentinel_utils import EEBoundingBox, bounding_box_from_centre\n\nfrom typing import Optional, List\n\n\nclass GeoWikiSentinelExporter(BaseSentinelExporter):\n\n    dataset = \"earth_engine_geowiki\"\n\n    def load_labels(self) -> pd.DataFrame:\n        # right now, this just loads geowiki data. In the future,\n        # it would be neat to merge all labels together\n        geowiki = self.data_folder / \"processed\" / GeoWikiExporter.dataset / \"data.nc\"\n        assert geowiki.exists(), \"GeoWiki processor must be run to load labels\"\n        return xr.open_dataset(geowiki).to_dataframe().dropna().reset_index()\n\n    def labels_to_bounding_boxes(\n        self, num_labelled_points: Optional[int], surrounding_metres: int\n    ) -> List[EEBoundingBox]:\n\n        output: List[EEBoundingBox] = []\n\n        for idx, row in tqdm(self.labels.iterrows()):\n            output.append(\n                bounding_box_from_centre(\n                    mid_lat=row[\"lat\"], mid_lon=row[\"lon\"], surrounding_metres=surrounding_metres,\n                )\n            )\n\n            if num_labelled_points is not None:\n                if len(output) >= num_labelled_points:\n                    return output\n        return output\n\n    def export_for_labels(\n        self,\n        days_per_timestep: int = 30,\n        start_date: date = date(2017, 3, 28),\n        end_date: date = date(2018, 3, 28),\n        num_labelled_points: Optional[int] = None,\n        surrounding_metres: int = 80,\n        checkpoint: bool = True,\n        monitor: bool = False,\n        fast: bool = True,\n    ) -> None:\n        r\"\"\"\n        Run the GeoWiki exporter. For each label, the exporter will export\n        int( (end_date - start_date).days / days_per_timestep) timesteps of data,\n        where each timestep consists of a mosaic of all available images within the\n        days_per_timestep of that timestep.\n        :param days_per_timestep: The number of days of data to use for each mosaiced image.\n        :param start_date: The start data of the data export\n        :param end_date: The end date of the data export\n        :param num_labelled_points: (Optional) The number of labelled points to export.\n        :param surrounding_metres: The number of metres surrounding each labelled point to export\n        :param checkpoint: Whether or not to check in self.data_folder to see if the file has\n            already been exported. If it has, skip it\n        :param monitor: Whether to monitor each task until it has been run\n        :param fast: Whether to use the faster cloudfree exporter. This function is considerably\n            faster, but cloud artefacts can be more pronounced. Default = True\n        \"\"\"\n        assert start_date >= self.min_date, f\"Sentinel data does not exist before {self.min_date}\"\n\n        bounding_boxes_to_download = self.labels_to_bounding_boxes(\n            num_labelled_points=num_labelled_points, surrounding_metres=surrounding_metres,\n        )\n\n        for idx, bounding_box in enumerate(bounding_boxes_to_download):\n            self._export_for_polygon(\n                polygon=bounding_box.to_ee_polygon(),\n                polygon_identifier=idx,\n                start_date=start_date,\n                end_date=end_date,\n                days_per_timestep=days_per_timestep,\n                checkpoint=checkpoint,\n                monitor=monitor,\n                fast=fast,\n            )\n",
  "history_output" : "",
  "history_begin_time" : 1646137583438,
  "history_end_time" : 1646137584470,
  "history_notes" : null,
  "history_process" : "mw544v",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "d364sol533j",
  "history_input" : "import pandas as pd\nimport xarray as xr\nfrom datetime import date\nfrom tqdm import tqdm\n\nfrom src_exporters_sentinel_base import BaseSentinelExporter\nfrom src_exporters_geowiki import GeoWikiExporter\nfrom src_exporters_sentinel_utils import EEBoundingBox, bounding_box_from_centre\n\nfrom typing import Optional, List\n\n\nclass GeoWikiSentinelExporter(BaseSentinelExporter):\n\n    dataset = \"earth_engine_geowiki\"\n\n    def load_labels(self) -> pd.DataFrame:\n        # right now, this just loads geowiki data. In the future,\n        # it would be neat to merge all labels together\n        geowiki = self.data_folder / \"processed\" / GeoWikiExporter.dataset / \"data.nc\"\n        assert geowiki.exists(), \"GeoWiki processor must be run to load labels\"\n        return xr.open_dataset(geowiki).to_dataframe().dropna().reset_index()\n\n    def labels_to_bounding_boxes(\n        self, num_labelled_points: Optional[int], surrounding_metres: int\n    ) -> List[EEBoundingBox]:\n\n        output: List[EEBoundingBox] = []\n\n        for idx, row in tqdm(self.labels.iterrows()):\n            output.append(\n                bounding_box_from_centre(\n                    mid_lat=row[\"lat\"], mid_lon=row[\"lon\"], surrounding_metres=surrounding_metres,\n                )\n            )\n\n            if num_labelled_points is not None:\n                if len(output) >= num_labelled_points:\n                    return output\n        return output\n\n    def export_for_labels(\n        self,\n        days_per_timestep: int = 30,\n        start_date: date = date(2017, 3, 28),\n        end_date: date = date(2018, 3, 28),\n        num_labelled_points: Optional[int] = None,\n        surrounding_metres: int = 80,\n        checkpoint: bool = True,\n        monitor: bool = False,\n        fast: bool = True,\n    ) -> None:\n        r\"\"\"\n        Run the GeoWiki exporter. For each label, the exporter will export\n        int( (end_date - start_date).days / days_per_timestep) timesteps of data,\n        where each timestep consists of a mosaic of all available images within the\n        days_per_timestep of that timestep.\n        :param days_per_timestep: The number of days of data to use for each mosaiced image.\n        :param start_date: The start data of the data export\n        :param end_date: The end date of the data export\n        :param num_labelled_points: (Optional) The number of labelled points to export.\n        :param surrounding_metres: The number of metres surrounding each labelled point to export\n        :param checkpoint: Whether or not to check in self.data_folder to see if the file has\n            already been exported. If it has, skip it\n        :param monitor: Whether to monitor each task until it has been run\n        :param fast: Whether to use the faster cloudfree exporter. This function is considerably\n            faster, but cloud artefacts can be more pronounced. Default = True\n        \"\"\"\n        assert start_date >= self.min_date, f\"Sentinel data does not exist before {self.min_date}\"\n\n        bounding_boxes_to_download = self.labels_to_bounding_boxes(\n            num_labelled_points=num_labelled_points, surrounding_metres=surrounding_metres,\n        )\n\n        for idx, bounding_box in enumerate(bounding_boxes_to_download):\n            self._export_for_polygon(\n                polygon=bounding_box.to_ee_polygon(),\n                polygon_identifier=idx,\n                start_date=start_date,\n                end_date=end_date,\n                days_per_timestep=days_per_timestep,\n                checkpoint=checkpoint,\n                monitor=monitor,\n                fast=fast,\n            )\n",
  "history_output" : "",
  "history_begin_time" : 1646112833934,
  "history_end_time" : 1646112837388,
  "history_notes" : null,
  "history_process" : "mw544v",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "a6ndvwubmq8",
  "history_input" : "import pandas as pd\nimport xarray as xr\nfrom datetime import date\nfrom tqdm import tqdm\n\nfrom src_exporters_sentinel_base import BaseSentinelExporter\nfrom src_exporters_geowiki import GeoWikiExporter\nfrom src_exporters_sentinel_utils import EEBoundingBox, bounding_box_from_centre\n\nfrom typing import Optional, List\n\n\nclass GeoWikiSentinelExporter(BaseSentinelExporter):\n\n    dataset = \"earth_engine_geowiki\"\n\n    def load_labels(self) -> pd.DataFrame:\n        # right now, this just loads geowiki data. In the future,\n        # it would be neat to merge all labels together\n        geowiki = self.data_folder / \"processed\" / GeoWikiExporter.dataset / \"data.nc\"\n        assert geowiki.exists(), \"GeoWiki processor must be run to load labels\"\n        return xr.open_dataset(geowiki).to_dataframe().dropna().reset_index()\n\n    def labels_to_bounding_boxes(\n        self, num_labelled_points: Optional[int], surrounding_metres: int\n    ) -> List[EEBoundingBox]:\n\n        output: List[EEBoundingBox] = []\n\n        for idx, row in tqdm(self.labels.iterrows()):\n            output.append(\n                bounding_box_from_centre(\n                    mid_lat=row[\"lat\"], mid_lon=row[\"lon\"], surrounding_metres=surrounding_metres,\n                )\n            )\n\n            if num_labelled_points is not None:\n                if len(output) >= num_labelled_points:\n                    return output\n        return output\n\n    def export_for_labels(\n        self,\n        days_per_timestep: int = 30,\n        start_date: date = date(2017, 3, 28),\n        end_date: date = date(2018, 3, 28),\n        num_labelled_points: Optional[int] = None,\n        surrounding_metres: int = 80,\n        checkpoint: bool = True,\n        monitor: bool = False,\n        fast: bool = True,\n    ) -> None:\n        r\"\"\"\n        Run the GeoWiki exporter. For each label, the exporter will export\n        int( (end_date - start_date).days / days_per_timestep) timesteps of data,\n        where each timestep consists of a mosaic of all available images within the\n        days_per_timestep of that timestep.\n        :param days_per_timestep: The number of days of data to use for each mosaiced image.\n        :param start_date: The start data of the data export\n        :param end_date: The end date of the data export\n        :param num_labelled_points: (Optional) The number of labelled points to export.\n        :param surrounding_metres: The number of metres surrounding each labelled point to export\n        :param checkpoint: Whether or not to check in self.data_folder to see if the file has\n            already been exported. If it has, skip it\n        :param monitor: Whether to monitor each task until it has been run\n        :param fast: Whether to use the faster cloudfree exporter. This function is considerably\n            faster, but cloud artefacts can be more pronounced. Default = True\n        \"\"\"\n        assert start_date >= self.min_date, f\"Sentinel data does not exist before {self.min_date}\"\n\n        bounding_boxes_to_download = self.labels_to_bounding_boxes(\n            num_labelled_points=num_labelled_points, surrounding_metres=surrounding_metres,\n        )\n\n        for idx, bounding_box in enumerate(bounding_boxes_to_download):\n            self._export_for_polygon(\n                polygon=bounding_box.to_ee_polygon(),\n                polygon_identifier=idx,\n                start_date=start_date,\n                end_date=end_date,\n                days_per_timestep=days_per_timestep,\n                checkpoint=checkpoint,\n                monitor=monitor,\n                fast=fast,\n            )\n",
  "history_output" : "",
  "history_begin_time" : 1646112724538,
  "history_end_time" : 1646112727880,
  "history_notes" : null,
  "history_process" : "mw544v",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "nveat8njo94",
  "history_input" : "import pandas as pd\nimport xarray as xr\nfrom datetime import date\nfrom tqdm import tqdm\n\nfrom src_exporters_sentinel_base import BaseSentinelExporter\nfrom src_exporters_geowiki import GeoWikiExporter\nfrom src_exporters_sentinel_utils import EEBoundingBox, bounding_box_from_centre\n\nfrom typing import Optional, List\n\n\nclass GeoWikiSentinelExporter(BaseSentinelExporter):\n\n    dataset = \"earth_engine_geowiki\"\n\n    def load_labels(self) -> pd.DataFrame:\n        # right now, this just loads geowiki data. In the future,\n        # it would be neat to merge all labels together\n        geowiki = self.data_folder / \"processed\" / GeoWikiExporter.dataset / \"data.nc\"\n        assert geowiki.exists(), \"GeoWiki processor must be run to load labels\"\n        return xr.open_dataset(geowiki).to_dataframe().dropna().reset_index()\n\n    def labels_to_bounding_boxes(\n        self, num_labelled_points: Optional[int], surrounding_metres: int\n    ) -> List[EEBoundingBox]:\n\n        output: List[EEBoundingBox] = []\n\n        for idx, row in tqdm(self.labels.iterrows()):\n            output.append(\n                bounding_box_from_centre(\n                    mid_lat=row[\"lat\"], mid_lon=row[\"lon\"], surrounding_metres=surrounding_metres,\n                )\n            )\n\n            if num_labelled_points is not None:\n                if len(output) >= num_labelled_points:\n                    return output\n        return output\n\n    def export_for_labels(\n        self,\n        days_per_timestep: int = 30,\n        start_date: date = date(2017, 3, 28),\n        end_date: date = date(2018, 3, 28),\n        num_labelled_points: Optional[int] = None,\n        surrounding_metres: int = 80,\n        checkpoint: bool = True,\n        monitor: bool = False,\n        fast: bool = True,\n    ) -> None:\n        r\"\"\"\n        Run the GeoWiki exporter. For each label, the exporter will export\n        int( (end_date - start_date).days / days_per_timestep) timesteps of data,\n        where each timestep consists of a mosaic of all available images within the\n        days_per_timestep of that timestep.\n        :param days_per_timestep: The number of days of data to use for each mosaiced image.\n        :param start_date: The start data of the data export\n        :param end_date: The end date of the data export\n        :param num_labelled_points: (Optional) The number of labelled points to export.\n        :param surrounding_metres: The number of metres surrounding each labelled point to export\n        :param checkpoint: Whether or not to check in self.data_folder to see if the file has\n            already been exported. If it has, skip it\n        :param monitor: Whether to monitor each task until it has been run\n        :param fast: Whether to use the faster cloudfree exporter. This function is considerably\n            faster, but cloud artefacts can be more pronounced. Default = True\n        \"\"\"\n        assert start_date >= self.min_date, f\"Sentinel data does not exist before {self.min_date}\"\n\n        bounding_boxes_to_download = self.labels_to_bounding_boxes(\n            num_labelled_points=num_labelled_points, surrounding_metres=surrounding_metres,\n        )\n\n        for idx, bounding_box in enumerate(bounding_boxes_to_download):\n            self._export_for_polygon(\n                polygon=bounding_box.to_ee_polygon(),\n                polygon_identifier=idx,\n                start_date=start_date,\n                end_date=end_date,\n                days_per_timestep=days_per_timestep,\n                checkpoint=checkpoint,\n                monitor=monitor,\n                fast=fast,\n            )\n",
  "history_output" : "",
  "history_begin_time" : 1646112280098,
  "history_end_time" : 1646112282742,
  "history_notes" : null,
  "history_process" : "mw544v",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "4agnjj1mzaq",
  "history_input" : "import pandas as pd\nimport xarray as xr\nfrom datetime import date\nfrom tqdm import tqdm\n\nfrom src_exporters_sentinel_base import BaseSentinelExporter\nfrom src_exporters_geowiki import GeoWikiExporter\nfrom src_exporters_sentinel_utils import EEBoundingBox, bounding_box_from_centre\n\nfrom typing import Optional, List\n\n\nclass GeoWikiSentinelExporter(BaseSentinelExporter):\n\n    dataset = \"earth_engine_geowiki\"\n\n    def load_labels(self) -> pd.DataFrame:\n        # right now, this just loads geowiki data. In the future,\n        # it would be neat to merge all labels together\n        geowiki = self.data_folder / \"processed\" / GeoWikiExporter.dataset / \"data.nc\"\n        assert geowiki.exists(), \"GeoWiki processor must be run to load labels\"\n        return xr.open_dataset(geowiki).to_dataframe().dropna().reset_index()\n\n    def labels_to_bounding_boxes(\n        self, num_labelled_points: Optional[int], surrounding_metres: int\n    ) -> List[EEBoundingBox]:\n\n        output: List[EEBoundingBox] = []\n\n        for idx, row in tqdm(self.labels.iterrows()):\n            output.append(\n                bounding_box_from_centre(\n                    mid_lat=row[\"lat\"], mid_lon=row[\"lon\"], surrounding_metres=surrounding_metres,\n                )\n            )\n\n            if num_labelled_points is not None:\n                if len(output) >= num_labelled_points:\n                    return output\n        return output\n\n    def export_for_labels(\n        self,\n        days_per_timestep: int = 30,\n        start_date: date = date(2017, 3, 28),\n        end_date: date = date(2018, 3, 28),\n        num_labelled_points: Optional[int] = None,\n        surrounding_metres: int = 80,\n        checkpoint: bool = True,\n        monitor: bool = False,\n        fast: bool = True,\n    ) -> None:\n        r\"\"\"\n        Run the GeoWiki exporter. For each label, the exporter will export\n        int( (end_date - start_date).days / days_per_timestep) timesteps of data,\n        where each timestep consists of a mosaic of all available images within the\n        days_per_timestep of that timestep.\n        :param days_per_timestep: The number of days of data to use for each mosaiced image.\n        :param start_date: The start data of the data export\n        :param end_date: The end date of the data export\n        :param num_labelled_points: (Optional) The number of labelled points to export.\n        :param surrounding_metres: The number of metres surrounding each labelled point to export\n        :param checkpoint: Whether or not to check in self.data_folder to see if the file has\n            already been exported. If it has, skip it\n        :param monitor: Whether to monitor each task until it has been run\n        :param fast: Whether to use the faster cloudfree exporter. This function is considerably\n            faster, but cloud artefacts can be more pronounced. Default = True\n        \"\"\"\n        assert start_date >= self.min_date, f\"Sentinel data does not exist before {self.min_date}\"\n\n        bounding_boxes_to_download = self.labels_to_bounding_boxes(\n            num_labelled_points=num_labelled_points, surrounding_metres=surrounding_metres,\n        )\n\n        for idx, bounding_box in enumerate(bounding_boxes_to_download):\n            self._export_for_polygon(\n                polygon=bounding_box.to_ee_polygon(),\n                polygon_identifier=idx,\n                start_date=start_date,\n                end_date=end_date,\n                days_per_timestep=days_per_timestep,\n                checkpoint=checkpoint,\n                monitor=monitor,\n                fast=fast,\n            )\n",
  "history_output" : "",
  "history_begin_time" : 1646112241084,
  "history_end_time" : 1646112244388,
  "history_notes" : null,
  "history_process" : "mw544v",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "fcou3lf6hd5",
  "history_input" : "import pandas as pd\nimport xarray as xr\nfrom datetime import date\nfrom tqdm import tqdm\n\nfrom src_exporters_sentinel_base import BaseSentinelExporter\nfrom src_exporters_geowiki import GeoWikiExporter\nfrom src_exporters_sentinel_utils import EEBoundingBox, bounding_box_from_centre\n\nfrom typing import Optional, List\n\n\nclass GeoWikiSentinelExporter(BaseSentinelExporter):\n\n    dataset = \"earth_engine_geowiki\"\n\n    def load_labels(self) -> pd.DataFrame:\n        # right now, this just loads geowiki data. In the future,\n        # it would be neat to merge all labels together\n        geowiki = self.data_folder / \"processed\" / GeoWikiExporter.dataset / \"data.nc\"\n        assert geowiki.exists(), \"GeoWiki processor must be run to load labels\"\n        return xr.open_dataset(geowiki).to_dataframe().dropna().reset_index()\n\n    def labels_to_bounding_boxes(\n        self, num_labelled_points: Optional[int], surrounding_metres: int\n    ) -> List[EEBoundingBox]:\n\n        output: List[EEBoundingBox] = []\n\n        for idx, row in tqdm(self.labels.iterrows()):\n            output.append(\n                bounding_box_from_centre(\n                    mid_lat=row[\"lat\"], mid_lon=row[\"lon\"], surrounding_metres=surrounding_metres,\n                )\n            )\n\n            if num_labelled_points is not None:\n                if len(output) >= num_labelled_points:\n                    return output\n        return output\n\n    def export_for_labels(\n        self,\n        days_per_timestep: int = 30,\n        start_date: date = date(2017, 3, 28),\n        end_date: date = date(2018, 3, 28),\n        num_labelled_points: Optional[int] = None,\n        surrounding_metres: int = 80,\n        checkpoint: bool = True,\n        monitor: bool = False,\n        fast: bool = True,\n    ) -> None:\n        r\"\"\"\n        Run the GeoWiki exporter. For each label, the exporter will export\n        int( (end_date - start_date).days / days_per_timestep) timesteps of data,\n        where each timestep consists of a mosaic of all available images within the\n        days_per_timestep of that timestep.\n        :param days_per_timestep: The number of days of data to use for each mosaiced image.\n        :param start_date: The start data of the data export\n        :param end_date: The end date of the data export\n        :param num_labelled_points: (Optional) The number of labelled points to export.\n        :param surrounding_metres: The number of metres surrounding each labelled point to export\n        :param checkpoint: Whether or not to check in self.data_folder to see if the file has\n            already been exported. If it has, skip it\n        :param monitor: Whether to monitor each task until it has been run\n        :param fast: Whether to use the faster cloudfree exporter. This function is considerably\n            faster, but cloud artefacts can be more pronounced. Default = True\n        \"\"\"\n        assert start_date >= self.min_date, f\"Sentinel data does not exist before {self.min_date}\"\n\n        bounding_boxes_to_download = self.labels_to_bounding_boxes(\n            num_labelled_points=num_labelled_points, surrounding_metres=surrounding_metres,\n        )\n\n        for idx, bounding_box in enumerate(bounding_boxes_to_download):\n            self._export_for_polygon(\n                polygon=bounding_box.to_ee_polygon(),\n                polygon_identifier=idx,\n                start_date=start_date,\n                end_date=end_date,\n                days_per_timestep=days_per_timestep,\n                checkpoint=checkpoint,\n                monitor=monitor,\n                fast=fast,\n            )\n",
  "history_output" : "",
  "history_begin_time" : 1646112136243,
  "history_end_time" : 1646112139354,
  "history_notes" : null,
  "history_process" : "mw544v",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "gdzfahzzjiv",
  "history_input" : "import pandas as pd\nimport xarray as xr\nfrom datetime import date\nfrom tqdm import tqdm\n\nfrom src_exporters_sentinel_base import BaseSentinelExporter\nfrom src_exporters_geowiki import GeoWikiExporter\nfrom src_exporters_sentinel_utils import EEBoundingBox, bounding_box_from_centre\n\nfrom typing import Optional, List\n\n\nclass GeoWikiSentinelExporter(BaseSentinelExporter):\n\n    dataset = \"earth_engine_geowiki\"\n\n    def load_labels(self) -> pd.DataFrame:\n        # right now, this just loads geowiki data. In the future,\n        # it would be neat to merge all labels together\n        geowiki = self.data_folder / \"processed\" / GeoWikiExporter.dataset / \"data.nc\"\n        assert geowiki.exists(), \"GeoWiki processor must be run to load labels\"\n        return xr.open_dataset(geowiki).to_dataframe().dropna().reset_index()\n\n    def labels_to_bounding_boxes(\n        self, num_labelled_points: Optional[int], surrounding_metres: int\n    ) -> List[EEBoundingBox]:\n\n        output: List[EEBoundingBox] = []\n\n        for idx, row in tqdm(self.labels.iterrows()):\n            output.append(\n                bounding_box_from_centre(\n                    mid_lat=row[\"lat\"], mid_lon=row[\"lon\"], surrounding_metres=surrounding_metres,\n                )\n            )\n\n            if num_labelled_points is not None:\n                if len(output) >= num_labelled_points:\n                    return output\n        return output\n\n    def export_for_labels(\n        self,\n        days_per_timestep: int = 30,\n        start_date: date = date(2017, 3, 28),\n        end_date: date = date(2018, 3, 28),\n        num_labelled_points: Optional[int] = None,\n        surrounding_metres: int = 80,\n        checkpoint: bool = True,\n        monitor: bool = False,\n        fast: bool = True,\n    ) -> None:\n        r\"\"\"\n        Run the GeoWiki exporter. For each label, the exporter will export\n        int( (end_date - start_date).days / days_per_timestep) timesteps of data,\n        where each timestep consists of a mosaic of all available images within the\n        days_per_timestep of that timestep.\n        :param days_per_timestep: The number of days of data to use for each mosaiced image.\n        :param start_date: The start data of the data export\n        :param end_date: The end date of the data export\n        :param num_labelled_points: (Optional) The number of labelled points to export.\n        :param surrounding_metres: The number of metres surrounding each labelled point to export\n        :param checkpoint: Whether or not to check in self.data_folder to see if the file has\n            already been exported. If it has, skip it\n        :param monitor: Whether to monitor each task until it has been run\n        :param fast: Whether to use the faster cloudfree exporter. This function is considerably\n            faster, but cloud artefacts can be more pronounced. Default = True\n        \"\"\"\n        assert start_date >= self.min_date, f\"Sentinel data does not exist before {self.min_date}\"\n\n        bounding_boxes_to_download = self.labels_to_bounding_boxes(\n            num_labelled_points=num_labelled_points, surrounding_metres=surrounding_metres,\n        )\n\n        for idx, bounding_box in enumerate(bounding_boxes_to_download):\n            self._export_for_polygon(\n                polygon=bounding_box.to_ee_polygon(),\n                polygon_identifier=idx,\n                start_date=start_date,\n                end_date=end_date,\n                days_per_timestep=days_per_timestep,\n                checkpoint=checkpoint,\n                monitor=monitor,\n                fast=fast,\n            )\n",
  "history_output" : "",
  "history_begin_time" : 1645393375698,
  "history_end_time" : 1645393381027,
  "history_notes" : null,
  "history_process" : "mw544v",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "xm9kxff64h7",
  "history_input" : "import pandas as pd\nimport xarray as xr\nfrom datetime import date\nfrom tqdm import tqdm\n\nfrom src_exporters_sentinel_base import BaseSentinelExporter\nfrom src_exporters_geowiki import GeoWikiExporter\nfrom src_exporters_sentinel_utils import EEBoundingBox, bounding_box_from_centre\n\nfrom typing import Optional, List\n\n\nclass GeoWikiSentinelExporter(BaseSentinelExporter):\n\n    dataset = \"earth_engine_geowiki\"\n\n    def load_labels(self) -> pd.DataFrame:\n        # right now, this just loads geowiki data. In the future,\n        # it would be neat to merge all labels together\n        geowiki = self.data_folder / \"processed\" / GeoWikiExporter.dataset / \"data.nc\"\n        assert geowiki.exists(), \"GeoWiki processor must be run to load labels\"\n        return xr.open_dataset(geowiki).to_dataframe().dropna().reset_index()\n\n    def labels_to_bounding_boxes(\n        self, num_labelled_points: Optional[int], surrounding_metres: int\n    ) -> List[EEBoundingBox]:\n\n        output: List[EEBoundingBox] = []\n\n        for idx, row in tqdm(self.labels.iterrows()):\n            output.append(\n                bounding_box_from_centre(\n                    mid_lat=row[\"lat\"], mid_lon=row[\"lon\"], surrounding_metres=surrounding_metres,\n                )\n            )\n\n            if num_labelled_points is not None:\n                if len(output) >= num_labelled_points:\n                    return output\n        return output\n\n    def export_for_labels(\n        self,\n        days_per_timestep: int = 30,\n        start_date: date = date(2017, 3, 28),\n        end_date: date = date(2018, 3, 28),\n        num_labelled_points: Optional[int] = None,\n        surrounding_metres: int = 80,\n        checkpoint: bool = True,\n        monitor: bool = False,\n        fast: bool = True,\n    ) -> None:\n        r\"\"\"\n        Run the GeoWiki exporter. For each label, the exporter will export\n        int( (end_date - start_date).days / days_per_timestep) timesteps of data,\n        where each timestep consists of a mosaic of all available images within the\n        days_per_timestep of that timestep.\n        :param days_per_timestep: The number of days of data to use for each mosaiced image.\n        :param start_date: The start data of the data export\n        :param end_date: The end date of the data export\n        :param num_labelled_points: (Optional) The number of labelled points to export.\n        :param surrounding_metres: The number of metres surrounding each labelled point to export\n        :param checkpoint: Whether or not to check in self.data_folder to see if the file has\n            already been exported. If it has, skip it\n        :param monitor: Whether to monitor each task until it has been run\n        :param fast: Whether to use the faster cloudfree exporter. This function is considerably\n            faster, but cloud artefacts can be more pronounced. Default = True\n        \"\"\"\n        assert start_date >= self.min_date, f\"Sentinel data does not exist before {self.min_date}\"\n\n        bounding_boxes_to_download = self.labels_to_bounding_boxes(\n            num_labelled_points=num_labelled_points, surrounding_metres=surrounding_metres,\n        )\n\n        for idx, bounding_box in enumerate(bounding_boxes_to_download):\n            self._export_for_polygon(\n                polygon=bounding_box.to_ee_polygon(),\n                polygon_identifier=idx,\n                start_date=start_date,\n                end_date=end_date,\n                days_per_timestep=days_per_timestep,\n                checkpoint=checkpoint,\n                monitor=monitor,\n                fast=fast,\n            )\n",
  "history_output" : "",
  "history_begin_time" : 1645389122525,
  "history_end_time" : 1645389127030,
  "history_notes" : null,
  "history_process" : "mw544v",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "0luxuahaqiv",
  "history_input" : "import pandas as pd\nimport xarray as xr\nfrom datetime import date\nfrom tqdm import tqdm\n\nfrom src_exporters_sentinel_base import BaseSentinelExporter\nfrom src_exporters_geowiki import GeoWikiExporter\nfrom src_exporters_sentinel_utils import EEBoundingBox, bounding_box_from_centre\n\nfrom typing import Optional, List\n\n\nclass GeoWikiSentinelExporter(BaseSentinelExporter):\n\n    dataset = \"earth_engine_geowiki\"\n\n    def load_labels(self) -> pd.DataFrame:\n        # right now, this just loads geowiki data. In the future,\n        # it would be neat to merge all labels together\n        geowiki = self.data_folder / \"processed\" / GeoWikiExporter.dataset / \"data.nc\"\n        assert geowiki.exists(), \"GeoWiki processor must be run to load labels\"\n        return xr.open_dataset(geowiki).to_dataframe().dropna().reset_index()\n\n    def labels_to_bounding_boxes(\n        self, num_labelled_points: Optional[int], surrounding_metres: int\n    ) -> List[EEBoundingBox]:\n\n        output: List[EEBoundingBox] = []\n\n        for idx, row in tqdm(self.labels.iterrows()):\n            output.append(\n                bounding_box_from_centre(\n                    mid_lat=row[\"lat\"], mid_lon=row[\"lon\"], surrounding_metres=surrounding_metres,\n                )\n            )\n\n            if num_labelled_points is not None:\n                if len(output) >= num_labelled_points:\n                    return output\n        return output\n\n    def export_for_labels(\n        self,\n        days_per_timestep: int = 30,\n        start_date: date = date(2017, 3, 28),\n        end_date: date = date(2018, 3, 28),\n        num_labelled_points: Optional[int] = None,\n        surrounding_metres: int = 80,\n        checkpoint: bool = True,\n        monitor: bool = False,\n        fast: bool = True,\n    ) -> None:\n        r\"\"\"\n        Run the GeoWiki exporter. For each label, the exporter will export\n        int( (end_date - start_date).days / days_per_timestep) timesteps of data,\n        where each timestep consists of a mosaic of all available images within the\n        days_per_timestep of that timestep.\n        :param days_per_timestep: The number of days of data to use for each mosaiced image.\n        :param start_date: The start data of the data export\n        :param end_date: The end date of the data export\n        :param num_labelled_points: (Optional) The number of labelled points to export.\n        :param surrounding_metres: The number of metres surrounding each labelled point to export\n        :param checkpoint: Whether or not to check in self.data_folder to see if the file has\n            already been exported. If it has, skip it\n        :param monitor: Whether to monitor each task until it has been run\n        :param fast: Whether to use the faster cloudfree exporter. This function is considerably\n            faster, but cloud artefacts can be more pronounced. Default = True\n        \"\"\"\n        assert start_date >= self.min_date, f\"Sentinel data does not exist before {self.min_date}\"\n\n        bounding_boxes_to_download = self.labels_to_bounding_boxes(\n            num_labelled_points=num_labelled_points, surrounding_metres=surrounding_metres,\n        )\n\n        for idx, bounding_box in enumerate(bounding_boxes_to_download):\n            self._export_for_polygon(\n                polygon=bounding_box.to_ee_polygon(),\n                polygon_identifier=idx,\n                start_date=start_date,\n                end_date=end_date,\n                days_per_timestep=days_per_timestep,\n                checkpoint=checkpoint,\n                monitor=monitor,\n                fast=fast,\n            )\n",
  "history_output" : "",
  "history_begin_time" : 1645389112363,
  "history_end_time" : 1645389112440,
  "history_notes" : null,
  "history_process" : "mw544v",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "weob74j91qf",
  "history_input" : "import pandas as pd\nimport xarray as xr\nfrom datetime import date\nfrom tqdm import tqdm\n\nfrom src_exporters_sentinel_base import BaseSentinelExporter\nfrom src_exporters_geowiki import GeoWikiExporter\nfrom src_exporters_sentinel_utils import EEBoundingBox, bounding_box_from_centre\n\nfrom typing import Optional, List\n\n\nclass GeoWikiSentinelExporter(BaseSentinelExporter):\n\n    dataset = \"earth_engine_geowiki\"\n\n    def load_labels(self) -> pd.DataFrame:\n        # right now, this just loads geowiki data. In the future,\n        # it would be neat to merge all labels together\n        geowiki = self.data_folder / \"processed\" / GeoWikiExporter.dataset / \"data.nc\"\n        assert geowiki.exists(), \"GeoWiki processor must be run to load labels\"\n        return xr.open_dataset(geowiki).to_dataframe().dropna().reset_index()\n\n    def labels_to_bounding_boxes(\n        self, num_labelled_points: Optional[int], surrounding_metres: int\n    ) -> List[EEBoundingBox]:\n\n        output: List[EEBoundingBox] = []\n\n        for idx, row in tqdm(self.labels.iterrows()):\n            output.append(\n                bounding_box_from_centre(\n                    mid_lat=row[\"lat\"], mid_lon=row[\"lon\"], surrounding_metres=surrounding_metres,\n                )\n            )\n\n            if num_labelled_points is not None:\n                if len(output) >= num_labelled_points:\n                    return output\n        return output\n\n    def export_for_labels(\n        self,\n        days_per_timestep: int = 30,\n        start_date: date = date(2017, 3, 28),\n        end_date: date = date(2018, 3, 28),\n        num_labelled_points: Optional[int] = None,\n        surrounding_metres: int = 80,\n        checkpoint: bool = True,\n        monitor: bool = False,\n        fast: bool = True,\n    ) -> None:\n        r\"\"\"\n        Run the GeoWiki exporter. For each label, the exporter will export\n        int( (end_date - start_date).days / days_per_timestep) timesteps of data,\n        where each timestep consists of a mosaic of all available images within the\n        days_per_timestep of that timestep.\n        :param days_per_timestep: The number of days of data to use for each mosaiced image.\n        :param start_date: The start data of the data export\n        :param end_date: The end date of the data export\n        :param num_labelled_points: (Optional) The number of labelled points to export.\n        :param surrounding_metres: The number of metres surrounding each labelled point to export\n        :param checkpoint: Whether or not to check in self.data_folder to see if the file has\n            already been exported. If it has, skip it\n        :param monitor: Whether to monitor each task until it has been run\n        :param fast: Whether to use the faster cloudfree exporter. This function is considerably\n            faster, but cloud artefacts can be more pronounced. Default = True\n        \"\"\"\n        assert start_date >= self.min_date, f\"Sentinel data does not exist before {self.min_date}\"\n\n        bounding_boxes_to_download = self.labels_to_bounding_boxes(\n            num_labelled_points=num_labelled_points, surrounding_metres=surrounding_metres,\n        )\n\n        for idx, bounding_box in enumerate(bounding_boxes_to_download):\n            self._export_for_polygon(\n                polygon=bounding_box.to_ee_polygon(),\n                polygon_identifier=idx,\n                start_date=start_date,\n                end_date=end_date,\n                days_per_timestep=days_per_timestep,\n                checkpoint=checkpoint,\n                monitor=monitor,\n                fast=fast,\n            )\n",
  "history_output" : "",
  "history_begin_time" : 1645388793686,
  "history_end_time" : 1645388794208,
  "history_notes" : null,
  "history_process" : "mw544v",
  "host_id" : "100001",
  "indicator" : "Done"
},]
