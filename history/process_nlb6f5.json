[{
  "history_id" : "aq4hhjfalhg",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1666167825339,
  "history_end_time" : 1666167825339,
  "history_notes" : null,
  "history_process" : "nlb6f5",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "cqnud7j28oq",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1666167772298,
  "history_end_time" : 1666167772298,
  "history_notes" : null,
  "history_process" : "nlb6f5",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "t2u3w02iwjg",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1666166465575,
  "history_end_time" : 1666166465575,
  "history_notes" : null,
  "history_process" : "nlb6f5",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "4czog1fkcam",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1666166410235,
  "history_end_time" : 1666166419927,
  "history_notes" : null,
  "history_process" : "nlb6f5",
  "host_id" : "100001",
  "indicator" : "Stopped"
},{
  "history_id" : "645jq0yrfno",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1666164233056,
  "history_end_time" : 1666164233056,
  "history_notes" : null,
  "history_process" : "nlb6f5",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "o7oxjma3dmh",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1666163607252,
  "history_end_time" : 1666163607252,
  "history_notes" : null,
  "history_process" : "nlb6f5",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "shc9fbnemgw",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1666137012928,
  "history_end_time" : 1666137012928,
  "history_notes" : null,
  "history_process" : "nlb6f5",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "9mpeay9oepl",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1666136593466,
  "history_end_time" : 1666136593466,
  "history_notes" : null,
  "history_process" : "nlb6f5",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "30wddzl3vlo",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1666136435745,
  "history_end_time" : 1666136435745,
  "history_notes" : null,
  "history_process" : "nlb6f5",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "wuu6w0xwm4w",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1666134110727,
  "history_end_time" : 1666134110727,
  "history_notes" : null,
  "history_process" : "nlb6f5",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "tcdja2rgndp",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1666134036878,
  "history_end_time" : 1666134036878,
  "history_notes" : null,
  "history_process" : "nlb6f5",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "113t22votwf",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1666134008931,
  "history_end_time" : 1666134008931,
  "history_notes" : null,
  "history_process" : "nlb6f5",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "np37azp12ps",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1666131993123,
  "history_end_time" : 1666131993123,
  "history_notes" : null,
  "history_process" : "nlb6f5",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "2iyuufu27n1",
  "history_input" : "import pandas as pd\nimport geopandas\nfrom tqdm import tqdm\nfrom datetime import timedelta, date\n\nfrom src_exporters_sentinel_base import BaseSentinelExporter\nfrom src_processors_kenya_non_crop import KenyaNonCropProcessor\nfrom src_exporters_sentinel_utils import EEBoundingBox, bounding_box_from_centre\n\nfrom typing import Optional, List\n\n\nclass KenyaNonCropSentinelExporter(BaseSentinelExporter):\n\n    dataset = \"earth_engine_kenya_non_crop\"\n\n    # data collection date\n    data_date = date(2020, 4, 16)\n\n    def load_labels(self) -> pd.DataFrame:\n        # right now, this just loads geowiki data. In the future,\n        # it would be neat to merge all labels together\n        non_crop = self.data_folder / \"processed\" / KenyaNonCropProcessor.dataset / \"data.geojson\"\n        assert non_crop.exists(), \"Kenya non crop processor must be run to load labels\"\n        return geopandas.read_file(non_crop)[[\"lat\", \"lon\"]]\n\n    def labels_to_bounding_boxes(\n        self, num_labelled_points: Optional[int], surrounding_metres: int\n    ) -> List[EEBoundingBox]:\n\n        output: List[EEBoundingBox] = []\n\n        for idx, row in tqdm(self.labels.iterrows()):\n\n            output.append(\n                bounding_box_from_centre(\n                    mid_lat=row[\"lat\"], mid_lon=row[\"lon\"], surrounding_metres=surrounding_metres,\n                ),\n            )\n\n            if num_labelled_points is not None:\n                if len(output) >= num_labelled_points:\n                    return output\n        return output\n\n    def export_for_labels(\n        self,\n        days_per_timestep: int = 30,\n        num_timesteps: int = 12,\n        num_labelled_points: Optional[int] = None,\n        surrounding_metres: int = 80,\n        checkpoint: bool = True,\n        monitor: bool = False,\n        fast: bool = True,\n    ) -> None:\n        r\"\"\"\n        :param days_per_timestep: The number of days of data to use for each mosaiced image.\n            Default = 30\n        :param num_timesteps: The number of timesteps to export. Default = 12\n        :param num_labelled_points: If not None, then only this many points will be exported.\n            Default = None.\n        :param surrouning_metres: The patch will be [2 * surrounding_metres,\n            2 * surrounding_metres], centered around the labelled point. Default = 80\n        :param checkpoint: Whether or not to check in self.data_folder to see if the file has\n            already been exported. If it has, skip it. Default = True\n        :param monitor: Whether to monitor each task until it has been run. Default = True\n        :param fast: Whether to use the faster cloudfree exporter. This function is considerably\n            faster, but cloud artefacts can be more pronounced. Default = True\n        \"\"\"\n\n        bounding_boxes_to_download = self.labels_to_bounding_boxes(\n            num_labelled_points=num_labelled_points, surrounding_metres=surrounding_metres,\n        )\n\n        start_date = self.data_date - num_timesteps * timedelta(days=days_per_timestep)\n\n        for idx, bounding_info in enumerate(bounding_boxes_to_download):\n\n            self._export_for_polygon(\n                polygon=bounding_info.to_ee_polygon(),\n                polygon_identifier=idx,\n                start_date=start_date,\n                end_date=self.data_date,\n                days_per_timestep=days_per_timestep,\n                checkpoint=checkpoint,\n                monitor=monitor,\n                fast=fast,\n            )\n",
  "history_output" : "",
  "history_begin_time" : 1666118278031,
  "history_end_time" : 1666118282765,
  "history_notes" : null,
  "history_process" : "nlb6f5",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "uvneou49sid",
  "history_input" : "import pandas as pd\nimport geopandas\nfrom tqdm import tqdm\nfrom datetime import timedelta, date\n\nfrom src_exporters_sentinel_base import BaseSentinelExporter\nfrom src_processors_kenya_non_crop import KenyaNonCropProcessor\nfrom src_exporters_sentinel_utils import EEBoundingBox, bounding_box_from_centre\n\nfrom typing import Optional, List\n\n\nclass KenyaNonCropSentinelExporter(BaseSentinelExporter):\n\n    dataset = \"earth_engine_kenya_non_crop\"\n\n    # data collection date\n    data_date = date(2020, 4, 16)\n\n    def load_labels(self) -> pd.DataFrame:\n        # right now, this just loads geowiki data. In the future,\n        # it would be neat to merge all labels together\n        non_crop = self.data_folder / \"processed\" / KenyaNonCropProcessor.dataset / \"data.geojson\"\n        assert non_crop.exists(), \"Kenya non crop processor must be run to load labels\"\n        return geopandas.read_file(non_crop)[[\"lat\", \"lon\"]]\n\n    def labels_to_bounding_boxes(\n        self, num_labelled_points: Optional[int], surrounding_metres: int\n    ) -> List[EEBoundingBox]:\n\n        output: List[EEBoundingBox] = []\n\n        for idx, row in tqdm(self.labels.iterrows()):\n\n            output.append(\n                bounding_box_from_centre(\n                    mid_lat=row[\"lat\"], mid_lon=row[\"lon\"], surrounding_metres=surrounding_metres,\n                ),\n            )\n\n            if num_labelled_points is not None:\n                if len(output) >= num_labelled_points:\n                    return output\n        return output\n\n    def export_for_labels(\n        self,\n        days_per_timestep: int = 30,\n        num_timesteps: int = 12,\n        num_labelled_points: Optional[int] = None,\n        surrounding_metres: int = 80,\n        checkpoint: bool = True,\n        monitor: bool = False,\n        fast: bool = True,\n    ) -> None:\n        r\"\"\"\n        :param days_per_timestep: The number of days of data to use for each mosaiced image.\n            Default = 30\n        :param num_timesteps: The number of timesteps to export. Default = 12\n        :param num_labelled_points: If not None, then only this many points will be exported.\n            Default = None.\n        :param surrouning_metres: The patch will be [2 * surrounding_metres,\n            2 * surrounding_metres], centered around the labelled point. Default = 80\n        :param checkpoint: Whether or not to check in self.data_folder to see if the file has\n            already been exported. If it has, skip it. Default = True\n        :param monitor: Whether to monitor each task until it has been run. Default = True\n        :param fast: Whether to use the faster cloudfree exporter. This function is considerably\n            faster, but cloud artefacts can be more pronounced. Default = True\n        \"\"\"\n\n        bounding_boxes_to_download = self.labels_to_bounding_boxes(\n            num_labelled_points=num_labelled_points, surrounding_metres=surrounding_metres,\n        )\n\n        start_date = self.data_date - num_timesteps * timedelta(days=days_per_timestep)\n\n        for idx, bounding_info in enumerate(bounding_boxes_to_download):\n\n            self._export_for_polygon(\n                polygon=bounding_info.to_ee_polygon(),\n                polygon_identifier=idx,\n                start_date=start_date,\n                end_date=self.data_date,\n                days_per_timestep=days_per_timestep,\n                checkpoint=checkpoint,\n                monitor=monitor,\n                fast=fast,\n            )\n",
  "history_output" : "",
  "history_begin_time" : 1655909878508,
  "history_end_time" : 1655909878925,
  "history_notes" : null,
  "history_process" : "nlb6f5",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "o4i5am23arc",
  "history_input" : "import pandas as pd\nimport geopandas\nfrom tqdm import tqdm\nfrom datetime import timedelta, date\n\nfrom src_exporters_sentinel_base import BaseSentinelExporter\nfrom src_processors_kenya_non_crop import KenyaNonCropProcessor\nfrom src_exporters_sentinel_utils import EEBoundingBox, bounding_box_from_centre\n\nfrom typing import Optional, List\n\n\nclass KenyaNonCropSentinelExporter(BaseSentinelExporter):\n\n    dataset = \"earth_engine_kenya_non_crop\"\n\n    # data collection date\n    data_date = date(2020, 4, 16)\n\n    def load_labels(self) -> pd.DataFrame:\n        # right now, this just loads geowiki data. In the future,\n        # it would be neat to merge all labels together\n        non_crop = self.data_folder / \"processed\" / KenyaNonCropProcessor.dataset / \"data.geojson\"\n        assert non_crop.exists(), \"Kenya non crop processor must be run to load labels\"\n        return geopandas.read_file(non_crop)[[\"lat\", \"lon\"]]\n\n    def labels_to_bounding_boxes(\n        self, num_labelled_points: Optional[int], surrounding_metres: int\n    ) -> List[EEBoundingBox]:\n\n        output: List[EEBoundingBox] = []\n\n        for idx, row in tqdm(self.labels.iterrows()):\n\n            output.append(\n                bounding_box_from_centre(\n                    mid_lat=row[\"lat\"], mid_lon=row[\"lon\"], surrounding_metres=surrounding_metres,\n                ),\n            )\n\n            if num_labelled_points is not None:\n                if len(output) >= num_labelled_points:\n                    return output\n        return output\n\n    def export_for_labels(\n        self,\n        days_per_timestep: int = 30,\n        num_timesteps: int = 12,\n        num_labelled_points: Optional[int] = None,\n        surrounding_metres: int = 80,\n        checkpoint: bool = True,\n        monitor: bool = False,\n        fast: bool = True,\n    ) -> None:\n        r\"\"\"\n        :param days_per_timestep: The number of days of data to use for each mosaiced image.\n            Default = 30\n        :param num_timesteps: The number of timesteps to export. Default = 12\n        :param num_labelled_points: If not None, then only this many points will be exported.\n            Default = None.\n        :param surrouning_metres: The patch will be [2 * surrounding_metres,\n            2 * surrounding_metres], centered around the labelled point. Default = 80\n        :param checkpoint: Whether or not to check in self.data_folder to see if the file has\n            already been exported. If it has, skip it. Default = True\n        :param monitor: Whether to monitor each task until it has been run. Default = True\n        :param fast: Whether to use the faster cloudfree exporter. This function is considerably\n            faster, but cloud artefacts can be more pronounced. Default = True\n        \"\"\"\n\n        bounding_boxes_to_download = self.labels_to_bounding_boxes(\n            num_labelled_points=num_labelled_points, surrounding_metres=surrounding_metres,\n        )\n\n        start_date = self.data_date - num_timesteps * timedelta(days=days_per_timestep)\n\n        for idx, bounding_info in enumerate(bounding_boxes_to_download):\n\n            self._export_for_polygon(\n                polygon=bounding_info.to_ee_polygon(),\n                polygon_identifier=idx,\n                start_date=start_date,\n                end_date=self.data_date,\n                days_per_timestep=days_per_timestep,\n                checkpoint=checkpoint,\n                monitor=monitor,\n                fast=fast,\n            )\n",
  "history_output" : "Traceback (most recent call last):\n  File \"src_exporters_sentinel_kenya_non_crop.py\", line 2, in <module>\n    import geopandas\n  File \"/opt/anaconda3/lib/python3.8/site-packages/geopandas/__init__.py\", line 1, in <module>\n    from geopandas._config import options  # noqa\n  File \"/opt/anaconda3/lib/python3.8/site-packages/geopandas/_config.py\", line 109, in <module>\n    default_value=_default_use_pygeos(),\n  File \"/opt/anaconda3/lib/python3.8/site-packages/geopandas/_config.py\", line 95, in _default_use_pygeos\n    import geopandas._compat as compat\n  File \"/opt/anaconda3/lib/python3.8/site-packages/geopandas/_compat.py\", line 227, in <module>\n    PYPROJ_LT_3 = LooseVersion(pyproj.__version__) < LooseVersion(\"3\")\nAttributeError: module 'pyproj' has no attribute '__version__'\n",
  "history_begin_time" : 1655908833236,
  "history_end_time" : 1655908834004,
  "history_notes" : null,
  "history_process" : "nlb6f5",
  "host_id" : "100001",
  "indicator" : "Failed"
},{
  "history_id" : "p938p58v2el",
  "history_input" : "import pandas as pd\nimport geopandas\nfrom tqdm import tqdm\nfrom datetime import timedelta, date\n\nfrom src_exporters_sentinel_base import BaseSentinelExporter\nfrom src_processors_kenya_non_crop import KenyaNonCropProcessor\nfrom src_exporters_sentinel_utils import EEBoundingBox, bounding_box_from_centre\n\nfrom typing import Optional, List\n\n\nclass KenyaNonCropSentinelExporter(BaseSentinelExporter):\n\n    dataset = \"earth_engine_kenya_non_crop\"\n\n    # data collection date\n    data_date = date(2020, 4, 16)\n\n    def load_labels(self) -> pd.DataFrame:\n        # right now, this just loads geowiki data. In the future,\n        # it would be neat to merge all labels together\n        non_crop = self.data_folder / \"processed\" / KenyaNonCropProcessor.dataset / \"data.geojson\"\n        assert non_crop.exists(), \"Kenya non crop processor must be run to load labels\"\n        return geopandas.read_file(non_crop)[[\"lat\", \"lon\"]]\n\n    def labels_to_bounding_boxes(\n        self, num_labelled_points: Optional[int], surrounding_metres: int\n    ) -> List[EEBoundingBox]:\n\n        output: List[EEBoundingBox] = []\n\n        for idx, row in tqdm(self.labels.iterrows()):\n\n            output.append(\n                bounding_box_from_centre(\n                    mid_lat=row[\"lat\"], mid_lon=row[\"lon\"], surrounding_metres=surrounding_metres,\n                ),\n            )\n\n            if num_labelled_points is not None:\n                if len(output) >= num_labelled_points:\n                    return output\n        return output\n\n    def export_for_labels(\n        self,\n        days_per_timestep: int = 30,\n        num_timesteps: int = 12,\n        num_labelled_points: Optional[int] = None,\n        surrounding_metres: int = 80,\n        checkpoint: bool = True,\n        monitor: bool = False,\n        fast: bool = True,\n    ) -> None:\n        r\"\"\"\n        :param days_per_timestep: The number of days of data to use for each mosaiced image.\n            Default = 30\n        :param num_timesteps: The number of timesteps to export. Default = 12\n        :param num_labelled_points: If not None, then only this many points will be exported.\n            Default = None.\n        :param surrouning_metres: The patch will be [2 * surrounding_metres,\n            2 * surrounding_metres], centered around the labelled point. Default = 80\n        :param checkpoint: Whether or not to check in self.data_folder to see if the file has\n            already been exported. If it has, skip it. Default = True\n        :param monitor: Whether to monitor each task until it has been run. Default = True\n        :param fast: Whether to use the faster cloudfree exporter. This function is considerably\n            faster, but cloud artefacts can be more pronounced. Default = True\n        \"\"\"\n\n        bounding_boxes_to_download = self.labels_to_bounding_boxes(\n            num_labelled_points=num_labelled_points, surrounding_metres=surrounding_metres,\n        )\n\n        start_date = self.data_date - num_timesteps * timedelta(days=days_per_timestep)\n\n        for idx, bounding_info in enumerate(bounding_boxes_to_download):\n\n            self._export_for_polygon(\n                polygon=bounding_info.to_ee_polygon(),\n                polygon_identifier=idx,\n                start_date=start_date,\n                end_date=self.data_date,\n                days_per_timestep=days_per_timestep,\n                checkpoint=checkpoint,\n                monitor=monitor,\n                fast=fast,\n            )\n",
  "history_output" : "Traceback (most recent call last):\n  File \"src_exporters_sentinel_kenya_non_crop.py\", line 2, in <module>\n    import geopandas\n  File \"/opt/anaconda3/lib/python3.8/site-packages/geopandas/__init__.py\", line 1, in <module>\n    from geopandas._config import options  # noqa\n  File \"/opt/anaconda3/lib/python3.8/site-packages/geopandas/_config.py\", line 109, in <module>\n    default_value=_default_use_pygeos(),\n  File \"/opt/anaconda3/lib/python3.8/site-packages/geopandas/_config.py\", line 95, in _default_use_pygeos\n    import geopandas._compat as compat\n  File \"/opt/anaconda3/lib/python3.8/site-packages/geopandas/_compat.py\", line 9, in <module>\n    import pyproj\n  File \"/opt/anaconda3/lib/python3.8/site-packages/pyproj/__init__.py\", line 81, in <module>\n    from pyproj.crs import CRS  # noqa: F401\n  File \"/opt/anaconda3/lib/python3.8/site-packages/pyproj/crs/__init__.py\", line 16, in <module>\n    from pyproj.crs.crs import (  # noqa: F401  pylint: disable=unused-import\n  File \"/opt/anaconda3/lib/python3.8/site-packages/pyproj/crs/crs.py\", line 13, in <module>\n    from pyproj._crs import (\nImportError: cannot import name 'AuthorityMatchInfo' from 'pyproj._crs' (/opt/anaconda3/lib/python3.8/site-packages/pyproj/_crs.cpython-38-darwin.so)\n",
  "history_begin_time" : 1655907427306,
  "history_end_time" : 1655907428289,
  "history_notes" : null,
  "history_process" : "nlb6f5",
  "host_id" : "100001",
  "indicator" : "Failed"
},{
  "history_id" : "rv75hw6j5lj",
  "history_input" : "import pandas as pd\nimport geopandas\nfrom tqdm import tqdm\nfrom datetime import timedelta, date\n\nfrom src_exporters_sentinel_base import BaseSentinelExporter\nfrom src_processors_kenya_non_crop import KenyaNonCropProcessor\nfrom src_exporters_sentinel_utils import EEBoundingBox, bounding_box_from_centre\n\nfrom typing import Optional, List\n\n\nclass KenyaNonCropSentinelExporter(BaseSentinelExporter):\n\n    dataset = \"earth_engine_kenya_non_crop\"\n\n    # data collection date\n    data_date = date(2020, 4, 16)\n\n    def load_labels(self) -> pd.DataFrame:\n        # right now, this just loads geowiki data. In the future,\n        # it would be neat to merge all labels together\n        non_crop = self.data_folder / \"processed\" / KenyaNonCropProcessor.dataset / \"data.geojson\"\n        assert non_crop.exists(), \"Kenya non crop processor must be run to load labels\"\n        return geopandas.read_file(non_crop)[[\"lat\", \"lon\"]]\n\n    def labels_to_bounding_boxes(\n        self, num_labelled_points: Optional[int], surrounding_metres: int\n    ) -> List[EEBoundingBox]:\n\n        output: List[EEBoundingBox] = []\n\n        for idx, row in tqdm(self.labels.iterrows()):\n\n            output.append(\n                bounding_box_from_centre(\n                    mid_lat=row[\"lat\"], mid_lon=row[\"lon\"], surrounding_metres=surrounding_metres,\n                ),\n            )\n\n            if num_labelled_points is not None:\n                if len(output) >= num_labelled_points:\n                    return output\n        return output\n\n    def export_for_labels(\n        self,\n        days_per_timestep: int = 30,\n        num_timesteps: int = 12,\n        num_labelled_points: Optional[int] = None,\n        surrounding_metres: int = 80,\n        checkpoint: bool = True,\n        monitor: bool = False,\n        fast: bool = True,\n    ) -> None:\n        r\"\"\"\n        :param days_per_timestep: The number of days of data to use for each mosaiced image.\n            Default = 30\n        :param num_timesteps: The number of timesteps to export. Default = 12\n        :param num_labelled_points: If not None, then only this many points will be exported.\n            Default = None.\n        :param surrouning_metres: The patch will be [2 * surrounding_metres,\n            2 * surrounding_metres], centered around the labelled point. Default = 80\n        :param checkpoint: Whether or not to check in self.data_folder to see if the file has\n            already been exported. If it has, skip it. Default = True\n        :param monitor: Whether to monitor each task until it has been run. Default = True\n        :param fast: Whether to use the faster cloudfree exporter. This function is considerably\n            faster, but cloud artefacts can be more pronounced. Default = True\n        \"\"\"\n\n        bounding_boxes_to_download = self.labels_to_bounding_boxes(\n            num_labelled_points=num_labelled_points, surrounding_metres=surrounding_metres,\n        )\n\n        start_date = self.data_date - num_timesteps * timedelta(days=days_per_timestep)\n\n        for idx, bounding_info in enumerate(bounding_boxes_to_download):\n\n            self._export_for_polygon(\n                polygon=bounding_info.to_ee_polygon(),\n                polygon_identifier=idx,\n                start_date=start_date,\n                end_date=self.data_date,\n                days_per_timestep=days_per_timestep,\n                checkpoint=checkpoint,\n                monitor=monitor,\n                fast=fast,\n            )\n",
  "history_output" : "Traceback (most recent call last):\n  File \"src_exporters_sentinel_kenya_non_crop.py\", line 1, in <module>\n    import pandas as pd\nModuleNotFoundError: No module named 'pandas'\n",
  "history_begin_time" : 1655907394001,
  "history_end_time" : 1655907403074,
  "history_notes" : null,
  "history_process" : "nlb6f5",
  "host_id" : "100001",
  "indicator" : "Stopped"
},{
  "history_id" : "5q3p69mpmro",
  "history_input" : "import pandas as pd\nimport geopandas\nfrom tqdm import tqdm\nfrom datetime import timedelta, date\n\nfrom src_exporters_sentinel_base import BaseSentinelExporter\nfrom src_processors_kenya_non_crop import KenyaNonCropProcessor\nfrom src_exporters_sentinel_utils import EEBoundingBox, bounding_box_from_centre\n\nfrom typing import Optional, List\n\n\nclass KenyaNonCropSentinelExporter(BaseSentinelExporter):\n\n    dataset = \"earth_engine_kenya_non_crop\"\n\n    # data collection date\n    data_date = date(2020, 4, 16)\n\n    def load_labels(self) -> pd.DataFrame:\n        # right now, this just loads geowiki data. In the future,\n        # it would be neat to merge all labels together\n        non_crop = self.data_folder / \"processed\" / KenyaNonCropProcessor.dataset / \"data.geojson\"\n        assert non_crop.exists(), \"Kenya non crop processor must be run to load labels\"\n        return geopandas.read_file(non_crop)[[\"lat\", \"lon\"]]\n\n    def labels_to_bounding_boxes(\n        self, num_labelled_points: Optional[int], surrounding_metres: int\n    ) -> List[EEBoundingBox]:\n\n        output: List[EEBoundingBox] = []\n\n        for idx, row in tqdm(self.labels.iterrows()):\n\n            output.append(\n                bounding_box_from_centre(\n                    mid_lat=row[\"lat\"], mid_lon=row[\"lon\"], surrounding_metres=surrounding_metres,\n                ),\n            )\n\n            if num_labelled_points is not None:\n                if len(output) >= num_labelled_points:\n                    return output\n        return output\n\n    def export_for_labels(\n        self,\n        days_per_timestep: int = 30,\n        num_timesteps: int = 12,\n        num_labelled_points: Optional[int] = None,\n        surrounding_metres: int = 80,\n        checkpoint: bool = True,\n        monitor: bool = False,\n        fast: bool = True,\n    ) -> None:\n        r\"\"\"\n        :param days_per_timestep: The number of days of data to use for each mosaiced image.\n            Default = 30\n        :param num_timesteps: The number of timesteps to export. Default = 12\n        :param num_labelled_points: If not None, then only this many points will be exported.\n            Default = None.\n        :param surrouning_metres: The patch will be [2 * surrounding_metres,\n            2 * surrounding_metres], centered around the labelled point. Default = 80\n        :param checkpoint: Whether or not to check in self.data_folder to see if the file has\n            already been exported. If it has, skip it. Default = True\n        :param monitor: Whether to monitor each task until it has been run. Default = True\n        :param fast: Whether to use the faster cloudfree exporter. This function is considerably\n            faster, but cloud artefacts can be more pronounced. Default = True\n        \"\"\"\n\n        bounding_boxes_to_download = self.labels_to_bounding_boxes(\n            num_labelled_points=num_labelled_points, surrounding_metres=surrounding_metres,\n        )\n\n        start_date = self.data_date - num_timesteps * timedelta(days=days_per_timestep)\n\n        for idx, bounding_info in enumerate(bounding_boxes_to_download):\n\n            self._export_for_polygon(\n                polygon=bounding_info.to_ee_polygon(),\n                polygon_identifier=idx,\n                start_date=start_date,\n                end_date=self.data_date,\n                days_per_timestep=days_per_timestep,\n                checkpoint=checkpoint,\n                monitor=monitor,\n                fast=fast,\n            )\n",
  "history_output" : "Traceback (most recent call last):\n  File \"src_exporters_sentinel_kenya_non_crop.py\", line 1, in <module>\n    import pandas as pd\nModuleNotFoundError: No module named 'pandas'\n",
  "history_begin_time" : 1655865869346,
  "history_end_time" : 1655865869490,
  "history_notes" : null,
  "history_process" : "nlb6f5",
  "host_id" : "100001",
  "indicator" : "Failed"
},{
  "history_id" : "aln4ccgw6is",
  "history_input" : "import pandas as pd\nimport geopandas\nfrom tqdm import tqdm\nfrom datetime import timedelta, date\n\nfrom src_exporters_sentinel_base import BaseSentinelExporter\nfrom src_processors_kenya_non_crop import KenyaNonCropProcessor\nfrom src_exporters_sentinel_utils import EEBoundingBox, bounding_box_from_centre\n\nfrom typing import Optional, List\n\n\nclass KenyaNonCropSentinelExporter(BaseSentinelExporter):\n\n    dataset = \"earth_engine_kenya_non_crop\"\n\n    # data collection date\n    data_date = date(2020, 4, 16)\n\n    def load_labels(self) -> pd.DataFrame:\n        # right now, this just loads geowiki data. In the future,\n        # it would be neat to merge all labels together\n        non_crop = self.data_folder / \"processed\" / KenyaNonCropProcessor.dataset / \"data.geojson\"\n        assert non_crop.exists(), \"Kenya non crop processor must be run to load labels\"\n        return geopandas.read_file(non_crop)[[\"lat\", \"lon\"]]\n\n    def labels_to_bounding_boxes(\n        self, num_labelled_points: Optional[int], surrounding_metres: int\n    ) -> List[EEBoundingBox]:\n\n        output: List[EEBoundingBox] = []\n\n        for idx, row in tqdm(self.labels.iterrows()):\n\n            output.append(\n                bounding_box_from_centre(\n                    mid_lat=row[\"lat\"], mid_lon=row[\"lon\"], surrounding_metres=surrounding_metres,\n                ),\n            )\n\n            if num_labelled_points is not None:\n                if len(output) >= num_labelled_points:\n                    return output\n        return output\n\n    def export_for_labels(\n        self,\n        days_per_timestep: int = 30,\n        num_timesteps: int = 12,\n        num_labelled_points: Optional[int] = None,\n        surrounding_metres: int = 80,\n        checkpoint: bool = True,\n        monitor: bool = False,\n        fast: bool = True,\n    ) -> None:\n        r\"\"\"\n        :param days_per_timestep: The number of days of data to use for each mosaiced image.\n            Default = 30\n        :param num_timesteps: The number of timesteps to export. Default = 12\n        :param num_labelled_points: If not None, then only this many points will be exported.\n            Default = None.\n        :param surrouning_metres: The patch will be [2 * surrounding_metres,\n            2 * surrounding_metres], centered around the labelled point. Default = 80\n        :param checkpoint: Whether or not to check in self.data_folder to see if the file has\n            already been exported. If it has, skip it. Default = True\n        :param monitor: Whether to monitor each task until it has been run. Default = True\n        :param fast: Whether to use the faster cloudfree exporter. This function is considerably\n            faster, but cloud artefacts can be more pronounced. Default = True\n        \"\"\"\n\n        bounding_boxes_to_download = self.labels_to_bounding_boxes(\n            num_labelled_points=num_labelled_points, surrounding_metres=surrounding_metres,\n        )\n\n        start_date = self.data_date - num_timesteps * timedelta(days=days_per_timestep)\n\n        for idx, bounding_info in enumerate(bounding_boxes_to_download):\n\n            self._export_for_polygon(\n                polygon=bounding_info.to_ee_polygon(),\n                polygon_identifier=idx,\n                start_date=start_date,\n                end_date=self.data_date,\n                days_per_timestep=days_per_timestep,\n                checkpoint=checkpoint,\n                monitor=monitor,\n                fast=fast,\n            )\n",
  "history_output" : "Traceback (most recent call last):\n  File \"src_exporters_sentinel_kenya_non_crop.py\", line 2, in <module>\n    import geopandas\n  File \"/opt/anaconda3/lib/python3.8/site-packages/geopandas/__init__.py\", line 1, in <module>\n    from geopandas._config import options  # noqa\n  File \"/opt/anaconda3/lib/python3.8/site-packages/geopandas/_config.py\", line 109, in <module>\n    default_value=_default_use_pygeos(),\n  File \"/opt/anaconda3/lib/python3.8/site-packages/geopandas/_config.py\", line 95, in _default_use_pygeos\n    import geopandas._compat as compat\n  File \"/opt/anaconda3/lib/python3.8/site-packages/geopandas/_compat.py\", line 9, in <module>\n    import pyproj\n  File \"/opt/anaconda3/lib/python3.8/site-packages/pyproj/__init__.py\", line 81, in <module>\n    from pyproj.crs import CRS  # noqa: F401\n  File \"/opt/anaconda3/lib/python3.8/site-packages/pyproj/crs/__init__.py\", line 16, in <module>\n    from pyproj.crs.crs import (  # noqa: F401  pylint: disable=unused-import\n  File \"/opt/anaconda3/lib/python3.8/site-packages/pyproj/crs/crs.py\", line 13, in <module>\n    from pyproj._crs import (\nImportError: cannot import name 'AuthorityMatchInfo' from 'pyproj._crs' (/opt/anaconda3/lib/python3.8/site-packages/pyproj/_crs.cpython-38-darwin.so)\n",
  "history_begin_time" : 1655865090444,
  "history_end_time" : 1655865091305,
  "history_notes" : null,
  "history_process" : "nlb6f5",
  "host_id" : "100001",
  "indicator" : "Failed"
},{
  "history_id" : "5chvlp1ygjn",
  "history_input" : "import pandas as pd\nimport geopandas\nfrom tqdm import tqdm\nfrom datetime import timedelta, date\n\nfrom src_exporters_sentinel_base import BaseSentinelExporter\nfrom src_processors_kenya_non_crop import KenyaNonCropProcessor\nfrom src_exporters_sentinel_utils import EEBoundingBox, bounding_box_from_centre\n\nfrom typing import Optional, List\n\n\nclass KenyaNonCropSentinelExporter(BaseSentinelExporter):\n\n    dataset = \"earth_engine_kenya_non_crop\"\n\n    # data collection date\n    data_date = date(2020, 4, 16)\n\n    def load_labels(self) -> pd.DataFrame:\n        # right now, this just loads geowiki data. In the future,\n        # it would be neat to merge all labels together\n        non_crop = self.data_folder / \"processed\" / KenyaNonCropProcessor.dataset / \"data.geojson\"\n        assert non_crop.exists(), \"Kenya non crop processor must be run to load labels\"\n        return geopandas.read_file(non_crop)[[\"lat\", \"lon\"]]\n\n    def labels_to_bounding_boxes(\n        self, num_labelled_points: Optional[int], surrounding_metres: int\n    ) -> List[EEBoundingBox]:\n\n        output: List[EEBoundingBox] = []\n\n        for idx, row in tqdm(self.labels.iterrows()):\n\n            output.append(\n                bounding_box_from_centre(\n                    mid_lat=row[\"lat\"], mid_lon=row[\"lon\"], surrounding_metres=surrounding_metres,\n                ),\n            )\n\n            if num_labelled_points is not None:\n                if len(output) >= num_labelled_points:\n                    return output\n        return output\n\n    def export_for_labels(\n        self,\n        days_per_timestep: int = 30,\n        num_timesteps: int = 12,\n        num_labelled_points: Optional[int] = None,\n        surrounding_metres: int = 80,\n        checkpoint: bool = True,\n        monitor: bool = False,\n        fast: bool = True,\n    ) -> None:\n        r\"\"\"\n        :param days_per_timestep: The number of days of data to use for each mosaiced image.\n            Default = 30\n        :param num_timesteps: The number of timesteps to export. Default = 12\n        :param num_labelled_points: If not None, then only this many points will be exported.\n            Default = None.\n        :param surrouning_metres: The patch will be [2 * surrounding_metres,\n            2 * surrounding_metres], centered around the labelled point. Default = 80\n        :param checkpoint: Whether or not to check in self.data_folder to see if the file has\n            already been exported. If it has, skip it. Default = True\n        :param monitor: Whether to monitor each task until it has been run. Default = True\n        :param fast: Whether to use the faster cloudfree exporter. This function is considerably\n            faster, but cloud artefacts can be more pronounced. Default = True\n        \"\"\"\n\n        bounding_boxes_to_download = self.labels_to_bounding_boxes(\n            num_labelled_points=num_labelled_points, surrounding_metres=surrounding_metres,\n        )\n\n        start_date = self.data_date - num_timesteps * timedelta(days=days_per_timestep)\n\n        for idx, bounding_info in enumerate(bounding_boxes_to_download):\n\n            self._export_for_polygon(\n                polygon=bounding_info.to_ee_polygon(),\n                polygon_identifier=idx,\n                start_date=start_date,\n                end_date=self.data_date,\n                days_per_timestep=days_per_timestep,\n                checkpoint=checkpoint,\n                monitor=monitor,\n                fast=fast,\n            )\n",
  "history_output" : "",
  "history_begin_time" : 1647347434919,
  "history_end_time" : 1647347436972,
  "history_notes" : null,
  "history_process" : "nlb6f5",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "c925cknu2g9",
  "history_input" : "import pandas as pd\nimport geopandas\nfrom tqdm import tqdm\nfrom datetime import timedelta, date\n\nfrom src_exporters_sentinel_base import BaseSentinelExporter\nfrom src_processors_kenya_non_crop import KenyaNonCropProcessor\nfrom src_exporters_sentinel_utils import EEBoundingBox, bounding_box_from_centre\n\nfrom typing import Optional, List\n\n\nclass KenyaNonCropSentinelExporter(BaseSentinelExporter):\n\n    dataset = \"earth_engine_kenya_non_crop\"\n\n    # data collection date\n    data_date = date(2020, 4, 16)\n\n    def load_labels(self) -> pd.DataFrame:\n        # right now, this just loads geowiki data. In the future,\n        # it would be neat to merge all labels together\n        non_crop = self.data_folder / \"processed\" / KenyaNonCropProcessor.dataset / \"data.geojson\"\n        assert non_crop.exists(), \"Kenya non crop processor must be run to load labels\"\n        return geopandas.read_file(non_crop)[[\"lat\", \"lon\"]]\n\n    def labels_to_bounding_boxes(\n        self, num_labelled_points: Optional[int], surrounding_metres: int\n    ) -> List[EEBoundingBox]:\n\n        output: List[EEBoundingBox] = []\n\n        for idx, row in tqdm(self.labels.iterrows()):\n\n            output.append(\n                bounding_box_from_centre(\n                    mid_lat=row[\"lat\"], mid_lon=row[\"lon\"], surrounding_metres=surrounding_metres,\n                ),\n            )\n\n            if num_labelled_points is not None:\n                if len(output) >= num_labelled_points:\n                    return output\n        return output\n\n    def export_for_labels(\n        self,\n        days_per_timestep: int = 30,\n        num_timesteps: int = 12,\n        num_labelled_points: Optional[int] = None,\n        surrounding_metres: int = 80,\n        checkpoint: bool = True,\n        monitor: bool = False,\n        fast: bool = True,\n    ) -> None:\n        r\"\"\"\n        :param days_per_timestep: The number of days of data to use for each mosaiced image.\n            Default = 30\n        :param num_timesteps: The number of timesteps to export. Default = 12\n        :param num_labelled_points: If not None, then only this many points will be exported.\n            Default = None.\n        :param surrouning_metres: The patch will be [2 * surrounding_metres,\n            2 * surrounding_metres], centered around the labelled point. Default = 80\n        :param checkpoint: Whether or not to check in self.data_folder to see if the file has\n            already been exported. If it has, skip it. Default = True\n        :param monitor: Whether to monitor each task until it has been run. Default = True\n        :param fast: Whether to use the faster cloudfree exporter. This function is considerably\n            faster, but cloud artefacts can be more pronounced. Default = True\n        \"\"\"\n\n        bounding_boxes_to_download = self.labels_to_bounding_boxes(\n            num_labelled_points=num_labelled_points, surrounding_metres=surrounding_metres,\n        )\n\n        start_date = self.data_date - num_timesteps * timedelta(days=days_per_timestep)\n\n        for idx, bounding_info in enumerate(bounding_boxes_to_download):\n\n            self._export_for_polygon(\n                polygon=bounding_info.to_ee_polygon(),\n                polygon_identifier=idx,\n                start_date=start_date,\n                end_date=self.data_date,\n                days_per_timestep=days_per_timestep,\n                checkpoint=checkpoint,\n                monitor=monitor,\n                fast=fast,\n            )\n",
  "history_output" : "",
  "history_begin_time" : 1647347335997,
  "history_end_time" : 1647347338000,
  "history_notes" : null,
  "history_process" : "nlb6f5",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "8svt5zs8x9r",
  "history_input" : "import pandas as pd\nimport geopandas\nfrom tqdm import tqdm\nfrom datetime import timedelta, date\n\nfrom src_exporters_sentinel_base import BaseSentinelExporter\nfrom src_processors_kenya_non_crop import KenyaNonCropProcessor\nfrom src_exporters_sentinel_utils import EEBoundingBox, bounding_box_from_centre\n\nfrom typing import Optional, List\n\n\nclass KenyaNonCropSentinelExporter(BaseSentinelExporter):\n\n    dataset = \"earth_engine_kenya_non_crop\"\n\n    # data collection date\n    data_date = date(2020, 4, 16)\n\n    def load_labels(self) -> pd.DataFrame:\n        # right now, this just loads geowiki data. In the future,\n        # it would be neat to merge all labels together\n        non_crop = self.data_folder / \"processed\" / KenyaNonCropProcessor.dataset / \"data.geojson\"\n        assert non_crop.exists(), \"Kenya non crop processor must be run to load labels\"\n        return geopandas.read_file(non_crop)[[\"lat\", \"lon\"]]\n\n    def labels_to_bounding_boxes(\n        self, num_labelled_points: Optional[int], surrounding_metres: int\n    ) -> List[EEBoundingBox]:\n\n        output: List[EEBoundingBox] = []\n\n        for idx, row in tqdm(self.labels.iterrows()):\n\n            output.append(\n                bounding_box_from_centre(\n                    mid_lat=row[\"lat\"], mid_lon=row[\"lon\"], surrounding_metres=surrounding_metres,\n                ),\n            )\n\n            if num_labelled_points is not None:\n                if len(output) >= num_labelled_points:\n                    return output\n        return output\n\n    def export_for_labels(\n        self,\n        days_per_timestep: int = 30,\n        num_timesteps: int = 12,\n        num_labelled_points: Optional[int] = None,\n        surrounding_metres: int = 80,\n        checkpoint: bool = True,\n        monitor: bool = False,\n        fast: bool = True,\n    ) -> None:\n        r\"\"\"\n        :param days_per_timestep: The number of days of data to use for each mosaiced image.\n            Default = 30\n        :param num_timesteps: The number of timesteps to export. Default = 12\n        :param num_labelled_points: If not None, then only this many points will be exported.\n            Default = None.\n        :param surrouning_metres: The patch will be [2 * surrounding_metres,\n            2 * surrounding_metres], centered around the labelled point. Default = 80\n        :param checkpoint: Whether or not to check in self.data_folder to see if the file has\n            already been exported. If it has, skip it. Default = True\n        :param monitor: Whether to monitor each task until it has been run. Default = True\n        :param fast: Whether to use the faster cloudfree exporter. This function is considerably\n            faster, but cloud artefacts can be more pronounced. Default = True\n        \"\"\"\n\n        bounding_boxes_to_download = self.labels_to_bounding_boxes(\n            num_labelled_points=num_labelled_points, surrounding_metres=surrounding_metres,\n        )\n\n        start_date = self.data_date - num_timesteps * timedelta(days=days_per_timestep)\n\n        for idx, bounding_info in enumerate(bounding_boxes_to_download):\n\n            self._export_for_polygon(\n                polygon=bounding_info.to_ee_polygon(),\n                polygon_identifier=idx,\n                start_date=start_date,\n                end_date=self.data_date,\n                days_per_timestep=days_per_timestep,\n                checkpoint=checkpoint,\n                monitor=monitor,\n                fast=fast,\n            )\n",
  "history_output" : "",
  "history_begin_time" : 1647347273868,
  "history_end_time" : 1647347274481,
  "history_notes" : null,
  "history_process" : "nlb6f5",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "aigzz06nwg7",
  "history_input" : "import pandas as pd\nimport geopandas\nfrom tqdm import tqdm\nfrom datetime import timedelta, date\n\nfrom src_exporters_sentinel_base import BaseSentinelExporter\nfrom src_processors_kenya_non_crop import KenyaNonCropProcessor\nfrom src_exporters_sentinel_utils import EEBoundingBox, bounding_box_from_centre\n\nfrom typing import Optional, List\n\n\nclass KenyaNonCropSentinelExporter(BaseSentinelExporter):\n\n    dataset = \"earth_engine_kenya_non_crop\"\n\n    # data collection date\n    data_date = date(2020, 4, 16)\n\n    def load_labels(self) -> pd.DataFrame:\n        # right now, this just loads geowiki data. In the future,\n        # it would be neat to merge all labels together\n        non_crop = self.data_folder / \"processed\" / KenyaNonCropProcessor.dataset / \"data.geojson\"\n        assert non_crop.exists(), \"Kenya non crop processor must be run to load labels\"\n        return geopandas.read_file(non_crop)[[\"lat\", \"lon\"]]\n\n    def labels_to_bounding_boxes(\n        self, num_labelled_points: Optional[int], surrounding_metres: int\n    ) -> List[EEBoundingBox]:\n\n        output: List[EEBoundingBox] = []\n\n        for idx, row in tqdm(self.labels.iterrows()):\n\n            output.append(\n                bounding_box_from_centre(\n                    mid_lat=row[\"lat\"], mid_lon=row[\"lon\"], surrounding_metres=surrounding_metres,\n                ),\n            )\n\n            if num_labelled_points is not None:\n                if len(output) >= num_labelled_points:\n                    return output\n        return output\n\n    def export_for_labels(\n        self,\n        days_per_timestep: int = 30,\n        num_timesteps: int = 12,\n        num_labelled_points: Optional[int] = None,\n        surrounding_metres: int = 80,\n        checkpoint: bool = True,\n        monitor: bool = False,\n        fast: bool = True,\n    ) -> None:\n        r\"\"\"\n        :param days_per_timestep: The number of days of data to use for each mosaiced image.\n            Default = 30\n        :param num_timesteps: The number of timesteps to export. Default = 12\n        :param num_labelled_points: If not None, then only this many points will be exported.\n            Default = None.\n        :param surrouning_metres: The patch will be [2 * surrounding_metres,\n            2 * surrounding_metres], centered around the labelled point. Default = 80\n        :param checkpoint: Whether or not to check in self.data_folder to see if the file has\n            already been exported. If it has, skip it. Default = True\n        :param monitor: Whether to monitor each task until it has been run. Default = True\n        :param fast: Whether to use the faster cloudfree exporter. This function is considerably\n            faster, but cloud artefacts can be more pronounced. Default = True\n        \"\"\"\n\n        bounding_boxes_to_download = self.labels_to_bounding_boxes(\n            num_labelled_points=num_labelled_points, surrounding_metres=surrounding_metres,\n        )\n\n        start_date = self.data_date - num_timesteps * timedelta(days=days_per_timestep)\n\n        for idx, bounding_info in enumerate(bounding_boxes_to_download):\n\n            self._export_for_polygon(\n                polygon=bounding_info.to_ee_polygon(),\n                polygon_identifier=idx,\n                start_date=start_date,\n                end_date=self.data_date,\n                days_per_timestep=days_per_timestep,\n                checkpoint=checkpoint,\n                monitor=monitor,\n                fast=fast,\n            )\n",
  "history_output" : "",
  "history_begin_time" : 1647347150702,
  "history_end_time" : 1647347152591,
  "history_notes" : null,
  "history_process" : "nlb6f5",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "wxg0he07emj",
  "history_input" : "import pandas as pd\nimport geopandas\nfrom tqdm import tqdm\nfrom datetime import timedelta, date\n\nfrom src_exporters_sentinel_base import BaseSentinelExporter\nfrom src_processors_kenya_non_crop import KenyaNonCropProcessor\nfrom src_exporters_sentinel_utils import EEBoundingBox, bounding_box_from_centre\n\nfrom typing import Optional, List\n\n\nclass KenyaNonCropSentinelExporter(BaseSentinelExporter):\n\n    dataset = \"earth_engine_kenya_non_crop\"\n\n    # data collection date\n    data_date = date(2020, 4, 16)\n\n    def load_labels(self) -> pd.DataFrame:\n        # right now, this just loads geowiki data. In the future,\n        # it would be neat to merge all labels together\n        non_crop = self.data_folder / \"processed\" / KenyaNonCropProcessor.dataset / \"data.geojson\"\n        assert non_crop.exists(), \"Kenya non crop processor must be run to load labels\"\n        return geopandas.read_file(non_crop)[[\"lat\", \"lon\"]]\n\n    def labels_to_bounding_boxes(\n        self, num_labelled_points: Optional[int], surrounding_metres: int\n    ) -> List[EEBoundingBox]:\n\n        output: List[EEBoundingBox] = []\n\n        for idx, row in tqdm(self.labels.iterrows()):\n\n            output.append(\n                bounding_box_from_centre(\n                    mid_lat=row[\"lat\"], mid_lon=row[\"lon\"], surrounding_metres=surrounding_metres,\n                ),\n            )\n\n            if num_labelled_points is not None:\n                if len(output) >= num_labelled_points:\n                    return output\n        return output\n\n    def export_for_labels(\n        self,\n        days_per_timestep: int = 30,\n        num_timesteps: int = 12,\n        num_labelled_points: Optional[int] = None,\n        surrounding_metres: int = 80,\n        checkpoint: bool = True,\n        monitor: bool = False,\n        fast: bool = True,\n    ) -> None:\n        r\"\"\"\n        :param days_per_timestep: The number of days of data to use for each mosaiced image.\n            Default = 30\n        :param num_timesteps: The number of timesteps to export. Default = 12\n        :param num_labelled_points: If not None, then only this many points will be exported.\n            Default = None.\n        :param surrouning_metres: The patch will be [2 * surrounding_metres,\n            2 * surrounding_metres], centered around the labelled point. Default = 80\n        :param checkpoint: Whether or not to check in self.data_folder to see if the file has\n            already been exported. If it has, skip it. Default = True\n        :param monitor: Whether to monitor each task until it has been run. Default = True\n        :param fast: Whether to use the faster cloudfree exporter. This function is considerably\n            faster, but cloud artefacts can be more pronounced. Default = True\n        \"\"\"\n\n        bounding_boxes_to_download = self.labels_to_bounding_boxes(\n            num_labelled_points=num_labelled_points, surrounding_metres=surrounding_metres,\n        )\n\n        start_date = self.data_date - num_timesteps * timedelta(days=days_per_timestep)\n\n        for idx, bounding_info in enumerate(bounding_boxes_to_download):\n\n            self._export_for_polygon(\n                polygon=bounding_info.to_ee_polygon(),\n                polygon_identifier=idx,\n                start_date=start_date,\n                end_date=self.data_date,\n                days_per_timestep=days_per_timestep,\n                checkpoint=checkpoint,\n                monitor=monitor,\n                fast=fast,\n            )\n",
  "history_output" : "",
  "history_begin_time" : 1647346825592,
  "history_end_time" : 1647346825937,
  "history_notes" : null,
  "history_process" : "nlb6f5",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "s47k7f1tmsb",
  "history_input" : "import pandas as pd\nimport geopandas\nfrom tqdm import tqdm\nfrom datetime import timedelta, date\n\nfrom src_exporters_sentinel_base import BaseSentinelExporter\nfrom src_processors_kenya_non_crop import KenyaNonCropProcessor\nfrom src_exporters_sentinel_utils import EEBoundingBox, bounding_box_from_centre\n\nfrom typing import Optional, List\n\n\nclass KenyaNonCropSentinelExporter(BaseSentinelExporter):\n\n    dataset = \"earth_engine_kenya_non_crop\"\n\n    # data collection date\n    data_date = date(2020, 4, 16)\n\n    def load_labels(self) -> pd.DataFrame:\n        # right now, this just loads geowiki data. In the future,\n        # it would be neat to merge all labels together\n        non_crop = self.data_folder / \"processed\" / KenyaNonCropProcessor.dataset / \"data.geojson\"\n        assert non_crop.exists(), \"Kenya non crop processor must be run to load labels\"\n        return geopandas.read_file(non_crop)[[\"lat\", \"lon\"]]\n\n    def labels_to_bounding_boxes(\n        self, num_labelled_points: Optional[int], surrounding_metres: int\n    ) -> List[EEBoundingBox]:\n\n        output: List[EEBoundingBox] = []\n\n        for idx, row in tqdm(self.labels.iterrows()):\n\n            output.append(\n                bounding_box_from_centre(\n                    mid_lat=row[\"lat\"], mid_lon=row[\"lon\"], surrounding_metres=surrounding_metres,\n                ),\n            )\n\n            if num_labelled_points is not None:\n                if len(output) >= num_labelled_points:\n                    return output\n        return output\n\n    def export_for_labels(\n        self,\n        days_per_timestep: int = 30,\n        num_timesteps: int = 12,\n        num_labelled_points: Optional[int] = None,\n        surrounding_metres: int = 80,\n        checkpoint: bool = True,\n        monitor: bool = False,\n        fast: bool = True,\n    ) -> None:\n        r\"\"\"\n        :param days_per_timestep: The number of days of data to use for each mosaiced image.\n            Default = 30\n        :param num_timesteps: The number of timesteps to export. Default = 12\n        :param num_labelled_points: If not None, then only this many points will be exported.\n            Default = None.\n        :param surrouning_metres: The patch will be [2 * surrounding_metres,\n            2 * surrounding_metres], centered around the labelled point. Default = 80\n        :param checkpoint: Whether or not to check in self.data_folder to see if the file has\n            already been exported. If it has, skip it. Default = True\n        :param monitor: Whether to monitor each task until it has been run. Default = True\n        :param fast: Whether to use the faster cloudfree exporter. This function is considerably\n            faster, but cloud artefacts can be more pronounced. Default = True\n        \"\"\"\n\n        bounding_boxes_to_download = self.labels_to_bounding_boxes(\n            num_labelled_points=num_labelled_points, surrounding_metres=surrounding_metres,\n        )\n\n        start_date = self.data_date - num_timesteps * timedelta(days=days_per_timestep)\n\n        for idx, bounding_info in enumerate(bounding_boxes_to_download):\n\n            self._export_for_polygon(\n                polygon=bounding_info.to_ee_polygon(),\n                polygon_identifier=idx,\n                start_date=start_date,\n                end_date=self.data_date,\n                days_per_timestep=days_per_timestep,\n                checkpoint=checkpoint,\n                monitor=monitor,\n                fast=fast,\n            )\n",
  "history_output" : "",
  "history_begin_time" : 1647346644188,
  "history_end_time" : 1647346646737,
  "history_notes" : null,
  "history_process" : "nlb6f5",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "egqzi1pfw4k",
  "history_input" : "import pandas as pd\nimport geopandas\nfrom tqdm import tqdm\nfrom datetime import timedelta, date\n\nfrom src_exporters_sentinel_base import BaseSentinelExporter\nfrom src_processors_kenya_non_crop import KenyaNonCropProcessor\nfrom src_exporters_sentinel_utils import EEBoundingBox, bounding_box_from_centre\n\nfrom typing import Optional, List\n\n\nclass KenyaNonCropSentinelExporter(BaseSentinelExporter):\n\n    dataset = \"earth_engine_kenya_non_crop\"\n\n    # data collection date\n    data_date = date(2020, 4, 16)\n\n    def load_labels(self) -> pd.DataFrame:\n        # right now, this just loads geowiki data. In the future,\n        # it would be neat to merge all labels together\n        non_crop = self.data_folder / \"processed\" / KenyaNonCropProcessor.dataset / \"data.geojson\"\n        assert non_crop.exists(), \"Kenya non crop processor must be run to load labels\"\n        return geopandas.read_file(non_crop)[[\"lat\", \"lon\"]]\n\n    def labels_to_bounding_boxes(\n        self, num_labelled_points: Optional[int], surrounding_metres: int\n    ) -> List[EEBoundingBox]:\n\n        output: List[EEBoundingBox] = []\n\n        for idx, row in tqdm(self.labels.iterrows()):\n\n            output.append(\n                bounding_box_from_centre(\n                    mid_lat=row[\"lat\"], mid_lon=row[\"lon\"], surrounding_metres=surrounding_metres,\n                ),\n            )\n\n            if num_labelled_points is not None:\n                if len(output) >= num_labelled_points:\n                    return output\n        return output\n\n    def export_for_labels(\n        self,\n        days_per_timestep: int = 30,\n        num_timesteps: int = 12,\n        num_labelled_points: Optional[int] = None,\n        surrounding_metres: int = 80,\n        checkpoint: bool = True,\n        monitor: bool = False,\n        fast: bool = True,\n    ) -> None:\n        r\"\"\"\n        :param days_per_timestep: The number of days of data to use for each mosaiced image.\n            Default = 30\n        :param num_timesteps: The number of timesteps to export. Default = 12\n        :param num_labelled_points: If not None, then only this many points will be exported.\n            Default = None.\n        :param surrouning_metres: The patch will be [2 * surrounding_metres,\n            2 * surrounding_metres], centered around the labelled point. Default = 80\n        :param checkpoint: Whether or not to check in self.data_folder to see if the file has\n            already been exported. If it has, skip it. Default = True\n        :param monitor: Whether to monitor each task until it has been run. Default = True\n        :param fast: Whether to use the faster cloudfree exporter. This function is considerably\n            faster, but cloud artefacts can be more pronounced. Default = True\n        \"\"\"\n\n        bounding_boxes_to_download = self.labels_to_bounding_boxes(\n            num_labelled_points=num_labelled_points, surrounding_metres=surrounding_metres,\n        )\n\n        start_date = self.data_date - num_timesteps * timedelta(days=days_per_timestep)\n\n        for idx, bounding_info in enumerate(bounding_boxes_to_download):\n\n            self._export_for_polygon(\n                polygon=bounding_info.to_ee_polygon(),\n                polygon_identifier=idx,\n                start_date=start_date,\n                end_date=self.data_date,\n                days_per_timestep=days_per_timestep,\n                checkpoint=checkpoint,\n                monitor=monitor,\n                fast=fast,\n            )\n",
  "history_output" : "",
  "history_begin_time" : 1647345844262,
  "history_end_time" : 1647345844469,
  "history_notes" : null,
  "history_process" : "nlb6f5",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "bmfwgveqtck",
  "history_input" : "import pandas as pd\nimport geopandas\nfrom tqdm import tqdm\nfrom datetime import timedelta, date\n\nfrom src_exporters_sentinel_base import BaseSentinelExporter\nfrom src_processors_kenya_non_crop import KenyaNonCropProcessor\nfrom src_exporters_sentinel_utils import EEBoundingBox, bounding_box_from_centre\n\nfrom typing import Optional, List\n\n\nclass KenyaNonCropSentinelExporter(BaseSentinelExporter):\n\n    dataset = \"earth_engine_kenya_non_crop\"\n\n    # data collection date\n    data_date = date(2020, 4, 16)\n\n    def load_labels(self) -> pd.DataFrame:\n        # right now, this just loads geowiki data. In the future,\n        # it would be neat to merge all labels together\n        non_crop = self.data_folder / \"processed\" / KenyaNonCropProcessor.dataset / \"data.geojson\"\n        assert non_crop.exists(), \"Kenya non crop processor must be run to load labels\"\n        return geopandas.read_file(non_crop)[[\"lat\", \"lon\"]]\n\n    def labels_to_bounding_boxes(\n        self, num_labelled_points: Optional[int], surrounding_metres: int\n    ) -> List[EEBoundingBox]:\n\n        output: List[EEBoundingBox] = []\n\n        for idx, row in tqdm(self.labels.iterrows()):\n\n            output.append(\n                bounding_box_from_centre(\n                    mid_lat=row[\"lat\"], mid_lon=row[\"lon\"], surrounding_metres=surrounding_metres,\n                ),\n            )\n\n            if num_labelled_points is not None:\n                if len(output) >= num_labelled_points:\n                    return output\n        return output\n\n    def export_for_labels(\n        self,\n        days_per_timestep: int = 30,\n        num_timesteps: int = 12,\n        num_labelled_points: Optional[int] = None,\n        surrounding_metres: int = 80,\n        checkpoint: bool = True,\n        monitor: bool = False,\n        fast: bool = True,\n    ) -> None:\n        r\"\"\"\n        :param days_per_timestep: The number of days of data to use for each mosaiced image.\n            Default = 30\n        :param num_timesteps: The number of timesteps to export. Default = 12\n        :param num_labelled_points: If not None, then only this many points will be exported.\n            Default = None.\n        :param surrouning_metres: The patch will be [2 * surrounding_metres,\n            2 * surrounding_metres], centered around the labelled point. Default = 80\n        :param checkpoint: Whether or not to check in self.data_folder to see if the file has\n            already been exported. If it has, skip it. Default = True\n        :param monitor: Whether to monitor each task until it has been run. Default = True\n        :param fast: Whether to use the faster cloudfree exporter. This function is considerably\n            faster, but cloud artefacts can be more pronounced. Default = True\n        \"\"\"\n\n        bounding_boxes_to_download = self.labels_to_bounding_boxes(\n            num_labelled_points=num_labelled_points, surrounding_metres=surrounding_metres,\n        )\n\n        start_date = self.data_date - num_timesteps * timedelta(days=days_per_timestep)\n\n        for idx, bounding_info in enumerate(bounding_boxes_to_download):\n\n            self._export_for_polygon(\n                polygon=bounding_info.to_ee_polygon(),\n                polygon_identifier=idx,\n                start_date=start_date,\n                end_date=self.data_date,\n                days_per_timestep=days_per_timestep,\n                checkpoint=checkpoint,\n                monitor=monitor,\n                fast=fast,\n            )\n",
  "history_output" : "",
  "history_begin_time" : 1647345662775,
  "history_end_time" : 1647345664923,
  "history_notes" : null,
  "history_process" : "nlb6f5",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "r3mqe8uskp4",
  "history_input" : "import pandas as pd\nimport geopandas\nfrom tqdm import tqdm\nfrom datetime import timedelta, date\n\nfrom src_exporters_sentinel_base import BaseSentinelExporter\nfrom src_processors_kenya_non_crop import KenyaNonCropProcessor\nfrom src_exporters_sentinel_utils import EEBoundingBox, bounding_box_from_centre\n\nfrom typing import Optional, List\n\n\nclass KenyaNonCropSentinelExporter(BaseSentinelExporter):\n\n    dataset = \"earth_engine_kenya_non_crop\"\n\n    # data collection date\n    data_date = date(2020, 4, 16)\n\n    def load_labels(self) -> pd.DataFrame:\n        # right now, this just loads geowiki data. In the future,\n        # it would be neat to merge all labels together\n        non_crop = self.data_folder / \"processed\" / KenyaNonCropProcessor.dataset / \"data.geojson\"\n        assert non_crop.exists(), \"Kenya non crop processor must be run to load labels\"\n        return geopandas.read_file(non_crop)[[\"lat\", \"lon\"]]\n\n    def labels_to_bounding_boxes(\n        self, num_labelled_points: Optional[int], surrounding_metres: int\n    ) -> List[EEBoundingBox]:\n\n        output: List[EEBoundingBox] = []\n\n        for idx, row in tqdm(self.labels.iterrows()):\n\n            output.append(\n                bounding_box_from_centre(\n                    mid_lat=row[\"lat\"], mid_lon=row[\"lon\"], surrounding_metres=surrounding_metres,\n                ),\n            )\n\n            if num_labelled_points is not None:\n                if len(output) >= num_labelled_points:\n                    return output\n        return output\n\n    def export_for_labels(\n        self,\n        days_per_timestep: int = 30,\n        num_timesteps: int = 12,\n        num_labelled_points: Optional[int] = None,\n        surrounding_metres: int = 80,\n        checkpoint: bool = True,\n        monitor: bool = False,\n        fast: bool = True,\n    ) -> None:\n        r\"\"\"\n        :param days_per_timestep: The number of days of data to use for each mosaiced image.\n            Default = 30\n        :param num_timesteps: The number of timesteps to export. Default = 12\n        :param num_labelled_points: If not None, then only this many points will be exported.\n            Default = None.\n        :param surrouning_metres: The patch will be [2 * surrounding_metres,\n            2 * surrounding_metres], centered around the labelled point. Default = 80\n        :param checkpoint: Whether or not to check in self.data_folder to see if the file has\n            already been exported. If it has, skip it. Default = True\n        :param monitor: Whether to monitor each task until it has been run. Default = True\n        :param fast: Whether to use the faster cloudfree exporter. This function is considerably\n            faster, but cloud artefacts can be more pronounced. Default = True\n        \"\"\"\n\n        bounding_boxes_to_download = self.labels_to_bounding_boxes(\n            num_labelled_points=num_labelled_points, surrounding_metres=surrounding_metres,\n        )\n\n        start_date = self.data_date - num_timesteps * timedelta(days=days_per_timestep)\n\n        for idx, bounding_info in enumerate(bounding_boxes_to_download):\n\n            self._export_for_polygon(\n                polygon=bounding_info.to_ee_polygon(),\n                polygon_identifier=idx,\n                start_date=start_date,\n                end_date=self.data_date,\n                days_per_timestep=days_per_timestep,\n                checkpoint=checkpoint,\n                monitor=monitor,\n                fast=fast,\n            )\n",
  "history_output" : "",
  "history_begin_time" : 1647340124876,
  "history_end_time" : 1647340126980,
  "history_notes" : null,
  "history_process" : "nlb6f5",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "i5asum601zd",
  "history_input" : "import pandas as pd\nimport geopandas\nfrom tqdm import tqdm\nfrom datetime import timedelta, date\n\nfrom src_exporters_sentinel_base import BaseSentinelExporter\nfrom src_processors_kenya_non_crop import KenyaNonCropProcessor\nfrom src_exporters_sentinel_utils import EEBoundingBox, bounding_box_from_centre\n\nfrom typing import Optional, List\n\n\nclass KenyaNonCropSentinelExporter(BaseSentinelExporter):\n\n    dataset = \"earth_engine_kenya_non_crop\"\n\n    # data collection date\n    data_date = date(2020, 4, 16)\n\n    def load_labels(self) -> pd.DataFrame:\n        # right now, this just loads geowiki data. In the future,\n        # it would be neat to merge all labels together\n        non_crop = self.data_folder / \"processed\" / KenyaNonCropProcessor.dataset / \"data.geojson\"\n        assert non_crop.exists(), \"Kenya non crop processor must be run to load labels\"\n        return geopandas.read_file(non_crop)[[\"lat\", \"lon\"]]\n\n    def labels_to_bounding_boxes(\n        self, num_labelled_points: Optional[int], surrounding_metres: int\n    ) -> List[EEBoundingBox]:\n\n        output: List[EEBoundingBox] = []\n\n        for idx, row in tqdm(self.labels.iterrows()):\n\n            output.append(\n                bounding_box_from_centre(\n                    mid_lat=row[\"lat\"], mid_lon=row[\"lon\"], surrounding_metres=surrounding_metres,\n                ),\n            )\n\n            if num_labelled_points is not None:\n                if len(output) >= num_labelled_points:\n                    return output\n        return output\n\n    def export_for_labels(\n        self,\n        days_per_timestep: int = 30,\n        num_timesteps: int = 12,\n        num_labelled_points: Optional[int] = None,\n        surrounding_metres: int = 80,\n        checkpoint: bool = True,\n        monitor: bool = False,\n        fast: bool = True,\n    ) -> None:\n        r\"\"\"\n        :param days_per_timestep: The number of days of data to use for each mosaiced image.\n            Default = 30\n        :param num_timesteps: The number of timesteps to export. Default = 12\n        :param num_labelled_points: If not None, then only this many points will be exported.\n            Default = None.\n        :param surrouning_metres: The patch will be [2 * surrounding_metres,\n            2 * surrounding_metres], centered around the labelled point. Default = 80\n        :param checkpoint: Whether or not to check in self.data_folder to see if the file has\n            already been exported. If it has, skip it. Default = True\n        :param monitor: Whether to monitor each task until it has been run. Default = True\n        :param fast: Whether to use the faster cloudfree exporter. This function is considerably\n            faster, but cloud artefacts can be more pronounced. Default = True\n        \"\"\"\n\n        bounding_boxes_to_download = self.labels_to_bounding_boxes(\n            num_labelled_points=num_labelled_points, surrounding_metres=surrounding_metres,\n        )\n\n        start_date = self.data_date - num_timesteps * timedelta(days=days_per_timestep)\n\n        for idx, bounding_info in enumerate(bounding_boxes_to_download):\n\n            self._export_for_polygon(\n                polygon=bounding_info.to_ee_polygon(),\n                polygon_identifier=idx,\n                start_date=start_date,\n                end_date=self.data_date,\n                days_per_timestep=days_per_timestep,\n                checkpoint=checkpoint,\n                monitor=monitor,\n                fast=fast,\n            )\n",
  "history_output" : "",
  "history_begin_time" : 1646147721220,
  "history_end_time" : 1646147721596,
  "history_notes" : null,
  "history_process" : "nlb6f5",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "dtyg2n57e3q",
  "history_input" : "import pandas as pd\nimport geopandas\nfrom tqdm import tqdm\nfrom datetime import timedelta, date\n\nfrom src_exporters_sentinel_base import BaseSentinelExporter\nfrom src_processors_kenya_non_crop import KenyaNonCropProcessor\nfrom src_exporters_sentinel_utils import EEBoundingBox, bounding_box_from_centre\n\nfrom typing import Optional, List\n\n\nclass KenyaNonCropSentinelExporter(BaseSentinelExporter):\n\n    dataset = \"earth_engine_kenya_non_crop\"\n\n    # data collection date\n    data_date = date(2020, 4, 16)\n\n    def load_labels(self) -> pd.DataFrame:\n        # right now, this just loads geowiki data. In the future,\n        # it would be neat to merge all labels together\n        non_crop = self.data_folder / \"processed\" / KenyaNonCropProcessor.dataset / \"data.geojson\"\n        assert non_crop.exists(), \"Kenya non crop processor must be run to load labels\"\n        return geopandas.read_file(non_crop)[[\"lat\", \"lon\"]]\n\n    def labels_to_bounding_boxes(\n        self, num_labelled_points: Optional[int], surrounding_metres: int\n    ) -> List[EEBoundingBox]:\n\n        output: List[EEBoundingBox] = []\n\n        for idx, row in tqdm(self.labels.iterrows()):\n\n            output.append(\n                bounding_box_from_centre(\n                    mid_lat=row[\"lat\"], mid_lon=row[\"lon\"], surrounding_metres=surrounding_metres,\n                ),\n            )\n\n            if num_labelled_points is not None:\n                if len(output) >= num_labelled_points:\n                    return output\n        return output\n\n    def export_for_labels(\n        self,\n        days_per_timestep: int = 30,\n        num_timesteps: int = 12,\n        num_labelled_points: Optional[int] = None,\n        surrounding_metres: int = 80,\n        checkpoint: bool = True,\n        monitor: bool = False,\n        fast: bool = True,\n    ) -> None:\n        r\"\"\"\n        :param days_per_timestep: The number of days of data to use for each mosaiced image.\n            Default = 30\n        :param num_timesteps: The number of timesteps to export. Default = 12\n        :param num_labelled_points: If not None, then only this many points will be exported.\n            Default = None.\n        :param surrouning_metres: The patch will be [2 * surrounding_metres,\n            2 * surrounding_metres], centered around the labelled point. Default = 80\n        :param checkpoint: Whether or not to check in self.data_folder to see if the file has\n            already been exported. If it has, skip it. Default = True\n        :param monitor: Whether to monitor each task until it has been run. Default = True\n        :param fast: Whether to use the faster cloudfree exporter. This function is considerably\n            faster, but cloud artefacts can be more pronounced. Default = True\n        \"\"\"\n\n        bounding_boxes_to_download = self.labels_to_bounding_boxes(\n            num_labelled_points=num_labelled_points, surrounding_metres=surrounding_metres,\n        )\n\n        start_date = self.data_date - num_timesteps * timedelta(days=days_per_timestep)\n\n        for idx, bounding_info in enumerate(bounding_boxes_to_download):\n\n            self._export_for_polygon(\n                polygon=bounding_info.to_ee_polygon(),\n                polygon_identifier=idx,\n                start_date=start_date,\n                end_date=self.data_date,\n                days_per_timestep=days_per_timestep,\n                checkpoint=checkpoint,\n                monitor=monitor,\n                fast=fast,\n            )\n",
  "history_output" : "",
  "history_begin_time" : 1646145432083,
  "history_end_time" : 1646145434283,
  "history_notes" : null,
  "history_process" : "nlb6f5",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "cgv0nnmyrg0",
  "history_input" : "import pandas as pd\nimport geopandas\nfrom tqdm import tqdm\nfrom datetime import timedelta, date\n\nfrom src_exporters_sentinel_base import BaseSentinelExporter\nfrom src_processors_kenya_non_crop import KenyaNonCropProcessor\nfrom src_exporters_sentinel_utils import EEBoundingBox, bounding_box_from_centre\n\nfrom typing import Optional, List\n\n\nclass KenyaNonCropSentinelExporter(BaseSentinelExporter):\n\n    dataset = \"earth_engine_kenya_non_crop\"\n\n    # data collection date\n    data_date = date(2020, 4, 16)\n\n    def load_labels(self) -> pd.DataFrame:\n        # right now, this just loads geowiki data. In the future,\n        # it would be neat to merge all labels together\n        non_crop = self.data_folder / \"processed\" / KenyaNonCropProcessor.dataset / \"data.geojson\"\n        assert non_crop.exists(), \"Kenya non crop processor must be run to load labels\"\n        return geopandas.read_file(non_crop)[[\"lat\", \"lon\"]]\n\n    def labels_to_bounding_boxes(\n        self, num_labelled_points: Optional[int], surrounding_metres: int\n    ) -> List[EEBoundingBox]:\n\n        output: List[EEBoundingBox] = []\n\n        for idx, row in tqdm(self.labels.iterrows()):\n\n            output.append(\n                bounding_box_from_centre(\n                    mid_lat=row[\"lat\"], mid_lon=row[\"lon\"], surrounding_metres=surrounding_metres,\n                ),\n            )\n\n            if num_labelled_points is not None:\n                if len(output) >= num_labelled_points:\n                    return output\n        return output\n\n    def export_for_labels(\n        self,\n        days_per_timestep: int = 30,\n        num_timesteps: int = 12,\n        num_labelled_points: Optional[int] = None,\n        surrounding_metres: int = 80,\n        checkpoint: bool = True,\n        monitor: bool = False,\n        fast: bool = True,\n    ) -> None:\n        r\"\"\"\n        :param days_per_timestep: The number of days of data to use for each mosaiced image.\n            Default = 30\n        :param num_timesteps: The number of timesteps to export. Default = 12\n        :param num_labelled_points: If not None, then only this many points will be exported.\n            Default = None.\n        :param surrouning_metres: The patch will be [2 * surrounding_metres,\n            2 * surrounding_metres], centered around the labelled point. Default = 80\n        :param checkpoint: Whether or not to check in self.data_folder to see if the file has\n            already been exported. If it has, skip it. Default = True\n        :param monitor: Whether to monitor each task until it has been run. Default = True\n        :param fast: Whether to use the faster cloudfree exporter. This function is considerably\n            faster, but cloud artefacts can be more pronounced. Default = True\n        \"\"\"\n\n        bounding_boxes_to_download = self.labels_to_bounding_boxes(\n            num_labelled_points=num_labelled_points, surrounding_metres=surrounding_metres,\n        )\n\n        start_date = self.data_date - num_timesteps * timedelta(days=days_per_timestep)\n\n        for idx, bounding_info in enumerate(bounding_boxes_to_download):\n\n            self._export_for_polygon(\n                polygon=bounding_info.to_ee_polygon(),\n                polygon_identifier=idx,\n                start_date=start_date,\n                end_date=self.data_date,\n                days_per_timestep=days_per_timestep,\n                checkpoint=checkpoint,\n                monitor=monitor,\n                fast=fast,\n            )\n",
  "history_output" : "",
  "history_begin_time" : 1646145213686,
  "history_end_time" : 1646145216404,
  "history_notes" : null,
  "history_process" : "nlb6f5",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "o3li010zosh",
  "history_input" : "import pandas as pd\nimport geopandas\nfrom tqdm import tqdm\nfrom datetime import timedelta, date\n\nfrom src_exporters_sentinel_base import BaseSentinelExporter\nfrom src_processors_kenya_non_crop import KenyaNonCropProcessor\nfrom src_exporters_sentinel_utils import EEBoundingBox, bounding_box_from_centre\n\nfrom typing import Optional, List\n\n\nclass KenyaNonCropSentinelExporter(BaseSentinelExporter):\n\n    dataset = \"earth_engine_kenya_non_crop\"\n\n    # data collection date\n    data_date = date(2020, 4, 16)\n\n    def load_labels(self) -> pd.DataFrame:\n        # right now, this just loads geowiki data. In the future,\n        # it would be neat to merge all labels together\n        non_crop = self.data_folder / \"processed\" / KenyaNonCropProcessor.dataset / \"data.geojson\"\n        assert non_crop.exists(), \"Kenya non crop processor must be run to load labels\"\n        return geopandas.read_file(non_crop)[[\"lat\", \"lon\"]]\n\n    def labels_to_bounding_boxes(\n        self, num_labelled_points: Optional[int], surrounding_metres: int\n    ) -> List[EEBoundingBox]:\n\n        output: List[EEBoundingBox] = []\n\n        for idx, row in tqdm(self.labels.iterrows()):\n\n            output.append(\n                bounding_box_from_centre(\n                    mid_lat=row[\"lat\"], mid_lon=row[\"lon\"], surrounding_metres=surrounding_metres,\n                ),\n            )\n\n            if num_labelled_points is not None:\n                if len(output) >= num_labelled_points:\n                    return output\n        return output\n\n    def export_for_labels(\n        self,\n        days_per_timestep: int = 30,\n        num_timesteps: int = 12,\n        num_labelled_points: Optional[int] = None,\n        surrounding_metres: int = 80,\n        checkpoint: bool = True,\n        monitor: bool = False,\n        fast: bool = True,\n    ) -> None:\n        r\"\"\"\n        :param days_per_timestep: The number of days of data to use for each mosaiced image.\n            Default = 30\n        :param num_timesteps: The number of timesteps to export. Default = 12\n        :param num_labelled_points: If not None, then only this many points will be exported.\n            Default = None.\n        :param surrouning_metres: The patch will be [2 * surrounding_metres,\n            2 * surrounding_metres], centered around the labelled point. Default = 80\n        :param checkpoint: Whether or not to check in self.data_folder to see if the file has\n            already been exported. If it has, skip it. Default = True\n        :param monitor: Whether to monitor each task until it has been run. Default = True\n        :param fast: Whether to use the faster cloudfree exporter. This function is considerably\n            faster, but cloud artefacts can be more pronounced. Default = True\n        \"\"\"\n\n        bounding_boxes_to_download = self.labels_to_bounding_boxes(\n            num_labelled_points=num_labelled_points, surrounding_metres=surrounding_metres,\n        )\n\n        start_date = self.data_date - num_timesteps * timedelta(days=days_per_timestep)\n\n        for idx, bounding_info in enumerate(bounding_boxes_to_download):\n\n            self._export_for_polygon(\n                polygon=bounding_info.to_ee_polygon(),\n                polygon_identifier=idx,\n                start_date=start_date,\n                end_date=self.data_date,\n                days_per_timestep=days_per_timestep,\n                checkpoint=checkpoint,\n                monitor=monitor,\n                fast=fast,\n            )\n",
  "history_output" : "",
  "history_begin_time" : 1646144603121,
  "history_end_time" : 1646144603328,
  "history_notes" : null,
  "history_process" : "nlb6f5",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "m4oegjae4ka",
  "history_input" : "import pandas as pd\nimport geopandas\nfrom tqdm import tqdm\nfrom datetime import timedelta, date\n\nfrom src_exporters_sentinel_base import BaseSentinelExporter\nfrom src_processors_kenya_non_crop import KenyaNonCropProcessor\nfrom src_exporters_sentinel_utils import EEBoundingBox, bounding_box_from_centre\n\nfrom typing import Optional, List\n\n\nclass KenyaNonCropSentinelExporter(BaseSentinelExporter):\n\n    dataset = \"earth_engine_kenya_non_crop\"\n\n    # data collection date\n    data_date = date(2020, 4, 16)\n\n    def load_labels(self) -> pd.DataFrame:\n        # right now, this just loads geowiki data. In the future,\n        # it would be neat to merge all labels together\n        non_crop = self.data_folder / \"processed\" / KenyaNonCropProcessor.dataset / \"data.geojson\"\n        assert non_crop.exists(), \"Kenya non crop processor must be run to load labels\"\n        return geopandas.read_file(non_crop)[[\"lat\", \"lon\"]]\n\n    def labels_to_bounding_boxes(\n        self, num_labelled_points: Optional[int], surrounding_metres: int\n    ) -> List[EEBoundingBox]:\n\n        output: List[EEBoundingBox] = []\n\n        for idx, row in tqdm(self.labels.iterrows()):\n\n            output.append(\n                bounding_box_from_centre(\n                    mid_lat=row[\"lat\"], mid_lon=row[\"lon\"], surrounding_metres=surrounding_metres,\n                ),\n            )\n\n            if num_labelled_points is not None:\n                if len(output) >= num_labelled_points:\n                    return output\n        return output\n\n    def export_for_labels(\n        self,\n        days_per_timestep: int = 30,\n        num_timesteps: int = 12,\n        num_labelled_points: Optional[int] = None,\n        surrounding_metres: int = 80,\n        checkpoint: bool = True,\n        monitor: bool = False,\n        fast: bool = True,\n    ) -> None:\n        r\"\"\"\n        :param days_per_timestep: The number of days of data to use for each mosaiced image.\n            Default = 30\n        :param num_timesteps: The number of timesteps to export. Default = 12\n        :param num_labelled_points: If not None, then only this many points will be exported.\n            Default = None.\n        :param surrouning_metres: The patch will be [2 * surrounding_metres,\n            2 * surrounding_metres], centered around the labelled point. Default = 80\n        :param checkpoint: Whether or not to check in self.data_folder to see if the file has\n            already been exported. If it has, skip it. Default = True\n        :param monitor: Whether to monitor each task until it has been run. Default = True\n        :param fast: Whether to use the faster cloudfree exporter. This function is considerably\n            faster, but cloud artefacts can be more pronounced. Default = True\n        \"\"\"\n\n        bounding_boxes_to_download = self.labels_to_bounding_boxes(\n            num_labelled_points=num_labelled_points, surrounding_metres=surrounding_metres,\n        )\n\n        start_date = self.data_date - num_timesteps * timedelta(days=days_per_timestep)\n\n        for idx, bounding_info in enumerate(bounding_boxes_to_download):\n\n            self._export_for_polygon(\n                polygon=bounding_info.to_ee_polygon(),\n                polygon_identifier=idx,\n                start_date=start_date,\n                end_date=self.data_date,\n                days_per_timestep=days_per_timestep,\n                checkpoint=checkpoint,\n                monitor=monitor,\n                fast=fast,\n            )\n",
  "history_output" : "",
  "history_begin_time" : 1646144387824,
  "history_end_time" : 1646144389457,
  "history_notes" : null,
  "history_process" : "nlb6f5",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "krtvxslxanf",
  "history_input" : "import pandas as pd\nimport geopandas\nfrom tqdm import tqdm\nfrom datetime import timedelta, date\n\nfrom src_exporters_sentinel_base import BaseSentinelExporter\nfrom src_processors_kenya_non_crop import KenyaNonCropProcessor\nfrom src_exporters_sentinel_utils import EEBoundingBox, bounding_box_from_centre\n\nfrom typing import Optional, List\n\n\nclass KenyaNonCropSentinelExporter(BaseSentinelExporter):\n\n    dataset = \"earth_engine_kenya_non_crop\"\n\n    # data collection date\n    data_date = date(2020, 4, 16)\n\n    def load_labels(self) -> pd.DataFrame:\n        # right now, this just loads geowiki data. In the future,\n        # it would be neat to merge all labels together\n        non_crop = self.data_folder / \"processed\" / KenyaNonCropProcessor.dataset / \"data.geojson\"\n        assert non_crop.exists(), \"Kenya non crop processor must be run to load labels\"\n        return geopandas.read_file(non_crop)[[\"lat\", \"lon\"]]\n\n    def labels_to_bounding_boxes(\n        self, num_labelled_points: Optional[int], surrounding_metres: int\n    ) -> List[EEBoundingBox]:\n\n        output: List[EEBoundingBox] = []\n\n        for idx, row in tqdm(self.labels.iterrows()):\n\n            output.append(\n                bounding_box_from_centre(\n                    mid_lat=row[\"lat\"], mid_lon=row[\"lon\"], surrounding_metres=surrounding_metres,\n                ),\n            )\n\n            if num_labelled_points is not None:\n                if len(output) >= num_labelled_points:\n                    return output\n        return output\n\n    def export_for_labels(\n        self,\n        days_per_timestep: int = 30,\n        num_timesteps: int = 12,\n        num_labelled_points: Optional[int] = None,\n        surrounding_metres: int = 80,\n        checkpoint: bool = True,\n        monitor: bool = False,\n        fast: bool = True,\n    ) -> None:\n        r\"\"\"\n        :param days_per_timestep: The number of days of data to use for each mosaiced image.\n            Default = 30\n        :param num_timesteps: The number of timesteps to export. Default = 12\n        :param num_labelled_points: If not None, then only this many points will be exported.\n            Default = None.\n        :param surrouning_metres: The patch will be [2 * surrounding_metres,\n            2 * surrounding_metres], centered around the labelled point. Default = 80\n        :param checkpoint: Whether or not to check in self.data_folder to see if the file has\n            already been exported. If it has, skip it. Default = True\n        :param monitor: Whether to monitor each task until it has been run. Default = True\n        :param fast: Whether to use the faster cloudfree exporter. This function is considerably\n            faster, but cloud artefacts can be more pronounced. Default = True\n        \"\"\"\n\n        bounding_boxes_to_download = self.labels_to_bounding_boxes(\n            num_labelled_points=num_labelled_points, surrounding_metres=surrounding_metres,\n        )\n\n        start_date = self.data_date - num_timesteps * timedelta(days=days_per_timestep)\n\n        for idx, bounding_info in enumerate(bounding_boxes_to_download):\n\n            self._export_for_polygon(\n                polygon=bounding_info.to_ee_polygon(),\n                polygon_identifier=idx,\n                start_date=start_date,\n                end_date=self.data_date,\n                days_per_timestep=days_per_timestep,\n                checkpoint=checkpoint,\n                monitor=monitor,\n                fast=fast,\n            )\n",
  "history_output" : "",
  "history_begin_time" : 1646144315237,
  "history_end_time" : 1646144317459,
  "history_notes" : null,
  "history_process" : "nlb6f5",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "qftnljj37z4",
  "history_input" : "import pandas as pd\nimport geopandas\nfrom tqdm import tqdm\nfrom datetime import timedelta, date\n\nfrom src_exporters_sentinel_base import BaseSentinelExporter\nfrom src_processors_kenya_non_crop import KenyaNonCropProcessor\nfrom src_exporters_sentinel_utils import EEBoundingBox, bounding_box_from_centre\n\nfrom typing import Optional, List\n\n\nclass KenyaNonCropSentinelExporter(BaseSentinelExporter):\n\n    dataset = \"earth_engine_kenya_non_crop\"\n\n    # data collection date\n    data_date = date(2020, 4, 16)\n\n    def load_labels(self) -> pd.DataFrame:\n        # right now, this just loads geowiki data. In the future,\n        # it would be neat to merge all labels together\n        non_crop = self.data_folder / \"processed\" / KenyaNonCropProcessor.dataset / \"data.geojson\"\n        assert non_crop.exists(), \"Kenya non crop processor must be run to load labels\"\n        return geopandas.read_file(non_crop)[[\"lat\", \"lon\"]]\n\n    def labels_to_bounding_boxes(\n        self, num_labelled_points: Optional[int], surrounding_metres: int\n    ) -> List[EEBoundingBox]:\n\n        output: List[EEBoundingBox] = []\n\n        for idx, row in tqdm(self.labels.iterrows()):\n\n            output.append(\n                bounding_box_from_centre(\n                    mid_lat=row[\"lat\"], mid_lon=row[\"lon\"], surrounding_metres=surrounding_metres,\n                ),\n            )\n\n            if num_labelled_points is not None:\n                if len(output) >= num_labelled_points:\n                    return output\n        return output\n\n    def export_for_labels(\n        self,\n        days_per_timestep: int = 30,\n        num_timesteps: int = 12,\n        num_labelled_points: Optional[int] = None,\n        surrounding_metres: int = 80,\n        checkpoint: bool = True,\n        monitor: bool = False,\n        fast: bool = True,\n    ) -> None:\n        r\"\"\"\n        :param days_per_timestep: The number of days of data to use for each mosaiced image.\n            Default = 30\n        :param num_timesteps: The number of timesteps to export. Default = 12\n        :param num_labelled_points: If not None, then only this many points will be exported.\n            Default = None.\n        :param surrouning_metres: The patch will be [2 * surrounding_metres,\n            2 * surrounding_metres], centered around the labelled point. Default = 80\n        :param checkpoint: Whether or not to check in self.data_folder to see if the file has\n            already been exported. If it has, skip it. Default = True\n        :param monitor: Whether to monitor each task until it has been run. Default = True\n        :param fast: Whether to use the faster cloudfree exporter. This function is considerably\n            faster, but cloud artefacts can be more pronounced. Default = True\n        \"\"\"\n\n        bounding_boxes_to_download = self.labels_to_bounding_boxes(\n            num_labelled_points=num_labelled_points, surrounding_metres=surrounding_metres,\n        )\n\n        start_date = self.data_date - num_timesteps * timedelta(days=days_per_timestep)\n\n        for idx, bounding_info in enumerate(bounding_boxes_to_download):\n\n            self._export_for_polygon(\n                polygon=bounding_info.to_ee_polygon(),\n                polygon_identifier=idx,\n                start_date=start_date,\n                end_date=self.data_date,\n                days_per_timestep=days_per_timestep,\n                checkpoint=checkpoint,\n                monitor=monitor,\n                fast=fast,\n            )\n",
  "history_output" : "",
  "history_begin_time" : 1646143407267,
  "history_end_time" : 1646143409557,
  "history_notes" : null,
  "history_process" : "nlb6f5",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "3a2y8bvfjop",
  "history_input" : "import pandas as pd\nimport geopandas\nfrom tqdm import tqdm\nfrom datetime import timedelta, date\n\nfrom src_exporters_sentinel_base import BaseSentinelExporter\nfrom src_processors_kenya_non_crop import KenyaNonCropProcessor\nfrom src_exporters_sentinel_utils import EEBoundingBox, bounding_box_from_centre\n\nfrom typing import Optional, List\n\n\nclass KenyaNonCropSentinelExporter(BaseSentinelExporter):\n\n    dataset = \"earth_engine_kenya_non_crop\"\n\n    # data collection date\n    data_date = date(2020, 4, 16)\n\n    def load_labels(self) -> pd.DataFrame:\n        # right now, this just loads geowiki data. In the future,\n        # it would be neat to merge all labels together\n        non_crop = self.data_folder / \"processed\" / KenyaNonCropProcessor.dataset / \"data.geojson\"\n        assert non_crop.exists(), \"Kenya non crop processor must be run to load labels\"\n        return geopandas.read_file(non_crop)[[\"lat\", \"lon\"]]\n\n    def labels_to_bounding_boxes(\n        self, num_labelled_points: Optional[int], surrounding_metres: int\n    ) -> List[EEBoundingBox]:\n\n        output: List[EEBoundingBox] = []\n\n        for idx, row in tqdm(self.labels.iterrows()):\n\n            output.append(\n                bounding_box_from_centre(\n                    mid_lat=row[\"lat\"], mid_lon=row[\"lon\"], surrounding_metres=surrounding_metres,\n                ),\n            )\n\n            if num_labelled_points is not None:\n                if len(output) >= num_labelled_points:\n                    return output\n        return output\n\n    def export_for_labels(\n        self,\n        days_per_timestep: int = 30,\n        num_timesteps: int = 12,\n        num_labelled_points: Optional[int] = None,\n        surrounding_metres: int = 80,\n        checkpoint: bool = True,\n        monitor: bool = False,\n        fast: bool = True,\n    ) -> None:\n        r\"\"\"\n        :param days_per_timestep: The number of days of data to use for each mosaiced image.\n            Default = 30\n        :param num_timesteps: The number of timesteps to export. Default = 12\n        :param num_labelled_points: If not None, then only this many points will be exported.\n            Default = None.\n        :param surrouning_metres: The patch will be [2 * surrounding_metres,\n            2 * surrounding_metres], centered around the labelled point. Default = 80\n        :param checkpoint: Whether or not to check in self.data_folder to see if the file has\n            already been exported. If it has, skip it. Default = True\n        :param monitor: Whether to monitor each task until it has been run. Default = True\n        :param fast: Whether to use the faster cloudfree exporter. This function is considerably\n            faster, but cloud artefacts can be more pronounced. Default = True\n        \"\"\"\n\n        bounding_boxes_to_download = self.labels_to_bounding_boxes(\n            num_labelled_points=num_labelled_points, surrounding_metres=surrounding_metres,\n        )\n\n        start_date = self.data_date - num_timesteps * timedelta(days=days_per_timestep)\n\n        for idx, bounding_info in enumerate(bounding_boxes_to_download):\n\n            self._export_for_polygon(\n                polygon=bounding_info.to_ee_polygon(),\n                polygon_identifier=idx,\n                start_date=start_date,\n                end_date=self.data_date,\n                days_per_timestep=days_per_timestep,\n                checkpoint=checkpoint,\n                monitor=monitor,\n                fast=fast,\n            )\n",
  "history_output" : "",
  "history_begin_time" : 1646143260832,
  "history_end_time" : 1646143261846,
  "history_notes" : null,
  "history_process" : "nlb6f5",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "donwa6h7df9",
  "history_input" : "import pandas as pd\nimport geopandas\nfrom tqdm import tqdm\nfrom datetime import timedelta, date\n\nfrom src_exporters_sentinel_base import BaseSentinelExporter\nfrom src_processors_kenya_non_crop import KenyaNonCropProcessor\nfrom src_exporters_sentinel_utils import EEBoundingBox, bounding_box_from_centre\n\nfrom typing import Optional, List\n\n\nclass KenyaNonCropSentinelExporter(BaseSentinelExporter):\n\n    dataset = \"earth_engine_kenya_non_crop\"\n\n    # data collection date\n    data_date = date(2020, 4, 16)\n\n    def load_labels(self) -> pd.DataFrame:\n        # right now, this just loads geowiki data. In the future,\n        # it would be neat to merge all labels together\n        non_crop = self.data_folder / \"processed\" / KenyaNonCropProcessor.dataset / \"data.geojson\"\n        assert non_crop.exists(), \"Kenya non crop processor must be run to load labels\"\n        return geopandas.read_file(non_crop)[[\"lat\", \"lon\"]]\n\n    def labels_to_bounding_boxes(\n        self, num_labelled_points: Optional[int], surrounding_metres: int\n    ) -> List[EEBoundingBox]:\n\n        output: List[EEBoundingBox] = []\n\n        for idx, row in tqdm(self.labels.iterrows()):\n\n            output.append(\n                bounding_box_from_centre(\n                    mid_lat=row[\"lat\"], mid_lon=row[\"lon\"], surrounding_metres=surrounding_metres,\n                ),\n            )\n\n            if num_labelled_points is not None:\n                if len(output) >= num_labelled_points:\n                    return output\n        return output\n\n    def export_for_labels(\n        self,\n        days_per_timestep: int = 30,\n        num_timesteps: int = 12,\n        num_labelled_points: Optional[int] = None,\n        surrounding_metres: int = 80,\n        checkpoint: bool = True,\n        monitor: bool = False,\n        fast: bool = True,\n    ) -> None:\n        r\"\"\"\n        :param days_per_timestep: The number of days of data to use for each mosaiced image.\n            Default = 30\n        :param num_timesteps: The number of timesteps to export. Default = 12\n        :param num_labelled_points: If not None, then only this many points will be exported.\n            Default = None.\n        :param surrouning_metres: The patch will be [2 * surrounding_metres,\n            2 * surrounding_metres], centered around the labelled point. Default = 80\n        :param checkpoint: Whether or not to check in self.data_folder to see if the file has\n            already been exported. If it has, skip it. Default = True\n        :param monitor: Whether to monitor each task until it has been run. Default = True\n        :param fast: Whether to use the faster cloudfree exporter. This function is considerably\n            faster, but cloud artefacts can be more pronounced. Default = True\n        \"\"\"\n\n        bounding_boxes_to_download = self.labels_to_bounding_boxes(\n            num_labelled_points=num_labelled_points, surrounding_metres=surrounding_metres,\n        )\n\n        start_date = self.data_date - num_timesteps * timedelta(days=days_per_timestep)\n\n        for idx, bounding_info in enumerate(bounding_boxes_to_download):\n\n            self._export_for_polygon(\n                polygon=bounding_info.to_ee_polygon(),\n                polygon_identifier=idx,\n                start_date=start_date,\n                end_date=self.data_date,\n                days_per_timestep=days_per_timestep,\n                checkpoint=checkpoint,\n                monitor=monitor,\n                fast=fast,\n            )\n",
  "history_output" : "",
  "history_begin_time" : 1646143179980,
  "history_end_time" : 1646143180688,
  "history_notes" : null,
  "history_process" : "nlb6f5",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "yq9kjiobugr",
  "history_input" : "import pandas as pd\nimport geopandas\nfrom tqdm import tqdm\nfrom datetime import timedelta, date\n\nfrom src_exporters_sentinel_base import BaseSentinelExporter\nfrom src_processors_kenya_non_crop import KenyaNonCropProcessor\nfrom src_exporters_sentinel_utils import EEBoundingBox, bounding_box_from_centre\n\nfrom typing import Optional, List\n\n\nclass KenyaNonCropSentinelExporter(BaseSentinelExporter):\n\n    dataset = \"earth_engine_kenya_non_crop\"\n\n    # data collection date\n    data_date = date(2020, 4, 16)\n\n    def load_labels(self) -> pd.DataFrame:\n        # right now, this just loads geowiki data. In the future,\n        # it would be neat to merge all labels together\n        non_crop = self.data_folder / \"processed\" / KenyaNonCropProcessor.dataset / \"data.geojson\"\n        assert non_crop.exists(), \"Kenya non crop processor must be run to load labels\"\n        return geopandas.read_file(non_crop)[[\"lat\", \"lon\"]]\n\n    def labels_to_bounding_boxes(\n        self, num_labelled_points: Optional[int], surrounding_metres: int\n    ) -> List[EEBoundingBox]:\n\n        output: List[EEBoundingBox] = []\n\n        for idx, row in tqdm(self.labels.iterrows()):\n\n            output.append(\n                bounding_box_from_centre(\n                    mid_lat=row[\"lat\"], mid_lon=row[\"lon\"], surrounding_metres=surrounding_metres,\n                ),\n            )\n\n            if num_labelled_points is not None:\n                if len(output) >= num_labelled_points:\n                    return output\n        return output\n\n    def export_for_labels(\n        self,\n        days_per_timestep: int = 30,\n        num_timesteps: int = 12,\n        num_labelled_points: Optional[int] = None,\n        surrounding_metres: int = 80,\n        checkpoint: bool = True,\n        monitor: bool = False,\n        fast: bool = True,\n    ) -> None:\n        r\"\"\"\n        :param days_per_timestep: The number of days of data to use for each mosaiced image.\n            Default = 30\n        :param num_timesteps: The number of timesteps to export. Default = 12\n        :param num_labelled_points: If not None, then only this many points will be exported.\n            Default = None.\n        :param surrouning_metres: The patch will be [2 * surrounding_metres,\n            2 * surrounding_metres], centered around the labelled point. Default = 80\n        :param checkpoint: Whether or not to check in self.data_folder to see if the file has\n            already been exported. If it has, skip it. Default = True\n        :param monitor: Whether to monitor each task until it has been run. Default = True\n        :param fast: Whether to use the faster cloudfree exporter. This function is considerably\n            faster, but cloud artefacts can be more pronounced. Default = True\n        \"\"\"\n\n        bounding_boxes_to_download = self.labels_to_bounding_boxes(\n            num_labelled_points=num_labelled_points, surrounding_metres=surrounding_metres,\n        )\n\n        start_date = self.data_date - num_timesteps * timedelta(days=days_per_timestep)\n\n        for idx, bounding_info in enumerate(bounding_boxes_to_download):\n\n            self._export_for_polygon(\n                polygon=bounding_info.to_ee_polygon(),\n                polygon_identifier=idx,\n                start_date=start_date,\n                end_date=self.data_date,\n                days_per_timestep=days_per_timestep,\n                checkpoint=checkpoint,\n                monitor=monitor,\n                fast=fast,\n            )\n",
  "history_output" : "",
  "history_begin_time" : 1646143145326,
  "history_end_time" : 1646143147515,
  "history_notes" : null,
  "history_process" : "nlb6f5",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "fr0li0c702t",
  "history_input" : "import pandas as pd\nimport geopandas\nfrom tqdm import tqdm\nfrom datetime import timedelta, date\n\nfrom src_exporters_sentinel_base import BaseSentinelExporter\nfrom src_processors_kenya_non_crop import KenyaNonCropProcessor\nfrom src_exporters_sentinel_utils import EEBoundingBox, bounding_box_from_centre\n\nfrom typing import Optional, List\n\n\nclass KenyaNonCropSentinelExporter(BaseSentinelExporter):\n\n    dataset = \"earth_engine_kenya_non_crop\"\n\n    # data collection date\n    data_date = date(2020, 4, 16)\n\n    def load_labels(self) -> pd.DataFrame:\n        # right now, this just loads geowiki data. In the future,\n        # it would be neat to merge all labels together\n        non_crop = self.data_folder / \"processed\" / KenyaNonCropProcessor.dataset / \"data.geojson\"\n        assert non_crop.exists(), \"Kenya non crop processor must be run to load labels\"\n        return geopandas.read_file(non_crop)[[\"lat\", \"lon\"]]\n\n    def labels_to_bounding_boxes(\n        self, num_labelled_points: Optional[int], surrounding_metres: int\n    ) -> List[EEBoundingBox]:\n\n        output: List[EEBoundingBox] = []\n\n        for idx, row in tqdm(self.labels.iterrows()):\n\n            output.append(\n                bounding_box_from_centre(\n                    mid_lat=row[\"lat\"], mid_lon=row[\"lon\"], surrounding_metres=surrounding_metres,\n                ),\n            )\n\n            if num_labelled_points is not None:\n                if len(output) >= num_labelled_points:\n                    return output\n        return output\n\n    def export_for_labels(\n        self,\n        days_per_timestep: int = 30,\n        num_timesteps: int = 12,\n        num_labelled_points: Optional[int] = None,\n        surrounding_metres: int = 80,\n        checkpoint: bool = True,\n        monitor: bool = False,\n        fast: bool = True,\n    ) -> None:\n        r\"\"\"\n        :param days_per_timestep: The number of days of data to use for each mosaiced image.\n            Default = 30\n        :param num_timesteps: The number of timesteps to export. Default = 12\n        :param num_labelled_points: If not None, then only this many points will be exported.\n            Default = None.\n        :param surrouning_metres: The patch will be [2 * surrounding_metres,\n            2 * surrounding_metres], centered around the labelled point. Default = 80\n        :param checkpoint: Whether or not to check in self.data_folder to see if the file has\n            already been exported. If it has, skip it. Default = True\n        :param monitor: Whether to monitor each task until it has been run. Default = True\n        :param fast: Whether to use the faster cloudfree exporter. This function is considerably\n            faster, but cloud artefacts can be more pronounced. Default = True\n        \"\"\"\n\n        bounding_boxes_to_download = self.labels_to_bounding_boxes(\n            num_labelled_points=num_labelled_points, surrounding_metres=surrounding_metres,\n        )\n\n        start_date = self.data_date - num_timesteps * timedelta(days=days_per_timestep)\n\n        for idx, bounding_info in enumerate(bounding_boxes_to_download):\n\n            self._export_for_polygon(\n                polygon=bounding_info.to_ee_polygon(),\n                polygon_identifier=idx,\n                start_date=start_date,\n                end_date=self.data_date,\n                days_per_timestep=days_per_timestep,\n                checkpoint=checkpoint,\n                monitor=monitor,\n                fast=fast,\n            )\n",
  "history_output" : "",
  "history_begin_time" : 1646143112092,
  "history_end_time" : 1646143114489,
  "history_notes" : null,
  "history_process" : "nlb6f5",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "d12i46y8fn1",
  "history_input" : "import pandas as pd\nimport geopandas\nfrom tqdm import tqdm\nfrom datetime import timedelta, date\n\nfrom src_exporters_sentinel_base import BaseSentinelExporter\nfrom src_processors_kenya_non_crop import KenyaNonCropProcessor\nfrom src_exporters_sentinel_utils import EEBoundingBox, bounding_box_from_centre\n\nfrom typing import Optional, List\n\n\nclass KenyaNonCropSentinelExporter(BaseSentinelExporter):\n\n    dataset = \"earth_engine_kenya_non_crop\"\n\n    # data collection date\n    data_date = date(2020, 4, 16)\n\n    def load_labels(self) -> pd.DataFrame:\n        # right now, this just loads geowiki data. In the future,\n        # it would be neat to merge all labels together\n        non_crop = self.data_folder / \"processed\" / KenyaNonCropProcessor.dataset / \"data.geojson\"\n        assert non_crop.exists(), \"Kenya non crop processor must be run to load labels\"\n        return geopandas.read_file(non_crop)[[\"lat\", \"lon\"]]\n\n    def labels_to_bounding_boxes(\n        self, num_labelled_points: Optional[int], surrounding_metres: int\n    ) -> List[EEBoundingBox]:\n\n        output: List[EEBoundingBox] = []\n\n        for idx, row in tqdm(self.labels.iterrows()):\n\n            output.append(\n                bounding_box_from_centre(\n                    mid_lat=row[\"lat\"], mid_lon=row[\"lon\"], surrounding_metres=surrounding_metres,\n                ),\n            )\n\n            if num_labelled_points is not None:\n                if len(output) >= num_labelled_points:\n                    return output\n        return output\n\n    def export_for_labels(\n        self,\n        days_per_timestep: int = 30,\n        num_timesteps: int = 12,\n        num_labelled_points: Optional[int] = None,\n        surrounding_metres: int = 80,\n        checkpoint: bool = True,\n        monitor: bool = False,\n        fast: bool = True,\n    ) -> None:\n        r\"\"\"\n        :param days_per_timestep: The number of days of data to use for each mosaiced image.\n            Default = 30\n        :param num_timesteps: The number of timesteps to export. Default = 12\n        :param num_labelled_points: If not None, then only this many points will be exported.\n            Default = None.\n        :param surrouning_metres: The patch will be [2 * surrounding_metres,\n            2 * surrounding_metres], centered around the labelled point. Default = 80\n        :param checkpoint: Whether or not to check in self.data_folder to see if the file has\n            already been exported. If it has, skip it. Default = True\n        :param monitor: Whether to monitor each task until it has been run. Default = True\n        :param fast: Whether to use the faster cloudfree exporter. This function is considerably\n            faster, but cloud artefacts can be more pronounced. Default = True\n        \"\"\"\n\n        bounding_boxes_to_download = self.labels_to_bounding_boxes(\n            num_labelled_points=num_labelled_points, surrounding_metres=surrounding_metres,\n        )\n\n        start_date = self.data_date - num_timesteps * timedelta(days=days_per_timestep)\n\n        for idx, bounding_info in enumerate(bounding_boxes_to_download):\n\n            self._export_for_polygon(\n                polygon=bounding_info.to_ee_polygon(),\n                polygon_identifier=idx,\n                start_date=start_date,\n                end_date=self.data_date,\n                days_per_timestep=days_per_timestep,\n                checkpoint=checkpoint,\n                monitor=monitor,\n                fast=fast,\n            )\n",
  "history_output" : "",
  "history_begin_time" : 1646139379959,
  "history_end_time" : 1646139382062,
  "history_notes" : null,
  "history_process" : "nlb6f5",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "v8myvf0u0y2",
  "history_input" : "import pandas as pd\nimport geopandas\nfrom tqdm import tqdm\nfrom datetime import timedelta, date\n\nfrom src_exporters_sentinel_base import BaseSentinelExporter\nfrom src_processors_kenya_non_crop import KenyaNonCropProcessor\nfrom src_exporters_sentinel_utils import EEBoundingBox, bounding_box_from_centre\n\nfrom typing import Optional, List\n\n\nclass KenyaNonCropSentinelExporter(BaseSentinelExporter):\n\n    dataset = \"earth_engine_kenya_non_crop\"\n\n    # data collection date\n    data_date = date(2020, 4, 16)\n\n    def load_labels(self) -> pd.DataFrame:\n        # right now, this just loads geowiki data. In the future,\n        # it would be neat to merge all labels together\n        non_crop = self.data_folder / \"processed\" / KenyaNonCropProcessor.dataset / \"data.geojson\"\n        assert non_crop.exists(), \"Kenya non crop processor must be run to load labels\"\n        return geopandas.read_file(non_crop)[[\"lat\", \"lon\"]]\n\n    def labels_to_bounding_boxes(\n        self, num_labelled_points: Optional[int], surrounding_metres: int\n    ) -> List[EEBoundingBox]:\n\n        output: List[EEBoundingBox] = []\n\n        for idx, row in tqdm(self.labels.iterrows()):\n\n            output.append(\n                bounding_box_from_centre(\n                    mid_lat=row[\"lat\"], mid_lon=row[\"lon\"], surrounding_metres=surrounding_metres,\n                ),\n            )\n\n            if num_labelled_points is not None:\n                if len(output) >= num_labelled_points:\n                    return output\n        return output\n\n    def export_for_labels(\n        self,\n        days_per_timestep: int = 30,\n        num_timesteps: int = 12,\n        num_labelled_points: Optional[int] = None,\n        surrounding_metres: int = 80,\n        checkpoint: bool = True,\n        monitor: bool = False,\n        fast: bool = True,\n    ) -> None:\n        r\"\"\"\n        :param days_per_timestep: The number of days of data to use for each mosaiced image.\n            Default = 30\n        :param num_timesteps: The number of timesteps to export. Default = 12\n        :param num_labelled_points: If not None, then only this many points will be exported.\n            Default = None.\n        :param surrouning_metres: The patch will be [2 * surrounding_metres,\n            2 * surrounding_metres], centered around the labelled point. Default = 80\n        :param checkpoint: Whether or not to check in self.data_folder to see if the file has\n            already been exported. If it has, skip it. Default = True\n        :param monitor: Whether to monitor each task until it has been run. Default = True\n        :param fast: Whether to use the faster cloudfree exporter. This function is considerably\n            faster, but cloud artefacts can be more pronounced. Default = True\n        \"\"\"\n\n        bounding_boxes_to_download = self.labels_to_bounding_boxes(\n            num_labelled_points=num_labelled_points, surrounding_metres=surrounding_metres,\n        )\n\n        start_date = self.data_date - num_timesteps * timedelta(days=days_per_timestep)\n\n        for idx, bounding_info in enumerate(bounding_boxes_to_download):\n\n            self._export_for_polygon(\n                polygon=bounding_info.to_ee_polygon(),\n                polygon_identifier=idx,\n                start_date=start_date,\n                end_date=self.data_date,\n                days_per_timestep=days_per_timestep,\n                checkpoint=checkpoint,\n                monitor=monitor,\n                fast=fast,\n            )\n",
  "history_output" : "",
  "history_begin_time" : 1646139290482,
  "history_end_time" : 1646139292799,
  "history_notes" : null,
  "history_process" : "nlb6f5",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "zbtsxmflt54",
  "history_input" : "import pandas as pd\nimport geopandas\nfrom tqdm import tqdm\nfrom datetime import timedelta, date\n\nfrom src_exporters_sentinel_base import BaseSentinelExporter\nfrom src_processors_kenya_non_crop import KenyaNonCropProcessor\nfrom src_exporters_sentinel_utils import EEBoundingBox, bounding_box_from_centre\n\nfrom typing import Optional, List\n\n\nclass KenyaNonCropSentinelExporter(BaseSentinelExporter):\n\n    dataset = \"earth_engine_kenya_non_crop\"\n\n    # data collection date\n    data_date = date(2020, 4, 16)\n\n    def load_labels(self) -> pd.DataFrame:\n        # right now, this just loads geowiki data. In the future,\n        # it would be neat to merge all labels together\n        non_crop = self.data_folder / \"processed\" / KenyaNonCropProcessor.dataset / \"data.geojson\"\n        assert non_crop.exists(), \"Kenya non crop processor must be run to load labels\"\n        return geopandas.read_file(non_crop)[[\"lat\", \"lon\"]]\n\n    def labels_to_bounding_boxes(\n        self, num_labelled_points: Optional[int], surrounding_metres: int\n    ) -> List[EEBoundingBox]:\n\n        output: List[EEBoundingBox] = []\n\n        for idx, row in tqdm(self.labels.iterrows()):\n\n            output.append(\n                bounding_box_from_centre(\n                    mid_lat=row[\"lat\"], mid_lon=row[\"lon\"], surrounding_metres=surrounding_metres,\n                ),\n            )\n\n            if num_labelled_points is not None:\n                if len(output) >= num_labelled_points:\n                    return output\n        return output\n\n    def export_for_labels(\n        self,\n        days_per_timestep: int = 30,\n        num_timesteps: int = 12,\n        num_labelled_points: Optional[int] = None,\n        surrounding_metres: int = 80,\n        checkpoint: bool = True,\n        monitor: bool = False,\n        fast: bool = True,\n    ) -> None:\n        r\"\"\"\n        :param days_per_timestep: The number of days of data to use for each mosaiced image.\n            Default = 30\n        :param num_timesteps: The number of timesteps to export. Default = 12\n        :param num_labelled_points: If not None, then only this many points will be exported.\n            Default = None.\n        :param surrouning_metres: The patch will be [2 * surrounding_metres,\n            2 * surrounding_metres], centered around the labelled point. Default = 80\n        :param checkpoint: Whether or not to check in self.data_folder to see if the file has\n            already been exported. If it has, skip it. Default = True\n        :param monitor: Whether to monitor each task until it has been run. Default = True\n        :param fast: Whether to use the faster cloudfree exporter. This function is considerably\n            faster, but cloud artefacts can be more pronounced. Default = True\n        \"\"\"\n\n        bounding_boxes_to_download = self.labels_to_bounding_boxes(\n            num_labelled_points=num_labelled_points, surrounding_metres=surrounding_metres,\n        )\n\n        start_date = self.data_date - num_timesteps * timedelta(days=days_per_timestep)\n\n        for idx, bounding_info in enumerate(bounding_boxes_to_download):\n\n            self._export_for_polygon(\n                polygon=bounding_info.to_ee_polygon(),\n                polygon_identifier=idx,\n                start_date=start_date,\n                end_date=self.data_date,\n                days_per_timestep=days_per_timestep,\n                checkpoint=checkpoint,\n                monitor=monitor,\n                fast=fast,\n            )\n",
  "history_output" : "",
  "history_begin_time" : 1646139248175,
  "history_end_time" : 1646139250548,
  "history_notes" : null,
  "history_process" : "nlb6f5",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "xeioifq967m",
  "history_input" : "import pandas as pd\nimport geopandas\nfrom tqdm import tqdm\nfrom datetime import timedelta, date\n\nfrom src_exporters_sentinel_base import BaseSentinelExporter\nfrom src_processors_kenya_non_crop import KenyaNonCropProcessor\nfrom src_exporters_sentinel_utils import EEBoundingBox, bounding_box_from_centre\n\nfrom typing import Optional, List\n\n\nclass KenyaNonCropSentinelExporter(BaseSentinelExporter):\n\n    dataset = \"earth_engine_kenya_non_crop\"\n\n    # data collection date\n    data_date = date(2020, 4, 16)\n\n    def load_labels(self) -> pd.DataFrame:\n        # right now, this just loads geowiki data. In the future,\n        # it would be neat to merge all labels together\n        non_crop = self.data_folder / \"processed\" / KenyaNonCropProcessor.dataset / \"data.geojson\"\n        assert non_crop.exists(), \"Kenya non crop processor must be run to load labels\"\n        return geopandas.read_file(non_crop)[[\"lat\", \"lon\"]]\n\n    def labels_to_bounding_boxes(\n        self, num_labelled_points: Optional[int], surrounding_metres: int\n    ) -> List[EEBoundingBox]:\n\n        output: List[EEBoundingBox] = []\n\n        for idx, row in tqdm(self.labels.iterrows()):\n\n            output.append(\n                bounding_box_from_centre(\n                    mid_lat=row[\"lat\"], mid_lon=row[\"lon\"], surrounding_metres=surrounding_metres,\n                ),\n            )\n\n            if num_labelled_points is not None:\n                if len(output) >= num_labelled_points:\n                    return output\n        return output\n\n    def export_for_labels(\n        self,\n        days_per_timestep: int = 30,\n        num_timesteps: int = 12,\n        num_labelled_points: Optional[int] = None,\n        surrounding_metres: int = 80,\n        checkpoint: bool = True,\n        monitor: bool = False,\n        fast: bool = True,\n    ) -> None:\n        r\"\"\"\n        :param days_per_timestep: The number of days of data to use for each mosaiced image.\n            Default = 30\n        :param num_timesteps: The number of timesteps to export. Default = 12\n        :param num_labelled_points: If not None, then only this many points will be exported.\n            Default = None.\n        :param surrouning_metres: The patch will be [2 * surrounding_metres,\n            2 * surrounding_metres], centered around the labelled point. Default = 80\n        :param checkpoint: Whether or not to check in self.data_folder to see if the file has\n            already been exported. If it has, skip it. Default = True\n        :param monitor: Whether to monitor each task until it has been run. Default = True\n        :param fast: Whether to use the faster cloudfree exporter. This function is considerably\n            faster, but cloud artefacts can be more pronounced. Default = True\n        \"\"\"\n\n        bounding_boxes_to_download = self.labels_to_bounding_boxes(\n            num_labelled_points=num_labelled_points, surrounding_metres=surrounding_metres,\n        )\n\n        start_date = self.data_date - num_timesteps * timedelta(days=days_per_timestep)\n\n        for idx, bounding_info in enumerate(bounding_boxes_to_download):\n\n            self._export_for_polygon(\n                polygon=bounding_info.to_ee_polygon(),\n                polygon_identifier=idx,\n                start_date=start_date,\n                end_date=self.data_date,\n                days_per_timestep=days_per_timestep,\n                checkpoint=checkpoint,\n                monitor=monitor,\n                fast=fast,\n            )\n",
  "history_output" : "",
  "history_begin_time" : 1646139192386,
  "history_end_time" : 1646139194508,
  "history_notes" : null,
  "history_process" : "nlb6f5",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "y1l02dnllka",
  "history_input" : "import pandas as pd\nimport geopandas\nfrom tqdm import tqdm\nfrom datetime import timedelta, date\n\nfrom src_exporters_sentinel_base import BaseSentinelExporter\nfrom src_processors_kenya_non_crop import KenyaNonCropProcessor\nfrom src_exporters_sentinel_utils import EEBoundingBox, bounding_box_from_centre\n\nfrom typing import Optional, List\n\n\nclass KenyaNonCropSentinelExporter(BaseSentinelExporter):\n\n    dataset = \"earth_engine_kenya_non_crop\"\n\n    # data collection date\n    data_date = date(2020, 4, 16)\n\n    def load_labels(self) -> pd.DataFrame:\n        # right now, this just loads geowiki data. In the future,\n        # it would be neat to merge all labels together\n        non_crop = self.data_folder / \"processed\" / KenyaNonCropProcessor.dataset / \"data.geojson\"\n        assert non_crop.exists(), \"Kenya non crop processor must be run to load labels\"\n        return geopandas.read_file(non_crop)[[\"lat\", \"lon\"]]\n\n    def labels_to_bounding_boxes(\n        self, num_labelled_points: Optional[int], surrounding_metres: int\n    ) -> List[EEBoundingBox]:\n\n        output: List[EEBoundingBox] = []\n\n        for idx, row in tqdm(self.labels.iterrows()):\n\n            output.append(\n                bounding_box_from_centre(\n                    mid_lat=row[\"lat\"], mid_lon=row[\"lon\"], surrounding_metres=surrounding_metres,\n                ),\n            )\n\n            if num_labelled_points is not None:\n                if len(output) >= num_labelled_points:\n                    return output\n        return output\n\n    def export_for_labels(\n        self,\n        days_per_timestep: int = 30,\n        num_timesteps: int = 12,\n        num_labelled_points: Optional[int] = None,\n        surrounding_metres: int = 80,\n        checkpoint: bool = True,\n        monitor: bool = False,\n        fast: bool = True,\n    ) -> None:\n        r\"\"\"\n        :param days_per_timestep: The number of days of data to use for each mosaiced image.\n            Default = 30\n        :param num_timesteps: The number of timesteps to export. Default = 12\n        :param num_labelled_points: If not None, then only this many points will be exported.\n            Default = None.\n        :param surrouning_metres: The patch will be [2 * surrounding_metres,\n            2 * surrounding_metres], centered around the labelled point. Default = 80\n        :param checkpoint: Whether or not to check in self.data_folder to see if the file has\n            already been exported. If it has, skip it. Default = True\n        :param monitor: Whether to monitor each task until it has been run. Default = True\n        :param fast: Whether to use the faster cloudfree exporter. This function is considerably\n            faster, but cloud artefacts can be more pronounced. Default = True\n        \"\"\"\n\n        bounding_boxes_to_download = self.labels_to_bounding_boxes(\n            num_labelled_points=num_labelled_points, surrounding_metres=surrounding_metres,\n        )\n\n        start_date = self.data_date - num_timesteps * timedelta(days=days_per_timestep)\n\n        for idx, bounding_info in enumerate(bounding_boxes_to_download):\n\n            self._export_for_polygon(\n                polygon=bounding_info.to_ee_polygon(),\n                polygon_identifier=idx,\n                start_date=start_date,\n                end_date=self.data_date,\n                days_per_timestep=days_per_timestep,\n                checkpoint=checkpoint,\n                monitor=monitor,\n                fast=fast,\n            )\n",
  "history_output" : "",
  "history_begin_time" : 1646139153851,
  "history_end_time" : 1646139156398,
  "history_notes" : null,
  "history_process" : "nlb6f5",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "ongof7g6c6m",
  "history_input" : "import pandas as pd\nimport geopandas\nfrom tqdm import tqdm\nfrom datetime import timedelta, date\n\nfrom src_exporters_sentinel_base import BaseSentinelExporter\nfrom src_processors_kenya_non_crop import KenyaNonCropProcessor\nfrom src_exporters_sentinel_utils import EEBoundingBox, bounding_box_from_centre\n\nfrom typing import Optional, List\n\n\nclass KenyaNonCropSentinelExporter(BaseSentinelExporter):\n\n    dataset = \"earth_engine_kenya_non_crop\"\n\n    # data collection date\n    data_date = date(2020, 4, 16)\n\n    def load_labels(self) -> pd.DataFrame:\n        # right now, this just loads geowiki data. In the future,\n        # it would be neat to merge all labels together\n        non_crop = self.data_folder / \"processed\" / KenyaNonCropProcessor.dataset / \"data.geojson\"\n        assert non_crop.exists(), \"Kenya non crop processor must be run to load labels\"\n        return geopandas.read_file(non_crop)[[\"lat\", \"lon\"]]\n\n    def labels_to_bounding_boxes(\n        self, num_labelled_points: Optional[int], surrounding_metres: int\n    ) -> List[EEBoundingBox]:\n\n        output: List[EEBoundingBox] = []\n\n        for idx, row in tqdm(self.labels.iterrows()):\n\n            output.append(\n                bounding_box_from_centre(\n                    mid_lat=row[\"lat\"], mid_lon=row[\"lon\"], surrounding_metres=surrounding_metres,\n                ),\n            )\n\n            if num_labelled_points is not None:\n                if len(output) >= num_labelled_points:\n                    return output\n        return output\n\n    def export_for_labels(\n        self,\n        days_per_timestep: int = 30,\n        num_timesteps: int = 12,\n        num_labelled_points: Optional[int] = None,\n        surrounding_metres: int = 80,\n        checkpoint: bool = True,\n        monitor: bool = False,\n        fast: bool = True,\n    ) -> None:\n        r\"\"\"\n        :param days_per_timestep: The number of days of data to use for each mosaiced image.\n            Default = 30\n        :param num_timesteps: The number of timesteps to export. Default = 12\n        :param num_labelled_points: If not None, then only this many points will be exported.\n            Default = None.\n        :param surrouning_metres: The patch will be [2 * surrounding_metres,\n            2 * surrounding_metres], centered around the labelled point. Default = 80\n        :param checkpoint: Whether or not to check in self.data_folder to see if the file has\n            already been exported. If it has, skip it. Default = True\n        :param monitor: Whether to monitor each task until it has been run. Default = True\n        :param fast: Whether to use the faster cloudfree exporter. This function is considerably\n            faster, but cloud artefacts can be more pronounced. Default = True\n        \"\"\"\n\n        bounding_boxes_to_download = self.labels_to_bounding_boxes(\n            num_labelled_points=num_labelled_points, surrounding_metres=surrounding_metres,\n        )\n\n        start_date = self.data_date - num_timesteps * timedelta(days=days_per_timestep)\n\n        for idx, bounding_info in enumerate(bounding_boxes_to_download):\n\n            self._export_for_polygon(\n                polygon=bounding_info.to_ee_polygon(),\n                polygon_identifier=idx,\n                start_date=start_date,\n                end_date=self.data_date,\n                days_per_timestep=days_per_timestep,\n                checkpoint=checkpoint,\n                monitor=monitor,\n                fast=fast,\n            )\n",
  "history_output" : "",
  "history_begin_time" : 1646138503652,
  "history_end_time" : 1646138505859,
  "history_notes" : null,
  "history_process" : "nlb6f5",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "8kd64ufok64",
  "history_input" : "import pandas as pd\nimport geopandas\nfrom tqdm import tqdm\nfrom datetime import timedelta, date\n\nfrom src_exporters_sentinel_base import BaseSentinelExporter\nfrom src_processors_kenya_non_crop import KenyaNonCropProcessor\nfrom src_exporters_sentinel_utils import EEBoundingBox, bounding_box_from_centre\n\nfrom typing import Optional, List\n\n\nclass KenyaNonCropSentinelExporter(BaseSentinelExporter):\n\n    dataset = \"earth_engine_kenya_non_crop\"\n\n    # data collection date\n    data_date = date(2020, 4, 16)\n\n    def load_labels(self) -> pd.DataFrame:\n        # right now, this just loads geowiki data. In the future,\n        # it would be neat to merge all labels together\n        non_crop = self.data_folder / \"processed\" / KenyaNonCropProcessor.dataset / \"data.geojson\"\n        assert non_crop.exists(), \"Kenya non crop processor must be run to load labels\"\n        return geopandas.read_file(non_crop)[[\"lat\", \"lon\"]]\n\n    def labels_to_bounding_boxes(\n        self, num_labelled_points: Optional[int], surrounding_metres: int\n    ) -> List[EEBoundingBox]:\n\n        output: List[EEBoundingBox] = []\n\n        for idx, row in tqdm(self.labels.iterrows()):\n\n            output.append(\n                bounding_box_from_centre(\n                    mid_lat=row[\"lat\"], mid_lon=row[\"lon\"], surrounding_metres=surrounding_metres,\n                ),\n            )\n\n            if num_labelled_points is not None:\n                if len(output) >= num_labelled_points:\n                    return output\n        return output\n\n    def export_for_labels(\n        self,\n        days_per_timestep: int = 30,\n        num_timesteps: int = 12,\n        num_labelled_points: Optional[int] = None,\n        surrounding_metres: int = 80,\n        checkpoint: bool = True,\n        monitor: bool = False,\n        fast: bool = True,\n    ) -> None:\n        r\"\"\"\n        :param days_per_timestep: The number of days of data to use for each mosaiced image.\n            Default = 30\n        :param num_timesteps: The number of timesteps to export. Default = 12\n        :param num_labelled_points: If not None, then only this many points will be exported.\n            Default = None.\n        :param surrouning_metres: The patch will be [2 * surrounding_metres,\n            2 * surrounding_metres], centered around the labelled point. Default = 80\n        :param checkpoint: Whether or not to check in self.data_folder to see if the file has\n            already been exported. If it has, skip it. Default = True\n        :param monitor: Whether to monitor each task until it has been run. Default = True\n        :param fast: Whether to use the faster cloudfree exporter. This function is considerably\n            faster, but cloud artefacts can be more pronounced. Default = True\n        \"\"\"\n\n        bounding_boxes_to_download = self.labels_to_bounding_boxes(\n            num_labelled_points=num_labelled_points, surrounding_metres=surrounding_metres,\n        )\n\n        start_date = self.data_date - num_timesteps * timedelta(days=days_per_timestep)\n\n        for idx, bounding_info in enumerate(bounding_boxes_to_download):\n\n            self._export_for_polygon(\n                polygon=bounding_info.to_ee_polygon(),\n                polygon_identifier=idx,\n                start_date=start_date,\n                end_date=self.data_date,\n                days_per_timestep=days_per_timestep,\n                checkpoint=checkpoint,\n                monitor=monitor,\n                fast=fast,\n            )\n",
  "history_output" : "",
  "history_begin_time" : 1646138446648,
  "history_end_time" : 1646138449083,
  "history_notes" : null,
  "history_process" : "nlb6f5",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "qyopyqw9h2q",
  "history_input" : "import pandas as pd\nimport geopandas\nfrom tqdm import tqdm\nfrom datetime import timedelta, date\n\nfrom src_exporters_sentinel_base import BaseSentinelExporter\nfrom src_processors_kenya_non_crop import KenyaNonCropProcessor\nfrom src_exporters_sentinel_utils import EEBoundingBox, bounding_box_from_centre\n\nfrom typing import Optional, List\n\n\nclass KenyaNonCropSentinelExporter(BaseSentinelExporter):\n\n    dataset = \"earth_engine_kenya_non_crop\"\n\n    # data collection date\n    data_date = date(2020, 4, 16)\n\n    def load_labels(self) -> pd.DataFrame:\n        # right now, this just loads geowiki data. In the future,\n        # it would be neat to merge all labels together\n        non_crop = self.data_folder / \"processed\" / KenyaNonCropProcessor.dataset / \"data.geojson\"\n        assert non_crop.exists(), \"Kenya non crop processor must be run to load labels\"\n        return geopandas.read_file(non_crop)[[\"lat\", \"lon\"]]\n\n    def labels_to_bounding_boxes(\n        self, num_labelled_points: Optional[int], surrounding_metres: int\n    ) -> List[EEBoundingBox]:\n\n        output: List[EEBoundingBox] = []\n\n        for idx, row in tqdm(self.labels.iterrows()):\n\n            output.append(\n                bounding_box_from_centre(\n                    mid_lat=row[\"lat\"], mid_lon=row[\"lon\"], surrounding_metres=surrounding_metres,\n                ),\n            )\n\n            if num_labelled_points is not None:\n                if len(output) >= num_labelled_points:\n                    return output\n        return output\n\n    def export_for_labels(\n        self,\n        days_per_timestep: int = 30,\n        num_timesteps: int = 12,\n        num_labelled_points: Optional[int] = None,\n        surrounding_metres: int = 80,\n        checkpoint: bool = True,\n        monitor: bool = False,\n        fast: bool = True,\n    ) -> None:\n        r\"\"\"\n        :param days_per_timestep: The number of days of data to use for each mosaiced image.\n            Default = 30\n        :param num_timesteps: The number of timesteps to export. Default = 12\n        :param num_labelled_points: If not None, then only this many points will be exported.\n            Default = None.\n        :param surrouning_metres: The patch will be [2 * surrounding_metres,\n            2 * surrounding_metres], centered around the labelled point. Default = 80\n        :param checkpoint: Whether or not to check in self.data_folder to see if the file has\n            already been exported. If it has, skip it. Default = True\n        :param monitor: Whether to monitor each task until it has been run. Default = True\n        :param fast: Whether to use the faster cloudfree exporter. This function is considerably\n            faster, but cloud artefacts can be more pronounced. Default = True\n        \"\"\"\n\n        bounding_boxes_to_download = self.labels_to_bounding_boxes(\n            num_labelled_points=num_labelled_points, surrounding_metres=surrounding_metres,\n        )\n\n        start_date = self.data_date - num_timesteps * timedelta(days=days_per_timestep)\n\n        for idx, bounding_info in enumerate(bounding_boxes_to_download):\n\n            self._export_for_polygon(\n                polygon=bounding_info.to_ee_polygon(),\n                polygon_identifier=idx,\n                start_date=start_date,\n                end_date=self.data_date,\n                days_per_timestep=days_per_timestep,\n                checkpoint=checkpoint,\n                monitor=monitor,\n                fast=fast,\n            )\n",
  "history_output" : "",
  "history_begin_time" : 1646138399311,
  "history_end_time" : 1646138401496,
  "history_notes" : null,
  "history_process" : "nlb6f5",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "q0oec3j0png",
  "history_input" : "import pandas as pd\nimport geopandas\nfrom tqdm import tqdm\nfrom datetime import timedelta, date\n\nfrom src_exporters_sentinel_base import BaseSentinelExporter\nfrom src_processors_kenya_non_crop import KenyaNonCropProcessor\nfrom src_exporters_sentinel_utils import EEBoundingBox, bounding_box_from_centre\n\nfrom typing import Optional, List\n\n\nclass KenyaNonCropSentinelExporter(BaseSentinelExporter):\n\n    dataset = \"earth_engine_kenya_non_crop\"\n\n    # data collection date\n    data_date = date(2020, 4, 16)\n\n    def load_labels(self) -> pd.DataFrame:\n        # right now, this just loads geowiki data. In the future,\n        # it would be neat to merge all labels together\n        non_crop = self.data_folder / \"processed\" / KenyaNonCropProcessor.dataset / \"data.geojson\"\n        assert non_crop.exists(), \"Kenya non crop processor must be run to load labels\"\n        return geopandas.read_file(non_crop)[[\"lat\", \"lon\"]]\n\n    def labels_to_bounding_boxes(\n        self, num_labelled_points: Optional[int], surrounding_metres: int\n    ) -> List[EEBoundingBox]:\n\n        output: List[EEBoundingBox] = []\n\n        for idx, row in tqdm(self.labels.iterrows()):\n\n            output.append(\n                bounding_box_from_centre(\n                    mid_lat=row[\"lat\"], mid_lon=row[\"lon\"], surrounding_metres=surrounding_metres,\n                ),\n            )\n\n            if num_labelled_points is not None:\n                if len(output) >= num_labelled_points:\n                    return output\n        return output\n\n    def export_for_labels(\n        self,\n        days_per_timestep: int = 30,\n        num_timesteps: int = 12,\n        num_labelled_points: Optional[int] = None,\n        surrounding_metres: int = 80,\n        checkpoint: bool = True,\n        monitor: bool = False,\n        fast: bool = True,\n    ) -> None:\n        r\"\"\"\n        :param days_per_timestep: The number of days of data to use for each mosaiced image.\n            Default = 30\n        :param num_timesteps: The number of timesteps to export. Default = 12\n        :param num_labelled_points: If not None, then only this many points will be exported.\n            Default = None.\n        :param surrouning_metres: The patch will be [2 * surrounding_metres,\n            2 * surrounding_metres], centered around the labelled point. Default = 80\n        :param checkpoint: Whether or not to check in self.data_folder to see if the file has\n            already been exported. If it has, skip it. Default = True\n        :param monitor: Whether to monitor each task until it has been run. Default = True\n        :param fast: Whether to use the faster cloudfree exporter. This function is considerably\n            faster, but cloud artefacts can be more pronounced. Default = True\n        \"\"\"\n\n        bounding_boxes_to_download = self.labels_to_bounding_boxes(\n            num_labelled_points=num_labelled_points, surrounding_metres=surrounding_metres,\n        )\n\n        start_date = self.data_date - num_timesteps * timedelta(days=days_per_timestep)\n\n        for idx, bounding_info in enumerate(bounding_boxes_to_download):\n\n            self._export_for_polygon(\n                polygon=bounding_info.to_ee_polygon(),\n                polygon_identifier=idx,\n                start_date=start_date,\n                end_date=self.data_date,\n                days_per_timestep=days_per_timestep,\n                checkpoint=checkpoint,\n                monitor=monitor,\n                fast=fast,\n            )\n",
  "history_output" : "",
  "history_begin_time" : 1646138282058,
  "history_end_time" : 1646138283003,
  "history_notes" : null,
  "history_process" : "nlb6f5",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "5hk6fjol9h3",
  "history_input" : "import pandas as pd\nimport geopandas\nfrom tqdm import tqdm\nfrom datetime import timedelta, date\n\nfrom src_exporters_sentinel_base import BaseSentinelExporter\nfrom src_processors_kenya_non_crop import KenyaNonCropProcessor\nfrom src_exporters_sentinel_utils import EEBoundingBox, bounding_box_from_centre\n\nfrom typing import Optional, List\n\n\nclass KenyaNonCropSentinelExporter(BaseSentinelExporter):\n\n    dataset = \"earth_engine_kenya_non_crop\"\n\n    # data collection date\n    data_date = date(2020, 4, 16)\n\n    def load_labels(self) -> pd.DataFrame:\n        # right now, this just loads geowiki data. In the future,\n        # it would be neat to merge all labels together\n        non_crop = self.data_folder / \"processed\" / KenyaNonCropProcessor.dataset / \"data.geojson\"\n        assert non_crop.exists(), \"Kenya non crop processor must be run to load labels\"\n        return geopandas.read_file(non_crop)[[\"lat\", \"lon\"]]\n\n    def labels_to_bounding_boxes(\n        self, num_labelled_points: Optional[int], surrounding_metres: int\n    ) -> List[EEBoundingBox]:\n\n        output: List[EEBoundingBox] = []\n\n        for idx, row in tqdm(self.labels.iterrows()):\n\n            output.append(\n                bounding_box_from_centre(\n                    mid_lat=row[\"lat\"], mid_lon=row[\"lon\"], surrounding_metres=surrounding_metres,\n                ),\n            )\n\n            if num_labelled_points is not None:\n                if len(output) >= num_labelled_points:\n                    return output\n        return output\n\n    def export_for_labels(\n        self,\n        days_per_timestep: int = 30,\n        num_timesteps: int = 12,\n        num_labelled_points: Optional[int] = None,\n        surrounding_metres: int = 80,\n        checkpoint: bool = True,\n        monitor: bool = False,\n        fast: bool = True,\n    ) -> None:\n        r\"\"\"\n        :param days_per_timestep: The number of days of data to use for each mosaiced image.\n            Default = 30\n        :param num_timesteps: The number of timesteps to export. Default = 12\n        :param num_labelled_points: If not None, then only this many points will be exported.\n            Default = None.\n        :param surrouning_metres: The patch will be [2 * surrounding_metres,\n            2 * surrounding_metres], centered around the labelled point. Default = 80\n        :param checkpoint: Whether or not to check in self.data_folder to see if the file has\n            already been exported. If it has, skip it. Default = True\n        :param monitor: Whether to monitor each task until it has been run. Default = True\n        :param fast: Whether to use the faster cloudfree exporter. This function is considerably\n            faster, but cloud artefacts can be more pronounced. Default = True\n        \"\"\"\n\n        bounding_boxes_to_download = self.labels_to_bounding_boxes(\n            num_labelled_points=num_labelled_points, surrounding_metres=surrounding_metres,\n        )\n\n        start_date = self.data_date - num_timesteps * timedelta(days=days_per_timestep)\n\n        for idx, bounding_info in enumerate(bounding_boxes_to_download):\n\n            self._export_for_polygon(\n                polygon=bounding_info.to_ee_polygon(),\n                polygon_identifier=idx,\n                start_date=start_date,\n                end_date=self.data_date,\n                days_per_timestep=days_per_timestep,\n                checkpoint=checkpoint,\n                monitor=monitor,\n                fast=fast,\n            )\n",
  "history_output" : "",
  "history_begin_time" : 1646138177210,
  "history_end_time" : 1646138177473,
  "history_notes" : null,
  "history_process" : "nlb6f5",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "t3vab8g4frc",
  "history_input" : "import pandas as pd\nimport geopandas\nfrom tqdm import tqdm\nfrom datetime import timedelta, date\n\nfrom src_exporters_sentinel_base import BaseSentinelExporter\nfrom src_processors_kenya_non_crop import KenyaNonCropProcessor\nfrom src_exporters_sentinel_utils import EEBoundingBox, bounding_box_from_centre\n\nfrom typing import Optional, List\n\n\nclass KenyaNonCropSentinelExporter(BaseSentinelExporter):\n\n    dataset = \"earth_engine_kenya_non_crop\"\n\n    # data collection date\n    data_date = date(2020, 4, 16)\n\n    def load_labels(self) -> pd.DataFrame:\n        # right now, this just loads geowiki data. In the future,\n        # it would be neat to merge all labels together\n        non_crop = self.data_folder / \"processed\" / KenyaNonCropProcessor.dataset / \"data.geojson\"\n        assert non_crop.exists(), \"Kenya non crop processor must be run to load labels\"\n        return geopandas.read_file(non_crop)[[\"lat\", \"lon\"]]\n\n    def labels_to_bounding_boxes(\n        self, num_labelled_points: Optional[int], surrounding_metres: int\n    ) -> List[EEBoundingBox]:\n\n        output: List[EEBoundingBox] = []\n\n        for idx, row in tqdm(self.labels.iterrows()):\n\n            output.append(\n                bounding_box_from_centre(\n                    mid_lat=row[\"lat\"], mid_lon=row[\"lon\"], surrounding_metres=surrounding_metres,\n                ),\n            )\n\n            if num_labelled_points is not None:\n                if len(output) >= num_labelled_points:\n                    return output\n        return output\n\n    def export_for_labels(\n        self,\n        days_per_timestep: int = 30,\n        num_timesteps: int = 12,\n        num_labelled_points: Optional[int] = None,\n        surrounding_metres: int = 80,\n        checkpoint: bool = True,\n        monitor: bool = False,\n        fast: bool = True,\n    ) -> None:\n        r\"\"\"\n        :param days_per_timestep: The number of days of data to use for each mosaiced image.\n            Default = 30\n        :param num_timesteps: The number of timesteps to export. Default = 12\n        :param num_labelled_points: If not None, then only this many points will be exported.\n            Default = None.\n        :param surrouning_metres: The patch will be [2 * surrounding_metres,\n            2 * surrounding_metres], centered around the labelled point. Default = 80\n        :param checkpoint: Whether or not to check in self.data_folder to see if the file has\n            already been exported. If it has, skip it. Default = True\n        :param monitor: Whether to monitor each task until it has been run. Default = True\n        :param fast: Whether to use the faster cloudfree exporter. This function is considerably\n            faster, but cloud artefacts can be more pronounced. Default = True\n        \"\"\"\n\n        bounding_boxes_to_download = self.labels_to_bounding_boxes(\n            num_labelled_points=num_labelled_points, surrounding_metres=surrounding_metres,\n        )\n\n        start_date = self.data_date - num_timesteps * timedelta(days=days_per_timestep)\n\n        for idx, bounding_info in enumerate(bounding_boxes_to_download):\n\n            self._export_for_polygon(\n                polygon=bounding_info.to_ee_polygon(),\n                polygon_identifier=idx,\n                start_date=start_date,\n                end_date=self.data_date,\n                days_per_timestep=days_per_timestep,\n                checkpoint=checkpoint,\n                monitor=monitor,\n                fast=fast,\n            )\n",
  "history_output" : "",
  "history_begin_time" : 1646138096259,
  "history_end_time" : 1646138097663,
  "history_notes" : null,
  "history_process" : "nlb6f5",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "r6twezc90co",
  "history_input" : "import pandas as pd\nimport geopandas\nfrom tqdm import tqdm\nfrom datetime import timedelta, date\n\nfrom src_exporters_sentinel_base import BaseSentinelExporter\nfrom src_processors_kenya_non_crop import KenyaNonCropProcessor\nfrom src_exporters_sentinel_utils import EEBoundingBox, bounding_box_from_centre\n\nfrom typing import Optional, List\n\n\nclass KenyaNonCropSentinelExporter(BaseSentinelExporter):\n\n    dataset = \"earth_engine_kenya_non_crop\"\n\n    # data collection date\n    data_date = date(2020, 4, 16)\n\n    def load_labels(self) -> pd.DataFrame:\n        # right now, this just loads geowiki data. In the future,\n        # it would be neat to merge all labels together\n        non_crop = self.data_folder / \"processed\" / KenyaNonCropProcessor.dataset / \"data.geojson\"\n        assert non_crop.exists(), \"Kenya non crop processor must be run to load labels\"\n        return geopandas.read_file(non_crop)[[\"lat\", \"lon\"]]\n\n    def labels_to_bounding_boxes(\n        self, num_labelled_points: Optional[int], surrounding_metres: int\n    ) -> List[EEBoundingBox]:\n\n        output: List[EEBoundingBox] = []\n\n        for idx, row in tqdm(self.labels.iterrows()):\n\n            output.append(\n                bounding_box_from_centre(\n                    mid_lat=row[\"lat\"], mid_lon=row[\"lon\"], surrounding_metres=surrounding_metres,\n                ),\n            )\n\n            if num_labelled_points is not None:\n                if len(output) >= num_labelled_points:\n                    return output\n        return output\n\n    def export_for_labels(\n        self,\n        days_per_timestep: int = 30,\n        num_timesteps: int = 12,\n        num_labelled_points: Optional[int] = None,\n        surrounding_metres: int = 80,\n        checkpoint: bool = True,\n        monitor: bool = False,\n        fast: bool = True,\n    ) -> None:\n        r\"\"\"\n        :param days_per_timestep: The number of days of data to use for each mosaiced image.\n            Default = 30\n        :param num_timesteps: The number of timesteps to export. Default = 12\n        :param num_labelled_points: If not None, then only this many points will be exported.\n            Default = None.\n        :param surrouning_metres: The patch will be [2 * surrounding_metres,\n            2 * surrounding_metres], centered around the labelled point. Default = 80\n        :param checkpoint: Whether or not to check in self.data_folder to see if the file has\n            already been exported. If it has, skip it. Default = True\n        :param monitor: Whether to monitor each task until it has been run. Default = True\n        :param fast: Whether to use the faster cloudfree exporter. This function is considerably\n            faster, but cloud artefacts can be more pronounced. Default = True\n        \"\"\"\n\n        bounding_boxes_to_download = self.labels_to_bounding_boxes(\n            num_labelled_points=num_labelled_points, surrounding_metres=surrounding_metres,\n        )\n\n        start_date = self.data_date - num_timesteps * timedelta(days=days_per_timestep)\n\n        for idx, bounding_info in enumerate(bounding_boxes_to_download):\n\n            self._export_for_polygon(\n                polygon=bounding_info.to_ee_polygon(),\n                polygon_identifier=idx,\n                start_date=start_date,\n                end_date=self.data_date,\n                days_per_timestep=days_per_timestep,\n                checkpoint=checkpoint,\n                monitor=monitor,\n                fast=fast,\n            )\n",
  "history_output" : "",
  "history_begin_time" : 1646137778746,
  "history_end_time" : 1646137781101,
  "history_notes" : null,
  "history_process" : "nlb6f5",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "mgqjngfotui",
  "history_input" : "import pandas as pd\nimport geopandas\nfrom tqdm import tqdm\nfrom datetime import timedelta, date\n\nfrom src_exporters_sentinel_base import BaseSentinelExporter\nfrom src_processors_kenya_non_crop import KenyaNonCropProcessor\nfrom src_exporters_sentinel_utils import EEBoundingBox, bounding_box_from_centre\n\nfrom typing import Optional, List\n\n\nclass KenyaNonCropSentinelExporter(BaseSentinelExporter):\n\n    dataset = \"earth_engine_kenya_non_crop\"\n\n    # data collection date\n    data_date = date(2020, 4, 16)\n\n    def load_labels(self) -> pd.DataFrame:\n        # right now, this just loads geowiki data. In the future,\n        # it would be neat to merge all labels together\n        non_crop = self.data_folder / \"processed\" / KenyaNonCropProcessor.dataset / \"data.geojson\"\n        assert non_crop.exists(), \"Kenya non crop processor must be run to load labels\"\n        return geopandas.read_file(non_crop)[[\"lat\", \"lon\"]]\n\n    def labels_to_bounding_boxes(\n        self, num_labelled_points: Optional[int], surrounding_metres: int\n    ) -> List[EEBoundingBox]:\n\n        output: List[EEBoundingBox] = []\n\n        for idx, row in tqdm(self.labels.iterrows()):\n\n            output.append(\n                bounding_box_from_centre(\n                    mid_lat=row[\"lat\"], mid_lon=row[\"lon\"], surrounding_metres=surrounding_metres,\n                ),\n            )\n\n            if num_labelled_points is not None:\n                if len(output) >= num_labelled_points:\n                    return output\n        return output\n\n    def export_for_labels(\n        self,\n        days_per_timestep: int = 30,\n        num_timesteps: int = 12,\n        num_labelled_points: Optional[int] = None,\n        surrounding_metres: int = 80,\n        checkpoint: bool = True,\n        monitor: bool = False,\n        fast: bool = True,\n    ) -> None:\n        r\"\"\"\n        :param days_per_timestep: The number of days of data to use for each mosaiced image.\n            Default = 30\n        :param num_timesteps: The number of timesteps to export. Default = 12\n        :param num_labelled_points: If not None, then only this many points will be exported.\n            Default = None.\n        :param surrouning_metres: The patch will be [2 * surrounding_metres,\n            2 * surrounding_metres], centered around the labelled point. Default = 80\n        :param checkpoint: Whether or not to check in self.data_folder to see if the file has\n            already been exported. If it has, skip it. Default = True\n        :param monitor: Whether to monitor each task until it has been run. Default = True\n        :param fast: Whether to use the faster cloudfree exporter. This function is considerably\n            faster, but cloud artefacts can be more pronounced. Default = True\n        \"\"\"\n\n        bounding_boxes_to_download = self.labels_to_bounding_boxes(\n            num_labelled_points=num_labelled_points, surrounding_metres=surrounding_metres,\n        )\n\n        start_date = self.data_date - num_timesteps * timedelta(days=days_per_timestep)\n\n        for idx, bounding_info in enumerate(bounding_boxes_to_download):\n\n            self._export_for_polygon(\n                polygon=bounding_info.to_ee_polygon(),\n                polygon_identifier=idx,\n                start_date=start_date,\n                end_date=self.data_date,\n                days_per_timestep=days_per_timestep,\n                checkpoint=checkpoint,\n                monitor=monitor,\n                fast=fast,\n            )\n",
  "history_output" : "",
  "history_begin_time" : 1646137684819,
  "history_end_time" : 1646137687299,
  "history_notes" : null,
  "history_process" : "nlb6f5",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "de2o3se8ra5",
  "history_input" : "import pandas as pd\nimport geopandas\nfrom tqdm import tqdm\nfrom datetime import timedelta, date\n\nfrom src_exporters_sentinel_base import BaseSentinelExporter\nfrom src_processors_kenya_non_crop import KenyaNonCropProcessor\nfrom src_exporters_sentinel_utils import EEBoundingBox, bounding_box_from_centre\n\nfrom typing import Optional, List\n\n\nclass KenyaNonCropSentinelExporter(BaseSentinelExporter):\n\n    dataset = \"earth_engine_kenya_non_crop\"\n\n    # data collection date\n    data_date = date(2020, 4, 16)\n\n    def load_labels(self) -> pd.DataFrame:\n        # right now, this just loads geowiki data. In the future,\n        # it would be neat to merge all labels together\n        non_crop = self.data_folder / \"processed\" / KenyaNonCropProcessor.dataset / \"data.geojson\"\n        assert non_crop.exists(), \"Kenya non crop processor must be run to load labels\"\n        return geopandas.read_file(non_crop)[[\"lat\", \"lon\"]]\n\n    def labels_to_bounding_boxes(\n        self, num_labelled_points: Optional[int], surrounding_metres: int\n    ) -> List[EEBoundingBox]:\n\n        output: List[EEBoundingBox] = []\n\n        for idx, row in tqdm(self.labels.iterrows()):\n\n            output.append(\n                bounding_box_from_centre(\n                    mid_lat=row[\"lat\"], mid_lon=row[\"lon\"], surrounding_metres=surrounding_metres,\n                ),\n            )\n\n            if num_labelled_points is not None:\n                if len(output) >= num_labelled_points:\n                    return output\n        return output\n\n    def export_for_labels(\n        self,\n        days_per_timestep: int = 30,\n        num_timesteps: int = 12,\n        num_labelled_points: Optional[int] = None,\n        surrounding_metres: int = 80,\n        checkpoint: bool = True,\n        monitor: bool = False,\n        fast: bool = True,\n    ) -> None:\n        r\"\"\"\n        :param days_per_timestep: The number of days of data to use for each mosaiced image.\n            Default = 30\n        :param num_timesteps: The number of timesteps to export. Default = 12\n        :param num_labelled_points: If not None, then only this many points will be exported.\n            Default = None.\n        :param surrouning_metres: The patch will be [2 * surrounding_metres,\n            2 * surrounding_metres], centered around the labelled point. Default = 80\n        :param checkpoint: Whether or not to check in self.data_folder to see if the file has\n            already been exported. If it has, skip it. Default = True\n        :param monitor: Whether to monitor each task until it has been run. Default = True\n        :param fast: Whether to use the faster cloudfree exporter. This function is considerably\n            faster, but cloud artefacts can be more pronounced. Default = True\n        \"\"\"\n\n        bounding_boxes_to_download = self.labels_to_bounding_boxes(\n            num_labelled_points=num_labelled_points, surrounding_metres=surrounding_metres,\n        )\n\n        start_date = self.data_date - num_timesteps * timedelta(days=days_per_timestep)\n\n        for idx, bounding_info in enumerate(bounding_boxes_to_download):\n\n            self._export_for_polygon(\n                polygon=bounding_info.to_ee_polygon(),\n                polygon_identifier=idx,\n                start_date=start_date,\n                end_date=self.data_date,\n                days_per_timestep=days_per_timestep,\n                checkpoint=checkpoint,\n                monitor=monitor,\n                fast=fast,\n            )\n",
  "history_output" : "",
  "history_begin_time" : 1646137574278,
  "history_end_time" : 1646137576296,
  "history_notes" : null,
  "history_process" : "nlb6f5",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "y3p72f0sslk",
  "history_input" : "import pandas as pd\nimport geopandas\nfrom tqdm import tqdm\nfrom datetime import timedelta, date\n\nfrom src_exporters_sentinel_base import BaseSentinelExporter\nfrom src_processors_kenya_non_crop import KenyaNonCropProcessor\nfrom src_exporters_sentinel_utils import EEBoundingBox, bounding_box_from_centre\n\nfrom typing import Optional, List\n\n\nclass KenyaNonCropSentinelExporter(BaseSentinelExporter):\n\n    dataset = \"earth_engine_kenya_non_crop\"\n\n    # data collection date\n    data_date = date(2020, 4, 16)\n\n    def load_labels(self) -> pd.DataFrame:\n        # right now, this just loads geowiki data. In the future,\n        # it would be neat to merge all labels together\n        non_crop = self.data_folder / \"processed\" / KenyaNonCropProcessor.dataset / \"data.geojson\"\n        assert non_crop.exists(), \"Kenya non crop processor must be run to load labels\"\n        return geopandas.read_file(non_crop)[[\"lat\", \"lon\"]]\n\n    def labels_to_bounding_boxes(\n        self, num_labelled_points: Optional[int], surrounding_metres: int\n    ) -> List[EEBoundingBox]:\n\n        output: List[EEBoundingBox] = []\n\n        for idx, row in tqdm(self.labels.iterrows()):\n\n            output.append(\n                bounding_box_from_centre(\n                    mid_lat=row[\"lat\"], mid_lon=row[\"lon\"], surrounding_metres=surrounding_metres,\n                ),\n            )\n\n            if num_labelled_points is not None:\n                if len(output) >= num_labelled_points:\n                    return output\n        return output\n\n    def export_for_labels(\n        self,\n        days_per_timestep: int = 30,\n        num_timesteps: int = 12,\n        num_labelled_points: Optional[int] = None,\n        surrounding_metres: int = 80,\n        checkpoint: bool = True,\n        monitor: bool = False,\n        fast: bool = True,\n    ) -> None:\n        r\"\"\"\n        :param days_per_timestep: The number of days of data to use for each mosaiced image.\n            Default = 30\n        :param num_timesteps: The number of timesteps to export. Default = 12\n        :param num_labelled_points: If not None, then only this many points will be exported.\n            Default = None.\n        :param surrouning_metres: The patch will be [2 * surrounding_metres,\n            2 * surrounding_metres], centered around the labelled point. Default = 80\n        :param checkpoint: Whether or not to check in self.data_folder to see if the file has\n            already been exported. If it has, skip it. Default = True\n        :param monitor: Whether to monitor each task until it has been run. Default = True\n        :param fast: Whether to use the faster cloudfree exporter. This function is considerably\n            faster, but cloud artefacts can be more pronounced. Default = True\n        \"\"\"\n\n        bounding_boxes_to_download = self.labels_to_bounding_boxes(\n            num_labelled_points=num_labelled_points, surrounding_metres=surrounding_metres,\n        )\n\n        start_date = self.data_date - num_timesteps * timedelta(days=days_per_timestep)\n\n        for idx, bounding_info in enumerate(bounding_boxes_to_download):\n\n            self._export_for_polygon(\n                polygon=bounding_info.to_ee_polygon(),\n                polygon_identifier=idx,\n                start_date=start_date,\n                end_date=self.data_date,\n                days_per_timestep=days_per_timestep,\n                checkpoint=checkpoint,\n                monitor=monitor,\n                fast=fast,\n            )\n",
  "history_output" : "",
  "history_begin_time" : 1646112839356,
  "history_end_time" : 1646112839594,
  "history_notes" : null,
  "history_process" : "nlb6f5",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "vx9qhehz57c",
  "history_input" : "import pandas as pd\nimport geopandas\nfrom tqdm import tqdm\nfrom datetime import timedelta, date\n\nfrom src_exporters_sentinel_base import BaseSentinelExporter\nfrom src_processors_kenya_non_crop import KenyaNonCropProcessor\nfrom src_exporters_sentinel_utils import EEBoundingBox, bounding_box_from_centre\n\nfrom typing import Optional, List\n\n\nclass KenyaNonCropSentinelExporter(BaseSentinelExporter):\n\n    dataset = \"earth_engine_kenya_non_crop\"\n\n    # data collection date\n    data_date = date(2020, 4, 16)\n\n    def load_labels(self) -> pd.DataFrame:\n        # right now, this just loads geowiki data. In the future,\n        # it would be neat to merge all labels together\n        non_crop = self.data_folder / \"processed\" / KenyaNonCropProcessor.dataset / \"data.geojson\"\n        assert non_crop.exists(), \"Kenya non crop processor must be run to load labels\"\n        return geopandas.read_file(non_crop)[[\"lat\", \"lon\"]]\n\n    def labels_to_bounding_boxes(\n        self, num_labelled_points: Optional[int], surrounding_metres: int\n    ) -> List[EEBoundingBox]:\n\n        output: List[EEBoundingBox] = []\n\n        for idx, row in tqdm(self.labels.iterrows()):\n\n            output.append(\n                bounding_box_from_centre(\n                    mid_lat=row[\"lat\"], mid_lon=row[\"lon\"], surrounding_metres=surrounding_metres,\n                ),\n            )\n\n            if num_labelled_points is not None:\n                if len(output) >= num_labelled_points:\n                    return output\n        return output\n\n    def export_for_labels(\n        self,\n        days_per_timestep: int = 30,\n        num_timesteps: int = 12,\n        num_labelled_points: Optional[int] = None,\n        surrounding_metres: int = 80,\n        checkpoint: bool = True,\n        monitor: bool = False,\n        fast: bool = True,\n    ) -> None:\n        r\"\"\"\n        :param days_per_timestep: The number of days of data to use for each mosaiced image.\n            Default = 30\n        :param num_timesteps: The number of timesteps to export. Default = 12\n        :param num_labelled_points: If not None, then only this many points will be exported.\n            Default = None.\n        :param surrouning_metres: The patch will be [2 * surrounding_metres,\n            2 * surrounding_metres], centered around the labelled point. Default = 80\n        :param checkpoint: Whether or not to check in self.data_folder to see if the file has\n            already been exported. If it has, skip it. Default = True\n        :param monitor: Whether to monitor each task until it has been run. Default = True\n        :param fast: Whether to use the faster cloudfree exporter. This function is considerably\n            faster, but cloud artefacts can be more pronounced. Default = True\n        \"\"\"\n\n        bounding_boxes_to_download = self.labels_to_bounding_boxes(\n            num_labelled_points=num_labelled_points, surrounding_metres=surrounding_metres,\n        )\n\n        start_date = self.data_date - num_timesteps * timedelta(days=days_per_timestep)\n\n        for idx, bounding_info in enumerate(bounding_boxes_to_download):\n\n            self._export_for_polygon(\n                polygon=bounding_info.to_ee_polygon(),\n                polygon_identifier=idx,\n                start_date=start_date,\n                end_date=self.data_date,\n                days_per_timestep=days_per_timestep,\n                checkpoint=checkpoint,\n                monitor=monitor,\n                fast=fast,\n            )\n",
  "history_output" : "",
  "history_begin_time" : 1646112731044,
  "history_end_time" : 1646112733313,
  "history_notes" : null,
  "history_process" : "nlb6f5",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "5cxfh5olqca",
  "history_input" : "import pandas as pd\nimport geopandas\nfrom tqdm import tqdm\nfrom datetime import timedelta, date\n\nfrom src_exporters_sentinel_base import BaseSentinelExporter\nfrom src_processors_kenya_non_crop import KenyaNonCropProcessor\nfrom src_exporters_sentinel_utils import EEBoundingBox, bounding_box_from_centre\n\nfrom typing import Optional, List\n\n\nclass KenyaNonCropSentinelExporter(BaseSentinelExporter):\n\n    dataset = \"earth_engine_kenya_non_crop\"\n\n    # data collection date\n    data_date = date(2020, 4, 16)\n\n    def load_labels(self) -> pd.DataFrame:\n        # right now, this just loads geowiki data. In the future,\n        # it would be neat to merge all labels together\n        non_crop = self.data_folder / \"processed\" / KenyaNonCropProcessor.dataset / \"data.geojson\"\n        assert non_crop.exists(), \"Kenya non crop processor must be run to load labels\"\n        return geopandas.read_file(non_crop)[[\"lat\", \"lon\"]]\n\n    def labels_to_bounding_boxes(\n        self, num_labelled_points: Optional[int], surrounding_metres: int\n    ) -> List[EEBoundingBox]:\n\n        output: List[EEBoundingBox] = []\n\n        for idx, row in tqdm(self.labels.iterrows()):\n\n            output.append(\n                bounding_box_from_centre(\n                    mid_lat=row[\"lat\"], mid_lon=row[\"lon\"], surrounding_metres=surrounding_metres,\n                ),\n            )\n\n            if num_labelled_points is not None:\n                if len(output) >= num_labelled_points:\n                    return output\n        return output\n\n    def export_for_labels(\n        self,\n        days_per_timestep: int = 30,\n        num_timesteps: int = 12,\n        num_labelled_points: Optional[int] = None,\n        surrounding_metres: int = 80,\n        checkpoint: bool = True,\n        monitor: bool = False,\n        fast: bool = True,\n    ) -> None:\n        r\"\"\"\n        :param days_per_timestep: The number of days of data to use for each mosaiced image.\n            Default = 30\n        :param num_timesteps: The number of timesteps to export. Default = 12\n        :param num_labelled_points: If not None, then only this many points will be exported.\n            Default = None.\n        :param surrouning_metres: The patch will be [2 * surrounding_metres,\n            2 * surrounding_metres], centered around the labelled point. Default = 80\n        :param checkpoint: Whether or not to check in self.data_folder to see if the file has\n            already been exported. If it has, skip it. Default = True\n        :param monitor: Whether to monitor each task until it has been run. Default = True\n        :param fast: Whether to use the faster cloudfree exporter. This function is considerably\n            faster, but cloud artefacts can be more pronounced. Default = True\n        \"\"\"\n\n        bounding_boxes_to_download = self.labels_to_bounding_boxes(\n            num_labelled_points=num_labelled_points, surrounding_metres=surrounding_metres,\n        )\n\n        start_date = self.data_date - num_timesteps * timedelta(days=days_per_timestep)\n\n        for idx, bounding_info in enumerate(bounding_boxes_to_download):\n\n            self._export_for_polygon(\n                polygon=bounding_info.to_ee_polygon(),\n                polygon_identifier=idx,\n                start_date=start_date,\n                end_date=self.data_date,\n                days_per_timestep=days_per_timestep,\n                checkpoint=checkpoint,\n                monitor=monitor,\n                fast=fast,\n            )\n",
  "history_output" : "",
  "history_begin_time" : 1646112282934,
  "history_end_time" : 1646112284881,
  "history_notes" : null,
  "history_process" : "nlb6f5",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "q5bqixe8nqu",
  "history_input" : "import pandas as pd\nimport geopandas\nfrom tqdm import tqdm\nfrom datetime import timedelta, date\n\nfrom src_exporters_sentinel_base import BaseSentinelExporter\nfrom src_processors_kenya_non_crop import KenyaNonCropProcessor\nfrom src_exporters_sentinel_utils import EEBoundingBox, bounding_box_from_centre\n\nfrom typing import Optional, List\n\n\nclass KenyaNonCropSentinelExporter(BaseSentinelExporter):\n\n    dataset = \"earth_engine_kenya_non_crop\"\n\n    # data collection date\n    data_date = date(2020, 4, 16)\n\n    def load_labels(self) -> pd.DataFrame:\n        # right now, this just loads geowiki data. In the future,\n        # it would be neat to merge all labels together\n        non_crop = self.data_folder / \"processed\" / KenyaNonCropProcessor.dataset / \"data.geojson\"\n        assert non_crop.exists(), \"Kenya non crop processor must be run to load labels\"\n        return geopandas.read_file(non_crop)[[\"lat\", \"lon\"]]\n\n    def labels_to_bounding_boxes(\n        self, num_labelled_points: Optional[int], surrounding_metres: int\n    ) -> List[EEBoundingBox]:\n\n        output: List[EEBoundingBox] = []\n\n        for idx, row in tqdm(self.labels.iterrows()):\n\n            output.append(\n                bounding_box_from_centre(\n                    mid_lat=row[\"lat\"], mid_lon=row[\"lon\"], surrounding_metres=surrounding_metres,\n                ),\n            )\n\n            if num_labelled_points is not None:\n                if len(output) >= num_labelled_points:\n                    return output\n        return output\n\n    def export_for_labels(\n        self,\n        days_per_timestep: int = 30,\n        num_timesteps: int = 12,\n        num_labelled_points: Optional[int] = None,\n        surrounding_metres: int = 80,\n        checkpoint: bool = True,\n        monitor: bool = False,\n        fast: bool = True,\n    ) -> None:\n        r\"\"\"\n        :param days_per_timestep: The number of days of data to use for each mosaiced image.\n            Default = 30\n        :param num_timesteps: The number of timesteps to export. Default = 12\n        :param num_labelled_points: If not None, then only this many points will be exported.\n            Default = None.\n        :param surrouning_metres: The patch will be [2 * surrounding_metres,\n            2 * surrounding_metres], centered around the labelled point. Default = 80\n        :param checkpoint: Whether or not to check in self.data_folder to see if the file has\n            already been exported. If it has, skip it. Default = True\n        :param monitor: Whether to monitor each task until it has been run. Default = True\n        :param fast: Whether to use the faster cloudfree exporter. This function is considerably\n            faster, but cloud artefacts can be more pronounced. Default = True\n        \"\"\"\n\n        bounding_boxes_to_download = self.labels_to_bounding_boxes(\n            num_labelled_points=num_labelled_points, surrounding_metres=surrounding_metres,\n        )\n\n        start_date = self.data_date - num_timesteps * timedelta(days=days_per_timestep)\n\n        for idx, bounding_info in enumerate(bounding_boxes_to_download):\n\n            self._export_for_polygon(\n                polygon=bounding_info.to_ee_polygon(),\n                polygon_identifier=idx,\n                start_date=start_date,\n                end_date=self.data_date,\n                days_per_timestep=days_per_timestep,\n                checkpoint=checkpoint,\n                monitor=monitor,\n                fast=fast,\n            )\n",
  "history_output" : "",
  "history_begin_time" : 1646112241110,
  "history_end_time" : 1646112243543,
  "history_notes" : null,
  "history_process" : "nlb6f5",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "s5f65276rud",
  "history_input" : "import pandas as pd\nimport geopandas\nfrom tqdm import tqdm\nfrom datetime import timedelta, date\n\nfrom src_exporters_sentinel_base import BaseSentinelExporter\nfrom src_processors_kenya_non_crop import KenyaNonCropProcessor\nfrom src_exporters_sentinel_utils import EEBoundingBox, bounding_box_from_centre\n\nfrom typing import Optional, List\n\n\nclass KenyaNonCropSentinelExporter(BaseSentinelExporter):\n\n    dataset = \"earth_engine_kenya_non_crop\"\n\n    # data collection date\n    data_date = date(2020, 4, 16)\n\n    def load_labels(self) -> pd.DataFrame:\n        # right now, this just loads geowiki data. In the future,\n        # it would be neat to merge all labels together\n        non_crop = self.data_folder / \"processed\" / KenyaNonCropProcessor.dataset / \"data.geojson\"\n        assert non_crop.exists(), \"Kenya non crop processor must be run to load labels\"\n        return geopandas.read_file(non_crop)[[\"lat\", \"lon\"]]\n\n    def labels_to_bounding_boxes(\n        self, num_labelled_points: Optional[int], surrounding_metres: int\n    ) -> List[EEBoundingBox]:\n\n        output: List[EEBoundingBox] = []\n\n        for idx, row in tqdm(self.labels.iterrows()):\n\n            output.append(\n                bounding_box_from_centre(\n                    mid_lat=row[\"lat\"], mid_lon=row[\"lon\"], surrounding_metres=surrounding_metres,\n                ),\n            )\n\n            if num_labelled_points is not None:\n                if len(output) >= num_labelled_points:\n                    return output\n        return output\n\n    def export_for_labels(\n        self,\n        days_per_timestep: int = 30,\n        num_timesteps: int = 12,\n        num_labelled_points: Optional[int] = None,\n        surrounding_metres: int = 80,\n        checkpoint: bool = True,\n        monitor: bool = False,\n        fast: bool = True,\n    ) -> None:\n        r\"\"\"\n        :param days_per_timestep: The number of days of data to use for each mosaiced image.\n            Default = 30\n        :param num_timesteps: The number of timesteps to export. Default = 12\n        :param num_labelled_points: If not None, then only this many points will be exported.\n            Default = None.\n        :param surrouning_metres: The patch will be [2 * surrounding_metres,\n            2 * surrounding_metres], centered around the labelled point. Default = 80\n        :param checkpoint: Whether or not to check in self.data_folder to see if the file has\n            already been exported. If it has, skip it. Default = True\n        :param monitor: Whether to monitor each task until it has been run. Default = True\n        :param fast: Whether to use the faster cloudfree exporter. This function is considerably\n            faster, but cloud artefacts can be more pronounced. Default = True\n        \"\"\"\n\n        bounding_boxes_to_download = self.labels_to_bounding_boxes(\n            num_labelled_points=num_labelled_points, surrounding_metres=surrounding_metres,\n        )\n\n        start_date = self.data_date - num_timesteps * timedelta(days=days_per_timestep)\n\n        for idx, bounding_info in enumerate(bounding_boxes_to_download):\n\n            self._export_for_polygon(\n                polygon=bounding_info.to_ee_polygon(),\n                polygon_identifier=idx,\n                start_date=start_date,\n                end_date=self.data_date,\n                days_per_timestep=days_per_timestep,\n                checkpoint=checkpoint,\n                monitor=monitor,\n                fast=fast,\n            )\n",
  "history_output" : "",
  "history_begin_time" : 1646112136735,
  "history_end_time" : 1646112138826,
  "history_notes" : null,
  "history_process" : "nlb6f5",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "if6swqb7q2r",
  "history_input" : "import pandas as pd\nimport geopandas\nfrom tqdm import tqdm\nfrom datetime import timedelta, date\n\nfrom src_exporters_sentinel_base import BaseSentinelExporter\nfrom src_processors_kenya_non_crop import KenyaNonCropProcessor\nfrom src_exporters_sentinel_utils import EEBoundingBox, bounding_box_from_centre\n\nfrom typing import Optional, List\n\n\nclass KenyaNonCropSentinelExporter(BaseSentinelExporter):\n\n    dataset = \"earth_engine_kenya_non_crop\"\n\n    # data collection date\n    data_date = date(2020, 4, 16)\n\n    def load_labels(self) -> pd.DataFrame:\n        # right now, this just loads geowiki data. In the future,\n        # it would be neat to merge all labels together\n        non_crop = self.data_folder / \"processed\" / KenyaNonCropProcessor.dataset / \"data.geojson\"\n        assert non_crop.exists(), \"Kenya non crop processor must be run to load labels\"\n        return geopandas.read_file(non_crop)[[\"lat\", \"lon\"]]\n\n    def labels_to_bounding_boxes(\n        self, num_labelled_points: Optional[int], surrounding_metres: int\n    ) -> List[EEBoundingBox]:\n\n        output: List[EEBoundingBox] = []\n\n        for idx, row in tqdm(self.labels.iterrows()):\n\n            output.append(\n                bounding_box_from_centre(\n                    mid_lat=row[\"lat\"], mid_lon=row[\"lon\"], surrounding_metres=surrounding_metres,\n                ),\n            )\n\n            if num_labelled_points is not None:\n                if len(output) >= num_labelled_points:\n                    return output\n        return output\n\n    def export_for_labels(\n        self,\n        days_per_timestep: int = 30,\n        num_timesteps: int = 12,\n        num_labelled_points: Optional[int] = None,\n        surrounding_metres: int = 80,\n        checkpoint: bool = True,\n        monitor: bool = False,\n        fast: bool = True,\n    ) -> None:\n        r\"\"\"\n        :param days_per_timestep: The number of days of data to use for each mosaiced image.\n            Default = 30\n        :param num_timesteps: The number of timesteps to export. Default = 12\n        :param num_labelled_points: If not None, then only this many points will be exported.\n            Default = None.\n        :param surrouning_metres: The patch will be [2 * surrounding_metres,\n            2 * surrounding_metres], centered around the labelled point. Default = 80\n        :param checkpoint: Whether or not to check in self.data_folder to see if the file has\n            already been exported. If it has, skip it. Default = True\n        :param monitor: Whether to monitor each task until it has been run. Default = True\n        :param fast: Whether to use the faster cloudfree exporter. This function is considerably\n            faster, but cloud artefacts can be more pronounced. Default = True\n        \"\"\"\n\n        bounding_boxes_to_download = self.labels_to_bounding_boxes(\n            num_labelled_points=num_labelled_points, surrounding_metres=surrounding_metres,\n        )\n\n        start_date = self.data_date - num_timesteps * timedelta(days=days_per_timestep)\n\n        for idx, bounding_info in enumerate(bounding_boxes_to_download):\n\n            self._export_for_polygon(\n                polygon=bounding_info.to_ee_polygon(),\n                polygon_identifier=idx,\n                start_date=start_date,\n                end_date=self.data_date,\n                days_per_timestep=days_per_timestep,\n                checkpoint=checkpoint,\n                monitor=monitor,\n                fast=fast,\n            )\n",
  "history_output" : "",
  "history_begin_time" : 1645393379534,
  "history_end_time" : 1645393379707,
  "history_notes" : null,
  "history_process" : "nlb6f5",
  "host_id" : "100001",
  "indicator" : "Done"
},]
