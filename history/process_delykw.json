[{
  "history_id" : "x3ouh2wedj3",
  "history_input" : "from pathlib import Path\nimport sys\nimport os\n\nsys.path.append(\"..\")\n\nfrom src_models_model import Model\nfrom src_analysis import plot_results\n\n\ndef kenya_crop_type_mapper():\n    data_dir = \"../data\"\n\n    test_folder = Path(\"../data/raw/earth_engine_plant_village_kenya/\")\n    test_files = test_folder.glob(\"*.tif\")\n    print(test_files)\n\n    list_of_models = list(Path('../data/lightning_logs/').glob('version*/checkpoints/*.ckpt'))\n    latest_model_path = str(max(list_of_models, key=os.path.getctime))\n    print(f\"Using model {latest_model_path}\")\n\n    model = Model.load_from_checkpoint(latest_model_path)\n\n    for test_path in test_files:\n\n        save_dir = Path(data_dir) / \"Autoencoder\"\n        save_dir.mkdir(exist_ok=True)\n\n        print(f\"Running for {test_path}\")\n\n        savepath = save_dir / f\"preds_{test_path.name}\"\n        if savepath.exists():\n            print(\"File already generated. Skipping\")\n            continue\n\n        out_forecasted = model.predict(test_path, with_forecaster=True)\n        plot_results(out_forecasted, test_path, savepath=save_dir, prefix=\"forecasted_\")\n\n        out_normal = model.predict(test_path, with_forecaster=False)\n        plot_results(out_normal, test_path, savepath=save_dir, prefix=\"full_input_\")\n\n        out_forecasted.to_netcdf(save_dir / f\"preds_forecasted_{test_path.name}.nc\")\n        out_normal.to_netcdf(save_dir / f\"preds_normal_{test_path.name}.nc\")\n\n\nif __name__ == \"__main__\":\n    print(\"Starting...predict.py\")\n    kenya_crop_type_mapper()\n",
  "history_output" : "Starting...predict.py\n<generator object Path.glob at 0x7f8c9832af90>\nUsing model ../data/lightning_logs/version_8/checkpoints/epoch=165.ckpt\nGot hyper parameters:  Namespace(alpha=10, batch_size=64, cache=True, classifier_base_layers=1, classifier_dropout=0.2, classifier_vector_size=128, data_folder='../data', forecast=True, forecasting_dropout=0.2, forecasting_vector_size=256, include_geowiki=True, input_months=5, learning_rate=0.001, max_epochs=1000, multi_headed=True, noise_factor=0.1, num_global_layers=1, num_local_layers=2, patience=10, remove_b1_b10=True, upsample=True)\nPredicting 7 timesteps in the forecaster\nUsing 1 layers for the global classifier\nUsing 2 layers for the local classifier\nRunning for ../data/raw/earth_engine_plant_village_kenya/1_2019-04-22_2020-04-16.tif\nNo GPU - not using one\n  0%|          | 0/288 [00:00<?, ?it/s]\n320it [00:00, 2893.81it/s]             \n320it [00:00, 2722.55it/s]\nNo GPU - not using one\n  0%|          | 0/288 [00:00<?, ?it/s]\n320it [00:00, 8868.39it/s]             \nRunning for ../data/raw/earth_engine_plant_village_kenya/9_2019-04-22_2020-04-16.tif\nNo GPU - not using one\n  0%|          | 0/288 [00:00<?, ?it/s]\n320it [00:00, 3462.56it/s]             \nNo GPU - not using one\n  0%|          | 0/288 [00:00<?, ?it/s]\n320it [00:00, 7416.00it/s]             \nRunning for ../data/raw/earth_engine_plant_village_kenya/6_2019-04-22_2020-04-16.tif\nNo GPU - not using one\n  0%|          | 0/288 [00:00<?, ?it/s]\n320it [00:00, 3499.87it/s]             \nNo GPU - not using one\n  0%|          | 0/288 [00:00<?, ?it/s]\n320it [00:00, 8685.55it/s]             \nRunning for ../data/raw/earth_engine_plant_village_kenya/3_2019-04-22_2020-04-16.tif\nNo GPU - not using one\n  0%|          | 0/288 [00:00<?, ?it/s]\n320it [00:00, 3606.29it/s]             \nNo GPU - not using one\n  0%|          | 0/288 [00:00<?, ?it/s]\n320it [00:00, 7109.33it/s]             \nRunning for ../data/raw/earth_engine_plant_village_kenya/4_2019-04-22_2020-04-16.tif\nNo GPU - not using one\n  0%|          | 0/288 [00:00<?, ?it/s]\n320it [00:00, 3382.70it/s]             \nNo GPU - not using one\n  0%|          | 0/288 [00:00<?, ?it/s]\n320it [00:00, 8676.28it/s]             \nRunning for ../data/raw/earth_engine_plant_village_kenya/5_2019-04-22_2020-04-16.tif\nNo GPU - not using one\n  0%|          | 0/288 [00:00<?, ?it/s]\n320it [00:00, 3460.02it/s]             \nNo GPU - not using one\n  0%|          | 0/288 [00:00<?, ?it/s]\n320it [00:00, 9005.00it/s]             \nRunning for ../data/raw/earth_engine_plant_village_kenya/0_2018-04-21_2019-04-16.tif\nNo GPU - not using one\n  0%|          | 0/288 [00:00<?, ?it/s]\n320it [00:00, 3406.86it/s]             \nNo GPU - not using one\n  0%|          | 0/288 [00:00<?, ?it/s]\n320it [00:00, 8691.11it/s]             \nRunning for ../data/raw/earth_engine_plant_village_kenya/2_2019-04-22_2020-04-16.tif\nNo GPU - not using one\n  0%|          | 0/288 [00:00<?, ?it/s]\n320it [00:00, 3466.43it/s]             \nNo GPU - not using one\n  0%|          | 0/288 [00:00<?, ?it/s]\n320it [00:00, 7459.19it/s]             \nRunning for ../data/raw/earth_engine_plant_village_kenya/7_2019-04-22_2020-04-16.tif\nNo GPU - not using one\n  0%|          | 0/305 [00:00<?, ?it/s]\n320it [00:00, 3320.53it/s]             \nNo GPU - not using one\n  0%|          | 0/305 [00:00<?, ?it/s]\n320it [00:00, 8703.68it/s]             \nRunning for ../data/raw/earth_engine_plant_village_kenya/8_2019-04-22_2020-04-16.tif\nNo GPU - not using one\n  0%|          | 0/288 [00:00<?, ?it/s]\n320it [00:00, 3472.60it/s]             \nNo GPU - not using one\n  0%|          | 0/288 [00:00<?, ?it/s]\n320it [00:00, 8361.38it/s]             \n",
  "history_begin_time" : 1666167852475,
  "history_end_time" : 1666167895854,
  "history_notes" : null,
  "history_process" : "delykw",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "lr3uxgpgh2n",
  "history_input" : "from pathlib import Path\nimport sys\nimport os\n\nsys.path.append(\"..\")\n\nfrom src_models_model import Model\nfrom src_analysis import plot_results\n\n\ndef kenya_crop_type_mapper():\n    data_dir = \"../data\"\n\n    test_folder = Path(\"../data/raw/earth_engine_plant_village_kenya/\")\n    test_files = test_folder.glob(\"*.tif\")\n    print(test_files)\n\n    list_of_models = list(Path('../data/lightning_logs/').glob('version*/checkpoints/*.ckpt'))\n    latest_model_path = str(max(list_of_models, key=os.path.getctime))\n    print(f\"Using model {latest_model_path}\")\n\n    model = Model.load_from_checkpoint(latest_model_path)\n\n    for test_path in test_files:\n\n        save_dir = Path(data_dir) / \"Autoencoder\"\n        save_dir.mkdir(exist_ok=True)\n\n        print(f\"Running for {test_path}\")\n\n        savepath = save_dir / f\"preds_{test_path.name}\"\n        if savepath.exists():\n            print(\"File already generated. Skipping\")\n            continue\n\n        out_forecasted = model.predict(test_path, with_forecaster=True)\n        plot_results(out_forecasted, test_path, savepath=save_dir, prefix=\"forecasted_\")\n\n        out_normal = model.predict(test_path, with_forecaster=False)\n        plot_results(out_normal, test_path, savepath=save_dir, prefix=\"full_input_\")\n\n        out_forecasted.to_netcdf(save_dir / f\"preds_forecasted_{test_path.name}.nc\")\n        out_normal.to_netcdf(save_dir / f\"preds_normal_{test_path.name}.nc\")\n\n\nif __name__ == \"__main__\":\n    print(\"Starting...predict.py\")\n    kenya_crop_type_mapper()\n",
  "history_output" : "Traceback (most recent call last):\n  File \"scripts_predict.py\", line 7, in <module>\n    from src_models_model import Model\n  File \"/Users/jensen/gw-workspace/lr3uxgpgh2n/src_models_model.py\", line 4, in <module>\n    import xarray as xr\nModuleNotFoundError: No module named 'xarray'\n",
  "history_begin_time" : 1666167780799,
  "history_end_time" : 1666167781055,
  "history_notes" : null,
  "history_process" : "delykw",
  "host_id" : "100001",
  "indicator" : "Failed"
},{
  "history_id" : "r1bwql5j5no",
  "history_input" : "from pathlib import Path\nimport sys\nimport os\n\nsys.path.append(\"..\")\n\nfrom src_models_model import Model\nfrom src_analysis import plot_results\n\n\ndef kenya_crop_type_mapper():\n    data_dir = \"../data\"\n\n    test_folder = Path(\"../data/raw/earth_engine_plant_village_kenya/\")\n    test_files = test_folder.glob(\"*.tif\")\n    print(test_files)\n\n    list_of_models = list(Path('../data/lightning_logs/').glob('version*/checkpoints/*.ckpt'))\n    latest_model_path = str(max(list_of_models, key=os.path.getctime))\n    print(f\"Using model {latest_model_path}\")\n\n    model = Model.load_from_checkpoint(latest_model_path)\n\n    for test_path in test_files:\n\n        save_dir = Path(data_dir) / \"Autoencoder\"\n        save_dir.mkdir(exist_ok=True)\n\n        print(f\"Running for {test_path}\")\n\n        savepath = save_dir / f\"preds_{test_path.name}\"\n        if savepath.exists():\n            print(\"File already generated. Skipping\")\n            continue\n\n        out_forecasted = model.predict(test_path, with_forecaster=True)\n        plot_results(out_forecasted, test_path, savepath=save_dir, prefix=\"forecasted_\")\n\n        out_normal = model.predict(test_path, with_forecaster=False)\n        plot_results(out_normal, test_path, savepath=save_dir, prefix=\"full_input_\")\n\n        out_forecasted.to_netcdf(save_dir / f\"preds_forecasted_{test_path.name}.nc\")\n        out_normal.to_netcdf(save_dir / f\"preds_normal_{test_path.name}.nc\")\n\n\nif __name__ == \"__main__\":\n    print(\"Starting...predict.py\")\n    kenya_crop_type_mapper()\n",
  "history_output" : "Starting...predict.py\n<generator object Path.glob at 0x7ff1e855af90>\nUsing model ../data/lightning_logs/version_7/checkpoints/epoch=165.ckpt\nGot hyper parameters:  Namespace(alpha=10, batch_size=64, cache=True, classifier_base_layers=1, classifier_dropout=0.2, classifier_vector_size=128, data_folder='../data', forecast=True, forecasting_dropout=0.2, forecasting_vector_size=256, include_geowiki=True, input_months=5, learning_rate=0.001, max_epochs=1000, multi_headed=True, noise_factor=0.1, num_global_layers=1, num_local_layers=2, patience=10, remove_b1_b10=True, upsample=True)\nPredicting 7 timesteps in the forecaster\nUsing 1 layers for the global classifier\nUsing 2 layers for the local classifier\nRunning for ../data/raw/earth_engine_plant_village_kenya/1_2019-04-22_2020-04-16.tif\nNo GPU - not using one\n  0%|          | 0/288 [00:00<?, ?it/s]\n 67%|██████▋   | 192/288 [00:00<00:00, 1913.32it/s]\n320it [00:00, 2246.04it/s]                         \nNo GPU - not using one\n  0%|          | 0/288 [00:00<?, ?it/s]\n320it [00:00, 7868.41it/s]             \nRunning for ../data/raw/earth_engine_plant_village_kenya/9_2019-04-22_2020-04-16.tif\nNo GPU - not using one\n  0%|          | 0/288 [00:00<?, ?it/s]\n320it [00:00, 3399.60it/s]             \nNo GPU - not using one\n  0%|          | 0/288 [00:00<?, ?it/s]\n320it [00:00, 8509.28it/s]             \nRunning for ../data/raw/earth_engine_plant_village_kenya/6_2019-04-22_2020-04-16.tif\nNo GPU - not using one\n  0%|          | 0/288 [00:00<?, ?it/s]\n320it [00:00, 3644.61it/s]             \nNo GPU - not using one\n  0%|          | 0/288 [00:00<?, ?it/s]\n320it [00:00, 8612.37it/s]             \nRunning for ../data/raw/earth_engine_plant_village_kenya/3_2019-04-22_2020-04-16.tif\nNo GPU - not using one\n  0%|          | 0/288 [00:00<?, ?it/s]\n320it [00:00, 3446.57it/s]             \nNo GPU - not using one\n  0%|          | 0/288 [00:00<?, ?it/s]\n320it [00:00, 8336.35it/s]             \nRunning for ../data/raw/earth_engine_plant_village_kenya/4_2019-04-22_2020-04-16.tif\nNo GPU - not using one\n  0%|          | 0/288 [00:00<?, ?it/s]\n320it [00:00, 3575.91it/s]             \nNo GPU - not using one\n  0%|          | 0/288 [00:00<?, ?it/s]\n320it [00:00, 8584.11it/s]             \nRunning for ../data/raw/earth_engine_plant_village_kenya/5_2019-04-22_2020-04-16.tif\nNo GPU - not using one\n  0%|          | 0/288 [00:00<?, ?it/s]\n320it [00:00, 3480.08it/s]             \nNo GPU - not using one\n  0%|          | 0/288 [00:00<?, ?it/s]\n320it [00:00, 8389.45it/s]             \nRunning for ../data/raw/earth_engine_plant_village_kenya/0_2018-04-21_2019-04-16.tif\nNo GPU - not using one\n  0%|          | 0/288 [00:00<?, ?it/s]\n320it [00:00, 3518.07it/s]             \nNo GPU - not using one\n  0%|          | 0/288 [00:00<?, ?it/s]\n320it [00:00, 8141.66it/s]             \nRunning for ../data/raw/earth_engine_plant_village_kenya/2_2019-04-22_2020-04-16.tif\nNo GPU - not using one\n  0%|          | 0/288 [00:00<?, ?it/s]\n320it [00:00, 3267.54it/s]             \nNo GPU - not using one\n  0%|          | 0/288 [00:00<?, ?it/s]\n320it [00:00, 8142.90it/s]             \nRunning for ../data/raw/earth_engine_plant_village_kenya/7_2019-04-22_2020-04-16.tif\nNo GPU - not using one\n  0%|          | 0/305 [00:00<?, ?it/s]\n320it [00:00, 3439.08it/s]             \nNo GPU - not using one\n  0%|          | 0/305 [00:00<?, ?it/s]\n320it [00:00, 8653.74it/s]             \nRunning for ../data/raw/earth_engine_plant_village_kenya/8_2019-04-22_2020-04-16.tif\nNo GPU - not using one\n  0%|          | 0/288 [00:00<?, ?it/s]\n320it [00:00, 3428.33it/s]             \nNo GPU - not using one\n  0%|          | 0/288 [00:00<?, ?it/s]\n320it [00:00, 7093.44it/s]             \n",
  "history_begin_time" : 1666166491820,
  "history_end_time" : 1666166535277,
  "history_notes" : null,
  "history_process" : "delykw",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "vxpy5ae9q63",
  "history_input" : "from pathlib import Path\nimport sys\nimport os\n\nsys.path.append(\"..\")\n\nfrom src_models_model import Model\nfrom src_analysis import plot_results\n\n\ndef kenya_crop_type_mapper():\n    data_dir = \"../data\"\n\n    test_folder = Path(\"../data/raw/earth_engine_plant_village_kenya/\")\n    test_files = test_folder.glob(\"*.tif\")\n    print(test_files)\n\n    list_of_models = list(Path('../data/lightning_logs/').glob('version*/checkpoints/*.ckpt'))\n    latest_model_path = str(max(list_of_models, key=os.path.getctime))\n    print(f\"Using model {latest_model_path}\")\n\n    model = Model.load_from_checkpoint(latest_model_path)\n\n    for test_path in test_files:\n\n        save_dir = Path(data_dir) / \"Autoencoder\"\n        save_dir.mkdir(exist_ok=True)\n\n        print(f\"Running for {test_path}\")\n\n        savepath = save_dir / f\"preds_{test_path.name}\"\n        if savepath.exists():\n            print(\"File already generated. Skipping\")\n            continue\n\n        out_forecasted = model.predict(test_path, with_forecaster=True)\n        plot_results(out_forecasted, test_path, savepath=save_dir, prefix=\"forecasted_\")\n\n        out_normal = model.predict(test_path, with_forecaster=False)\n        plot_results(out_normal, test_path, savepath=save_dir, prefix=\"full_input_\")\n\n        out_forecasted.to_netcdf(save_dir / f\"preds_forecasted_{test_path.name}.nc\")\n        out_normal.to_netcdf(save_dir / f\"preds_normal_{test_path.name}.nc\")\n\n\nif __name__ == \"__main__\":\n    print(\"Starting...predict.py\")\n    kenya_crop_type_mapper()\n",
  "history_output" : "Starting...predict.py\n<generator object Path.glob at 0x7fd6102f9f90>\nUsing model ../data/lightning_logs/version_6/checkpoints/epoch=165.ckpt\nGot hyper parameters:  Namespace(alpha=10, batch_size=64, cache=True, classifier_base_layers=1, classifier_dropout=0.2, classifier_vector_size=128, data_folder='../data', forecast=True, forecasting_dropout=0.2, forecasting_vector_size=256, include_geowiki=True, input_months=5, learning_rate=0.001, max_epochs=1000, multi_headed=True, noise_factor=0.1, num_global_layers=1, num_local_layers=2, patience=10, remove_b1_b10=True, upsample=True)\nPredicting 7 timesteps in the forecaster\nUsing 1 layers for the global classifier\nUsing 2 layers for the local classifier\nRunning for ../data/raw/earth_engine_plant_village_kenya/1_2019-04-22_2020-04-16.tif\nNo GPU - not using one\n  0%|          | 0/288 [00:00<?, ?it/s]\n320it [00:00, 3053.05it/s]             \n320it [00:00, 2911.91it/s]\nNo GPU - not using one\n  0%|          | 0/288 [00:00<?, ?it/s]\n320it [00:00, 10407.22it/s]            \nRunning for ../data/raw/earth_engine_plant_village_kenya/9_2019-04-22_2020-04-16.tif\nNo GPU - not using one\n  0%|          | 0/288 [00:00<?, ?it/s]\n320it [00:00, 4239.24it/s]             \nNo GPU - not using one\n  0%|          | 0/288 [00:00<?, ?it/s]\n320it [00:00, 10861.85it/s]            \nRunning for ../data/raw/earth_engine_plant_village_kenya/6_2019-04-22_2020-04-16.tif\nNo GPU - not using one\n  0%|          | 0/288 [00:00<?, ?it/s]\n320it [00:00, 4453.23it/s]             \nNo GPU - not using one\n  0%|          | 0/288 [00:00<?, ?it/s]\n320it [00:00, 9214.20it/s]             \nRunning for ../data/raw/earth_engine_plant_village_kenya/3_2019-04-22_2020-04-16.tif\nNo GPU - not using one\n  0%|          | 0/288 [00:00<?, ?it/s]\n320it [00:00, 4018.33it/s]             \nNo GPU - not using one\n  0%|          | 0/288 [00:00<?, ?it/s]\n320it [00:00, 10192.72it/s]            \nRunning for ../data/raw/earth_engine_plant_village_kenya/4_2019-04-22_2020-04-16.tif\nNo GPU - not using one\n  0%|          | 0/288 [00:00<?, ?it/s]\n320it [00:00, 4351.32it/s]             \nNo GPU - not using one\n  0%|          | 0/288 [00:00<?, ?it/s]\n320it [00:00, 10866.25it/s]            \nRunning for ../data/raw/earth_engine_plant_village_kenya/5_2019-04-22_2020-04-16.tif\nNo GPU - not using one\n  0%|          | 0/288 [00:00<?, ?it/s]\n320it [00:00, 4395.13it/s]             \nNo GPU - not using one\n  0%|          | 0/288 [00:00<?, ?it/s]\n320it [00:00, 10779.16it/s]            \nRunning for ../data/raw/earth_engine_plant_village_kenya/0_2018-04-21_2019-04-16.tif\nNo GPU - not using one\n  0%|          | 0/288 [00:00<?, ?it/s]\n320it [00:00, 3903.73it/s]             \nNo GPU - not using one\n  0%|          | 0/288 [00:00<?, ?it/s]\n320it [00:00, 10693.79it/s]            \nRunning for ../data/raw/earth_engine_plant_village_kenya/2_2019-04-22_2020-04-16.tif\nNo GPU - not using one\n  0%|          | 0/288 [00:00<?, ?it/s]\n320it [00:00, 4601.79it/s]             \nNo GPU - not using one\n  0%|          | 0/288 [00:00<?, ?it/s]\n320it [00:00, 10891.38it/s]            \nRunning for ../data/raw/earth_engine_plant_village_kenya/7_2019-04-22_2020-04-16.tif\nNo GPU - not using one\n  0%|          | 0/305 [00:00<?, ?it/s]\n320it [00:00, 4232.97it/s]             \nNo GPU - not using one\n  0%|          | 0/305 [00:00<?, ?it/s]\n320it [00:00, 10331.28it/s]            \nRunning for ../data/raw/earth_engine_plant_village_kenya/8_2019-04-22_2020-04-16.tif\nNo GPU - not using one\n  0%|          | 0/288 [00:00<?, ?it/s]\n320it [00:00, 4362.41it/s]             \nNo GPU - not using one\n  0%|          | 0/288 [00:00<?, ?it/s]\n320it [00:00, 10623.53it/s]            \n",
  "history_begin_time" : 1666164256786,
  "history_end_time" : 1666164291402,
  "history_notes" : null,
  "history_process" : "delykw",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "sb50l000v6t",
  "history_input" : "from pathlib import Path\nimport sys\nimport os\n\nsys.path.append(\"..\")\n\nfrom src_models_model import Model\nfrom src_analysis import plot_results\n\n\ndef kenya_crop_type_mapper():\n    data_dir = \"../data\"\n\n    test_folder = Path(\"../data/raw/earth_engine_plant_village_kenya/\")\n    test_files = test_folder.glob(\"*.tif\")\n    print(test_files)\n\n    list_of_models = list(Path('../data/lightning_logs/').glob('version*/checkpoints/*.ckpt'))\n    latest_model_path = str(max(list_of_models, key=os.path.getctime))\n    print(f\"Using model {latest_model_path}\")\n\n    model = Model.load_from_checkpoint(latest_model_path)\n\n    for test_path in test_files:\n\n        save_dir = Path(data_dir) / \"Autoencoder\"\n        save_dir.mkdir(exist_ok=True)\n\n        print(f\"Running for {test_path}\")\n\n        savepath = save_dir / f\"preds_{test_path.name}\"\n        if savepath.exists():\n            print(\"File already generated. Skipping\")\n            continue\n\n        out_forecasted = model.predict(test_path, with_forecaster=True)\n        plot_results(out_forecasted, test_path, savepath=save_dir, prefix=\"forecasted_\")\n\n        out_normal = model.predict(test_path, with_forecaster=False)\n        plot_results(out_normal, test_path, savepath=save_dir, prefix=\"full_input_\")\n\n        out_forecasted.to_netcdf(save_dir / f\"preds_forecasted_{test_path.name}.nc\")\n        out_normal.to_netcdf(save_dir / f\"preds_normal_{test_path.name}.nc\")\n\n\nif __name__ == \"__main__\":\n    print(\"Starting...predict.py\")\n    kenya_crop_type_mapper()\n",
  "history_output" : "Starting...predict.py\n<generator object Path.glob at 0x7fab1089af90>\nUsing model ../data/lightning_logs/version_5/checkpoints/epoch=165.ckpt\nGot hyper parameters:  Namespace(alpha=10, batch_size=64, cache=True, classifier_base_layers=1, classifier_dropout=0.2, classifier_vector_size=128, data_folder='../data', forecast=True, forecasting_dropout=0.2, forecasting_vector_size=256, include_geowiki=True, input_months=5, learning_rate=0.001, max_epochs=1000, multi_headed=True, noise_factor=0.1, num_global_layers=1, num_local_layers=2, patience=10, remove_b1_b10=True, upsample=True)\nPredicting 7 timesteps in the forecaster\nUsing 1 layers for the global classifier\nUsing 2 layers for the local classifier\nRunning for ../data/raw/earth_engine_plant_village_kenya/1_2019-04-22_2020-04-16.tif\nNo GPU - not using one\n  0%|          | 0/288 [00:00<?, ?it/s]\n320it [00:00, 3489.12it/s]             \nNo GPU - not using one\n  0%|          | 0/288 [00:00<?, ?it/s]\n320it [00:00, 10302.96it/s]            \nRunning for ../data/raw/earth_engine_plant_village_kenya/9_2019-04-22_2020-04-16.tif\nNo GPU - not using one\n  0%|          | 0/288 [00:00<?, ?it/s]\n320it [00:00, 4394.40it/s]             \nNo GPU - not using one\n  0%|          | 0/288 [00:00<?, ?it/s]\n320it [00:00, 10591.51it/s]            \nRunning for ../data/raw/earth_engine_plant_village_kenya/6_2019-04-22_2020-04-16.tif\nNo GPU - not using one\n  0%|          | 0/288 [00:00<?, ?it/s]\n320it [00:00, 4070.67it/s]             \nNo GPU - not using one\n  0%|          | 0/288 [00:00<?, ?it/s]\n320it [00:00, 10883.25it/s]            \nRunning for ../data/raw/earth_engine_plant_village_kenya/3_2019-04-22_2020-04-16.tif\nNo GPU - not using one\n  0%|          | 0/288 [00:00<?, ?it/s]\n320it [00:00, 4188.10it/s]             \nNo GPU - not using one\n  0%|          | 0/288 [00:00<?, ?it/s]\n320it [00:00, 10855.53it/s]            \nRunning for ../data/raw/earth_engine_plant_village_kenya/4_2019-04-22_2020-04-16.tif\nNo GPU - not using one\n  0%|          | 0/288 [00:00<?, ?it/s]\n320it [00:00, 4510.73it/s]             \nNo GPU - not using one\n  0%|          | 0/288 [00:00<?, ?it/s]\n320it [00:00, 10404.15it/s]            \nRunning for ../data/raw/earth_engine_plant_village_kenya/5_2019-04-22_2020-04-16.tif\nNo GPU - not using one\n  0%|          | 0/288 [00:00<?, ?it/s]\n320it [00:00, 4284.82it/s]             \nNo GPU - not using one\n  0%|          | 0/288 [00:00<?, ?it/s]\n320it [00:00, 9298.01it/s]             \nRunning for ../data/raw/earth_engine_plant_village_kenya/0_2018-04-21_2019-04-16.tif\nNo GPU - not using one\n  0%|          | 0/288 [00:00<?, ?it/s]\n320it [00:00, 4272.65it/s]             \nNo GPU - not using one\n  0%|          | 0/288 [00:00<?, ?it/s]\n320it [00:00, 10640.80it/s]            \nRunning for ../data/raw/earth_engine_plant_village_kenya/2_2019-04-22_2020-04-16.tif\nNo GPU - not using one\n  0%|          | 0/288 [00:00<?, ?it/s]\n320it [00:00, 4504.45it/s]             \nNo GPU - not using one\n  0%|          | 0/288 [00:00<?, ?it/s]\n320it [00:00, 10175.18it/s]            \nRunning for ../data/raw/earth_engine_plant_village_kenya/7_2019-04-22_2020-04-16.tif\nNo GPU - not using one\n  0%|          | 0/305 [00:00<?, ?it/s]\n320it [00:00, 4248.94it/s]             \nNo GPU - not using one\n  0%|          | 0/305 [00:00<?, ?it/s]\n320it [00:00, 10929.78it/s]            \nRunning for ../data/raw/earth_engine_plant_village_kenya/8_2019-04-22_2020-04-16.tif\nNo GPU - not using one\n  0%|          | 0/288 [00:00<?, ?it/s]\n320it [00:00, 4589.74it/s]             \nNo GPU - not using one\n  0%|          | 0/288 [00:00<?, ?it/s]\n320it [00:00, 11007.23it/s]            \n",
  "history_begin_time" : 1666163632052,
  "history_end_time" : 1666163666948,
  "history_notes" : null,
  "history_process" : "delykw",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "yd09ugyegk6",
  "history_input" : "from pathlib import Path\nimport sys\nimport os\n\nsys.path.append(\"..\")\n\nfrom src_models_model import Model\nfrom src_analysis import plot_results\n\n\ndef kenya_crop_type_mapper():\n    data_dir = \"../data\"\n\n    test_folder = Path(\"../data/raw/earth_engine_plant_village_kenya/\")\n    test_files = test_folder.glob(\"*.tif\")\n    print(test_files)\n\n    list_of_models = list(Path('../data/lightning_logs/').glob('version*/checkpoints/*.ckpt'))\n    latest_model_path = str(max(list_of_models, key=os.path.getctime))\n    print(f\"Using model {latest_model_path}\")\n\n    model = Model.load_from_checkpoint(latest_model_path)\n\n    for test_path in test_files:\n\n        save_dir = Path(data_dir) / \"Autoencoder\"\n        save_dir.mkdir(exist_ok=True)\n\n        print(f\"Running for {test_path}\")\n\n        savepath = save_dir / f\"preds_{test_path.name}\"\n        if savepath.exists():\n            print(\"File already generated. Skipping\")\n            continue\n\n        out_forecasted = model.predict(test_path, with_forecaster=True)\n        plot_results(out_forecasted, test_path, savepath=save_dir, prefix=\"forecasted_\")\n\n        out_normal = model.predict(test_path, with_forecaster=False)\n        plot_results(out_normal, test_path, savepath=save_dir, prefix=\"full_input_\")\n\n        out_forecasted.to_netcdf(save_dir / f\"preds_forecasted_{test_path.name}.nc\")\n        out_normal.to_netcdf(save_dir / f\"preds_normal_{test_path.name}.nc\")\n\n\nif __name__ == \"__main__\":\n    print(\"Starting...predict.py\")\n    kenya_crop_type_mapper()\n",
  "history_output" : "Starting...predict.py\n<generator object Path.glob at 0x7f8770571f90>\nUsing model ../data/lightning_logs/version_4/checkpoints/epoch=165.ckpt\nGot hyper parameters:  Namespace(alpha=10, batch_size=64, cache=True, classifier_base_layers=1, classifier_dropout=0.2, classifier_vector_size=128, data_folder='../data', forecast=True, forecasting_dropout=0.2, forecasting_vector_size=256, include_geowiki=True, input_months=5, learning_rate=0.001, max_epochs=1000, multi_headed=True, noise_factor=0.1, num_global_layers=1, num_local_layers=2, patience=10, remove_b1_b10=True, upsample=True)\nPredicting 7 timesteps in the forecaster\nUsing 1 layers for the global classifier\nUsing 2 layers for the local classifier\nRunning for ../data/raw/earth_engine_plant_village_kenya/1_2019-04-22_2020-04-16.tif\nNo GPU - not using one\n  0%|          | 0/288 [00:00<?, ?it/s]\n320it [00:00, 3574.39it/s]             \nNo GPU - not using one\n  0%|          | 0/288 [00:00<?, ?it/s]\n320it [00:00, 10406.57it/s]            \nRunning for ../data/raw/earth_engine_plant_village_kenya/9_2019-04-22_2020-04-16.tif\nNo GPU - not using one\n  0%|          | 0/288 [00:00<?, ?it/s]\n320it [00:00, 4388.80it/s]             \nNo GPU - not using one\n  0%|          | 0/288 [00:00<?, ?it/s]\n320it [00:00, 10824.36it/s]            \nRunning for ../data/raw/earth_engine_plant_village_kenya/6_2019-04-22_2020-04-16.tif\nNo GPU - not using one\n  0%|          | 0/288 [00:00<?, ?it/s]\n320it [00:00, 4478.34it/s]             \nNo GPU - not using one\n  0%|          | 0/288 [00:00<?, ?it/s]\n320it [00:00, 10915.92it/s]            \nRunning for ../data/raw/earth_engine_plant_village_kenya/3_2019-04-22_2020-04-16.tif\nNo GPU - not using one\n  0%|          | 0/288 [00:00<?, ?it/s]\n320it [00:00, 4356.87it/s]             \nNo GPU - not using one\n  0%|          | 0/288 [00:00<?, ?it/s]\n320it [00:00, 10529.85it/s]            \nRunning for ../data/raw/earth_engine_plant_village_kenya/4_2019-04-22_2020-04-16.tif\nNo GPU - not using one\n  0%|          | 0/288 [00:00<?, ?it/s]\n320it [00:00, 4385.84it/s]             \nNo GPU - not using one\n  0%|          | 0/288 [00:00<?, ?it/s]\n320it [00:00, 10590.09it/s]            \nRunning for ../data/raw/earth_engine_plant_village_kenya/5_2019-04-22_2020-04-16.tif\nNo GPU - not using one\n  0%|          | 0/288 [00:00<?, ?it/s]\n320it [00:00, 4503.88it/s]             \nNo GPU - not using one\n  0%|          | 0/288 [00:00<?, ?it/s]\n320it [00:00, 10660.32it/s]            \nRunning for ../data/raw/earth_engine_plant_village_kenya/0_2018-04-21_2019-04-16.tif\nNo GPU - not using one\n  0%|          | 0/288 [00:00<?, ?it/s]\n320it [00:00, 4473.01it/s]             \nNo GPU - not using one\n  0%|          | 0/288 [00:00<?, ?it/s]\n320it [00:00, 11053.55it/s]            \nRunning for ../data/raw/earth_engine_plant_village_kenya/2_2019-04-22_2020-04-16.tif\nNo GPU - not using one\n  0%|          | 0/288 [00:00<?, ?it/s]\n320it [00:00, 4389.46it/s]             \nNo GPU - not using one\n  0%|          | 0/288 [00:00<?, ?it/s]\n320it [00:00, 11063.12it/s]            \nRunning for ../data/raw/earth_engine_plant_village_kenya/7_2019-04-22_2020-04-16.tif\nNo GPU - not using one\n  0%|          | 0/305 [00:00<?, ?it/s]\n320it [00:00, 4339.39it/s]             \nNo GPU - not using one\n  0%|          | 0/305 [00:00<?, ?it/s]\n320it [00:00, 10510.06it/s]            \nRunning for ../data/raw/earth_engine_plant_village_kenya/8_2019-04-22_2020-04-16.tif\nNo GPU - not using one\n  0%|          | 0/288 [00:00<?, ?it/s]\n320it [00:00, 4399.41it/s]             \nNo GPU - not using one\n  0%|          | 0/288 [00:00<?, ?it/s]\n320it [00:00, 10960.40it/s]            \n",
  "history_begin_time" : 1666137037476,
  "history_end_time" : 1666137071550,
  "history_notes" : null,
  "history_process" : "delykw",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "pjn6c5sfmms",
  "history_input" : "from pathlib import Path\nimport sys\nimport os\n\nsys.path.append(\"..\")\n\nfrom src_models_model import Model\nfrom src_analysis import plot_results\n\n\ndef kenya_crop_type_mapper():\n    data_dir = \"../data\"\n\n    test_folder = Path(\"../data/raw/earth_engine_plant_village_kenya/\")\n    test_files = test_folder.glob(\"*.tif\")\n    print(test_files)\n\n    list_of_models = list(Path('../data/lightning_logs/').glob('version*/checkpoints/*.ckpt'))\n    latest_model_path = str(max(list_of_models, key=os.path.getctime))\n    print(f\"Using model {latest_model_path}\")\n\n    model = Model.load_from_checkpoint(latest_model_path)\n\n    for test_path in test_files:\n\n        save_dir = Path(data_dir) / \"Autoencoder\"\n        save_dir.mkdir(exist_ok=True)\n\n        print(f\"Running for {test_path}\")\n\n        savepath = save_dir / f\"preds_{test_path.name}\"\n        if savepath.exists():\n            print(\"File already generated. Skipping\")\n            continue\n\n        out_forecasted = model.predict(test_path, with_forecaster=True)\n        plot_results(out_forecasted, test_path, savepath=save_dir, prefix=\"forecasted_\")\n\n        out_normal = model.predict(test_path, with_forecaster=False)\n        plot_results(out_normal, test_path, savepath=save_dir, prefix=\"full_input_\")\n\n        out_forecasted.to_netcdf(save_dir / f\"preds_forecasted_{test_path.name}.nc\")\n        out_normal.to_netcdf(save_dir / f\"preds_normal_{test_path.name}.nc\")\n\n\nif __name__ == \"__main__\":\n    print(\"Starting...predict.py\")\n    kenya_crop_type_mapper()\n",
  "history_output" : "Starting...predict.py\n<generator object Path.glob at 0x7f98b1700f90>\nUsing model ../data/lightning_logs/version_3/checkpoints/epoch=165.ckpt\nGot hyper parameters:  Namespace(alpha=10, batch_size=64, cache=True, classifier_base_layers=1, classifier_dropout=0.2, classifier_vector_size=128, data_folder='../data', forecast=True, forecasting_dropout=0.2, forecasting_vector_size=256, include_geowiki=True, input_months=5, learning_rate=0.001, max_epochs=1000, multi_headed=True, noise_factor=0.1, num_global_layers=1, num_local_layers=2, patience=10, remove_b1_b10=True, upsample=True)\nPredicting 7 timesteps in the forecaster\nUsing 1 layers for the global classifier\nUsing 2 layers for the local classifier\nRunning for ../data/raw/earth_engine_plant_village_kenya/1_2019-04-22_2020-04-16.tif\nNo GPU - not using one\n  0%|          | 0/288 [00:00<?, ?it/s]\n320it [00:00, 3814.79it/s]             \nNo GPU - not using one\n  0%|          | 0/288 [00:00<?, ?it/s]\n320it [00:00, 10779.50it/s]            \nRunning for ../data/raw/earth_engine_plant_village_kenya/9_2019-04-22_2020-04-16.tif\nNo GPU - not using one\n  0%|          | 0/288 [00:00<?, ?it/s]\n320it [00:00, 4492.24it/s]             \nNo GPU - not using one\n  0%|          | 0/288 [00:00<?, ?it/s]\n320it [00:00, 10722.06it/s]            \nRunning for ../data/raw/earth_engine_plant_village_kenya/6_2019-04-22_2020-04-16.tif\nNo GPU - not using one\n  0%|          | 0/288 [00:00<?, ?it/s]\n320it [00:00, 4330.34it/s]             \nNo GPU - not using one\n  0%|          | 0/288 [00:00<?, ?it/s]\n320it [00:00, 10513.85it/s]            \nRunning for ../data/raw/earth_engine_plant_village_kenya/3_2019-04-22_2020-04-16.tif\nNo GPU - not using one\n  0%|          | 0/288 [00:00<?, ?it/s]\n320it [00:00, 4372.18it/s]             \nNo GPU - not using one\n  0%|          | 0/288 [00:00<?, ?it/s]\n320it [00:00, 10266.32it/s]            \nRunning for ../data/raw/earth_engine_plant_village_kenya/4_2019-04-22_2020-04-16.tif\nNo GPU - not using one\n  0%|          | 0/288 [00:00<?, ?it/s]\n320it [00:00, 4395.06it/s]             \nNo GPU - not using one\n  0%|          | 0/288 [00:00<?, ?it/s]\n320it [00:00, 10685.87it/s]            \nRunning for ../data/raw/earth_engine_plant_village_kenya/5_2019-04-22_2020-04-16.tif\nNo GPU - not using one\n  0%|          | 0/288 [00:00<?, ?it/s]\n320it [00:00, 4250.45it/s]             \nNo GPU - not using one\n  0%|          | 0/288 [00:00<?, ?it/s]\n320it [00:00, 10949.22it/s]            \nRunning for ../data/raw/earth_engine_plant_village_kenya/0_2018-04-21_2019-04-16.tif\nNo GPU - not using one\n  0%|          | 0/288 [00:00<?, ?it/s]\n320it [00:00, 4494.95it/s]             \nNo GPU - not using one\n  0%|          | 0/288 [00:00<?, ?it/s]\n320it [00:00, 11112.76it/s]            \nRunning for ../data/raw/earth_engine_plant_village_kenya/2_2019-04-22_2020-04-16.tif\nNo GPU - not using one\n  0%|          | 0/288 [00:00<?, ?it/s]\n320it [00:00, 4436.69it/s]             \nNo GPU - not using one\n  0%|          | 0/288 [00:00<?, ?it/s]\n320it [00:00, 10682.38it/s]            \nRunning for ../data/raw/earth_engine_plant_village_kenya/7_2019-04-22_2020-04-16.tif\nNo GPU - not using one\n  0%|          | 0/305 [00:00<?, ?it/s]\n320it [00:00, 4274.12it/s]             \nNo GPU - not using one\n  0%|          | 0/305 [00:00<?, ?it/s]\n320it [00:00, 10696.26it/s]            \nRunning for ../data/raw/earth_engine_plant_village_kenya/8_2019-04-22_2020-04-16.tif\nNo GPU - not using one\n  0%|          | 0/288 [00:00<?, ?it/s]\n320it [00:00, 4390.42it/s]             \nNo GPU - not using one\n  0%|          | 0/288 [00:00<?, ?it/s]\n320it [00:00, 11169.73it/s]            \n",
  "history_begin_time" : 1666136616011,
  "history_end_time" : 1666136648904,
  "history_notes" : null,
  "history_process" : "delykw",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "l6CxDd0OJPv0",
  "history_input" : "from pathlib import Path\nimport sys\nimport os\n\nsys.path.append(\"..\")\n\nfrom src_models_model import Model\nfrom src_analysis import plot_results\n\n\ndef kenya_crop_type_mapper():\n    data_dir = \"../data\"\n\n    test_folder = Path(\"../data/raw/earth_engine_plant_village_kenya/\")\n    test_files = test_folder.glob(\"*.tif\")\n    print(test_files)\n\n    list_of_models = list(Path('../data/lightning_logs/').glob('version*/checkpoints/*.ckpt'))\n    latest_model_path = str(max(list_of_models, key=os.path.getctime))\n    print(f\"Using model {latest_model_path}\")\n\n    model = Model.load_from_checkpoint(latest_model_path)\n\n    for test_path in test_files:\n\n        save_dir = Path(data_dir) / \"Autoencoder\"\n        save_dir.mkdir(exist_ok=True)\n\n        print(f\"Running for {test_path}\")\n\n        savepath = save_dir / f\"preds_{test_path.name}\"\n        if savepath.exists():\n            print(\"File already generated. Skipping\")\n            continue\n\n        out_forecasted = model.predict(test_path, with_forecaster=True)\n        plot_results(out_forecasted, test_path, savepath=save_dir, prefix=\"forecasted_\")\n\n        out_normal = model.predict(test_path, with_forecaster=False)\n        plot_results(out_normal, test_path, savepath=save_dir, prefix=\"full_input_\")\n\n        out_forecasted.to_netcdf(save_dir / f\"preds_forecasted_{test_path.name}.nc\")\n        out_normal.to_netcdf(save_dir / f\"preds_normal_{test_path.name}.nc\")\n\n\nif __name__ == \"__main__\":\n    print(\"Starting...predict.py\")\n    kenya_crop_type_mapper()\n",
  "history_output" : "Starting...predict.py\n<generator object Path.glob at 0x7f8390ad2660>\nUsing model ../data/lightning_logs/version_2/checkpoints/epoch=165.ckpt\nGot hyper parameters:  Namespace(alpha=10, batch_size=64, cache=True, classifier_base_layers=1, classifier_dropout=0.2, classifier_vector_size=128, data_folder='../data', forecast=True, forecasting_dropout=0.2, forecasting_vector_size=256, include_geowiki=True, input_months=5, learning_rate=0.001, max_epochs=1000, multi_headed=True, noise_factor=0.1, num_global_layers=1, num_local_layers=2, patience=10, remove_b1_b10=True, upsample=True)\nPredicting 7 timesteps in the forecaster\nUsing 1 layers for the global classifier\nUsing 2 layers for the local classifier\nRunning for ../data/raw/earth_engine_plant_village_kenya/1_2019-04-22_2020-04-16.tif\nNo GPU - not using one\n  0%|          | 0/288 [00:00<?, ?it/s]\n320it [00:00, 3239.78it/s]             \nNo GPU - not using one\n  0%|          | 0/288 [00:00<?, ?it/s]\n320it [00:00, 10222.61it/s]            \nRunning for ../data/raw/earth_engine_plant_village_kenya/9_2019-04-22_2020-04-16.tif\nNo GPU - not using one\n  0%|          | 0/288 [00:00<?, ?it/s]\n320it [00:00, 4219.53it/s]             \nNo GPU - not using one\n  0%|          | 0/288 [00:00<?, ?it/s]\n320it [00:00, 10441.14it/s]            \nRunning for ../data/raw/earth_engine_plant_village_kenya/6_2019-04-22_2020-04-16.tif\nNo GPU - not using one\n  0%|          | 0/288 [00:00<?, ?it/s]\n320it [00:00, 4280.41it/s]             \nNo GPU - not using one\n  0%|          | 0/288 [00:00<?, ?it/s]\n320it [00:00, 10542.18it/s]            \nRunning for ../data/raw/earth_engine_plant_village_kenya/3_2019-04-22_2020-04-16.tif\nNo GPU - not using one\n  0%|          | 0/288 [00:00<?, ?it/s]\n320it [00:00, 4325.95it/s]             \nNo GPU - not using one\n  0%|          | 0/288 [00:00<?, ?it/s]\n320it [00:00, 10207.37it/s]            \nRunning for ../data/raw/earth_engine_plant_village_kenya/4_2019-04-22_2020-04-16.tif\nNo GPU - not using one\n  0%|          | 0/288 [00:00<?, ?it/s]\n320it [00:00, 4383.44it/s]             \nNo GPU - not using one\n  0%|          | 0/288 [00:00<?, ?it/s]\n320it [00:00, 10510.81it/s]            \nRunning for ../data/raw/earth_engine_plant_village_kenya/5_2019-04-22_2020-04-16.tif\nNo GPU - not using one\n  0%|          | 0/288 [00:00<?, ?it/s]\n320it [00:00, 4306.93it/s]             \nNo GPU - not using one\n  0%|          | 0/288 [00:00<?, ?it/s]\n320it [00:00, 10536.38it/s]            \nRunning for ../data/raw/earth_engine_plant_village_kenya/0_2018-04-21_2019-04-16.tif\nNo GPU - not using one\n  0%|          | 0/288 [00:00<?, ?it/s]\n320it [00:00, 4189.16it/s]             \nNo GPU - not using one\n  0%|          | 0/288 [00:00<?, ?it/s]\n320it [00:00, 10037.00it/s]            \nRunning for ../data/raw/earth_engine_plant_village_kenya/2_2019-04-22_2020-04-16.tif\nNo GPU - not using one\n  0%|          | 0/288 [00:00<?, ?it/s]\n320it [00:00, 4409.07it/s]             \nNo GPU - not using one\n  0%|          | 0/288 [00:00<?, ?it/s]\n320it [00:00, 10521.76it/s]            \nRunning for ../data/raw/earth_engine_plant_village_kenya/7_2019-04-22_2020-04-16.tif\nNo GPU - not using one\n  0%|          | 0/305 [00:00<?, ?it/s]\n320it [00:00, 4239.87it/s]             \nNo GPU - not using one\n  0%|          | 0/305 [00:00<?, ?it/s]\n320it [00:00, 9854.89it/s]             \nRunning for ../data/raw/earth_engine_plant_village_kenya/8_2019-04-22_2020-04-16.tif\nNo GPU - not using one\n  0%|          | 0/288 [00:00<?, ?it/s]\n320it [00:00, 4415.26it/s]             \nNo GPU - not using one\n  0%|          | 0/288 [00:00<?, ?it/s]\n320it [00:00, 9783.49it/s]             \n",
  "history_begin_time" : 1666136540105,
  "history_end_time" : 1666136585450,
  "history_notes" : null,
  "history_process" : "delykw",
  "host_id" : null,
  "indicator" : "Done"
},{
  "history_id" : "Mrcjj4R44NDg",
  "history_input" : "from pathlib import Path\nimport sys\nimport os\n\nsys.path.append(\"..\")\n\nfrom src_models_model import Model\nfrom src_analysis import plot_results\n\n\ndef kenya_crop_type_mapper():\n    data_dir = \"../data\"\n\n    test_folder = Path(\"../data/raw/earth_engine_plant_village_kenya/\")\n    test_files = test_folder.glob(\"*.tif\")\n    print(test_files)\n\n    list_of_models = list(Path('../data/lightning_logs/').glob('version*/checkpoints/*.ckpt'))\n    latest_model_path = str(max(list_of_models, key=os.path.getctime))\n    print(f\"Using model {latest_model_path}\")\n\n    model = Model.load_from_checkpoint(latest_model_path)\n\n    for test_path in test_files:\n\n        save_dir = Path(data_dir) / \"Autoencoder\"\n        save_dir.mkdir(exist_ok=True)\n\n        print(f\"Running for {test_path}\")\n\n        savepath = save_dir / f\"preds_{test_path.name}\"\n        if savepath.exists():\n            print(\"File already generated. Skipping\")\n            continue\n\n        out_forecasted = model.predict(test_path, with_forecaster=True)\n        plot_results(out_forecasted, test_path, savepath=save_dir, prefix=\"forecasted_\")\n\n        out_normal = model.predict(test_path, with_forecaster=False)\n        plot_results(out_normal, test_path, savepath=save_dir, prefix=\"full_input_\")\n\n        out_forecasted.to_netcdf(save_dir / f\"preds_forecasted_{test_path.name}.nc\")\n        out_normal.to_netcdf(save_dir / f\"preds_normal_{test_path.name}.nc\")\n\n\nif __name__ == \"__main__\":\n    print(\"Starting...predict.py\")\n    kenya_crop_type_mapper()\n",
  "history_output" : "Starting...predict.py\n<generator object Path.glob at 0x7fd55a184660>\nUsing model ../data/lightning_logs/version_2/checkpoints/epoch=165.ckpt\nGot hyper parameters:  Namespace(alpha=10, batch_size=64, cache=True, classifier_base_layers=1, classifier_dropout=0.2, classifier_vector_size=128, data_folder='../data', forecast=True, forecasting_dropout=0.2, forecasting_vector_size=256, include_geowiki=True, input_months=5, learning_rate=0.001, max_epochs=1000, multi_headed=True, noise_factor=0.1, num_global_layers=1, num_local_layers=2, patience=10, remove_b1_b10=True, upsample=True)\nPredicting 7 timesteps in the forecaster\nUsing 1 layers for the global classifier\nUsing 2 layers for the local classifier\nRunning for ../data/raw/earth_engine_plant_village_kenya/1_2019-04-22_2020-04-16.tif\nNo GPU - not using one\nTraceback (most recent call last):\n  File \"scripts_predict.py\", line 48, in <module>\n    kenya_crop_type_mapper()\n  File \"scripts_predict.py\", line 36, in kenya_crop_type_mapper\n    out_forecasted = model.predict(test_path, with_forecaster=True)\n  File \"/Users/jensen/gw-workspace/Mrcjj4R44NDg/src_models_model.py\", line 162, in predict\n    input_data = tif_to_np(\n  File \"/Users/jensen/gw-workspace/Mrcjj4R44NDg/src_models_utils.py\", line 34, in tif_to_np\n    x = BaseEngineer.load_tif(\n  File \"/Users/jensen/gw-workspace/Mrcjj4R44NDg/src_engineer_base.py\", line 129, in load_tif\n    da = xr.open_rasterio(filepath).rename(\"FEATURES\") / 10000\n  File \"/Users/jensen/virtualenvs/pythonProject/lib/python3.8/site-packages/xarray/backends/rasterio_.py\", line 270, in open_rasterio\n    import rasterio\nModuleNotFoundError: No module named 'rasterio'\n",
  "history_begin_time" : 1666136508578,
  "history_end_time" : 1666136512209,
  "history_notes" : null,
  "history_process" : "delykw",
  "host_id" : null,
  "indicator" : "Failed"
},{
  "history_id" : "oxtohb0ylml",
  "history_input" : "from pathlib import Path\nimport sys\nimport os\n\nsys.path.append(\"..\")\n\nfrom src_models_model import Model\nfrom src_analysis import plot_results\n\n\ndef kenya_crop_type_mapper():\n    data_dir = \"../data\"\n\n    test_folder = Path(\"../data/raw/earth_engine_plant_village_kenya/\")\n    test_files = test_folder.glob(\"*.tif\")\n    print(test_files)\n\n    list_of_models = list(Path('../data/lightning_logs/').glob('version*/checkpoints/*.ckpt'))\n    latest_model_path = str(max(list_of_models, key=os.path.getctime))\n    print(f\"Using model {latest_model_path}\")\n\n    model = Model.load_from_checkpoint(latest_model_path)\n\n    for test_path in test_files:\n\n        save_dir = Path(data_dir) / \"Autoencoder\"\n        save_dir.mkdir(exist_ok=True)\n\n        print(f\"Running for {test_path}\")\n\n        savepath = save_dir / f\"preds_{test_path.name}\"\n        if savepath.exists():\n            print(\"File already generated. Skipping\")\n            continue\n\n        out_forecasted = model.predict(test_path, with_forecaster=True)\n        plot_results(out_forecasted, test_path, savepath=save_dir, prefix=\"forecasted_\")\n\n        out_normal = model.predict(test_path, with_forecaster=False)\n        plot_results(out_normal, test_path, savepath=save_dir, prefix=\"full_input_\")\n\n        out_forecasted.to_netcdf(save_dir / f\"preds_forecasted_{test_path.name}.nc\")\n        out_normal.to_netcdf(save_dir / f\"preds_normal_{test_path.name}.nc\")\n\n\nif __name__ == \"__main__\":\n    print(\"Starting...predict.py\")\n    kenya_crop_type_mapper()\n",
  "history_output" : "Traceback (most recent call last):\n  File \"scripts_predict.py\", line 8, in <module>\n    from src_analysis import plot_results\n  File \"/Users/jensen/gw-workspace/oxtohb0ylml/src_analysis.py\", line 4, in <module>\n    import cartopy.crs as ccrs\nModuleNotFoundError: No module named 'cartopy'\n",
  "history_begin_time" : 1666136460534,
  "history_end_time" : 1666136463545,
  "history_notes" : null,
  "history_process" : "delykw",
  "host_id" : "100001",
  "indicator" : "Failed"
},{
  "history_id" : "gpcee8bn4wg",
  "history_input" : "from pathlib import Path\nimport sys\nimport os\n\nsys.path.append(\"..\")\n\nfrom src_models_model import Model\nfrom src_analysis import plot_results\n\n\ndef kenya_crop_type_mapper():\n    data_dir = \"../data\"\n\n    test_folder = Path(\"../data/raw/earth_engine_plant_village_kenya/\")\n    test_files = test_folder.glob(\"*.tif\")\n    print(test_files)\n\n    list_of_models = list(Path('../data/lightning_logs/').glob('version*/checkpoints/*.ckpt'))\n    latest_model_path = str(max(list_of_models, key=os.path.getctime))\n    print(f\"Using model {latest_model_path}\")\n\n    model = Model.load_from_checkpoint(latest_model_path)\n\n    for test_path in test_files:\n\n        save_dir = Path(data_dir) / \"Autoencoder\"\n        save_dir.mkdir(exist_ok=True)\n\n        print(f\"Running for {test_path}\")\n\n        savepath = save_dir / f\"preds_{test_path.name}\"\n        if savepath.exists():\n            print(\"File already generated. Skipping\")\n            continue\n\n        out_forecasted = model.predict(test_path, with_forecaster=True)\n        plot_results(out_forecasted, test_path, savepath=save_dir, prefix=\"forecasted_\")\n\n        out_normal = model.predict(test_path, with_forecaster=False)\n        plot_results(out_normal, test_path, savepath=save_dir, prefix=\"full_input_\")\n\n        out_forecasted.to_netcdf(save_dir / f\"preds_forecasted_{test_path.name}.nc\")\n        out_normal.to_netcdf(save_dir / f\"preds_normal_{test_path.name}.nc\")\n\n\nif __name__ == \"__main__\":\n    print(\"Starting...predict.py\")\n    kenya_crop_type_mapper()\n",
  "history_output" : "Traceback (most recent call last):\n  File \"scripts_predict.py\", line 8, in <module>\n    from src_analysis import plot_results\n  File \"/Users/jensen/gw-workspace/gpcee8bn4wg/src_analysis.py\", line 4, in <module>\n    import cartopy.crs as ccrs\nModuleNotFoundError: No module named 'cartopy'\n",
  "history_begin_time" : 1666134137404,
  "history_end_time" : 1666134141323,
  "history_notes" : null,
  "history_process" : "delykw",
  "host_id" : "100001",
  "indicator" : "Failed"
},{
  "history_id" : "6kbawmgbl2l",
  "history_input" : "from pathlib import Path\nimport sys\nimport os\n\nsys.path.append(\"..\")\n\nfrom src_models_model import Model\nfrom src_analysis import plot_results\n\n\ndef kenya_crop_type_mapper():\n    data_dir = \"../data\"\n\n    test_folder = Path(\"../data/raw/earth_engine_plant_village_kenya/\")\n    test_files = test_folder.glob(\"*.tif\")\n    print(test_files)\n\n    list_of_models = list(Path('../data/lightning_logs/').glob('version*/checkpoints/*.ckpt'))\n    latest_model_path = str(max(list_of_models, key=os.path.getctime))\n    print(f\"Using model {latest_model_path}\")\n\n    model = Model.load_from_checkpoint(latest_model_path)\n\n    for test_path in test_files:\n\n        save_dir = Path(data_dir) / \"Autoencoder\"\n        save_dir.mkdir(exist_ok=True)\n\n        print(f\"Running for {test_path}\")\n\n        savepath = save_dir / f\"preds_{test_path.name}\"\n        if savepath.exists():\n            print(\"File already generated. Skipping\")\n            continue\n\n        out_forecasted = model.predict(test_path, with_forecaster=True)\n        plot_results(out_forecasted, test_path, savepath=save_dir, prefix=\"forecasted_\")\n\n        out_normal = model.predict(test_path, with_forecaster=False)\n        plot_results(out_normal, test_path, savepath=save_dir, prefix=\"full_input_\")\n\n        out_forecasted.to_netcdf(save_dir / f\"preds_forecasted_{test_path.name}.nc\")\n        out_normal.to_netcdf(save_dir / f\"preds_normal_{test_path.name}.nc\")\n\n\nif __name__ == \"__main__\":\n    print(\"Starting...predict.py\")\n    kenya_crop_type_mapper()\n",
  "history_output" : "Traceback (most recent call last):\n  File \"scripts_predict.py\", line 7, in <module>\n    from src_models_model import Model\n  File \"/Users/jensen/gw-workspace/6kbawmgbl2l/src_models_model.py\", line 11, in <module>\n    import pytorch_lightning as pl\nModuleNotFoundError: No module named 'pytorch_lightning'\n",
  "history_begin_time" : 1666134052370,
  "history_end_time" : 1666134053513,
  "history_notes" : null,
  "history_process" : "delykw",
  "host_id" : "100001",
  "indicator" : "Failed"
},{
  "history_id" : "vye97pwnecr",
  "history_input" : "from pathlib import Path\nimport sys\nimport os\n\nsys.path.append(\"..\")\n\nfrom src_models_model import Model\nfrom src_analysis import plot_results\n\n\ndef kenya_crop_type_mapper():\n    data_dir = \"../data\"\n\n    test_folder = Path(\"../data/raw/earth_engine_plant_village_kenya/\")\n    test_files = test_folder.glob(\"*.tif\")\n    print(test_files)\n\n    list_of_models = list(Path('../data/lightning_logs/').glob('version*/checkpoints/*.ckpt'))\n    latest_model_path = str(max(list_of_models, key=os.path.getctime))\n    print(f\"Using model {latest_model_path}\")\n\n    model = Model.load_from_checkpoint(latest_model_path)\n\n    for test_path in test_files:\n\n        save_dir = Path(data_dir) / \"Autoencoder\"\n        save_dir.mkdir(exist_ok=True)\n\n        print(f\"Running for {test_path}\")\n\n        savepath = save_dir / f\"preds_{test_path.name}\"\n        if savepath.exists():\n            print(\"File already generated. Skipping\")\n            continue\n\n        out_forecasted = model.predict(test_path, with_forecaster=True)\n        plot_results(out_forecasted, test_path, savepath=save_dir, prefix=\"forecasted_\")\n\n        out_normal = model.predict(test_path, with_forecaster=False)\n        plot_results(out_normal, test_path, savepath=save_dir, prefix=\"full_input_\")\n\n        out_forecasted.to_netcdf(save_dir / f\"preds_forecasted_{test_path.name}.nc\")\n        out_normal.to_netcdf(save_dir / f\"preds_normal_{test_path.name}.nc\")\n\n\nif __name__ == \"__main__\":\n    print(\"Starting...predict.py\")\n    kenya_crop_type_mapper()\n",
  "history_output" : "Traceback (most recent call last):\n  File \"scripts_predict.py\", line 7, in <module>\n    from src_models_model import Model\n  File \"/Users/jensen/gw-workspace/vye97pwnecr/src_models_model.py\", line 4, in <module>\n    import xarray as xr\nModuleNotFoundError: No module named 'xarray'\n",
  "history_begin_time" : 1666134017561,
  "history_end_time" : 1666134017782,
  "history_notes" : null,
  "history_process" : "delykw",
  "host_id" : "100001",
  "indicator" : "Failed"
},{
  "history_id" : "pqtd91vlb98",
  "history_input" : "from pathlib import Path\nimport sys\nimport os\n\nsys.path.append(\"..\")\n\nfrom src_models_model import Model\nfrom src_analysis import plot_results\n\n\ndef kenya_crop_type_mapper():\n    data_dir = \"../data\"\n\n    test_folder = Path(\"../data/raw/earth_engine_plant_village_kenya/\")\n    test_files = test_folder.glob(\"*.tif\")\n    print(test_files)\n\n    list_of_models = list(Path('../data/lightning_logs/').glob('version*/checkpoints/*.ckpt'))\n    latest_model_path = str(max(list_of_models, key=os.path.getctime))\n    print(f\"Using model {latest_model_path}\")\n\n    model = Model.load_from_checkpoint(latest_model_path)\n\n    for test_path in test_files:\n\n        save_dir = Path(data_dir) / \"Autoencoder\"\n        save_dir.mkdir(exist_ok=True)\n\n        print(f\"Running for {test_path}\")\n\n        savepath = save_dir / f\"preds_{test_path.name}\"\n        if savepath.exists():\n            print(\"File already generated. Skipping\")\n            continue\n\n        out_forecasted = model.predict(test_path, with_forecaster=True)\n        plot_results(out_forecasted, test_path, savepath=save_dir, prefix=\"forecasted_\")\n\n        out_normal = model.predict(test_path, with_forecaster=False)\n        plot_results(out_normal, test_path, savepath=save_dir, prefix=\"full_input_\")\n\n        out_forecasted.to_netcdf(save_dir / f\"preds_forecasted_{test_path.name}.nc\")\n        out_normal.to_netcdf(save_dir / f\"preds_normal_{test_path.name}.nc\")\n\n\nif __name__ == \"__main__\":\n    print(\"Starting...predict.py\")\n    kenya_crop_type_mapper()\n",
  "history_output" : "Traceback (most recent call last):\n  File \"scripts_predict.py\", line 7, in <module>\n    from src_models_model import Model\n  File \"/Users/jensen/gw-workspace/pqtd91vlb98/src_models_model.py\", line 4, in <module>\n    import xarray as xr\nModuleNotFoundError: No module named 'xarray'\n",
  "history_begin_time" : 1666132000759,
  "history_end_time" : 1666132001011,
  "history_notes" : null,
  "history_process" : "delykw",
  "host_id" : "100001",
  "indicator" : "Failed"
},{
  "history_id" : "wlv8yvn2vf6",
  "history_input" : "from pathlib import Path\nimport sys\nimport os\n\nsys.path.append(\"..\")\n\nfrom src_models_model import Model\nfrom src_analysis import plot_results\n\n\ndef kenya_crop_type_mapper():\n    data_dir = \"../data\"\n\n    test_folder = Path(\"../data/raw/earth_engine_plant_village_kenya/\")\n    test_files = test_folder.glob(\"*.tif\")\n    print(test_files)\n\n    list_of_models = list(Path('../data/lightning_logs/').glob('version*/checkpoints/*.ckpt'))\n    latest_model_path = str(max(list_of_models, key=os.path.getctime))\n    print(f\"Using model {latest_model_path}\")\n\n    model = Model.load_from_checkpoint(latest_model_path)\n\n    for test_path in test_files:\n\n        save_dir = Path(data_dir) / \"Autoencoder\"\n        save_dir.mkdir(exist_ok=True)\n\n        print(f\"Running for {test_path}\")\n\n        savepath = save_dir / f\"preds_{test_path.name}\"\n        if savepath.exists():\n            print(\"File already generated. Skipping\")\n            continue\n\n        out_forecasted = model.predict(test_path, with_forecaster=True)\n        plot_results(out_forecasted, test_path, savepath=save_dir, prefix=\"forecasted_\")\n\n        out_normal = model.predict(test_path, with_forecaster=False)\n        plot_results(out_normal, test_path, savepath=save_dir, prefix=\"full_input_\")\n\n        out_forecasted.to_netcdf(save_dir / f\"preds_forecasted_{test_path.name}.nc\")\n        out_normal.to_netcdf(save_dir / f\"preds_normal_{test_path.name}.nc\")\n\n\nif __name__ == \"__main__\":\n    print(\"Starting...predict.py\")\n    kenya_crop_type_mapper()\n",
  "history_output" : "",
  "history_begin_time" : 1666118340036,
  "history_end_time" : 1666118344061,
  "history_notes" : null,
  "history_process" : "delykw",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "j41rcc56axe",
  "history_input" : "from pathlib import Path\nimport sys\nimport os\n\nsys.path.append(\"..\")\n\nfrom src_models_model import Model\nfrom src_analysis import plot_results\n\n\ndef kenya_crop_type_mapper():\n    data_dir = \"../data\"\n\n    test_folder = Path(\"../data/raw/earth_engine_plant_village_kenya/\")\n    test_files = test_folder.glob(\"*.tif\")\n    print(test_files)\n\n    list_of_models = list(Path('../data/lightning_logs/').glob('version*/checkpoints/*.ckpt'))\n    latest_model_path = str(max(list_of_models, key=os.path.getctime))\n    print(f\"Using model {latest_model_path}\")\n\n    model = Model.load_from_checkpoint(latest_model_path)\n\n    for test_path in test_files:\n\n        save_dir = Path(data_dir) / \"Autoencoder\"\n        save_dir.mkdir(exist_ok=True)\n\n        print(f\"Running for {test_path}\")\n\n        savepath = save_dir / f\"preds_{test_path.name}\"\n        if savepath.exists():\n            print(\"File already generated. Skipping\")\n            continue\n\n        out_forecasted = model.predict(test_path, with_forecaster=True)\n        plot_results(out_forecasted, test_path, savepath=save_dir, prefix=\"forecasted_\")\n\n        out_normal = model.predict(test_path, with_forecaster=False)\n        plot_results(out_normal, test_path, savepath=save_dir, prefix=\"full_input_\")\n\n        out_forecasted.to_netcdf(save_dir / f\"preds_forecasted_{test_path.name}.nc\")\n        out_normal.to_netcdf(save_dir / f\"preds_normal_{test_path.name}.nc\")\n\n\nif __name__ == \"__main__\":\n    print(\"Starting...predict.py\")\n    kenya_crop_type_mapper()\n",
  "history_output" : "ERROR 1: PROJ: proj_identify: /opt/anaconda3/share/proj/proj.db lacks DATABASE.LAYOUT.VERSION.MAJOR / DATABASE.LAYOUT.VERSION.MINOR metadata. It comes from another PROJ installation.\n  0%|          | 0/288 [00:00<?, ?it/s]\n 89%|████████▉ | 256/288 [00:00<00:00, 2310.06it/s]ERROR 1: PROJ: proj_identify: /opt/anaconda3/share/proj/proj.db lacks DATABASE.LAYOUT.VERSION.MAJOR / DATABASE.LAYOUT.VERSION.MINOR metadata. It comes from another PROJ installation.\n320it [00:00, 837.54it/s]                          ERROR 1: PROJ: proj_identify: /opt/anaconda3/share/proj/proj.db lacks DATABASE.LAYOUT.VERSION.MAJOR / DATABASE.LAYOUT.VERSION.MINOR metadata. It comes from another PROJ installation.\n  0%|          | 0/288 [00:00<?, ?it/s]ERROR 1: PROJ: proj_identify: /opt/anaconda3/share/proj/proj.db lacks DATABASE.LAYOUT.VERSION.MAJOR / DATABASE.LAYOUT.VERSION.MINOR metadata. It comes from another PROJ installation.\n320it [00:00, 1242.42it/s]             ERROR 1: PROJ: proj_identify: /opt/anaconda3/share/proj/proj.db lacks DATABASE.LAYOUT.VERSION.MAJOR / DATABASE.LAYOUT.VERSION.MINOR metadata. It comes from another PROJ installation.\n  0%|          | 0/288 [00:00<?, ?it/s]ERROR 1: PROJ: proj_identify: /opt/anaconda3/share/proj/proj.db lacks DATABASE.LAYOUT.VERSION.MAJOR / DATABASE.LAYOUT.VERSION.MINOR metadata. It comes from another PROJ installation.\n320it [00:00, 1037.72it/s]             ERROR 1: PROJ: proj_identify: /opt/anaconda3/share/proj/proj.db lacks DATABASE.LAYOUT.VERSION.MAJOR / DATABASE.LAYOUT.VERSION.MINOR metadata. It comes from another PROJ installation.\n  0%|          | 0/288 [00:00<?, ?it/s]ERROR 1: PROJ: proj_identify: /opt/anaconda3/share/proj/proj.db lacks DATABASE.LAYOUT.VERSION.MAJOR / DATABASE.LAYOUT.VERSION.MINOR metadata. It comes from another PROJ installation.\n320it [00:00, 1262.64it/s]             ERROR 1: PROJ: proj_identify: /opt/anaconda3/share/proj/proj.db lacks DATABASE.LAYOUT.VERSION.MAJOR / DATABASE.LAYOUT.VERSION.MINOR metadata. It comes from another PROJ installation.\n  0%|          | 0/288 [00:00<?, ?it/s]ERROR 1: PROJ: proj_identify: /opt/anaconda3/share/proj/proj.db lacks DATABASE.LAYOUT.VERSION.MAJOR / DATABASE.LAYOUT.VERSION.MINOR metadata. It comes from another PROJ installation.\n320it [00:00, 1056.46it/s]             ERROR 1: PROJ: proj_identify: /opt/anaconda3/share/proj/proj.db lacks DATABASE.LAYOUT.VERSION.MAJOR / DATABASE.LAYOUT.VERSION.MINOR metadata. It comes from another PROJ installation.\n  0%|          | 0/288 [00:00<?, ?it/s]ERROR 1: PROJ: proj_identify: /opt/anaconda3/share/proj/proj.db lacks DATABASE.LAYOUT.VERSION.MAJOR / DATABASE.LAYOUT.VERSION.MINOR metadata. It comes from another PROJ installation.\n320it [00:00, 1335.17it/s]             ERROR 1: PROJ: proj_identify: /opt/anaconda3/share/proj/proj.db lacks DATABASE.LAYOUT.VERSION.MAJOR / DATABASE.LAYOUT.VERSION.MINOR metadata. It comes from another PROJ installation.\n  0%|          | 0/288 [00:00<?, ?it/s]\n320it [00:00, 2931.06it/s]             ERROR 1: PROJ: proj_identify: /opt/anaconda3/share/proj/proj.db lacks DATABASE.LAYOUT.VERSION.MAJOR / DATABASE.LAYOUT.VERSION.MINOR metadata. It comes from another PROJ installation.\n320it [00:00, 896.97it/s] ERROR 1: PROJ: proj_identify: /opt/anaconda3/share/proj/proj.db lacks DATABASE.LAYOUT.VERSION.MAJOR / DATABASE.LAYOUT.VERSION.MINOR metadata. It comes from another PROJ installation.\n  0%|          | 0/288 [00:00<?, ?it/s]ERROR 1: PROJ: proj_identify: /opt/anaconda3/share/proj/proj.db lacks DATABASE.LAYOUT.VERSION.MAJOR / DATABASE.LAYOUT.VERSION.MINOR metadata. It comes from another PROJ installation.\n320it [00:00, 1267.80it/s]             ERROR 1: PROJ: proj_identify: /opt/anaconda3/share/proj/proj.db lacks DATABASE.LAYOUT.VERSION.MAJOR / DATABASE.LAYOUT.VERSION.MINOR metadata. It comes from another PROJ installation.\n  0%|          | 0/288 [00:00<?, ?it/s]\n320it [00:00, 3192.30it/s]             ERROR 1: PROJ: proj_identify: /opt/anaconda3/share/proj/proj.db lacks DATABASE.LAYOUT.VERSION.MAJOR / DATABASE.LAYOUT.VERSION.MINOR metadata. It comes from another PROJ installation.\n320it [00:00, 1022.72it/s]ERROR 1: PROJ: proj_identify: /opt/anaconda3/share/proj/proj.db lacks DATABASE.LAYOUT.VERSION.MAJOR / DATABASE.LAYOUT.VERSION.MINOR metadata. It comes from another PROJ installation.\n  0%|          | 0/288 [00:00<?, ?it/s]ERROR 1: PROJ: proj_identify: /opt/anaconda3/share/proj/proj.db lacks DATABASE.LAYOUT.VERSION.MAJOR / DATABASE.LAYOUT.VERSION.MINOR metadata. It comes from another PROJ installation.\n320it [00:00, 1259.57it/s]             ERROR 1: PROJ: proj_identify: /opt/anaconda3/share/proj/proj.db lacks DATABASE.LAYOUT.VERSION.MAJOR / DATABASE.LAYOUT.VERSION.MINOR metadata. It comes from another PROJ installation.\n  0%|          | 0/288 [00:00<?, ?it/s]ERROR 1: PROJ: proj_identify: /opt/anaconda3/share/proj/proj.db lacks DATABASE.LAYOUT.VERSION.MAJOR / DATABASE.LAYOUT.VERSION.MINOR metadata. It comes from another PROJ installation.\n320it [00:00, 998.95it/s]              ERROR 1: PROJ: proj_identify: /opt/anaconda3/share/proj/proj.db lacks DATABASE.LAYOUT.VERSION.MAJOR / DATABASE.LAYOUT.VERSION.MINOR metadata. It comes from another PROJ installation.\n  0%|          | 0/288 [00:00<?, ?it/s]ERROR 1: PROJ: proj_identify: /opt/anaconda3/share/proj/proj.db lacks DATABASE.LAYOUT.VERSION.MAJOR / DATABASE.LAYOUT.VERSION.MINOR metadata. It comes from another PROJ installation.\n320it [00:00, 1329.32it/s]             ERROR 1: PROJ: proj_identify: /opt/anaconda3/share/proj/proj.db lacks DATABASE.LAYOUT.VERSION.MAJOR / DATABASE.LAYOUT.VERSION.MINOR metadata. It comes from another PROJ installation.\n  0%|          | 0/288 [00:00<?, ?it/s]\n320it [00:00, 2802.27it/s]             ERROR 1: PROJ: proj_identify: /opt/anaconda3/share/proj/proj.db lacks DATABASE.LAYOUT.VERSION.MAJOR / DATABASE.LAYOUT.VERSION.MINOR metadata. It comes from another PROJ installation.\n320it [00:00, 928.57it/s] ERROR 1: PROJ: proj_identify: /opt/anaconda3/share/proj/proj.db lacks DATABASE.LAYOUT.VERSION.MAJOR / DATABASE.LAYOUT.VERSION.MINOR metadata. It comes from another PROJ installation.\n  0%|          | 0/288 [00:00<?, ?it/s]ERROR 1: PROJ: proj_identify: /opt/anaconda3/share/proj/proj.db lacks DATABASE.LAYOUT.VERSION.MAJOR / DATABASE.LAYOUT.VERSION.MINOR metadata. It comes from another PROJ installation.\n320it [00:00, 1305.04it/s]             ERROR 1: PROJ: proj_identify: /opt/anaconda3/share/proj/proj.db lacks DATABASE.LAYOUT.VERSION.MAJOR / DATABASE.LAYOUT.VERSION.MINOR metadata. It comes from another PROJ installation.\n  0%|          | 0/288 [00:00<?, ?it/s]ERROR 1: PROJ: proj_identify: /opt/anaconda3/share/proj/proj.db lacks DATABASE.LAYOUT.VERSION.MAJOR / DATABASE.LAYOUT.VERSION.MINOR metadata. It comes from another PROJ installation.\n320it [00:00, 1076.79it/s]             ERROR 1: PROJ: proj_identify: /opt/anaconda3/share/proj/proj.db lacks DATABASE.LAYOUT.VERSION.MAJOR / DATABASE.LAYOUT.VERSION.MINOR metadata. It comes from another PROJ installation.\n  0%|          | 0/288 [00:00<?, ?it/s]ERROR 1: PROJ: proj_identify: /opt/anaconda3/share/proj/proj.db lacks DATABASE.LAYOUT.VERSION.MAJOR / DATABASE.LAYOUT.VERSION.MINOR metadata. It comes from another PROJ installation.\n320it [00:00, 1378.40it/s]             ERROR 1: PROJ: proj_identify: /opt/anaconda3/share/proj/proj.db lacks DATABASE.LAYOUT.VERSION.MAJOR / DATABASE.LAYOUT.VERSION.MINOR metadata. It comes from another PROJ installation.\n  0%|          | 0/305 [00:00<?, ?it/s]\n320it [00:00, 2884.70it/s]             ERROR 1: PROJ: proj_identify: /opt/anaconda3/share/proj/proj.db lacks DATABASE.LAYOUT.VERSION.MAJOR / DATABASE.LAYOUT.VERSION.MINOR metadata. It comes from another PROJ installation.\n320it [00:00, 954.97it/s] ERROR 1: PROJ: proj_identify: /opt/anaconda3/share/proj/proj.db lacks DATABASE.LAYOUT.VERSION.MAJOR / DATABASE.LAYOUT.VERSION.MINOR metadata. It comes from another PROJ installation.\n  0%|          | 0/305 [00:00<?, ?it/s]ERROR 1: PROJ: proj_identify: /opt/anaconda3/share/proj/proj.db lacks DATABASE.LAYOUT.VERSION.MAJOR / DATABASE.LAYOUT.VERSION.MINOR metadata. It comes from another PROJ installation.\n320it [00:00, 1370.33it/s]             ERROR 1: PROJ: proj_identify: /opt/anaconda3/share/proj/proj.db lacks DATABASE.LAYOUT.VERSION.MAJOR / DATABASE.LAYOUT.VERSION.MINOR metadata. It comes from another PROJ installation.\n  0%|          | 0/288 [00:00<?, ?it/s]ERROR 1: PROJ: proj_identify: /opt/anaconda3/share/proj/proj.db lacks DATABASE.LAYOUT.VERSION.MAJOR / DATABASE.LAYOUT.VERSION.MINOR metadata. It comes from another PROJ installation.\n320it [00:00, 1015.83it/s]             ERROR 1: PROJ: proj_identify: /opt/anaconda3/share/proj/proj.db lacks DATABASE.LAYOUT.VERSION.MAJOR / DATABASE.LAYOUT.VERSION.MINOR metadata. It comes from another PROJ installation.\n  0%|          | 0/288 [00:00<?, ?it/s]ERROR 1: PROJ: proj_identify: /opt/anaconda3/share/proj/proj.db lacks DATABASE.LAYOUT.VERSION.MAJOR / DATABASE.LAYOUT.VERSION.MINOR metadata. It comes from another PROJ installation.\n320it [00:00, 1163.93it/s]             \nStarting...predict.py\n<generator object Path.glob at 0x7fb9b95a6270>\nUsing model ../data/lightning_logs/version_1/checkpoints/epoch=165.ckpt\nPredicting 7 timesteps in the forecaster\nUsing 1 layers for the global classifier\nUsing 2 layers for the local classifier\nRunning for ../data/raw/earth_engine_plant_village_kenya/1_2019-04-22_2020-04-16.tif\nNo GPU - not using one\nNo GPU - not using one\nRunning for ../data/raw/earth_engine_plant_village_kenya/9_2019-04-22_2020-04-16.tif\nNo GPU - not using one\nNo GPU - not using one\nRunning for ../data/raw/earth_engine_plant_village_kenya/6_2019-04-22_2020-04-16.tif\nNo GPU - not using one\nNo GPU - not using one\nRunning for ../data/raw/earth_engine_plant_village_kenya/3_2019-04-22_2020-04-16.tif\nNo GPU - not using one\nNo GPU - not using one\nRunning for ../data/raw/earth_engine_plant_village_kenya/4_2019-04-22_2020-04-16.tif\nNo GPU - not using one\nNo GPU - not using one\nRunning for ../data/raw/earth_engine_plant_village_kenya/5_2019-04-22_2020-04-16.tif\nNo GPU - not using one\nNo GPU - not using one\nRunning for ../data/raw/earth_engine_plant_village_kenya/0_2018-04-21_2019-04-16.tif\nNo GPU - not using one\nNo GPU - not using one\nRunning for ../data/raw/earth_engine_plant_village_kenya/2_2019-04-22_2020-04-16.tif\nNo GPU - not using one\nNo GPU - not using one\nRunning for ../data/raw/earth_engine_plant_village_kenya/7_2019-04-22_2020-04-16.tif\nNo GPU - not using one\nNo GPU - not using one\nRunning for ../data/raw/earth_engine_plant_village_kenya/8_2019-04-22_2020-04-16.tif\nNo GPU - not using one\nNo GPU - not using one\n",
  "history_begin_time" : 1655909920637,
  "history_end_time" : 1655909965527,
  "history_notes" : null,
  "history_process" : "delykw",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "vynr7p349wz",
  "history_input" : "from pathlib import Path\nimport sys\nimport os\n\nsys.path.append(\"..\")\n\nfrom src_models_model import Model\nfrom src_analysis import plot_results\n\n\ndef kenya_crop_type_mapper():\n    data_dir = \"../data\"\n\n    test_folder = Path(\"../data/raw/earth_engine_plant_village_kenya/\")\n    test_files = test_folder.glob(\"*.tif\")\n    print(test_files)\n\n    list_of_models = list(Path('../data/lightning_logs/').glob('version*/checkpoints/*.ckpt'))\n    latest_model_path = str(max(list_of_models, key=os.path.getctime))\n    print(f\"Using model {latest_model_path}\")\n\n    model = Model.load_from_checkpoint(latest_model_path)\n\n    for test_path in test_files:\n\n        save_dir = Path(data_dir) / \"Autoencoder\"\n        save_dir.mkdir(exist_ok=True)\n\n        print(f\"Running for {test_path}\")\n\n        savepath = save_dir / f\"preds_{test_path.name}\"\n        if savepath.exists():\n            print(\"File already generated. Skipping\")\n            continue\n\n        out_forecasted = model.predict(test_path, with_forecaster=True)\n        plot_results(out_forecasted, test_path, savepath=save_dir, prefix=\"forecasted_\")\n\n        out_normal = model.predict(test_path, with_forecaster=False)\n        plot_results(out_normal, test_path, savepath=save_dir, prefix=\"full_input_\")\n\n        out_forecasted.to_netcdf(save_dir / f\"preds_forecasted_{test_path.name}.nc\")\n        out_normal.to_netcdf(save_dir / f\"preds_normal_{test_path.name}.nc\")\n\n\nif __name__ == \"__main__\":\n    print(\"Starting...predict.py\")\n    kenya_crop_type_mapper()\n",
  "history_output" : "",
  "history_begin_time" : 1655908835205,
  "history_end_time" : 1655908835646,
  "history_notes" : null,
  "history_process" : "delykw",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "g29ed0i3wf0",
  "history_input" : "from pathlib import Path\nimport sys\nimport os\n\nsys.path.append(\"..\")\n\nfrom src_models_model import Model\nfrom src_analysis import plot_results\n\n\ndef kenya_crop_type_mapper():\n    data_dir = \"../data\"\n\n    test_folder = Path(\"../data/raw/earth_engine_plant_village_kenya/\")\n    test_files = test_folder.glob(\"*.tif\")\n    print(test_files)\n\n    list_of_models = list(Path('../data/lightning_logs/').glob('version*/checkpoints/*.ckpt'))\n    latest_model_path = str(max(list_of_models, key=os.path.getctime))\n    print(f\"Using model {latest_model_path}\")\n\n    model = Model.load_from_checkpoint(latest_model_path)\n\n    for test_path in test_files:\n\n        save_dir = Path(data_dir) / \"Autoencoder\"\n        save_dir.mkdir(exist_ok=True)\n\n        print(f\"Running for {test_path}\")\n\n        savepath = save_dir / f\"preds_{test_path.name}\"\n        if savepath.exists():\n            print(\"File already generated. Skipping\")\n            continue\n\n        out_forecasted = model.predict(test_path, with_forecaster=True)\n        plot_results(out_forecasted, test_path, savepath=save_dir, prefix=\"forecasted_\")\n\n        out_normal = model.predict(test_path, with_forecaster=False)\n        plot_results(out_normal, test_path, savepath=save_dir, prefix=\"full_input_\")\n\n        out_forecasted.to_netcdf(save_dir / f\"preds_forecasted_{test_path.name}.nc\")\n        out_normal.to_netcdf(save_dir / f\"preds_normal_{test_path.name}.nc\")\n\n\nif __name__ == \"__main__\":\n    print(\"Starting...predict.py\")\n    kenya_crop_type_mapper()\n",
  "history_output" : "Traceback (most recent call last):\n  File \"scripts_predict.py\", line 7, in <module>\n    from src_models_model import Model\n  File \"/Users/uhhmed/gw-workspace/g29ed0i3wf0/src_models_model.py\", line 22, in <module>\n    from src_models_data import CropDataset\n  File \"/Users/uhhmed/gw-workspace/g29ed0i3wf0/src_models_data.py\", line 4, in <module>\n    import geopandas\n  File \"/opt/anaconda3/lib/python3.8/site-packages/geopandas/__init__.py\", line 1, in <module>\n    from geopandas._config import options  # noqa\n  File \"/opt/anaconda3/lib/python3.8/site-packages/geopandas/_config.py\", line 109, in <module>\n    default_value=_default_use_pygeos(),\n  File \"/opt/anaconda3/lib/python3.8/site-packages/geopandas/_config.py\", line 95, in _default_use_pygeos\n    import geopandas._compat as compat\n  File \"/opt/anaconda3/lib/python3.8/site-packages/geopandas/_compat.py\", line 9, in <module>\n    import pyproj\n  File \"/opt/anaconda3/lib/python3.8/site-packages/pyproj/__init__.py\", line 81, in <module>\n    from pyproj.crs import CRS  # noqa: F401\n  File \"/opt/anaconda3/lib/python3.8/site-packages/pyproj/crs/__init__.py\", line 16, in <module>\n    from pyproj.crs.crs import (  # noqa: F401  pylint: disable=unused-import\n  File \"/opt/anaconda3/lib/python3.8/site-packages/pyproj/crs/crs.py\", line 13, in <module>\n    from pyproj._crs import (\nImportError: cannot import name 'AuthorityMatchInfo' from 'pyproj._crs' (/opt/anaconda3/lib/python3.8/site-packages/pyproj/_crs.cpython-38-darwin.so)\n",
  "history_begin_time" : 1655907448346,
  "history_end_time" : 1655907452386,
  "history_notes" : null,
  "history_process" : "delykw",
  "host_id" : "100001",
  "indicator" : "Failed"
},{
  "history_id" : "cwwrilhp2zc",
  "history_input" : "from pathlib import Path\nimport sys\nimport os\n\nsys.path.append(\"..\")\n\nfrom src_models_model import Model\nfrom src_analysis import plot_results\n\n\ndef kenya_crop_type_mapper():\n    data_dir = \"../data\"\n\n    test_folder = Path(\"../data/raw/earth_engine_plant_village_kenya/\")\n    test_files = test_folder.glob(\"*.tif\")\n    print(test_files)\n\n    list_of_models = list(Path('../data/lightning_logs/').glob('version*/checkpoints/*.ckpt'))\n    latest_model_path = str(max(list_of_models, key=os.path.getctime))\n    print(f\"Using model {latest_model_path}\")\n\n    model = Model.load_from_checkpoint(latest_model_path)\n\n    for test_path in test_files:\n\n        save_dir = Path(data_dir) / \"Autoencoder\"\n        save_dir.mkdir(exist_ok=True)\n\n        print(f\"Running for {test_path}\")\n\n        savepath = save_dir / f\"preds_{test_path.name}\"\n        if savepath.exists():\n            print(\"File already generated. Skipping\")\n            continue\n\n        out_forecasted = model.predict(test_path, with_forecaster=True)\n        plot_results(out_forecasted, test_path, savepath=save_dir, prefix=\"forecasted_\")\n\n        out_normal = model.predict(test_path, with_forecaster=False)\n        plot_results(out_normal, test_path, savepath=save_dir, prefix=\"full_input_\")\n\n        out_forecasted.to_netcdf(save_dir / f\"preds_forecasted_{test_path.name}.nc\")\n        out_normal.to_netcdf(save_dir / f\"preds_normal_{test_path.name}.nc\")\n\n\nif __name__ == \"__main__\":\n    print(\"Starting...predict.py\")\n    kenya_crop_type_mapper()\n",
  "history_output" : "",
  "history_begin_time" : 1655907401758,
  "history_end_time" : 1655907403095,
  "history_notes" : null,
  "history_process" : "delykw",
  "host_id" : "100001",
  "indicator" : "Stopped"
},{
  "history_id" : "oc2cz4tckqy",
  "history_input" : "from pathlib import Path\nimport sys\nimport os\n\nsys.path.append(\"..\")\n\nfrom src_models_model import Model\nfrom src_analysis import plot_results\n\n\ndef kenya_crop_type_mapper():\n    data_dir = \"../data\"\n\n    test_folder = Path(\"../data/raw/earth_engine_plant_village_kenya/\")\n    test_files = test_folder.glob(\"*.tif\")\n    print(test_files)\n\n    list_of_models = list(Path('../data/lightning_logs/').glob('version*/checkpoints/*.ckpt'))\n    latest_model_path = str(max(list_of_models, key=os.path.getctime))\n    print(f\"Using model {latest_model_path}\")\n\n    model = Model.load_from_checkpoint(latest_model_path)\n\n    for test_path in test_files:\n\n        save_dir = Path(data_dir) / \"Autoencoder\"\n        save_dir.mkdir(exist_ok=True)\n\n        print(f\"Running for {test_path}\")\n\n        savepath = save_dir / f\"preds_{test_path.name}\"\n        if savepath.exists():\n            print(\"File already generated. Skipping\")\n            continue\n\n        out_forecasted = model.predict(test_path, with_forecaster=True)\n        plot_results(out_forecasted, test_path, savepath=save_dir, prefix=\"forecasted_\")\n\n        out_normal = model.predict(test_path, with_forecaster=False)\n        plot_results(out_normal, test_path, savepath=save_dir, prefix=\"full_input_\")\n\n        out_forecasted.to_netcdf(save_dir / f\"preds_forecasted_{test_path.name}.nc\")\n        out_normal.to_netcdf(save_dir / f\"preds_normal_{test_path.name}.nc\")\n\n\nif __name__ == \"__main__\":\n    print(\"Starting...predict.py\")\n    kenya_crop_type_mapper()\n",
  "history_output" : "Traceback (most recent call last):\n  File \"scripts_predict.py\", line 7, in <module>\n    from src_models_model import Model\n  File \"/Users/uhhmed/gw-workspace/oc2cz4tckqy/src_models_model.py\", line 3, in <module>\n    import numpy as np\nModuleNotFoundError: No module named 'numpy'\n",
  "history_begin_time" : 1655865866275,
  "history_end_time" : 1655865866462,
  "history_notes" : null,
  "history_process" : "delykw",
  "host_id" : "100001",
  "indicator" : "Failed"
},{
  "history_id" : "nqk6y1y3gg2",
  "history_input" : "from pathlib import Path\nimport sys\nimport os\n\nsys.path.append(\"..\")\n\nfrom src_models_model import Model\nfrom src_analysis import plot_results\n\n\ndef kenya_crop_type_mapper():\n    data_dir = \"../data\"\n\n    test_folder = Path(\"../data/raw/earth_engine_plant_village_kenya/\")\n    test_files = test_folder.glob(\"*.tif\")\n    print(test_files)\n\n    list_of_models = list(Path('../data/lightning_logs/').glob('version*/checkpoints/*.ckpt'))\n    latest_model_path = str(max(list_of_models, key=os.path.getctime))\n    print(f\"Using model {latest_model_path}\")\n\n    model = Model.load_from_checkpoint(latest_model_path)\n\n    for test_path in test_files:\n\n        save_dir = Path(data_dir) / \"Autoencoder\"\n        save_dir.mkdir(exist_ok=True)\n\n        print(f\"Running for {test_path}\")\n\n        savepath = save_dir / f\"preds_{test_path.name}\"\n        if savepath.exists():\n            print(\"File already generated. Skipping\")\n            continue\n\n        out_forecasted = model.predict(test_path, with_forecaster=True)\n        plot_results(out_forecasted, test_path, savepath=save_dir, prefix=\"forecasted_\")\n\n        out_normal = model.predict(test_path, with_forecaster=False)\n        plot_results(out_normal, test_path, savepath=save_dir, prefix=\"full_input_\")\n\n        out_forecasted.to_netcdf(save_dir / f\"preds_forecasted_{test_path.name}.nc\")\n        out_normal.to_netcdf(save_dir / f\"preds_normal_{test_path.name}.nc\")\n\n\nif __name__ == \"__main__\":\n    print(\"Starting...predict.py\")\n    kenya_crop_type_mapper()\n",
  "history_output" : "Traceback (most recent call last):\n  File \"scripts_predict.py\", line 7, in <module>\n    from src_models_model import Model\n  File \"/Users/uhhmed/gw-workspace/nqk6y1y3gg2/src_models_model.py\", line 22, in <module>\n    from src_models_data import CropDataset\n  File \"/Users/uhhmed/gw-workspace/nqk6y1y3gg2/src_models_data.py\", line 4, in <module>\n    import geopandas\n  File \"/opt/anaconda3/lib/python3.8/site-packages/geopandas/__init__.py\", line 1, in <module>\n    from geopandas._config import options  # noqa\n  File \"/opt/anaconda3/lib/python3.8/site-packages/geopandas/_config.py\", line 109, in <module>\n    default_value=_default_use_pygeos(),\n  File \"/opt/anaconda3/lib/python3.8/site-packages/geopandas/_config.py\", line 95, in _default_use_pygeos\n    import geopandas._compat as compat\n  File \"/opt/anaconda3/lib/python3.8/site-packages/geopandas/_compat.py\", line 9, in <module>\n    import pyproj\n  File \"/opt/anaconda3/lib/python3.8/site-packages/pyproj/__init__.py\", line 81, in <module>\n    from pyproj.crs import CRS  # noqa: F401\n  File \"/opt/anaconda3/lib/python3.8/site-packages/pyproj/crs/__init__.py\", line 16, in <module>\n    from pyproj.crs.crs import (  # noqa: F401  pylint: disable=unused-import\n  File \"/opt/anaconda3/lib/python3.8/site-packages/pyproj/crs/crs.py\", line 13, in <module>\n    from pyproj._crs import (\nImportError: cannot import name 'AuthorityMatchInfo' from 'pyproj._crs' (/opt/anaconda3/lib/python3.8/site-packages/pyproj/_crs.cpython-38-darwin.so)\n",
  "history_begin_time" : 1655865101703,
  "history_end_time" : 1655865106413,
  "history_notes" : null,
  "history_process" : "delykw",
  "host_id" : "100001",
  "indicator" : "Failed"
},{
  "history_id" : "o6esrks4ou6",
  "history_input" : "from pathlib import Path\nimport sys\nimport os\n\nsys.path.append(\"..\")\n\nfrom src_models_model import Model\nfrom src_analysis import plot_results\n\n\ndef kenya_crop_type_mapper():\n    data_dir = \"../data\"\n\n    test_folder = Path(\"../data/raw/earth_engine_plant_village_kenya/\")\n    test_files = test_folder.glob(\"*.tif\")\n    print(test_files)\n\n    list_of_models = list(Path('../data/lightning_logs/').glob('version*/checkpoints/*.ckpt'))\n    latest_model_path = str(max(list_of_models, key=os.path.getctime))\n    print(f\"Using model {latest_model_path}\")\n\n    model = Model.load_from_checkpoint(latest_model_path)\n\n    for test_path in test_files:\n\n        save_dir = Path(data_dir) / \"Autoencoder\"\n        save_dir.mkdir(exist_ok=True)\n\n        print(f\"Running for {test_path}\")\n\n        savepath = save_dir / f\"preds_{test_path.name}\"\n        if savepath.exists():\n            print(\"File already generated. Skipping\")\n            continue\n\n        out_forecasted = model.predict(test_path, with_forecaster=True)\n        plot_results(out_forecasted, test_path, savepath=save_dir, prefix=\"forecasted_\")\n\n        out_normal = model.predict(test_path, with_forecaster=False)\n        plot_results(out_normal, test_path, savepath=save_dir, prefix=\"full_input_\")\n\n        out_forecasted.to_netcdf(save_dir / f\"preds_forecasted_{test_path.name}.nc\")\n        out_normal.to_netcdf(save_dir / f\"preds_normal_{test_path.name}.nc\")\n\n\nif __name__ == \"__main__\":\n    print(\"Starting...predict.py\")\n    kenya_crop_type_mapper()\n",
  "history_output" : "",
  "history_begin_time" : 1647347437345,
  "history_end_time" : 1647347437804,
  "history_notes" : null,
  "history_process" : "delykw",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "zo7yx9dkkh5",
  "history_input" : "from pathlib import Path\nimport sys\nimport os\n\nsys.path.append(\"..\")\n\nfrom src_models_model import Model\nfrom src_analysis import plot_results\n\n\ndef kenya_crop_type_mapper():\n    data_dir = \"../data\"\n\n    test_folder = Path(\"../data/raw/earth_engine_plant_village_kenya/\")\n    test_files = test_folder.glob(\"*.tif\")\n    print(test_files)\n\n    list_of_models = list(Path('../data/lightning_logs/').glob('version*/checkpoints/*.ckpt'))\n    latest_model_path = str(max(list_of_models, key=os.path.getctime))\n    print(f\"Using model {latest_model_path}\")\n\n    model = Model.load_from_checkpoint(latest_model_path)\n\n    for test_path in test_files:\n\n        save_dir = Path(data_dir) / \"Autoencoder\"\n        save_dir.mkdir(exist_ok=True)\n\n        print(f\"Running for {test_path}\")\n\n        savepath = save_dir / f\"preds_{test_path.name}\"\n        if savepath.exists():\n            print(\"File already generated. Skipping\")\n            continue\n\n        out_forecasted = model.predict(test_path, with_forecaster=True)\n        plot_results(out_forecasted, test_path, savepath=save_dir, prefix=\"forecasted_\")\n\n        out_normal = model.predict(test_path, with_forecaster=False)\n        plot_results(out_normal, test_path, savepath=save_dir, prefix=\"full_input_\")\n\n        out_forecasted.to_netcdf(save_dir / f\"preds_forecasted_{test_path.name}.nc\")\n        out_normal.to_netcdf(save_dir / f\"preds_normal_{test_path.name}.nc\")\n\n\nif __name__ == \"__main__\":\n    print(\"Starting...predict.py\")\n    kenya_crop_type_mapper()\n",
  "history_output" : "ERROR 1: PROJ: proj_identify: /opt/anaconda3/share/proj/proj.db lacks DATABASE.LAYOUT.VERSION.MAJOR / DATABASE.LAYOUT.VERSION.MINOR metadata. It comes from another PROJ installation.\n  0%|          | 0/288 [00:00<?, ?it/s]ERROR 1: PROJ: proj_identify: /opt/anaconda3/share/proj/proj.db lacks DATABASE.LAYOUT.VERSION.MAJOR / DATABASE.LAYOUT.VERSION.MINOR metadata. It comes from another PROJ installation.\n320it [00:00, 974.60it/s]              ERROR 1: PROJ: proj_identify: /opt/anaconda3/share/proj/proj.db lacks DATABASE.LAYOUT.VERSION.MAJOR / DATABASE.LAYOUT.VERSION.MINOR metadata. It comes from another PROJ installation.\n  0%|          | 0/288 [00:00<?, ?it/s]ERROR 1: PROJ: proj_identify: /opt/anaconda3/share/proj/proj.db lacks DATABASE.LAYOUT.VERSION.MAJOR / DATABASE.LAYOUT.VERSION.MINOR metadata. It comes from another PROJ installation.\n320it [00:00, 1507.58it/s]             ERROR 1: PROJ: proj_identify: /opt/anaconda3/share/proj/proj.db lacks DATABASE.LAYOUT.VERSION.MAJOR / DATABASE.LAYOUT.VERSION.MINOR metadata. It comes from another PROJ installation.\n  0%|          | 0/288 [00:00<?, ?it/s]ERROR 1: PROJ: proj_identify: /opt/anaconda3/share/proj/proj.db lacks DATABASE.LAYOUT.VERSION.MAJOR / DATABASE.LAYOUT.VERSION.MINOR metadata. It comes from another PROJ installation.\n320it [00:00, 1172.59it/s]             ERROR 1: PROJ: proj_identify: /opt/anaconda3/share/proj/proj.db lacks DATABASE.LAYOUT.VERSION.MAJOR / DATABASE.LAYOUT.VERSION.MINOR metadata. It comes from another PROJ installation.\n  0%|          | 0/288 [00:00<?, ?it/s]ERROR 1: PROJ: proj_identify: /opt/anaconda3/share/proj/proj.db lacks DATABASE.LAYOUT.VERSION.MAJOR / DATABASE.LAYOUT.VERSION.MINOR metadata. It comes from another PROJ installation.\n320it [00:00, 1608.04it/s]             ERROR 1: PROJ: proj_identify: /opt/anaconda3/share/proj/proj.db lacks DATABASE.LAYOUT.VERSION.MAJOR / DATABASE.LAYOUT.VERSION.MINOR metadata. It comes from another PROJ installation.\n  0%|          | 0/288 [00:00<?, ?it/s]ERROR 1: PROJ: proj_identify: /opt/anaconda3/share/proj/proj.db lacks DATABASE.LAYOUT.VERSION.MAJOR / DATABASE.LAYOUT.VERSION.MINOR metadata. It comes from another PROJ installation.\n320it [00:00, 1383.68it/s]             ERROR 1: PROJ: proj_identify: /opt/anaconda3/share/proj/proj.db lacks DATABASE.LAYOUT.VERSION.MAJOR / DATABASE.LAYOUT.VERSION.MINOR metadata. It comes from another PROJ installation.\n  0%|          | 0/288 [00:00<?, ?it/s]ERROR 1: PROJ: proj_identify: /opt/anaconda3/share/proj/proj.db lacks DATABASE.LAYOUT.VERSION.MAJOR / DATABASE.LAYOUT.VERSION.MINOR metadata. It comes from another PROJ installation.\n320it [00:00, 1707.96it/s]             ERROR 1: PROJ: proj_identify: /opt/anaconda3/share/proj/proj.db lacks DATABASE.LAYOUT.VERSION.MAJOR / DATABASE.LAYOUT.VERSION.MINOR metadata. It comes from another PROJ installation.\n  0%|          | 0/288 [00:00<?, ?it/s]ERROR 1: PROJ: proj_identify: /opt/anaconda3/share/proj/proj.db lacks DATABASE.LAYOUT.VERSION.MAJOR / DATABASE.LAYOUT.VERSION.MINOR metadata. It comes from another PROJ installation.\n320it [00:00, 1350.56it/s]             ERROR 1: PROJ: proj_identify: /opt/anaconda3/share/proj/proj.db lacks DATABASE.LAYOUT.VERSION.MAJOR / DATABASE.LAYOUT.VERSION.MINOR metadata. It comes from another PROJ installation.\n  0%|          | 0/288 [00:00<?, ?it/s]ERROR 1: PROJ: proj_identify: /opt/anaconda3/share/proj/proj.db lacks DATABASE.LAYOUT.VERSION.MAJOR / DATABASE.LAYOUT.VERSION.MINOR metadata. It comes from another PROJ installation.\n320it [00:00, 1698.12it/s]             ERROR 1: PROJ: proj_identify: /opt/anaconda3/share/proj/proj.db lacks DATABASE.LAYOUT.VERSION.MAJOR / DATABASE.LAYOUT.VERSION.MINOR metadata. It comes from another PROJ installation.\n  0%|          | 0/288 [00:00<?, ?it/s]ERROR 1: PROJ: proj_identify: /opt/anaconda3/share/proj/proj.db lacks DATABASE.LAYOUT.VERSION.MAJOR / DATABASE.LAYOUT.VERSION.MINOR metadata. It comes from another PROJ installation.\n320it [00:00, 1180.29it/s]             ERROR 1: PROJ: proj_identify: /opt/anaconda3/share/proj/proj.db lacks DATABASE.LAYOUT.VERSION.MAJOR / DATABASE.LAYOUT.VERSION.MINOR metadata. It comes from another PROJ installation.\n  0%|          | 0/288 [00:00<?, ?it/s]ERROR 1: PROJ: proj_identify: /opt/anaconda3/share/proj/proj.db lacks DATABASE.LAYOUT.VERSION.MAJOR / DATABASE.LAYOUT.VERSION.MINOR metadata. It comes from another PROJ installation.\n320it [00:00, 1642.95it/s]             ERROR 1: PROJ: proj_identify: /opt/anaconda3/share/proj/proj.db lacks DATABASE.LAYOUT.VERSION.MAJOR / DATABASE.LAYOUT.VERSION.MINOR metadata. It comes from another PROJ installation.\n  0%|          | 0/288 [00:00<?, ?it/s]ERROR 1: PROJ: proj_identify: /opt/anaconda3/share/proj/proj.db lacks DATABASE.LAYOUT.VERSION.MAJOR / DATABASE.LAYOUT.VERSION.MINOR metadata. It comes from another PROJ installation.\n320it [00:00, 1286.87it/s]             ERROR 1: PROJ: proj_identify: /opt/anaconda3/share/proj/proj.db lacks DATABASE.LAYOUT.VERSION.MAJOR / DATABASE.LAYOUT.VERSION.MINOR metadata. It comes from another PROJ installation.\n  0%|          | 0/288 [00:00<?, ?it/s]ERROR 1: PROJ: proj_identify: /opt/anaconda3/share/proj/proj.db lacks DATABASE.LAYOUT.VERSION.MAJOR / DATABASE.LAYOUT.VERSION.MINOR metadata. It comes from another PROJ installation.\n320it [00:00, 1794.26it/s]             ERROR 1: PROJ: proj_identify: /opt/anaconda3/share/proj/proj.db lacks DATABASE.LAYOUT.VERSION.MAJOR / DATABASE.LAYOUT.VERSION.MINOR metadata. It comes from another PROJ installation.\n  0%|          | 0/288 [00:00<?, ?it/s]ERROR 1: PROJ: proj_identify: /opt/anaconda3/share/proj/proj.db lacks DATABASE.LAYOUT.VERSION.MAJOR / DATABASE.LAYOUT.VERSION.MINOR metadata. It comes from another PROJ installation.\n320it [00:00, 1402.01it/s]             ERROR 1: PROJ: proj_identify: /opt/anaconda3/share/proj/proj.db lacks DATABASE.LAYOUT.VERSION.MAJOR / DATABASE.LAYOUT.VERSION.MINOR metadata. It comes from another PROJ installation.\n  0%|          | 0/288 [00:00<?, ?it/s]ERROR 1: PROJ: proj_identify: /opt/anaconda3/share/proj/proj.db lacks DATABASE.LAYOUT.VERSION.MAJOR / DATABASE.LAYOUT.VERSION.MINOR metadata. It comes from another PROJ installation.\n320it [00:00, 1809.06it/s]             ERROR 1: PROJ: proj_identify: /opt/anaconda3/share/proj/proj.db lacks DATABASE.LAYOUT.VERSION.MAJOR / DATABASE.LAYOUT.VERSION.MINOR metadata. It comes from another PROJ installation.\n  0%|          | 0/288 [00:00<?, ?it/s]ERROR 1: PROJ: proj_identify: /opt/anaconda3/share/proj/proj.db lacks DATABASE.LAYOUT.VERSION.MAJOR / DATABASE.LAYOUT.VERSION.MINOR metadata. It comes from another PROJ installation.\n320it [00:00, 1256.67it/s]             ERROR 1: PROJ: proj_identify: /opt/anaconda3/share/proj/proj.db lacks DATABASE.LAYOUT.VERSION.MAJOR / DATABASE.LAYOUT.VERSION.MINOR metadata. It comes from another PROJ installation.\n  0%|          | 0/288 [00:00<?, ?it/s]ERROR 1: PROJ: proj_identify: /opt/anaconda3/share/proj/proj.db lacks DATABASE.LAYOUT.VERSION.MAJOR / DATABASE.LAYOUT.VERSION.MINOR metadata. It comes from another PROJ installation.\n320it [00:00, 1634.24it/s]             ERROR 1: PROJ: proj_identify: /opt/anaconda3/share/proj/proj.db lacks DATABASE.LAYOUT.VERSION.MAJOR / DATABASE.LAYOUT.VERSION.MINOR metadata. It comes from another PROJ installation.\n  0%|          | 0/305 [00:00<?, ?it/s]ERROR 1: PROJ: proj_identify: /opt/anaconda3/share/proj/proj.db lacks DATABASE.LAYOUT.VERSION.MAJOR / DATABASE.LAYOUT.VERSION.MINOR metadata. It comes from another PROJ installation.\n320it [00:00, 1279.74it/s]             ERROR 1: PROJ: proj_identify: /opt/anaconda3/share/proj/proj.db lacks DATABASE.LAYOUT.VERSION.MAJOR / DATABASE.LAYOUT.VERSION.MINOR metadata. It comes from another PROJ installation.\n  0%|          | 0/305 [00:00<?, ?it/s]ERROR 1: PROJ: proj_identify: /opt/anaconda3/share/proj/proj.db lacks DATABASE.LAYOUT.VERSION.MAJOR / DATABASE.LAYOUT.VERSION.MINOR metadata. It comes from another PROJ installation.\n320it [00:00, 1703.46it/s]             ERROR 1: PROJ: proj_identify: /opt/anaconda3/share/proj/proj.db lacks DATABASE.LAYOUT.VERSION.MAJOR / DATABASE.LAYOUT.VERSION.MINOR metadata. It comes from another PROJ installation.\n  0%|          | 0/288 [00:00<?, ?it/s]ERROR 1: PROJ: proj_identify: /opt/anaconda3/share/proj/proj.db lacks DATABASE.LAYOUT.VERSION.MAJOR / DATABASE.LAYOUT.VERSION.MINOR metadata. It comes from another PROJ installation.\n320it [00:00, 1245.74it/s]             ERROR 1: PROJ: proj_identify: /opt/anaconda3/share/proj/proj.db lacks DATABASE.LAYOUT.VERSION.MAJOR / DATABASE.LAYOUT.VERSION.MINOR metadata. It comes from another PROJ installation.\n  0%|          | 0/288 [00:00<?, ?it/s]ERROR 1: PROJ: proj_identify: /opt/anaconda3/share/proj/proj.db lacks DATABASE.LAYOUT.VERSION.MAJOR / DATABASE.LAYOUT.VERSION.MINOR metadata. It comes from another PROJ installation.\n320it [00:00, 1615.48it/s]             \nStarting...predict.py\n<generator object Path.glob at 0x7fbdc3a9e120>\nUsing model ../data/lightning_logs/version_0/checkpoints/epoch=165.ckpt\nPredicting 7 timesteps in the forecaster\nUsing 1 layers for the global classifier\nUsing 2 layers for the local classifier\nRunning for ../data/raw/earth_engine_plant_village_kenya/1_2019-04-22_2020-04-16.tif\nNo GPU - not using one\nNo GPU - not using one\nRunning for ../data/raw/earth_engine_plant_village_kenya/9_2019-04-22_2020-04-16.tif\nNo GPU - not using one\nNo GPU - not using one\nRunning for ../data/raw/earth_engine_plant_village_kenya/6_2019-04-22_2020-04-16.tif\nNo GPU - not using one\nNo GPU - not using one\nRunning for ../data/raw/earth_engine_plant_village_kenya/3_2019-04-22_2020-04-16.tif\nNo GPU - not using one\nNo GPU - not using one\nRunning for ../data/raw/earth_engine_plant_village_kenya/4_2019-04-22_2020-04-16.tif\nNo GPU - not using one\nNo GPU - not using one\nRunning for ../data/raw/earth_engine_plant_village_kenya/5_2019-04-22_2020-04-16.tif\nNo GPU - not using one\nNo GPU - not using one\nRunning for ../data/raw/earth_engine_plant_village_kenya/0_2018-04-21_2019-04-16.tif\nNo GPU - not using one\nNo GPU - not using one\nRunning for ../data/raw/earth_engine_plant_village_kenya/2_2019-04-22_2020-04-16.tif\nNo GPU - not using one\nNo GPU - not using one\nRunning for ../data/raw/earth_engine_plant_village_kenya/7_2019-04-22_2020-04-16.tif\nNo GPU - not using one\nNo GPU - not using one\nRunning for ../data/raw/earth_engine_plant_village_kenya/8_2019-04-22_2020-04-16.tif\nNo GPU - not using one\nNo GPU - not using one\n",
  "history_begin_time" : 1647347368199,
  "history_end_time" : 1647347399926,
  "history_notes" : null,
  "history_process" : "delykw",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "8e4g0k2h6tg",
  "history_input" : "from pathlib import Path\nimport sys\nimport os\n\nsys.path.append(\"..\")\n\nfrom src_models_model import Model\nfrom src_analysis import plot_results\n\n\ndef kenya_crop_type_mapper():\n    data_dir = \"../data\"\n\n    test_folder = Path(\"../data/raw/earth_engine_plant_village_kenya/\")\n    test_files = test_folder.glob(\"*.tif\")\n    print(test_files)\n\n    list_of_models = list(Path('../data/lightning_logs/').glob('version*/checkpoints/*.ckpt'))\n    latest_model_path = str(max(list_of_models, key=os.path.getctime))\n    print(f\"Using model {latest_model_path}\")\n\n    model = Model.load_from_checkpoint(latest_model_path)\n\n    for test_path in test_files:\n\n        save_dir = Path(data_dir) / \"Autoencoder\"\n        save_dir.mkdir(exist_ok=True)\n\n        print(f\"Running for {test_path}\")\n\n        savepath = save_dir / f\"preds_{test_path.name}\"\n        if savepath.exists():\n            print(\"File already generated. Skipping\")\n            continue\n\n        out_forecasted = model.predict(test_path, with_forecaster=True)\n        plot_results(out_forecasted, test_path, savepath=save_dir, prefix=\"forecasted_\")\n\n        out_normal = model.predict(test_path, with_forecaster=False)\n        plot_results(out_normal, test_path, savepath=save_dir, prefix=\"full_input_\")\n\n        out_forecasted.to_netcdf(save_dir / f\"preds_forecasted_{test_path.name}.nc\")\n        out_normal.to_netcdf(save_dir / f\"preds_normal_{test_path.name}.nc\")\n\n\nif __name__ == \"__main__\":\n    print(\"Starting...predict.py\")\n    kenya_crop_type_mapper()\n",
  "history_output" : "Starting...predict.py\n<generator object Path.glob at 0x7fcadba9e120>\nTraceback (most recent call last):\n  File \"scripts_predict.py\", line 48, in <module>\n    kenya_crop_type_mapper()\n  File \"scripts_predict.py\", line 19, in kenya_crop_type_mapper\n    latest_model_path = str(max(list_of_models, key=os.path.getctime))\nValueError: max() arg is an empty sequence\n",
  "history_begin_time" : 1647347280272,
  "history_end_time" : 1647347284366,
  "history_notes" : null,
  "history_process" : "delykw",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "kgglgxya5xw",
  "history_input" : "from pathlib import Path\nimport sys\nimport os\n\nsys.path.append(\"..\")\n\nfrom src_models_model import Model\nfrom src_analysis import plot_results\n\n\ndef kenya_crop_type_mapper():\n    data_dir = \"../data\"\n\n    test_folder = Path(\"../data/raw/earth_engine_plant_village_kenya/\")\n    test_files = test_folder.glob(\"*.tif\")\n    print(test_files)\n\n    list_of_models = list(Path('../data/lightning_logs/').glob('version*/checkpoints/*.ckpt'))\n    latest_model_path = str(max(list_of_models, key=os.path.getctime))\n    print(f\"Using model {latest_model_path}\")\n\n    model = Model.load_from_checkpoint(latest_model_path)\n\n    for test_path in test_files:\n\n        save_dir = Path(data_dir) / \"Autoencoder\"\n        save_dir.mkdir(exist_ok=True)\n\n        print(f\"Running for {test_path}\")\n\n        savepath = save_dir / f\"preds_{test_path.name}\"\n        if savepath.exists():\n            print(\"File already generated. Skipping\")\n            continue\n\n        out_forecasted = model.predict(test_path, with_forecaster=True)\n        plot_results(out_forecasted, test_path, savepath=save_dir, prefix=\"forecasted_\")\n\n        out_normal = model.predict(test_path, with_forecaster=False)\n        plot_results(out_normal, test_path, savepath=save_dir, prefix=\"full_input_\")\n\n        out_forecasted.to_netcdf(save_dir / f\"preds_forecasted_{test_path.name}.nc\")\n        out_normal.to_netcdf(save_dir / f\"preds_normal_{test_path.name}.nc\")\n\n\nif __name__ == \"__main__\":\n    print(\"Starting...predict.py\")\n    kenya_crop_type_mapper()\n",
  "history_output" : "Starting...predict.py\n<generator object Path.glob at 0x7fbc5da26f20>\nTraceback (most recent call last):\n  File \"scripts_predict.py\", line 48, in <module>\n    kenya_crop_type_mapper()\n  File \"scripts_predict.py\", line 19, in kenya_crop_type_mapper\n    latest_model_path = str(max(list_of_models, key=os.path.getctime))\nValueError: max() arg is an empty sequence\n",
  "history_begin_time" : 1647347140898,
  "history_end_time" : 1647347144356,
  "history_notes" : null,
  "history_process" : "delykw",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "ixrj5zz7o7y",
  "history_input" : "from pathlib import Path\nimport sys\nimport os\n\nsys.path.append(\"..\")\n\nfrom src_models_model import Model\nfrom src_analysis import plot_results\n\n\ndef kenya_crop_type_mapper():\n    data_dir = \"../data\"\n\n    test_folder = Path(\"../data/raw/earth_engine_plant_village_kenya/\")\n    test_files = test_folder.glob(\"*.tif\")\n    print(test_files)\n\n    list_of_models = list(Path('../data/lightning_logs/').glob('version*/checkpoints/*.ckpt'))\n    latest_model_path = str(max(list_of_models, key=os.path.getctime))\n    print(f\"Using model {latest_model_path}\")\n\n    model = Model.load_from_checkpoint(latest_model_path)\n\n    for test_path in test_files:\n\n        save_dir = Path(data_dir) / \"Autoencoder\"\n        save_dir.mkdir(exist_ok=True)\n\n        print(f\"Running for {test_path}\")\n\n        savepath = save_dir / f\"preds_{test_path.name}\"\n        if savepath.exists():\n            print(\"File already generated. Skipping\")\n            continue\n\n        out_forecasted = model.predict(test_path, with_forecaster=True)\n        plot_results(out_forecasted, test_path, savepath=save_dir, prefix=\"forecasted_\")\n\n        out_normal = model.predict(test_path, with_forecaster=False)\n        plot_results(out_normal, test_path, savepath=save_dir, prefix=\"full_input_\")\n\n        out_forecasted.to_netcdf(save_dir / f\"preds_forecasted_{test_path.name}.nc\")\n        out_normal.to_netcdf(save_dir / f\"preds_normal_{test_path.name}.nc\")\n\n\nif __name__ == \"__main__\":\n    print(\"Starting...predict.py\")\n    kenya_crop_type_mapper()\n",
  "history_output" : "",
  "history_begin_time" : 1647346838978,
  "history_end_time" : 1647346840984,
  "history_notes" : null,
  "history_process" : "delykw",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "jtwhjtjndrf",
  "history_input" : "from pathlib import Path\nimport sys\nimport os\n\nsys.path.append(\"..\")\n\nfrom src_models_model import Model\nfrom src_analysis import plot_results\n\n\ndef kenya_crop_type_mapper():\n    data_dir = \"../data\"\n\n    test_folder = Path(\"../data/raw/earth_engine_plant_village_kenya/\")\n    test_files = test_folder.glob(\"*.tif\")\n    print(test_files)\n\n    list_of_models = list(Path('../data/lightning_logs/').glob('version*/checkpoints/*.ckpt'))\n    latest_model_path = str(max(list_of_models, key=os.path.getctime))\n    print(f\"Using model {latest_model_path}\")\n\n    model = Model.load_from_checkpoint(latest_model_path)\n\n    for test_path in test_files:\n\n        save_dir = Path(data_dir) / \"Autoencoder\"\n        save_dir.mkdir(exist_ok=True)\n\n        print(f\"Running for {test_path}\")\n\n        savepath = save_dir / f\"preds_{test_path.name}\"\n        if savepath.exists():\n            print(\"File already generated. Skipping\")\n            continue\n\n        out_forecasted = model.predict(test_path, with_forecaster=True)\n        plot_results(out_forecasted, test_path, savepath=save_dir, prefix=\"forecasted_\")\n\n        out_normal = model.predict(test_path, with_forecaster=False)\n        plot_results(out_normal, test_path, savepath=save_dir, prefix=\"full_input_\")\n\n        out_forecasted.to_netcdf(save_dir / f\"preds_forecasted_{test_path.name}.nc\")\n        out_normal.to_netcdf(save_dir / f\"preds_normal_{test_path.name}.nc\")\n\n\nif __name__ == \"__main__\":\n    print(\"Starting...predict.py\")\n    kenya_crop_type_mapper()\n",
  "history_output" : "ERROR 1: PROJ: proj_identify: /opt/anaconda3/share/proj/proj.db lacks DATABASE.LAYOUT.VERSION.MAJOR / DATABASE.LAYOUT.VERSION.MINOR metadata. It comes from another PROJ installation.\n  0%|          | 0/288 [00:00<?, ?it/s]ERROR 1: PROJ: proj_identify: /opt/anaconda3/share/proj/proj.db lacks DATABASE.LAYOUT.VERSION.MAJOR / DATABASE.LAYOUT.VERSION.MINOR metadata. It comes from another PROJ installation.\n320it [00:00, 1145.92it/s]             ERROR 1: PROJ: proj_identify: /opt/anaconda3/share/proj/proj.db lacks DATABASE.LAYOUT.VERSION.MAJOR / DATABASE.LAYOUT.VERSION.MINOR metadata. It comes from another PROJ installation.\n  0%|          | 0/288 [00:00<?, ?it/s]ERROR 1: PROJ: proj_identify: /opt/anaconda3/share/proj/proj.db lacks DATABASE.LAYOUT.VERSION.MAJOR / DATABASE.LAYOUT.VERSION.MINOR metadata. It comes from another PROJ installation.\n320it [00:00, 1276.63it/s]             ERROR 1: PROJ: proj_identify: /opt/anaconda3/share/proj/proj.db lacks DATABASE.LAYOUT.VERSION.MAJOR / DATABASE.LAYOUT.VERSION.MINOR metadata. It comes from another PROJ installation.\n  0%|          | 0/288 [00:00<?, ?it/s]ERROR 1: PROJ: proj_identify: /opt/anaconda3/share/proj/proj.db lacks DATABASE.LAYOUT.VERSION.MAJOR / DATABASE.LAYOUT.VERSION.MINOR metadata. It comes from another PROJ installation.\n320it [00:00, 1309.53it/s]             ERROR 1: PROJ: proj_identify: /opt/anaconda3/share/proj/proj.db lacks DATABASE.LAYOUT.VERSION.MAJOR / DATABASE.LAYOUT.VERSION.MINOR metadata. It comes from another PROJ installation.\n  0%|          | 0/288 [00:00<?, ?it/s]ERROR 1: PROJ: proj_identify: /opt/anaconda3/share/proj/proj.db lacks DATABASE.LAYOUT.VERSION.MAJOR / DATABASE.LAYOUT.VERSION.MINOR metadata. It comes from another PROJ installation.\n320it [00:00, 1650.60it/s]             ERROR 1: PROJ: proj_identify: /opt/anaconda3/share/proj/proj.db lacks DATABASE.LAYOUT.VERSION.MAJOR / DATABASE.LAYOUT.VERSION.MINOR metadata. It comes from another PROJ installation.\n  0%|          | 0/288 [00:00<?, ?it/s]ERROR 1: PROJ: proj_identify: /opt/anaconda3/share/proj/proj.db lacks DATABASE.LAYOUT.VERSION.MAJOR / DATABASE.LAYOUT.VERSION.MINOR metadata. It comes from another PROJ installation.\n320it [00:00, 1211.35it/s]             ERROR 1: PROJ: proj_identify: /opt/anaconda3/share/proj/proj.db lacks DATABASE.LAYOUT.VERSION.MAJOR / DATABASE.LAYOUT.VERSION.MINOR metadata. It comes from another PROJ installation.\n  0%|          | 0/288 [00:00<?, ?it/s]ERROR 1: PROJ: proj_identify: /opt/anaconda3/share/proj/proj.db lacks DATABASE.LAYOUT.VERSION.MAJOR / DATABASE.LAYOUT.VERSION.MINOR metadata. It comes from another PROJ installation.\n320it [00:00, 1641.91it/s]             ERROR 1: PROJ: proj_identify: /opt/anaconda3/share/proj/proj.db lacks DATABASE.LAYOUT.VERSION.MAJOR / DATABASE.LAYOUT.VERSION.MINOR metadata. It comes from another PROJ installation.\n  0%|          | 0/288 [00:00<?, ?it/s]ERROR 1: PROJ: proj_identify: /opt/anaconda3/share/proj/proj.db lacks DATABASE.LAYOUT.VERSION.MAJOR / DATABASE.LAYOUT.VERSION.MINOR metadata. It comes from another PROJ installation.\n320it [00:00, 1358.52it/s]             ERROR 1: PROJ: proj_identify: /opt/anaconda3/share/proj/proj.db lacks DATABASE.LAYOUT.VERSION.MAJOR / DATABASE.LAYOUT.VERSION.MINOR metadata. It comes from another PROJ installation.\n  0%|          | 0/288 [00:00<?, ?it/s]ERROR 1: PROJ: proj_identify: /opt/anaconda3/share/proj/proj.db lacks DATABASE.LAYOUT.VERSION.MAJOR / DATABASE.LAYOUT.VERSION.MINOR metadata. It comes from another PROJ installation.\n320it [00:00, 1339.65it/s]             ERROR 1: PROJ: proj_identify: /opt/anaconda3/share/proj/proj.db lacks DATABASE.LAYOUT.VERSION.MAJOR / DATABASE.LAYOUT.VERSION.MINOR metadata. It comes from another PROJ installation.\n  0%|          | 0/288 [00:00<?, ?it/s]ERROR 1: PROJ: proj_identify: /opt/anaconda3/share/proj/proj.db lacks DATABASE.LAYOUT.VERSION.MAJOR / DATABASE.LAYOUT.VERSION.MINOR metadata. It comes from another PROJ installation.\n320it [00:00, 1189.92it/s]             ERROR 1: PROJ: proj_identify: /opt/anaconda3/share/proj/proj.db lacks DATABASE.LAYOUT.VERSION.MAJOR / DATABASE.LAYOUT.VERSION.MINOR metadata. It comes from another PROJ installation.\n  0%|          | 0/288 [00:00<?, ?it/s]ERROR 1: PROJ: proj_identify: /opt/anaconda3/share/proj/proj.db lacks DATABASE.LAYOUT.VERSION.MAJOR / DATABASE.LAYOUT.VERSION.MINOR metadata. It comes from another PROJ installation.\n320it [00:00, 1721.57it/s]             ERROR 1: PROJ: proj_identify: /opt/anaconda3/share/proj/proj.db lacks DATABASE.LAYOUT.VERSION.MAJOR / DATABASE.LAYOUT.VERSION.MINOR metadata. It comes from another PROJ installation.\n  0%|          | 0/288 [00:00<?, ?it/s]ERROR 1: PROJ: proj_identify: /opt/anaconda3/share/proj/proj.db lacks DATABASE.LAYOUT.VERSION.MAJOR / DATABASE.LAYOUT.VERSION.MINOR metadata. It comes from another PROJ installation.\n320it [00:00, 1227.37it/s]             ERROR 1: PROJ: proj_identify: /opt/anaconda3/share/proj/proj.db lacks DATABASE.LAYOUT.VERSION.MAJOR / DATABASE.LAYOUT.VERSION.MINOR metadata. It comes from another PROJ installation.\n  0%|          | 0/288 [00:00<?, ?it/s]ERROR 1: PROJ: proj_identify: /opt/anaconda3/share/proj/proj.db lacks DATABASE.LAYOUT.VERSION.MAJOR / DATABASE.LAYOUT.VERSION.MINOR metadata. It comes from another PROJ installation.\n320it [00:00, 1665.59it/s]             ERROR 1: PROJ: proj_identify: /opt/anaconda3/share/proj/proj.db lacks DATABASE.LAYOUT.VERSION.MAJOR / DATABASE.LAYOUT.VERSION.MINOR metadata. It comes from another PROJ installation.\n  0%|          | 0/288 [00:00<?, ?it/s]ERROR 1: PROJ: proj_identify: /opt/anaconda3/share/proj/proj.db lacks DATABASE.LAYOUT.VERSION.MAJOR / DATABASE.LAYOUT.VERSION.MINOR metadata. It comes from another PROJ installation.\n320it [00:00, 1144.59it/s]             ERROR 1: PROJ: proj_identify: /opt/anaconda3/share/proj/proj.db lacks DATABASE.LAYOUT.VERSION.MAJOR / DATABASE.LAYOUT.VERSION.MINOR metadata. It comes from another PROJ installation.\n  0%|          | 0/288 [00:00<?, ?it/s]ERROR 1: PROJ: proj_identify: /opt/anaconda3/share/proj/proj.db lacks DATABASE.LAYOUT.VERSION.MAJOR / DATABASE.LAYOUT.VERSION.MINOR metadata. It comes from another PROJ installation.\n320it [00:00, 1350.47it/s]             ERROR 1: PROJ: proj_identify: /opt/anaconda3/share/proj/proj.db lacks DATABASE.LAYOUT.VERSION.MAJOR / DATABASE.LAYOUT.VERSION.MINOR metadata. It comes from another PROJ installation.\n  0%|          | 0/288 [00:00<?, ?it/s]ERROR 1: PROJ: proj_identify: /opt/anaconda3/share/proj/proj.db lacks DATABASE.LAYOUT.VERSION.MAJOR / DATABASE.LAYOUT.VERSION.MINOR metadata. It comes from another PROJ installation.\n320it [00:00, 1273.66it/s]             ERROR 1: PROJ: proj_identify: /opt/anaconda3/share/proj/proj.db lacks DATABASE.LAYOUT.VERSION.MAJOR / DATABASE.LAYOUT.VERSION.MINOR metadata. It comes from another PROJ installation.\n  0%|          | 0/288 [00:00<?, ?it/s]ERROR 1: PROJ: proj_identify: /opt/anaconda3/share/proj/proj.db lacks DATABASE.LAYOUT.VERSION.MAJOR / DATABASE.LAYOUT.VERSION.MINOR metadata. It comes from another PROJ installation.\n320it [00:00, 1713.57it/s]             ERROR 1: PROJ: proj_identify: /opt/anaconda3/share/proj/proj.db lacks DATABASE.LAYOUT.VERSION.MAJOR / DATABASE.LAYOUT.VERSION.MINOR metadata. It comes from another PROJ installation.\n  0%|          | 0/305 [00:00<?, ?it/s]ERROR 1: PROJ: proj_identify: /opt/anaconda3/share/proj/proj.db lacks DATABASE.LAYOUT.VERSION.MAJOR / DATABASE.LAYOUT.VERSION.MINOR metadata. It comes from another PROJ installation.\n320it [00:00, 1375.46it/s]             ERROR 1: PROJ: proj_identify: /opt/anaconda3/share/proj/proj.db lacks DATABASE.LAYOUT.VERSION.MAJOR / DATABASE.LAYOUT.VERSION.MINOR metadata. It comes from another PROJ installation.\n  0%|          | 0/305 [00:00<?, ?it/s]ERROR 1: PROJ: proj_identify: /opt/anaconda3/share/proj/proj.db lacks DATABASE.LAYOUT.VERSION.MAJOR / DATABASE.LAYOUT.VERSION.MINOR metadata. It comes from another PROJ installation.\n320it [00:00, 1773.83it/s]             ERROR 1: PROJ: proj_identify: /opt/anaconda3/share/proj/proj.db lacks DATABASE.LAYOUT.VERSION.MAJOR / DATABASE.LAYOUT.VERSION.MINOR metadata. It comes from another PROJ installation.\n  0%|          | 0/288 [00:00<?, ?it/s]ERROR 1: PROJ: proj_identify: /opt/anaconda3/share/proj/proj.db lacks DATABASE.LAYOUT.VERSION.MAJOR / DATABASE.LAYOUT.VERSION.MINOR metadata. It comes from another PROJ installation.\n320it [00:00, 1272.73it/s]             ERROR 1: PROJ: proj_identify: /opt/anaconda3/share/proj/proj.db lacks DATABASE.LAYOUT.VERSION.MAJOR / DATABASE.LAYOUT.VERSION.MINOR metadata. It comes from another PROJ installation.\n  0%|          | 0/288 [00:00<?, ?it/s]ERROR 1: PROJ: proj_identify: /opt/anaconda3/share/proj/proj.db lacks DATABASE.LAYOUT.VERSION.MAJOR / DATABASE.LAYOUT.VERSION.MINOR metadata. It comes from another PROJ installation.\n320it [00:00, 1724.73it/s]             \nStarting...predict.py\n<generator object Path.glob at 0x7fac09121120>\nUsing model ../data/lightning_logs/version_14/checkpoints/epoch=165.ckpt\nPredicting 7 timesteps in the forecaster\nUsing 1 layers for the global classifier\nUsing 2 layers for the local classifier\nRunning for ../data/raw/earth_engine_plant_village_kenya/1_2019-04-22_2020-04-16.tif\nNo GPU - not using one\nNo GPU - not using one\nRunning for ../data/raw/earth_engine_plant_village_kenya/9_2019-04-22_2020-04-16.tif\nNo GPU - not using one\nNo GPU - not using one\nRunning for ../data/raw/earth_engine_plant_village_kenya/6_2019-04-22_2020-04-16.tif\nNo GPU - not using one\nNo GPU - not using one\nRunning for ../data/raw/earth_engine_plant_village_kenya/3_2019-04-22_2020-04-16.tif\nNo GPU - not using one\nNo GPU - not using one\nRunning for ../data/raw/earth_engine_plant_village_kenya/4_2019-04-22_2020-04-16.tif\nNo GPU - not using one\nNo GPU - not using one\nRunning for ../data/raw/earth_engine_plant_village_kenya/5_2019-04-22_2020-04-16.tif\nNo GPU - not using one\nNo GPU - not using one\nRunning for ../data/raw/earth_engine_plant_village_kenya/0_2018-04-21_2019-04-16.tif\nNo GPU - not using one\nNo GPU - not using one\nRunning for ../data/raw/earth_engine_plant_village_kenya/2_2019-04-22_2020-04-16.tif\nNo GPU - not using one\nNo GPU - not using one\nRunning for ../data/raw/earth_engine_plant_village_kenya/7_2019-04-22_2020-04-16.tif\nNo GPU - not using one\nNo GPU - not using one\nRunning for ../data/raw/earth_engine_plant_village_kenya/8_2019-04-22_2020-04-16.tif\nNo GPU - not using one\nNo GPU - not using one\n",
  "history_begin_time" : 1647346680415,
  "history_end_time" : 1647346712890,
  "history_notes" : null,
  "history_process" : "delykw",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "ipyp7fbqivj",
  "history_input" : "from pathlib import Path\nimport sys\nimport os\n\nsys.path.append(\"..\")\n\nfrom src_models_model import Model\nfrom src_analysis import plot_results\n\n\ndef kenya_crop_type_mapper():\n    data_dir = \"../data\"\n\n    test_folder = Path(\"../data/raw/earth_engine_plant_village_kenya/\")\n    test_files = test_folder.glob(\"*.tif\")\n    print(test_files)\n\n    list_of_models = list(Path('../data/lightning_logs/').glob('version*/checkpoints/*.ckpt'))\n    latest_model_path = str(max(list_of_models, key=os.path.getctime))\n    print(f\"Using model {latest_model_path}\")\n\n    model = Model.load_from_checkpoint(latest_model_path)\n\n    for test_path in test_files:\n\n        save_dir = Path(data_dir) / \"Autoencoder\"\n        save_dir.mkdir(exist_ok=True)\n\n        print(f\"Running for {test_path}\")\n\n        savepath = save_dir / f\"preds_{test_path.name}\"\n        if savepath.exists():\n            print(\"File already generated. Skipping\")\n            continue\n\n        out_forecasted = model.predict(test_path, with_forecaster=True)\n        plot_results(out_forecasted, test_path, savepath=save_dir, prefix=\"forecasted_\")\n\n        out_normal = model.predict(test_path, with_forecaster=False)\n        plot_results(out_normal, test_path, savepath=save_dir, prefix=\"full_input_\")\n\n        out_forecasted.to_netcdf(save_dir / f\"preds_forecasted_{test_path.name}.nc\")\n        out_normal.to_netcdf(save_dir / f\"preds_normal_{test_path.name}.nc\")\n\n\nif __name__ == \"__main__\":\n    print(\"Starting...predict.py\")\n    kenya_crop_type_mapper()\n",
  "history_output" : "",
  "history_begin_time" : 1647345856797,
  "history_end_time" : 1647345856884,
  "history_notes" : null,
  "history_process" : "delykw",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "7e4e5er2tu2",
  "history_input" : "from pathlib import Path\nimport sys\nimport os\n\nsys.path.append(\"..\")\n\nfrom src_models_model import Model\nfrom src_analysis import plot_results\n\n\ndef kenya_crop_type_mapper():\n    data_dir = \"../data\"\n\n    test_folder = Path(\"../data/raw/earth_engine_plant_village_kenya/\")\n    test_files = test_folder.glob(\"*.tif\")\n    print(test_files)\n\n    list_of_models = list(Path('../data/lightning_logs/').glob('version*/checkpoints/*.ckpt'))\n    latest_model_path = str(max(list_of_models, key=os.path.getctime))\n    print(f\"Using model {latest_model_path}\")\n\n    model = Model.load_from_checkpoint(latest_model_path)\n\n    for test_path in test_files:\n\n        save_dir = Path(data_dir) / \"Autoencoder\"\n        save_dir.mkdir(exist_ok=True)\n\n        print(f\"Running for {test_path}\")\n\n        savepath = save_dir / f\"preds_{test_path.name}\"\n        if savepath.exists():\n            print(\"File already generated. Skipping\")\n            continue\n\n        out_forecasted = model.predict(test_path, with_forecaster=True)\n        plot_results(out_forecasted, test_path, savepath=save_dir, prefix=\"forecasted_\")\n\n        out_normal = model.predict(test_path, with_forecaster=False)\n        plot_results(out_normal, test_path, savepath=save_dir, prefix=\"full_input_\")\n\n        out_forecasted.to_netcdf(save_dir / f\"preds_forecasted_{test_path.name}.nc\")\n        out_normal.to_netcdf(save_dir / f\"preds_normal_{test_path.name}.nc\")\n\n\nif __name__ == \"__main__\":\n    print(\"Starting...predict.py\")\n    kenya_crop_type_mapper()\n",
  "history_output" : "ERROR 1: PROJ: proj_identify: /opt/anaconda3/share/proj/proj.db lacks DATABASE.LAYOUT.VERSION.MAJOR / DATABASE.LAYOUT.VERSION.MINOR metadata. It comes from another PROJ installation.\n  0%|          | 0/288 [00:00<?, ?it/s]ERROR 1: PROJ: proj_identify: /opt/anaconda3/share/proj/proj.db lacks DATABASE.LAYOUT.VERSION.MAJOR / DATABASE.LAYOUT.VERSION.MINOR metadata. It comes from another PROJ installation.\n320it [00:00, 1186.70it/s]             ERROR 1: PROJ: proj_identify: /opt/anaconda3/share/proj/proj.db lacks DATABASE.LAYOUT.VERSION.MAJOR / DATABASE.LAYOUT.VERSION.MINOR metadata. It comes from another PROJ installation.\n  0%|          | 0/288 [00:00<?, ?it/s]ERROR 1: PROJ: proj_identify: /opt/anaconda3/share/proj/proj.db lacks DATABASE.LAYOUT.VERSION.MAJOR / DATABASE.LAYOUT.VERSION.MINOR metadata. It comes from another PROJ installation.\n320it [00:00, 1321.39it/s]             ERROR 1: PROJ: proj_identify: /opt/anaconda3/share/proj/proj.db lacks DATABASE.LAYOUT.VERSION.MAJOR / DATABASE.LAYOUT.VERSION.MINOR metadata. It comes from another PROJ installation.\n  0%|          | 0/288 [00:00<?, ?it/s]ERROR 1: PROJ: proj_identify: /opt/anaconda3/share/proj/proj.db lacks DATABASE.LAYOUT.VERSION.MAJOR / DATABASE.LAYOUT.VERSION.MINOR metadata. It comes from another PROJ installation.\n320it [00:00, 1010.88it/s]             ERROR 1: PROJ: proj_identify: /opt/anaconda3/share/proj/proj.db lacks DATABASE.LAYOUT.VERSION.MAJOR / DATABASE.LAYOUT.VERSION.MINOR metadata. It comes from another PROJ installation.\n  0%|          | 0/288 [00:00<?, ?it/s]ERROR 1: PROJ: proj_identify: /opt/anaconda3/share/proj/proj.db lacks DATABASE.LAYOUT.VERSION.MAJOR / DATABASE.LAYOUT.VERSION.MINOR metadata. It comes from another PROJ installation.\n320it [00:00, 1124.82it/s]             ERROR 1: PROJ: proj_identify: /opt/anaconda3/share/proj/proj.db lacks DATABASE.LAYOUT.VERSION.MAJOR / DATABASE.LAYOUT.VERSION.MINOR metadata. It comes from another PROJ installation.\n  0%|          | 0/288 [00:00<?, ?it/s]\n 22%|██▏       | 64/288 [00:00<00:00, 362.09it/s]ERROR 1: PROJ: proj_identify: /opt/anaconda3/share/proj/proj.db lacks DATABASE.LAYOUT.VERSION.MAJOR / DATABASE.LAYOUT.VERSION.MINOR metadata. It comes from another PROJ installation.\n320it [00:00, 640.92it/s]                        ERROR 1: PROJ: proj_identify: /opt/anaconda3/share/proj/proj.db lacks DATABASE.LAYOUT.VERSION.MAJOR / DATABASE.LAYOUT.VERSION.MINOR metadata. It comes from another PROJ installation.\n  0%|          | 0/288 [00:00<?, ?it/s]ERROR 1: PROJ: proj_identify: /opt/anaconda3/share/proj/proj.db lacks DATABASE.LAYOUT.VERSION.MAJOR / DATABASE.LAYOUT.VERSION.MINOR metadata. It comes from another PROJ installation.\n320it [00:00, 1337.99it/s]             ERROR 1: PROJ: proj_identify: /opt/anaconda3/share/proj/proj.db lacks DATABASE.LAYOUT.VERSION.MAJOR / DATABASE.LAYOUT.VERSION.MINOR metadata. It comes from another PROJ installation.\n  0%|          | 0/288 [00:00<?, ?it/s]ERROR 1: PROJ: proj_identify: /opt/anaconda3/share/proj/proj.db lacks DATABASE.LAYOUT.VERSION.MAJOR / DATABASE.LAYOUT.VERSION.MINOR metadata. It comes from another PROJ installation.\n320it [00:00, 1192.50it/s]             ERROR 1: PROJ: proj_identify: /opt/anaconda3/share/proj/proj.db lacks DATABASE.LAYOUT.VERSION.MAJOR / DATABASE.LAYOUT.VERSION.MINOR metadata. It comes from another PROJ installation.\n  0%|          | 0/288 [00:00<?, ?it/s]ERROR 1: PROJ: proj_identify: /opt/anaconda3/share/proj/proj.db lacks DATABASE.LAYOUT.VERSION.MAJOR / DATABASE.LAYOUT.VERSION.MINOR metadata. It comes from another PROJ installation.\n320it [00:00, 1665.41it/s]             ERROR 1: PROJ: proj_identify: /opt/anaconda3/share/proj/proj.db lacks DATABASE.LAYOUT.VERSION.MAJOR / DATABASE.LAYOUT.VERSION.MINOR metadata. It comes from another PROJ installation.\n  0%|          | 0/288 [00:00<?, ?it/s]ERROR 1: PROJ: proj_identify: /opt/anaconda3/share/proj/proj.db lacks DATABASE.LAYOUT.VERSION.MAJOR / DATABASE.LAYOUT.VERSION.MINOR metadata. It comes from another PROJ installation.\n320it [00:00, 1293.15it/s]             ERROR 1: PROJ: proj_identify: /opt/anaconda3/share/proj/proj.db lacks DATABASE.LAYOUT.VERSION.MAJOR / DATABASE.LAYOUT.VERSION.MINOR metadata. It comes from another PROJ installation.\n  0%|          | 0/288 [00:00<?, ?it/s]ERROR 1: PROJ: proj_identify: /opt/anaconda3/share/proj/proj.db lacks DATABASE.LAYOUT.VERSION.MAJOR / DATABASE.LAYOUT.VERSION.MINOR metadata. It comes from another PROJ installation.\n320it [00:00, 1696.97it/s]             ERROR 1: PROJ: proj_identify: /opt/anaconda3/share/proj/proj.db lacks DATABASE.LAYOUT.VERSION.MAJOR / DATABASE.LAYOUT.VERSION.MINOR metadata. It comes from another PROJ installation.\n  0%|          | 0/288 [00:00<?, ?it/s]ERROR 1: PROJ: proj_identify: /opt/anaconda3/share/proj/proj.db lacks DATABASE.LAYOUT.VERSION.MAJOR / DATABASE.LAYOUT.VERSION.MINOR metadata. It comes from another PROJ installation.\n320it [00:00, 1319.50it/s]             ERROR 1: PROJ: proj_identify: /opt/anaconda3/share/proj/proj.db lacks DATABASE.LAYOUT.VERSION.MAJOR / DATABASE.LAYOUT.VERSION.MINOR metadata. It comes from another PROJ installation.\n  0%|          | 0/288 [00:00<?, ?it/s]ERROR 1: PROJ: proj_identify: /opt/anaconda3/share/proj/proj.db lacks DATABASE.LAYOUT.VERSION.MAJOR / DATABASE.LAYOUT.VERSION.MINOR metadata. It comes from another PROJ installation.\n320it [00:00, 1648.38it/s]             ERROR 1: PROJ: proj_identify: /opt/anaconda3/share/proj/proj.db lacks DATABASE.LAYOUT.VERSION.MAJOR / DATABASE.LAYOUT.VERSION.MINOR metadata. It comes from another PROJ installation.\n  0%|          | 0/288 [00:00<?, ?it/s]ERROR 1: PROJ: proj_identify: /opt/anaconda3/share/proj/proj.db lacks DATABASE.LAYOUT.VERSION.MAJOR / DATABASE.LAYOUT.VERSION.MINOR metadata. It comes from another PROJ installation.\n320it [00:00, 1263.61it/s]             ERROR 1: PROJ: proj_identify: /opt/anaconda3/share/proj/proj.db lacks DATABASE.LAYOUT.VERSION.MAJOR / DATABASE.LAYOUT.VERSION.MINOR metadata. It comes from another PROJ installation.\n  0%|          | 0/288 [00:00<?, ?it/s]ERROR 1: PROJ: proj_identify: /opt/anaconda3/share/proj/proj.db lacks DATABASE.LAYOUT.VERSION.MAJOR / DATABASE.LAYOUT.VERSION.MINOR metadata. It comes from another PROJ installation.\n320it [00:00, 1677.02it/s]             ERROR 1: PROJ: proj_identify: /opt/anaconda3/share/proj/proj.db lacks DATABASE.LAYOUT.VERSION.MAJOR / DATABASE.LAYOUT.VERSION.MINOR metadata. It comes from another PROJ installation.\n  0%|          | 0/288 [00:00<?, ?it/s]ERROR 1: PROJ: proj_identify: /opt/anaconda3/share/proj/proj.db lacks DATABASE.LAYOUT.VERSION.MAJOR / DATABASE.LAYOUT.VERSION.MINOR metadata. It comes from another PROJ installation.\n320it [00:00, 1227.45it/s]             ERROR 1: PROJ: proj_identify: /opt/anaconda3/share/proj/proj.db lacks DATABASE.LAYOUT.VERSION.MAJOR / DATABASE.LAYOUT.VERSION.MINOR metadata. It comes from another PROJ installation.\n  0%|          | 0/288 [00:00<?, ?it/s]ERROR 1: PROJ: proj_identify: /opt/anaconda3/share/proj/proj.db lacks DATABASE.LAYOUT.VERSION.MAJOR / DATABASE.LAYOUT.VERSION.MINOR metadata. It comes from another PROJ installation.\n320it [00:00, 1660.26it/s]             ERROR 1: PROJ: proj_identify: /opt/anaconda3/share/proj/proj.db lacks DATABASE.LAYOUT.VERSION.MAJOR / DATABASE.LAYOUT.VERSION.MINOR metadata. It comes from another PROJ installation.\n  0%|          | 0/305 [00:00<?, ?it/s]ERROR 1: PROJ: proj_identify: /opt/anaconda3/share/proj/proj.db lacks DATABASE.LAYOUT.VERSION.MAJOR / DATABASE.LAYOUT.VERSION.MINOR metadata. It comes from another PROJ installation.\n320it [00:00, 1295.17it/s]             ERROR 1: PROJ: proj_identify: /opt/anaconda3/share/proj/proj.db lacks DATABASE.LAYOUT.VERSION.MAJOR / DATABASE.LAYOUT.VERSION.MINOR metadata. It comes from another PROJ installation.\n  0%|          | 0/305 [00:00<?, ?it/s]ERROR 1: PROJ: proj_identify: /opt/anaconda3/share/proj/proj.db lacks DATABASE.LAYOUT.VERSION.MAJOR / DATABASE.LAYOUT.VERSION.MINOR metadata. It comes from another PROJ installation.\n320it [00:00, 1683.16it/s]             ERROR 1: PROJ: proj_identify: /opt/anaconda3/share/proj/proj.db lacks DATABASE.LAYOUT.VERSION.MAJOR / DATABASE.LAYOUT.VERSION.MINOR metadata. It comes from another PROJ installation.\n  0%|          | 0/288 [00:00<?, ?it/s]ERROR 1: PROJ: proj_identify: /opt/anaconda3/share/proj/proj.db lacks DATABASE.LAYOUT.VERSION.MAJOR / DATABASE.LAYOUT.VERSION.MINOR metadata. It comes from another PROJ installation.\n320it [00:00, 1265.43it/s]             ERROR 1: PROJ: proj_identify: /opt/anaconda3/share/proj/proj.db lacks DATABASE.LAYOUT.VERSION.MAJOR / DATABASE.LAYOUT.VERSION.MINOR metadata. It comes from another PROJ installation.\n  0%|          | 0/288 [00:00<?, ?it/s]ERROR 1: PROJ: proj_identify: /opt/anaconda3/share/proj/proj.db lacks DATABASE.LAYOUT.VERSION.MAJOR / DATABASE.LAYOUT.VERSION.MINOR metadata. It comes from another PROJ installation.\n320it [00:00, 1671.71it/s]             \nStarting...predict.py\n<generator object Path.glob at 0x7f82a1025f20>\nUsing model ../data/lightning_logs/version_13/checkpoints/epoch=165.ckpt\nPredicting 7 timesteps in the forecaster\nUsing 1 layers for the global classifier\nUsing 2 layers for the local classifier\nRunning for ../data/raw/earth_engine_plant_village_kenya/1_2019-04-22_2020-04-16.tif\nNo GPU - not using one\nNo GPU - not using one\nRunning for ../data/raw/earth_engine_plant_village_kenya/9_2019-04-22_2020-04-16.tif\nNo GPU - not using one\nNo GPU - not using one\nRunning for ../data/raw/earth_engine_plant_village_kenya/6_2019-04-22_2020-04-16.tif\nNo GPU - not using one\nNo GPU - not using one\nRunning for ../data/raw/earth_engine_plant_village_kenya/3_2019-04-22_2020-04-16.tif\nNo GPU - not using one\nNo GPU - not using one\nRunning for ../data/raw/earth_engine_plant_village_kenya/4_2019-04-22_2020-04-16.tif\nNo GPU - not using one\nNo GPU - not using one\nRunning for ../data/raw/earth_engine_plant_village_kenya/5_2019-04-22_2020-04-16.tif\nNo GPU - not using one\nNo GPU - not using one\nRunning for ../data/raw/earth_engine_plant_village_kenya/0_2018-04-21_2019-04-16.tif\nNo GPU - not using one\nNo GPU - not using one\nRunning for ../data/raw/earth_engine_plant_village_kenya/2_2019-04-22_2020-04-16.tif\nNo GPU - not using one\nNo GPU - not using one\nRunning for ../data/raw/earth_engine_plant_village_kenya/7_2019-04-22_2020-04-16.tif\nNo GPU - not using one\nNo GPU - not using one\nRunning for ../data/raw/earth_engine_plant_village_kenya/8_2019-04-22_2020-04-16.tif\nNo GPU - not using one\nNo GPU - not using one\n",
  "history_begin_time" : 1647345661897,
  "history_end_time" : 1647345695105,
  "history_notes" : null,
  "history_process" : "delykw",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "c5ylKQGnrD6s",
  "history_input" : "from pathlib import Path\nimport sys\nimport os\n\nsys.path.append(\"..\")\n\nfrom src_models_model import Model\nfrom src_analysis import plot_results\n\n\ndef kenya_crop_type_mapper():\n    data_dir = \"../data\"\n\n    test_folder = Path(\"../data/raw/earth_engine_plant_village_kenya/\")\n    test_files = test_folder.glob(\"*.tif\")\n    print(test_files)\n\n    list_of_models = list(Path('../data/lightning_logs/').glob('version*/checkpoints/*.ckpt'))\n    latest_model_path = str(max(list_of_models, key=os.path.getctime))\n    print(f\"Using model {latest_model_path}\")\n\n    model = Model.load_from_checkpoint(latest_model_path)\n\n    for test_path in test_files:\n\n        save_dir = Path(data_dir) / \"Autoencoder\"\n        save_dir.mkdir(exist_ok=True)\n\n        print(f\"Running for {test_path}\")\n\n        savepath = save_dir / f\"preds_{test_path.name}\"\n        if savepath.exists():\n            print(\"File already generated. Skipping\")\n            continue\n\n        out_forecasted = model.predict(test_path, with_forecaster=True)\n        plot_results(out_forecasted, test_path, savepath=save_dir, prefix=\"forecasted_\")\n\n        out_normal = model.predict(test_path, with_forecaster=False)\n        plot_results(out_normal, test_path, savepath=save_dir, prefix=\"full_input_\")\n\n        out_forecasted.to_netcdf(save_dir / f\"preds_forecasted_{test_path.name}.nc\")\n        out_normal.to_netcdf(save_dir / f\"preds_normal_{test_path.name}.nc\")\n\n\nif __name__ == \"__main__\":\n    print(\"Starting...predict.py\")\n    kenya_crop_type_mapper()\n",
  "history_output" : "ERROR 1: PROJ: proj_identify: /opt/anaconda3/share/proj/proj.db lacks DATABASE.LAYOUT.VERSION.MAJOR / DATABASE.LAYOUT.VERSION.MINOR metadata. It comes from another PROJ installation.\n  0%|          | 0/288 [00:00<?, ?it/s]\n 89%|████████▉ | 256/288 [00:00<00:00, 2427.32it/s]ERROR 1: PROJ: proj_identify: /opt/anaconda3/share/proj/proj.db lacks DATABASE.LAYOUT.VERSION.MAJOR / DATABASE.LAYOUT.VERSION.MINOR metadata. It comes from another PROJ installation.\n320it [00:00, 996.52it/s]                          ERROR 1: PROJ: proj_identify: /opt/anaconda3/share/proj/proj.db lacks DATABASE.LAYOUT.VERSION.MAJOR / DATABASE.LAYOUT.VERSION.MINOR metadata. It comes from another PROJ installation.\n  0%|          | 0/288 [00:00<?, ?it/s]ERROR 1: PROJ: proj_identify: /opt/anaconda3/share/proj/proj.db lacks DATABASE.LAYOUT.VERSION.MAJOR / DATABASE.LAYOUT.VERSION.MINOR metadata. It comes from another PROJ installation.\n320it [00:00, 1646.63it/s]             ERROR 1: PROJ: proj_identify: /opt/anaconda3/share/proj/proj.db lacks DATABASE.LAYOUT.VERSION.MAJOR / DATABASE.LAYOUT.VERSION.MINOR metadata. It comes from another PROJ installation.\n  0%|          | 0/288 [00:00<?, ?it/s]ERROR 1: PROJ: proj_identify: /opt/anaconda3/share/proj/proj.db lacks DATABASE.LAYOUT.VERSION.MAJOR / DATABASE.LAYOUT.VERSION.MINOR metadata. It comes from another PROJ installation.\n320it [00:00, 1270.84it/s]             ERROR 1: PROJ: proj_identify: /opt/anaconda3/share/proj/proj.db lacks DATABASE.LAYOUT.VERSION.MAJOR / DATABASE.LAYOUT.VERSION.MINOR metadata. It comes from another PROJ installation.\n  0%|          | 0/288 [00:00<?, ?it/s]ERROR 1: PROJ: proj_identify: /opt/anaconda3/share/proj/proj.db lacks DATABASE.LAYOUT.VERSION.MAJOR / DATABASE.LAYOUT.VERSION.MINOR metadata. It comes from another PROJ installation.\n320it [00:00, 1696.19it/s]             ERROR 1: PROJ: proj_identify: /opt/anaconda3/share/proj/proj.db lacks DATABASE.LAYOUT.VERSION.MAJOR / DATABASE.LAYOUT.VERSION.MINOR metadata. It comes from another PROJ installation.\n  0%|          | 0/288 [00:00<?, ?it/s]ERROR 1: PROJ: proj_identify: /opt/anaconda3/share/proj/proj.db lacks DATABASE.LAYOUT.VERSION.MAJOR / DATABASE.LAYOUT.VERSION.MINOR metadata. It comes from another PROJ installation.\n320it [00:00, 1310.98it/s]             ERROR 1: PROJ: proj_identify: /opt/anaconda3/share/proj/proj.db lacks DATABASE.LAYOUT.VERSION.MAJOR / DATABASE.LAYOUT.VERSION.MINOR metadata. It comes from another PROJ installation.\n  0%|          | 0/288 [00:00<?, ?it/s]ERROR 1: PROJ: proj_identify: /opt/anaconda3/share/proj/proj.db lacks DATABASE.LAYOUT.VERSION.MAJOR / DATABASE.LAYOUT.VERSION.MINOR metadata. It comes from another PROJ installation.\n320it [00:00, 1774.60it/s]             ERROR 1: PROJ: proj_identify: /opt/anaconda3/share/proj/proj.db lacks DATABASE.LAYOUT.VERSION.MAJOR / DATABASE.LAYOUT.VERSION.MINOR metadata. It comes from another PROJ installation.\n  0%|          | 0/288 [00:00<?, ?it/s]ERROR 1: PROJ: proj_identify: /opt/anaconda3/share/proj/proj.db lacks DATABASE.LAYOUT.VERSION.MAJOR / DATABASE.LAYOUT.VERSION.MINOR metadata. It comes from another PROJ installation.\n320it [00:00, 1390.27it/s]             ERROR 1: PROJ: proj_identify: /opt/anaconda3/share/proj/proj.db lacks DATABASE.LAYOUT.VERSION.MAJOR / DATABASE.LAYOUT.VERSION.MINOR metadata. It comes from another PROJ installation.\n  0%|          | 0/288 [00:00<?, ?it/s]ERROR 1: PROJ: proj_identify: /opt/anaconda3/share/proj/proj.db lacks DATABASE.LAYOUT.VERSION.MAJOR / DATABASE.LAYOUT.VERSION.MINOR metadata. It comes from another PROJ installation.\n320it [00:00, 1676.31it/s]             ERROR 1: PROJ: proj_identify: /opt/anaconda3/share/proj/proj.db lacks DATABASE.LAYOUT.VERSION.MAJOR / DATABASE.LAYOUT.VERSION.MINOR metadata. It comes from another PROJ installation.\n  0%|          | 0/288 [00:00<?, ?it/s]ERROR 1: PROJ: proj_identify: /opt/anaconda3/share/proj/proj.db lacks DATABASE.LAYOUT.VERSION.MAJOR / DATABASE.LAYOUT.VERSION.MINOR metadata. It comes from another PROJ installation.\n320it [00:00, 1224.37it/s]             ERROR 1: PROJ: proj_identify: /opt/anaconda3/share/proj/proj.db lacks DATABASE.LAYOUT.VERSION.MAJOR / DATABASE.LAYOUT.VERSION.MINOR metadata. It comes from another PROJ installation.\n  0%|          | 0/288 [00:00<?, ?it/s]ERROR 1: PROJ: proj_identify: /opt/anaconda3/share/proj/proj.db lacks DATABASE.LAYOUT.VERSION.MAJOR / DATABASE.LAYOUT.VERSION.MINOR metadata. It comes from another PROJ installation.\n320it [00:00, 1739.48it/s]             ERROR 1: PROJ: proj_identify: /opt/anaconda3/share/proj/proj.db lacks DATABASE.LAYOUT.VERSION.MAJOR / DATABASE.LAYOUT.VERSION.MINOR metadata. It comes from another PROJ installation.\n  0%|          | 0/288 [00:00<?, ?it/s]ERROR 1: PROJ: proj_identify: /opt/anaconda3/share/proj/proj.db lacks DATABASE.LAYOUT.VERSION.MAJOR / DATABASE.LAYOUT.VERSION.MINOR metadata. It comes from another PROJ installation.\n320it [00:00, 1392.16it/s]             ERROR 1: PROJ: proj_identify: /opt/anaconda3/share/proj/proj.db lacks DATABASE.LAYOUT.VERSION.MAJOR / DATABASE.LAYOUT.VERSION.MINOR metadata. It comes from another PROJ installation.\n  0%|          | 0/288 [00:00<?, ?it/s]ERROR 1: PROJ: proj_identify: /opt/anaconda3/share/proj/proj.db lacks DATABASE.LAYOUT.VERSION.MAJOR / DATABASE.LAYOUT.VERSION.MINOR metadata. It comes from another PROJ installation.\n320it [00:00, 1787.47it/s]             ERROR 1: PROJ: proj_identify: /opt/anaconda3/share/proj/proj.db lacks DATABASE.LAYOUT.VERSION.MAJOR / DATABASE.LAYOUT.VERSION.MINOR metadata. It comes from another PROJ installation.\n  0%|          | 0/288 [00:00<?, ?it/s]ERROR 1: PROJ: proj_identify: /opt/anaconda3/share/proj/proj.db lacks DATABASE.LAYOUT.VERSION.MAJOR / DATABASE.LAYOUT.VERSION.MINOR metadata. It comes from another PROJ installation.\n320it [00:00, 1430.02it/s]             ERROR 1: PROJ: proj_identify: /opt/anaconda3/share/proj/proj.db lacks DATABASE.LAYOUT.VERSION.MAJOR / DATABASE.LAYOUT.VERSION.MINOR metadata. It comes from another PROJ installation.\n  0%|          | 0/288 [00:00<?, ?it/s]ERROR 1: PROJ: proj_identify: /opt/anaconda3/share/proj/proj.db lacks DATABASE.LAYOUT.VERSION.MAJOR / DATABASE.LAYOUT.VERSION.MINOR metadata. It comes from another PROJ installation.\n320it [00:00, 1688.93it/s]             ERROR 1: PROJ: proj_identify: /opt/anaconda3/share/proj/proj.db lacks DATABASE.LAYOUT.VERSION.MAJOR / DATABASE.LAYOUT.VERSION.MINOR metadata. It comes from another PROJ installation.\n  0%|          | 0/288 [00:00<?, ?it/s]ERROR 1: PROJ: proj_identify: /opt/anaconda3/share/proj/proj.db lacks DATABASE.LAYOUT.VERSION.MAJOR / DATABASE.LAYOUT.VERSION.MINOR metadata. It comes from another PROJ installation.\n320it [00:00, 1451.21it/s]             ERROR 1: PROJ: proj_identify: /opt/anaconda3/share/proj/proj.db lacks DATABASE.LAYOUT.VERSION.MAJOR / DATABASE.LAYOUT.VERSION.MINOR metadata. It comes from another PROJ installation.\n  0%|          | 0/288 [00:00<?, ?it/s]ERROR 1: PROJ: proj_identify: /opt/anaconda3/share/proj/proj.db lacks DATABASE.LAYOUT.VERSION.MAJOR / DATABASE.LAYOUT.VERSION.MINOR metadata. It comes from another PROJ installation.\n320it [00:00, 1805.54it/s]             ERROR 1: PROJ: proj_identify: /opt/anaconda3/share/proj/proj.db lacks DATABASE.LAYOUT.VERSION.MAJOR / DATABASE.LAYOUT.VERSION.MINOR metadata. It comes from another PROJ installation.\n  0%|          | 0/305 [00:00<?, ?it/s]ERROR 1: PROJ: proj_identify: /opt/anaconda3/share/proj/proj.db lacks DATABASE.LAYOUT.VERSION.MAJOR / DATABASE.LAYOUT.VERSION.MINOR metadata. It comes from another PROJ installation.\n320it [00:00, 1416.07it/s]             ERROR 1: PROJ: proj_identify: /opt/anaconda3/share/proj/proj.db lacks DATABASE.LAYOUT.VERSION.MAJOR / DATABASE.LAYOUT.VERSION.MINOR metadata. It comes from another PROJ installation.\n  0%|          | 0/305 [00:00<?, ?it/s]ERROR 1: PROJ: proj_identify: /opt/anaconda3/share/proj/proj.db lacks DATABASE.LAYOUT.VERSION.MAJOR / DATABASE.LAYOUT.VERSION.MINOR metadata. It comes from another PROJ installation.\n320it [00:00, 1839.96it/s]             ERROR 1: PROJ: proj_identify: /opt/anaconda3/share/proj/proj.db lacks DATABASE.LAYOUT.VERSION.MAJOR / DATABASE.LAYOUT.VERSION.MINOR metadata. It comes from another PROJ installation.\n  0%|          | 0/288 [00:00<?, ?it/s]ERROR 1: PROJ: proj_identify: /opt/anaconda3/share/proj/proj.db lacks DATABASE.LAYOUT.VERSION.MAJOR / DATABASE.LAYOUT.VERSION.MINOR metadata. It comes from another PROJ installation.\n320it [00:00, 1428.96it/s]             ERROR 1: PROJ: proj_identify: /opt/anaconda3/share/proj/proj.db lacks DATABASE.LAYOUT.VERSION.MAJOR / DATABASE.LAYOUT.VERSION.MINOR metadata. It comes from another PROJ installation.\n  0%|          | 0/288 [00:00<?, ?it/s]ERROR 1: PROJ: proj_identify: /opt/anaconda3/share/proj/proj.db lacks DATABASE.LAYOUT.VERSION.MAJOR / DATABASE.LAYOUT.VERSION.MINOR metadata. It comes from another PROJ installation.\n320it [00:00, 1767.08it/s]             \nStarting...predict.py\n<generator object Path.glob at 0x7fbc34a9f120>\nUsing model ../data/lightning_logs/version_13/checkpoints/epoch=165.ckpt\nPredicting 7 timesteps in the forecaster\nUsing 1 layers for the global classifier\nUsing 2 layers for the local classifier\nRunning for ../data/raw/earth_engine_plant_village_kenya/1_2019-04-22_2020-04-16.tif\nNo GPU - not using one\nNo GPU - not using one\nRunning for ../data/raw/earth_engine_plant_village_kenya/9_2019-04-22_2020-04-16.tif\nNo GPU - not using one\nNo GPU - not using one\nRunning for ../data/raw/earth_engine_plant_village_kenya/6_2019-04-22_2020-04-16.tif\nNo GPU - not using one\nNo GPU - not using one\nRunning for ../data/raw/earth_engine_plant_village_kenya/3_2019-04-22_2020-04-16.tif\nNo GPU - not using one\nNo GPU - not using one\nRunning for ../data/raw/earth_engine_plant_village_kenya/4_2019-04-22_2020-04-16.tif\nNo GPU - not using one\nNo GPU - not using one\nRunning for ../data/raw/earth_engine_plant_village_kenya/5_2019-04-22_2020-04-16.tif\nNo GPU - not using one\nNo GPU - not using one\nRunning for ../data/raw/earth_engine_plant_village_kenya/0_2018-04-21_2019-04-16.tif\nNo GPU - not using one\nNo GPU - not using one\nRunning for ../data/raw/earth_engine_plant_village_kenya/2_2019-04-22_2020-04-16.tif\nNo GPU - not using one\nNo GPU - not using one\nRunning for ../data/raw/earth_engine_plant_village_kenya/7_2019-04-22_2020-04-16.tif\nNo GPU - not using one\nNo GPU - not using one\nRunning for ../data/raw/earth_engine_plant_village_kenya/8_2019-04-22_2020-04-16.tif\nNo GPU - not using one\nNo GPU - not using one\n",
  "history_begin_time" : 1647345506260,
  "history_end_time" : 1647345538694,
  "history_notes" : null,
  "history_process" : "delykw",
  "host_id" : null,
  "indicator" : "Done"
},{
  "history_id" : "3D68RCE17eVc",
  "history_input" : "from pathlib import Path\nimport sys\n\nsys.path.append(\"..\")\n\nfrom src_models_model import Model\nfrom src_analysis import plot_results\n\n\ndef kenya_crop_type_mapper():\n    data_dir = \"../data\"\n\n    test_folder = Path(\"../data/raw/earth_engine_plant_village_kenya/\")\n    test_files = test_folder.glob(\"*.tif\")\n    print(test_files)\n\n    list_of_models = list(Path('../data/lightning_logs/').glob('version*/checkpoints/*.ckpt'))\n    latest_model_path = str(max(list_of_models, key=os.path.getctime))\n    print(f\"Using model {latest_model_path}\")\n\n    model = Model.load_from_checkpoint(latest_model_path)\n\n    for test_path in test_files:\n\n        save_dir = Path(data_dir) / \"Autoencoder\"\n        save_dir.mkdir(exist_ok=True)\n\n        print(f\"Running for {test_path}\")\n\n        savepath = save_dir / f\"preds_{test_path.name}\"\n        if savepath.exists():\n            print(\"File already generated. Skipping\")\n            continue\n\n        out_forecasted = model.predict(test_path, with_forecaster=True)\n        plot_results(out_forecasted, test_path, savepath=save_dir, prefix=\"forecasted_\")\n\n        out_normal = model.predict(test_path, with_forecaster=False)\n        plot_results(out_normal, test_path, savepath=save_dir, prefix=\"full_input_\")\n\n        out_forecasted.to_netcdf(save_dir / f\"preds_forecasted_{test_path.name}.nc\")\n        out_normal.to_netcdf(save_dir / f\"preds_normal_{test_path.name}.nc\")\n\n\nif __name__ == \"__main__\":\n    print(\"Starting...predict.py\")\n    kenya_crop_type_mapper()\n",
  "history_output" : "Starting...predict.py\n<generator object Path.glob at 0x7fa29ea9e120>\nTraceback (most recent call last):\n  File \"scripts_predict.py\", line 47, in <module>\n    kenya_crop_type_mapper()\n  File \"scripts_predict.py\", line 18, in kenya_crop_type_mapper\n    latest_model_path = str(max(list_of_models, key=os.path.getctime))\nNameError: name 'os' is not defined\n",
  "history_begin_time" : 1647345489698,
  "history_end_time" : 1647345492925,
  "history_notes" : null,
  "history_process" : "delykw",
  "host_id" : null,
  "indicator" : "Done"
},{
  "history_id" : "iBr0ZQ2hsPa8",
  "history_input" : "from pathlib import Path\nimport sys\n\nsys.path.append(\"..\")\n\nfrom src_models_model import Model\nfrom src_analysis import plot_results\n\n\ndef kenya_crop_type_mapper():\n    data_dir = \"../data\"\n\n    test_folder = Path(\"../data/raw/earth_engine_plant_village_kenya/\")\n    test_files = test_folder.glob(\"*.tif\")\n    print(test_files)\n\n    list_of_models = list(Path('../data/lightning_logs/').glob('version*/checkpoints/*.ckpt'))\n    latest_model_path = str(max(list_of_checkpoints, key=os.path.getctime))\n    print(f\"Using model {latest_model_path}\")\n\n    model = Model.load_from_checkpoint(latest_model_path)\n\n    for test_path in test_files:\n\n        save_dir = Path(data_dir) / \"Autoencoder\"\n        save_dir.mkdir(exist_ok=True)\n\n        print(f\"Running for {test_path}\")\n\n        savepath = save_dir / f\"preds_{test_path.name}\"\n        if savepath.exists():\n            print(\"File already generated. Skipping\")\n            continue\n\n        out_forecasted = model.predict(test_path, with_forecaster=True)\n        plot_results(out_forecasted, test_path, savepath=save_dir, prefix=\"forecasted_\")\n\n        out_normal = model.predict(test_path, with_forecaster=False)\n        plot_results(out_normal, test_path, savepath=save_dir, prefix=\"full_input_\")\n\n        out_forecasted.to_netcdf(save_dir / f\"preds_forecasted_{test_path.name}.nc\")\n        out_normal.to_netcdf(save_dir / f\"preds_normal_{test_path.name}.nc\")\n\n\nif __name__ == \"__main__\":\n    print(\"Starting...predict.py\")\n    kenya_crop_type_mapper()\n",
  "history_output" : "Starting...predict.py\n<generator object Path.glob at 0x7fbf1e39e120>\nTraceback (most recent call last):\n  File \"scripts_predict.py\", line 47, in <module>\n    kenya_crop_type_mapper()\n  File \"scripts_predict.py\", line 18, in kenya_crop_type_mapper\n    latest_model_path = str(max(list_of_checkpoints, key=os.path.getctime))\nNameError: name 'list_of_checkpoints' is not defined\n",
  "history_begin_time" : 1647345467945,
  "history_end_time" : 1647345473633,
  "history_notes" : null,
  "history_process" : "delykw",
  "host_id" : null,
  "indicator" : "Done"
},{
  "history_id" : "xlbgvgpuqq7",
  "history_input" : "from pathlib import Path\nimport sys\n\nsys.path.append(\"..\")\n\nfrom src_models_model import Model\nfrom src_analysis import plot_results\n\n\ndef kenya_crop_type_mapper():\n    data_dir = \"../data\"\n\n    test_folder = Path(\"../data/raw/earth_engine_plant_village_kenya/\")\n    test_files = test_folder.glob(\"*.tif\")\n    print(test_files)\n\n    model_path = \"../data/lightning_logs/version_8/checkpoints/epoch=165.ckpt\"\n    print(f\"Using model {model_path}\")\n\n    model = Model.load_from_checkpoint(model_path)\n\n    for test_path in test_files:\n\n        save_dir = Path(data_dir) / \"Autoencoder\"\n        save_dir.mkdir(exist_ok=True)\n\n        print(f\"Running for {test_path}\")\n\n        savepath = save_dir / f\"preds_{test_path.name}\"\n        if savepath.exists():\n            print(\"File already generated. Skipping\")\n            continue\n\n        out_forecasted = model.predict(test_path, with_forecaster=True)\n        plot_results(out_forecasted, test_path, savepath=save_dir, prefix=\"forecasted_\")\n\n        out_normal = model.predict(test_path, with_forecaster=False)\n        plot_results(out_normal, test_path, savepath=save_dir, prefix=\"full_input_\")\n\n        out_forecasted.to_netcdf(save_dir / f\"preds_forecasted_{test_path.name}.nc\")\n        out_normal.to_netcdf(save_dir / f\"preds_normal_{test_path.name}.nc\")\n\n\nif __name__ == \"__main__\":\n    print(\"Starting...predict.py\")\n    kenya_crop_type_mapper()\n",
  "history_output" : "",
  "history_begin_time" : 1647340172206,
  "history_end_time" : 1647340174334,
  "history_notes" : null,
  "history_process" : "delykw",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "78hlq0442nu",
  "history_input" : "from pathlib import Path\nimport sys\n\nsys.path.append(\"..\")\n\nfrom src_models_model import Model\nfrom src_analysis import plot_results\n\n\ndef kenya_crop_type_mapper():\n    data_dir = \"../data\"\n\n    test_folder = Path(\"../data/raw/earth_engine_plant_village_kenya/\")\n    test_files = test_folder.glob(\"*.tif\")\n    print(test_files)\n\n    model_path = \"../data/lightning_logs/version_8/checkpoints/epoch=165.ckpt\"\n    print(f\"Using model {model_path}\")\n\n    model = Model.load_from_checkpoint(model_path)\n\n    for test_path in test_files:\n\n        save_dir = Path(data_dir) / \"Autoencoder\"\n        save_dir.mkdir(exist_ok=True)\n\n        print(f\"Running for {test_path}\")\n\n        savepath = save_dir / f\"preds_{test_path.name}\"\n        if savepath.exists():\n            print(\"File already generated. Skipping\")\n            continue\n\n        out_forecasted = model.predict(test_path, with_forecaster=True)\n        plot_results(out_forecasted, test_path, savepath=save_dir, prefix=\"forecasted_\")\n\n        out_normal = model.predict(test_path, with_forecaster=False)\n        plot_results(out_normal, test_path, savepath=save_dir, prefix=\"full_input_\")\n\n        out_forecasted.to_netcdf(save_dir / f\"preds_forecasted_{test_path.name}.nc\")\n        out_normal.to_netcdf(save_dir / f\"preds_normal_{test_path.name}.nc\")\n\n\nif __name__ == \"__main__\":\n    print(\"Starting...predict.py\")\n    kenya_crop_type_mapper()\n",
  "history_output" : "",
  "history_begin_time" : 1646147754204,
  "history_end_time" : 1646147756996,
  "history_notes" : null,
  "history_process" : "delykw",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "9g6yk0rnee3",
  "history_input" : "from pathlib import Path\nimport sys\n\nsys.path.append(\"..\")\n\nfrom src_models_model import Model\nfrom src_analysis import plot_results\n\n\ndef kenya_crop_type_mapper():\n    data_dir = \"../data\"\n\n    test_folder = Path(\"../data/raw/earth_engine_plant_village_kenya/\")\n    test_files = test_folder.glob(\"*.tif\")\n    print(test_files)\n\n    model_path = \"../data/lightning_logs/version_8/checkpoints/epoch=165.ckpt\"\n    print(f\"Using model {model_path}\")\n\n    model = Model.load_from_checkpoint(model_path)\n\n    for test_path in test_files:\n\n        save_dir = Path(data_dir) / \"Autoencoder\"\n        save_dir.mkdir(exist_ok=True)\n\n        print(f\"Running for {test_path}\")\n\n        savepath = save_dir / f\"preds_{test_path.name}\"\n        if savepath.exists():\n            print(\"File already generated. Skipping\")\n            continue\n\n        out_forecasted = model.predict(test_path, with_forecaster=True)\n        plot_results(out_forecasted, test_path, savepath=save_dir, prefix=\"forecasted_\")\n\n        out_normal = model.predict(test_path, with_forecaster=False)\n        plot_results(out_normal, test_path, savepath=save_dir, prefix=\"full_input_\")\n\n        out_forecasted.to_netcdf(save_dir / f\"preds_forecasted_{test_path.name}.nc\")\n        out_normal.to_netcdf(save_dir / f\"preds_normal_{test_path.name}.nc\")\n\n\nif __name__ == \"__main__\":\n    print(\"Starting...predict.py\")\n    kenya_crop_type_mapper()\n",
  "history_output" : "  0%|          | 0/288 [00:00<?, ?it/s]\n 67%|██████▋   | 192/288 [00:00<00:00, 1896.41it/s]\n320it [00:00, 1235.33it/s]                         \n  0%|          | 0/288 [00:00<?, ?it/s]\n320it [00:00, 2256.37it/s]             \n  0%|          | 0/288 [00:00<?, ?it/s]\n320it [00:00, 1680.58it/s]             \n  0%|          | 0/288 [00:00<?, ?it/s]\n320it [00:00, 2096.89it/s]             \n  0%|          | 0/288 [00:00<?, ?it/s]\n320it [00:00, 1633.60it/s]             \n  0%|          | 0/288 [00:00<?, ?it/s]\n320it [00:00, 2211.34it/s]             \n  0%|          | 0/288 [00:00<?, ?it/s]\n320it [00:00, 1659.17it/s]             \n  0%|          | 0/288 [00:00<?, ?it/s]\n320it [00:00, 1901.12it/s]             \n  0%|          | 0/288 [00:00<?, ?it/s]\n320it [00:00, 1628.67it/s]             \n  0%|          | 0/288 [00:00<?, ?it/s]\n320it [00:00, 2178.00it/s]             \n  0%|          | 0/288 [00:00<?, ?it/s]\n320it [00:00, 1465.99it/s]             \n  0%|          | 0/288 [00:00<?, ?it/s]\n320it [00:00, 2286.42it/s]             \n  0%|          | 0/288 [00:00<?, ?it/s]\n320it [00:00, 1384.55it/s]             \n  0%|          | 0/288 [00:00<?, ?it/s]\n320it [00:00, 2043.76it/s]             \n  0%|          | 0/288 [00:00<?, ?it/s]\n320it [00:00, 1619.01it/s]             \n  0%|          | 0/288 [00:00<?, ?it/s]\n320it [00:00, 2269.52it/s]             \n  0%|          | 0/305 [00:00<?, ?it/s]\n320it [00:00, 1565.40it/s]             \n  0%|          | 0/305 [00:00<?, ?it/s]\n320it [00:00, 2311.94it/s]             \n  0%|          | 0/288 [00:00<?, ?it/s]\n320it [00:00, 1621.36it/s]             \n  0%|          | 0/288 [00:00<?, ?it/s]\n320it [00:00, 2303.35it/s]             \nStarting...predict.py\n<generator object Path.glob at 0x7ffe2781c200>\nUsing model ../data/lightning_logs/version_8/checkpoints/epoch=165.ckpt\nPredicting 7 timesteps in the forecaster\nUsing 1 layers for the global classifier\nUsing 2 layers for the local classifier\nRunning for ../data/raw/earth_engine_plant_village_kenya/1_2019-04-22_2020-04-16.tif\nNo GPU - not using one\nNo GPU - not using one\nRunning for ../data/raw/earth_engine_plant_village_kenya/9_2019-04-22_2020-04-16.tif\nNo GPU - not using one\nNo GPU - not using one\nRunning for ../data/raw/earth_engine_plant_village_kenya/6_2019-04-22_2020-04-16.tif\nNo GPU - not using one\nNo GPU - not using one\nRunning for ../data/raw/earth_engine_plant_village_kenya/3_2019-04-22_2020-04-16.tif\nNo GPU - not using one\nNo GPU - not using one\nRunning for ../data/raw/earth_engine_plant_village_kenya/4_2019-04-22_2020-04-16.tif\nNo GPU - not using one\nNo GPU - not using one\nRunning for ../data/raw/earth_engine_plant_village_kenya/5_2019-04-22_2020-04-16.tif\nNo GPU - not using one\nNo GPU - not using one\nRunning for ../data/raw/earth_engine_plant_village_kenya/0_2018-04-21_2019-04-16.tif\nNo GPU - not using one\nNo GPU - not using one\nRunning for ../data/raw/earth_engine_plant_village_kenya/2_2019-04-22_2020-04-16.tif\nNo GPU - not using one\nNo GPU - not using one\nRunning for ../data/raw/earth_engine_plant_village_kenya/7_2019-04-22_2020-04-16.tif\nNo GPU - not using one\nNo GPU - not using one\nRunning for ../data/raw/earth_engine_plant_village_kenya/8_2019-04-22_2020-04-16.tif\nNo GPU - not using one\nNo GPU - not using one\n",
  "history_begin_time" : 1646145452688,
  "history_end_time" : 1646145483423,
  "history_notes" : null,
  "history_process" : "delykw",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "q2g6i0vymhv",
  "history_input" : "from pathlib import Path\nimport sys\n\nsys.path.append(\"..\")\n\nfrom src_models_model import Model\nfrom src_analysis import plot_results\n\n\ndef kenya_crop_type_mapper():\n    data_dir = \"../data\"\n\n    test_folder = Path(\"../data/raw/earth_engine_plant_village_kenya/\")\n    test_files = test_folder.glob(\"*.tif\")\n    print(test_files)\n\n    model_path = \"../data/lightning_logs/version_8/checkpoints/epoch=165.ckpt\"\n    print(f\"Using model {model_path}\")\n\n    model = Model.load_from_checkpoint(model_path)\n\n    for test_path in test_files:\n\n        save_dir = Path(data_dir) / \"Autoencoder\"\n        save_dir.mkdir(exist_ok=True)\n\n        print(f\"Running for {test_path}\")\n\n        savepath = save_dir / f\"preds_{test_path.name}\"\n        if savepath.exists():\n            print(\"File already generated. Skipping\")\n            continue\n\n        out_forecasted = model.predict(test_path, with_forecaster=True)\n        plot_results(out_forecasted, test_path, savepath=save_dir, prefix=\"forecasted_\")\n\n        out_normal = model.predict(test_path, with_forecaster=False)\n        plot_results(out_normal, test_path, savepath=save_dir, prefix=\"full_input_\")\n\n        out_forecasted.to_netcdf(save_dir / f\"preds_forecasted_{test_path.name}.nc\")\n        out_normal.to_netcdf(save_dir / f\"preds_normal_{test_path.name}.nc\")\n\n\nif __name__ == \"__main__\":\n    print(\"Starting...predict.py\")\n    kenya_crop_type_mapper()\n",
  "history_output" : "  0%|          | 0/288 [00:00<?, ?it/s]\n320it [00:00, 1596.69it/s]             \n  0%|          | 0/288 [00:00<?, ?it/s]\n320it [00:00, 1654.08it/s]             \n  0%|          | 0/288 [00:00<?, ?it/s]\n320it [00:00, 1626.51it/s]             \n  0%|          | 0/288 [00:00<?, ?it/s]\n320it [00:00, 2314.16it/s]             \n  0%|          | 0/288 [00:00<?, ?it/s]\n320it [00:00, 3199.36it/s]             \n320it [00:00, 1463.39it/s]\n  0%|          | 0/288 [00:00<?, ?it/s]\n320it [00:00, 2016.10it/s]             \n  0%|          | 0/288 [00:00<?, ?it/s]\n320it [00:00, 1630.42it/s]             \n  0%|          | 0/288 [00:00<?, ?it/s]\n320it [00:00, 2285.99it/s]             \n  0%|          | 0/288 [00:00<?, ?it/s]\n320it [00:00, 1591.15it/s]             \n  0%|          | 0/288 [00:00<?, ?it/s]\n320it [00:00, 2363.15it/s]             \n  0%|          | 0/288 [00:00<?, ?it/s]\n320it [00:00, 2913.64it/s]             \n320it [00:00, 1236.83it/s]\n  0%|          | 0/288 [00:00<?, ?it/s]\n320it [00:00, 2136.64it/s]             \n  0%|          | 0/288 [00:00<?, ?it/s]\n320it [00:00, 1500.30it/s]             \n  0%|          | 0/288 [00:00<?, ?it/s]\n320it [00:00, 2061.24it/s]             \n  0%|          | 0/288 [00:00<?, ?it/s]\n320it [00:00, 1433.04it/s]             \n  0%|          | 0/288 [00:00<?, ?it/s]\n320it [00:00, 2250.16it/s]             \n  0%|          | 0/305 [00:00<?, ?it/s]\n320it [00:00, 1662.94it/s]             \n  0%|          | 0/305 [00:00<?, ?it/s]\n320it [00:00, 2189.92it/s]             \n  0%|          | 0/288 [00:00<?, ?it/s]\n320it [00:00, 1707.62it/s]             \n  0%|          | 0/288 [00:00<?, ?it/s]\n320it [00:00, 2308.74it/s]             \nStarting...predict.py\n<generator object Path.glob at 0x7fdf0019b200>\nUsing model ../data/lightning_logs/version_8/checkpoints/epoch=165.ckpt\nPredicting 7 timesteps in the forecaster\nUsing 1 layers for the global classifier\nUsing 2 layers for the local classifier\nRunning for ../data/raw/earth_engine_plant_village_kenya/1_2019-04-22_2020-04-16.tif\nNo GPU - not using one\nNo GPU - not using one\nRunning for ../data/raw/earth_engine_plant_village_kenya/9_2019-04-22_2020-04-16.tif\nNo GPU - not using one\nNo GPU - not using one\nRunning for ../data/raw/earth_engine_plant_village_kenya/6_2019-04-22_2020-04-16.tif\nNo GPU - not using one\nNo GPU - not using one\nRunning for ../data/raw/earth_engine_plant_village_kenya/3_2019-04-22_2020-04-16.tif\nNo GPU - not using one\nNo GPU - not using one\nRunning for ../data/raw/earth_engine_plant_village_kenya/4_2019-04-22_2020-04-16.tif\nNo GPU - not using one\nNo GPU - not using one\nRunning for ../data/raw/earth_engine_plant_village_kenya/5_2019-04-22_2020-04-16.tif\nNo GPU - not using one\nNo GPU - not using one\nRunning for ../data/raw/earth_engine_plant_village_kenya/0_2018-04-21_2019-04-16.tif\nNo GPU - not using one\nNo GPU - not using one\nRunning for ../data/raw/earth_engine_plant_village_kenya/2_2019-04-22_2020-04-16.tif\nNo GPU - not using one\nNo GPU - not using one\nRunning for ../data/raw/earth_engine_plant_village_kenya/7_2019-04-22_2020-04-16.tif\nNo GPU - not using one\nNo GPU - not using one\nRunning for ../data/raw/earth_engine_plant_village_kenya/8_2019-04-22_2020-04-16.tif\nNo GPU - not using one\nNo GPU - not using one\n",
  "history_begin_time" : 1646145239467,
  "history_end_time" : 1646145269732,
  "history_notes" : null,
  "history_process" : "delykw",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "76z9d4it3iq",
  "history_input" : "from pathlib import Path\nimport sys\n\nsys.path.append(\"..\")\n\nfrom src_models_model import Model\nfrom src_analysis import plot_results\n\n\ndef kenya_crop_type_mapper():\n    data_dir = \"../data\"\n\n    test_folder = Path(\"../data/raw/earth_engine_plant_village_kenya/\")\n    test_files = test_folder.glob(\"*.tif\")\n    print(test_files)\n\n    model_path = \"../data/lightning_logs/version_8/checkpoints/epoch=165.ckpt\"\n    print(f\"Using model {model_path}\")\n\n    model = Model.load_from_checkpoint(model_path)\n\n    for test_path in test_files:\n\n        save_dir = Path(data_dir) / \"Autoencoder\"\n        save_dir.mkdir(exist_ok=True)\n\n        print(f\"Running for {test_path}\")\n\n        savepath = save_dir / f\"preds_{test_path.name}\"\n        if savepath.exists():\n            print(\"File already generated. Skipping\")\n            continue\n\n        out_forecasted = model.predict(test_path, with_forecaster=True)\n        plot_results(out_forecasted, test_path, savepath=save_dir, prefix=\"forecasted_\")\n\n        out_normal = model.predict(test_path, with_forecaster=False)\n        plot_results(out_normal, test_path, savepath=save_dir, prefix=\"full_input_\")\n\n        out_forecasted.to_netcdf(save_dir / f\"preds_forecasted_{test_path.name}.nc\")\n        out_normal.to_netcdf(save_dir / f\"preds_normal_{test_path.name}.nc\")\n\n\nif __name__ == \"__main__\":\n    print(\"Starting...predict.py\")\n    kenya_crop_type_mapper()\n",
  "history_output" : "  0%|          | 0/288 [00:00<?, ?it/s]\n 89%|████████▉ | 256/288 [00:00<00:00, 2548.30it/s]\n320it [00:00, 1339.84it/s]                         \n  0%|          | 0/288 [00:00<?, ?it/s]\n320it [00:00, 2182.87it/s]             \n  0%|          | 0/288 [00:00<?, ?it/s]\n320it [00:00, 1609.84it/s]             \n  0%|          | 0/288 [00:00<?, ?it/s]\n320it [00:00, 2264.73it/s]             \n  0%|          | 0/288 [00:00<?, ?it/s]\n320it [00:00, 1627.03it/s]             \n  0%|          | 0/288 [00:00<?, ?it/s]\n320it [00:00, 2183.51it/s]             \n  0%|          | 0/288 [00:00<?, ?it/s]\n320it [00:00, 1623.84it/s]             \n  0%|          | 0/288 [00:00<?, ?it/s]\n320it [00:00, 2312.87it/s]             \n  0%|          | 0/288 [00:00<?, ?it/s]\n320it [00:00, 1393.75it/s]             \n  0%|          | 0/288 [00:00<?, ?it/s]\n320it [00:00, 2220.46it/s]             \n  0%|          | 0/288 [00:00<?, ?it/s]\n320it [00:00, 1602.59it/s]             \n  0%|          | 0/288 [00:00<?, ?it/s]\n320it [00:00, 2300.45it/s]             \n  0%|          | 0/288 [00:00<?, ?it/s]\n320it [00:00, 1635.25it/s]             \n  0%|          | 0/288 [00:00<?, ?it/s]\n320it [00:00, 2374.81it/s]             \n  0%|          | 0/288 [00:00<?, ?it/s]\n320it [00:00, 1660.34it/s]             \n  0%|          | 0/288 [00:00<?, ?it/s]\n320it [00:00, 2323.12it/s]             \n  0%|          | 0/305 [00:00<?, ?it/s]\n320it [00:00, 1322.31it/s]             \n  0%|          | 0/305 [00:00<?, ?it/s]\n320it [00:00, 2248.38it/s]             \n  0%|          | 0/288 [00:00<?, ?it/s]\n320it [00:00, 1622.86it/s]             \n  0%|          | 0/288 [00:00<?, ?it/s]\n320it [00:00, 2291.11it/s]             \nStarting...predict.py\n<generator object Path.glob at 0x7f92c4818200>\nUsing model ../data/lightning_logs/version_8/checkpoints/epoch=165.ckpt\nPredicting 7 timesteps in the forecaster\nUsing 1 layers for the global classifier\nUsing 2 layers for the local classifier\nRunning for ../data/raw/earth_engine_plant_village_kenya/1_2019-04-22_2020-04-16.tif\nNo GPU - not using one\nNo GPU - not using one\nRunning for ../data/raw/earth_engine_plant_village_kenya/9_2019-04-22_2020-04-16.tif\nNo GPU - not using one\nNo GPU - not using one\nRunning for ../data/raw/earth_engine_plant_village_kenya/6_2019-04-22_2020-04-16.tif\nNo GPU - not using one\nNo GPU - not using one\nRunning for ../data/raw/earth_engine_plant_village_kenya/3_2019-04-22_2020-04-16.tif\nNo GPU - not using one\nNo GPU - not using one\nRunning for ../data/raw/earth_engine_plant_village_kenya/4_2019-04-22_2020-04-16.tif\nNo GPU - not using one\nNo GPU - not using one\nRunning for ../data/raw/earth_engine_plant_village_kenya/5_2019-04-22_2020-04-16.tif\nNo GPU - not using one\nNo GPU - not using one\nRunning for ../data/raw/earth_engine_plant_village_kenya/0_2018-04-21_2019-04-16.tif\nNo GPU - not using one\nNo GPU - not using one\nRunning for ../data/raw/earth_engine_plant_village_kenya/2_2019-04-22_2020-04-16.tif\nNo GPU - not using one\nNo GPU - not using one\nRunning for ../data/raw/earth_engine_plant_village_kenya/7_2019-04-22_2020-04-16.tif\nNo GPU - not using one\nNo GPU - not using one\nRunning for ../data/raw/earth_engine_plant_village_kenya/8_2019-04-22_2020-04-16.tif\nNo GPU - not using one\nNo GPU - not using one\n",
  "history_begin_time" : 1646144630814,
  "history_end_time" : 1646144661933,
  "history_notes" : null,
  "history_process" : "delykw",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "nh2wd3ebrxz",
  "history_input" : "from pathlib import Path\nimport sys\n\nsys.path.append(\"..\")\n\nfrom src_models_model import Model\nfrom src_analysis import plot_results\n\n\ndef kenya_crop_type_mapper():\n    data_dir = \"../data\"\n\n    test_folder = Path(\"../data/raw/earth_engine_plant_village_kenya/\")\n    test_files = test_folder.glob(\"*.tif\")\n    print(test_files)\n\n    model_path = \"../data/lightning_logs/version_0/checkpoints/\"\n    checkpoint = list(model_path.glob(\"*.ckpt\"))\n    print(f\"Using model {str(checkpoint[0])}\")\n\n    model = Model.load_from_checkpoint(str(checkpoint[0]))\n\n    for test_path in test_files:\n\n        save_dir = Path(data_dir) / \"Autoencoder\"\n        save_dir.mkdir(exist_ok=True)\n\n        print(f\"Running for {test_path}\")\n\n        savepath = save_dir / f\"preds_{test_path.name}\"\n        if savepath.exists():\n            print(\"File already generated. Skipping\")\n            continue\n\n        out_forecasted = model.predict(test_path, with_forecaster=True)\n        plot_results(out_forecasted, test_path, savepath=save_dir, prefix=\"forecasted_\")\n\n        out_normal = model.predict(test_path, with_forecaster=False)\n        plot_results(out_normal, test_path, savepath=save_dir, prefix=\"full_input_\")\n\n        out_forecasted.to_netcdf(save_dir / f\"preds_forecasted_{test_path.name}.nc\")\n        out_normal.to_netcdf(save_dir / f\"preds_normal_{test_path.name}.nc\")\n\n\nif __name__ == \"__main__\":\n    print(\"Starting...predict.py\")\n    kenya_crop_type_mapper()\n",
  "history_output" : "Starting...predict.py\n<generator object Path.glob at 0x7feb73118200>\nTraceback (most recent call last):\n  File \"scripts_predict.py\", line 47, in <module>\n    kenya_crop_type_mapper()\n  File \"scripts_predict.py\", line 18, in kenya_crop_type_mapper\n    checkpoint = list(model_path.glob(\"*.ckpt\"))\nAttributeError: 'str' object has no attribute 'glob'\n",
  "history_begin_time" : 1646144409721,
  "history_end_time" : 1646144413274,
  "history_notes" : null,
  "history_process" : "delykw",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "3i2ztb84umm",
  "history_input" : "from pathlib import Path\nimport sys\n\nsys.path.append(\"..\")\n\nfrom src_models_model import Model\nfrom src_analysis import plot_results\n\n\ndef kenya_crop_type_mapper():\n    data_dir = \"../data\"\n\n    test_folder = Path(\"../data/raw/earth_engine_plant_village_kenya/\")\n    test_files = test_folder.glob(\"*.tif\")\n    print(test_files)\n\n    model_path = \"../data/lightning_logs/version_0/checkpoints/\"\n    checkpoint = list(log_folder.glob(\"*.ckpt\"))\n    print(f\"Using model {str(checkpoint[0])}\")\n\n    model = Model.load_from_checkpoint(str(checkpoint[0]))\n\n    for test_path in test_files:\n\n        save_dir = Path(data_dir) / \"Autoencoder\"\n        save_dir.mkdir(exist_ok=True)\n\n        print(f\"Running for {test_path}\")\n\n        savepath = save_dir / f\"preds_{test_path.name}\"\n        if savepath.exists():\n            print(\"File already generated. Skipping\")\n            continue\n\n        out_forecasted = model.predict(test_path, with_forecaster=True)\n        plot_results(out_forecasted, test_path, savepath=save_dir, prefix=\"forecasted_\")\n\n        out_normal = model.predict(test_path, with_forecaster=False)\n        plot_results(out_normal, test_path, savepath=save_dir, prefix=\"full_input_\")\n\n        out_forecasted.to_netcdf(save_dir / f\"preds_forecasted_{test_path.name}.nc\")\n        out_normal.to_netcdf(save_dir / f\"preds_normal_{test_path.name}.nc\")\n\n\nif __name__ == \"__main__\":\n    print(\"Starting...predict.py\")\n    kenya_crop_type_mapper()\n",
  "history_output" : "Starting...predict.py\n<generator object Path.glob at 0x7fa8a929b200>\nTraceback (most recent call last):\n  File \"scripts_predict.py\", line 47, in <module>\n    kenya_crop_type_mapper()\n  File \"scripts_predict.py\", line 18, in kenya_crop_type_mapper\n    checkpoint = list(log_folder.glob(\"*.ckpt\"))\nNameError: name 'log_folder' is not defined\n",
  "history_begin_time" : 1646144338527,
  "history_end_time" : 1646144341984,
  "history_notes" : null,
  "history_process" : "delykw",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "6cgotf8omek",
  "history_input" : "from pathlib import Path\nimport sys\n\nsys.path.append(\"..\")\n\nfrom src_models_model import Model\nfrom src_analysis import plot_results\n\n\ndef kenya_crop_type_mapper():\n    data_dir = \"../data\"\n\n    test_folder = Path(\"../data/raw/earth_engine_plant_village_kenya/\")\n    test_files = test_folder.glob(\"*.tif\")\n    print(test_files)\n\n    model_path = Path(\"../data/lightning_logs/version_0/checkpoints/\")\n    checkpoint_file = model_path.glob(\"*.ckpt\")\n    print(f\"Using model {checkpoint_file[-1]}\")\n\n    model = Model.load_from_checkpoint(checkpoint_file[-1])\n\n    for test_path in test_files:\n\n        save_dir = Path(data_dir) / \"Autoencoder\"\n        save_dir.mkdir(exist_ok=True)\n\n        print(f\"Running for {test_path}\")\n\n        savepath = save_dir / f\"preds_{test_path.name}\"\n        if savepath.exists():\n            print(\"File already generated. Skipping\")\n            continue\n\n        out_forecasted = model.predict(test_path, with_forecaster=True)\n        plot_results(out_forecasted, test_path, savepath=save_dir, prefix=\"forecasted_\")\n\n        out_normal = model.predict(test_path, with_forecaster=False)\n        plot_results(out_normal, test_path, savepath=save_dir, prefix=\"full_input_\")\n\n        out_forecasted.to_netcdf(save_dir / f\"preds_forecasted_{test_path.name}.nc\")\n        out_normal.to_netcdf(save_dir / f\"preds_normal_{test_path.name}.nc\")\n\n\nif __name__ == \"__main__\":\n    print(\"Starting...predict.py\")\n    kenya_crop_type_mapper()\n",
  "history_output" : "Starting...predict.py\n<generator object Path.glob at 0x7fdc7ba1c270>\nTraceback (most recent call last):\n  File \"scripts_predict.py\", line 47, in <module>\n    kenya_crop_type_mapper()\n  File \"scripts_predict.py\", line 19, in kenya_crop_type_mapper\n    print(f\"Using model {checkpoint_file[-1]}\")\nTypeError: 'generator' object is not subscriptable\n",
  "history_begin_time" : 1646143439547,
  "history_end_time" : 1646143443677,
  "history_notes" : null,
  "history_process" : "delykw",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "oz88df6fusb",
  "history_input" : "from pathlib import Path\nimport sys\n\nsys.path.append(\"..\")\n\nfrom src_models_model import Model\nfrom src_analysis import plot_results\n\n\ndef kenya_crop_type_mapper():\n    data_dir = \"../data\"\n\n    test_folder = Path(\"../data/raw/earth_engine_plant_village_kenya/\")\n    test_files = test_folder.glob(\"*.tif\")\n    print(test_files)\n\n    model_path = \"/data/lightning_logs/version_0/checkpoints/\"\n    checkpoint_file = model_path.glob(\"*.ckpt\")\n    print(f\"Using model {checkpoint_file[0]}\")\n\n    model = Model.load_from_checkpoint(checkpoint_file[0])\n\n    for test_path in test_files:\n\n        save_dir = Path(data_dir) / \"Autoencoder\"\n        save_dir.mkdir(exist_ok=True)\n\n        print(f\"Running for {test_path}\")\n\n        savepath = save_dir / f\"preds_{test_path.name}\"\n        if savepath.exists():\n            print(\"File already generated. Skipping\")\n            continue\n\n        out_forecasted = model.predict(test_path, with_forecaster=True)\n        plot_results(out_forecasted, test_path, savepath=save_dir, prefix=\"forecasted_\")\n\n        out_normal = model.predict(test_path, with_forecaster=False)\n        plot_results(out_normal, test_path, savepath=save_dir, prefix=\"full_input_\")\n\n        out_forecasted.to_netcdf(save_dir / f\"preds_forecasted_{test_path.name}.nc\")\n        out_normal.to_netcdf(save_dir / f\"preds_normal_{test_path.name}.nc\")\n\n\nif __name__ == \"__main__\":\n    print(\"Starting...predict.py\")\n    kenya_crop_type_mapper()\n",
  "history_output" : "Starting...predict.py\n<generator object Path.glob at 0x7faa5c01c270>\nTraceback (most recent call last):\n  File \"scripts_predict.py\", line 47, in <module>\n    kenya_crop_type_mapper()\n  File \"scripts_predict.py\", line 18, in kenya_crop_type_mapper\n    checkpoint_file = model_path.glob(\"*.ckpt\")\nAttributeError: 'str' object has no attribute 'glob'\n",
  "history_begin_time" : 1646143290125,
  "history_end_time" : 1646143294695,
  "history_notes" : null,
  "history_process" : "delykw",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "f6rnrbmsprb",
  "history_input" : "from pathlib import Path\nimport sys\n\nsys.path.append(\"..\")\n\nfrom src_models_model import Model\nfrom src_analysis import plot_results\n\n\ndef kenya_crop_type_mapper():\n    data_dir = \"../data\"\n\n    test_folder = Path(\"../data/raw/earth_engine_plant_village_kenya/\")\n    test_files = test_folder.glob(\"*.tif\")\n    print(test_files)\n\n    model_path = \"/data/lightning_logs/version_0/checkpoints/\"\n    checkpoint_file = model_path.glob(\"*.ckpt\")\n    print(f\"Using model {checkpoint_file[0]}\")\n\n    model = Model.load_from_checkpoint(checkpoint_file[0])\n\n    for test_path in test_files:\n\n        save_dir = Path(data_dir) / \"Autoencoder\"\n        save_dir.mkdir(exist_ok=True)\n\n        print(f\"Running for {test_path}\")\n\n        savepath = save_dir / f\"preds_{test_path.name}\"\n        if savepath.exists():\n            print(\"File already generated. Skipping\")\n            continue\n\n        out_forecasted = model.predict(test_path, with_forecaster=True)\n        plot_results(out_forecasted, test_path, savepath=save_dir, prefix=\"forecasted_\")\n\n        out_normal = model.predict(test_path, with_forecaster=False)\n        plot_results(out_normal, test_path, savepath=save_dir, prefix=\"full_input_\")\n\n        out_forecasted.to_netcdf(save_dir / f\"preds_forecasted_{test_path.name}.nc\")\n        out_normal.to_netcdf(save_dir / f\"preds_normal_{test_path.name}.nc\")\n\n\nif __name__ == \"__main__\":\n    print(\"Starting...predict.py\")\n    kenya_crop_type_mapper()\n",
  "history_output" : "",
  "history_begin_time" : 1646138298082,
  "history_end_time" : 1646138300666,
  "history_notes" : null,
  "history_process" : "delykw",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "z41nymfwoye",
  "history_input" : "from pathlib import Path\nimport sys\n\nsys.path.append(\"..\")\n\nfrom src_models_model import Model\nfrom src_analysis import plot_results\n\n\ndef kenya_crop_type_mapper():\n    data_dir = \"../data\"\n\n    test_folder = Path(\"../data/raw/earth_engine_plant_village_kenya/\")\n    test_files = test_folder.glob(\"*.tif\")\n    print(test_files)\n\n    model_path = \"/data/lightning_logs/version_0/checkpoints/\"\n    checkpoint_file = model_path.glob(\"*.ckpt\")\n    print(f\"Using model {checkpoint_file[0]}\")\n\n    model = Model.load_from_checkpoint(checkpoint_file[0])\n\n    for test_path in test_files:\n\n        save_dir = Path(data_dir) / \"Autoencoder\"\n        save_dir.mkdir(exist_ok=True)\n\n        print(f\"Running for {test_path}\")\n\n        savepath = save_dir / f\"preds_{test_path.name}\"\n        if savepath.exists():\n            print(\"File already generated. Skipping\")\n            continue\n\n        out_forecasted = model.predict(test_path, with_forecaster=True)\n        plot_results(out_forecasted, test_path, savepath=save_dir, prefix=\"forecasted_\")\n\n        out_normal = model.predict(test_path, with_forecaster=False)\n        plot_results(out_normal, test_path, savepath=save_dir, prefix=\"full_input_\")\n\n        out_forecasted.to_netcdf(save_dir / f\"preds_forecasted_{test_path.name}.nc\")\n        out_normal.to_netcdf(save_dir / f\"preds_normal_{test_path.name}.nc\")\n\n\nif __name__ == \"__main__\":\n    print(\"Starting...predict.py\")\n    kenya_crop_type_mapper()\n",
  "history_output" : "",
  "history_begin_time" : 1646138200205,
  "history_end_time" : 1646138201672,
  "history_notes" : null,
  "history_process" : "delykw",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "hd1bhs3lxpx",
  "history_input" : "from pathlib import Path\nimport sys\n\nsys.path.append(\"..\")\n\nfrom src_models_model import Model\nfrom src_analysis import plot_results\n\n\ndef kenya_crop_type_mapper():\n    data_dir = \"../data\"\n\n    test_folder = Path(\"../data/raw/earth_engine_plant_village_kenya/\")\n    test_files = test_folder.glob(\"*.tif\")\n    print(test_files)\n\n    model_path = \"/data/lightning_logs/version_0/checkpoints/\"\n    checkpoint_file = model_path.glob(\"*.ckpt\")\n    print(f\"Using model {checkpoint_file[0]}\")\n\n    model = Model.load_from_checkpoint(checkpoint_file[0])\n\n    for test_path in test_files:\n\n        save_dir = Path(data_dir) / \"Autoencoder\"\n        save_dir.mkdir(exist_ok=True)\n\n        print(f\"Running for {test_path}\")\n\n        savepath = save_dir / f\"preds_{test_path.name}\"\n        if savepath.exists():\n            print(\"File already generated. Skipping\")\n            continue\n\n        out_forecasted = model.predict(test_path, with_forecaster=True)\n        plot_results(out_forecasted, test_path, savepath=save_dir, prefix=\"forecasted_\")\n\n        out_normal = model.predict(test_path, with_forecaster=False)\n        plot_results(out_normal, test_path, savepath=save_dir, prefix=\"full_input_\")\n\n        out_forecasted.to_netcdf(save_dir / f\"preds_forecasted_{test_path.name}.nc\")\n        out_normal.to_netcdf(save_dir / f\"preds_normal_{test_path.name}.nc\")\n\n\nif __name__ == \"__main__\":\n    print(\"Starting...predict.py\")\n    kenya_crop_type_mapper()\n",
  "history_output" : "",
  "history_begin_time" : 1646138113354,
  "history_end_time" : 1646138114967,
  "history_notes" : null,
  "history_process" : "delykw",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "aqzkceku2t6",
  "history_input" : "from pathlib import Path\nimport sys\n\nsys.path.append(\"..\")\n\nfrom src_models_model import Model\nfrom src_analysis import plot_results\n\n\ndef kenya_crop_type_mapper():\n    data_dir = \"../data\"\n\n    test_folder = Path(\"../data/raw/earth_engine_plant_village_kenya/\")\n    test_files = test_folder.glob(\"*.tif\")\n    print(test_files)\n\n    model_path = \"/data/lightning_logs/version_0/checkpoints/\"\n    checkpoint_file = model_path.glob(\"*.ckpt\")\n    print(f\"Using model {checkpoint_file[0]}\")\n\n    model = Model.load_from_checkpoint(checkpoint_file[0])\n\n    for test_path in test_files:\n\n        save_dir = Path(data_dir) / \"Autoencoder\"\n        save_dir.mkdir(exist_ok=True)\n\n        print(f\"Running for {test_path}\")\n\n        savepath = save_dir / f\"preds_{test_path.name}\"\n        if savepath.exists():\n            print(\"File already generated. Skipping\")\n            continue\n\n        out_forecasted = model.predict(test_path, with_forecaster=True)\n        plot_results(out_forecasted, test_path, savepath=save_dir, prefix=\"forecasted_\")\n\n        out_normal = model.predict(test_path, with_forecaster=False)\n        plot_results(out_normal, test_path, savepath=save_dir, prefix=\"full_input_\")\n\n        out_forecasted.to_netcdf(save_dir / f\"preds_forecasted_{test_path.name}.nc\")\n        out_normal.to_netcdf(save_dir / f\"preds_normal_{test_path.name}.nc\")\n\n\nif __name__ == \"__main__\":\n    kenya_crop_type_mapper()\n",
  "history_output" : "",
  "history_begin_time" : 1646137798547,
  "history_end_time" : 1646137800317,
  "history_notes" : null,
  "history_process" : "delykw",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "6uhgrx6v7x5",
  "history_input" : "from pathlib import Path\nimport sys\n\nsys.path.append(\"..\")\n\nfrom src_models_model import Model\nfrom src_analysis import plot_results\n\n\ndef kenya_crop_type_mapper():\n    data_dir = \"../data\"\n\n    test_folder = Path(\"../data/raw/earth_engine_plant_village_kenya/\")\n    test_files = test_folder.glob(\"*.tif\")\n    print(test_files)\n\n    model_path = \"/data/lightning_logs/version_0/checkpoints/\"\n    checkpoint_file = model_path.glob(\"*.ckpt\")\n    print(f\"Using model {checkpoint_file[0]}\")\n\n    model = Model.load_from_checkpoint(checkpoint_file[0])\n\n    for test_path in test_files:\n\n        save_dir = Path(data_dir) / \"Autoencoder\"\n        save_dir.mkdir(exist_ok=True)\n\n        print(f\"Running for {test_path}\")\n\n        savepath = save_dir / f\"preds_{test_path.name}\"\n        if savepath.exists():\n            print(\"File already generated. Skipping\")\n            continue\n\n        out_forecasted = model.predict(test_path, with_forecaster=True)\n        plot_results(out_forecasted, test_path, savepath=save_dir, prefix=\"forecasted_\")\n\n        out_normal = model.predict(test_path, with_forecaster=False)\n        plot_results(out_normal, test_path, savepath=save_dir, prefix=\"full_input_\")\n\n        out_forecasted.to_netcdf(save_dir / f\"preds_forecasted_{test_path.name}.nc\")\n        out_normal.to_netcdf(save_dir / f\"preds_normal_{test_path.name}.nc\")\n\n\nif __name__ == \"__main__\":\n    kenya_crop_type_mapper()\n",
  "history_output" : "<generator object Path.glob at 0x7faef4aab660>\nTraceback (most recent call last):\n  File \"scripts_predict.py\", line 46, in <module>\n    kenya_crop_type_mapper()\n  File \"scripts_predict.py\", line 18, in kenya_crop_type_mapper\n    checkpoint_file = model_path.glob(\"*.ckpt\")\nAttributeError: 'str' object has no attribute 'glob'\n",
  "history_begin_time" : 1646137705030,
  "history_end_time" : 1646137709648,
  "history_notes" : null,
  "history_process" : "delykw",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "sk6aodi5ez8",
  "history_input" : "from pathlib import Path\nimport sys\n\nsys.path.append(\"..\")\n\nfrom src_models_model import Model\nfrom src_analysis import plot_results\n\n\ndef kenya_crop_type_mapper():\n    data_dir = \"../data\"\n\n    test_folder = Path(\"../data/raw/earth_engine_plant_village_kenya/\")\n    test_files = test_folder.glob(\"*.tif\")\n    print(test_files)\n\n    model_path = \"/data/lightning_logs/version_0/checkpoints/\"\n\tcheckpoint_file = model_path.glob(\"*.ckpt\")\n    print(f\"Using model {checkpoint_file[0]}\")\n\n    model = Model.load_from_checkpoint(checkpoint_file[0])\n\n    for test_path in test_files:\n\n        save_dir = Path(data_dir) / \"Autoencoder\"\n        save_dir.mkdir(exist_ok=True)\n\n        print(f\"Running for {test_path}\")\n\n        savepath = save_dir / f\"preds_{test_path.name}\"\n        if savepath.exists():\n            print(\"File already generated. Skipping\")\n            continue\n\n        out_forecasted = model.predict(test_path, with_forecaster=True)\n        plot_results(out_forecasted, test_path, savepath=save_dir, prefix=\"forecasted_\")\n\n        out_normal = model.predict(test_path, with_forecaster=False)\n        plot_results(out_normal, test_path, savepath=save_dir, prefix=\"full_input_\")\n\n        out_forecasted.to_netcdf(save_dir / f\"preds_forecasted_{test_path.name}.nc\")\n        out_normal.to_netcdf(save_dir / f\"preds_normal_{test_path.name}.nc\")\n\n\nif __name__ == \"__main__\":\n    kenya_crop_type_mapper()\n",
  "history_output" : "  File \"scripts_predict.py\", line 18\n    checkpoint_file = model_path.glob(\"*.ckpt\")\n                                              ^\nTabError: inconsistent use of tabs and spaces in indentation\n",
  "history_begin_time" : 1646137596505,
  "history_end_time" : 1646137596636,
  "history_notes" : null,
  "history_process" : "delykw",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "pvsxgy7v6zy",
  "history_input" : null,
  "history_output" : null,
  "history_begin_time" : null,
  "history_end_time" : 1666166419938,
  "history_notes" : null,
  "history_process" : "delykw",
  "host_id" : "100001",
  "indicator" : "Stopped"
},]
