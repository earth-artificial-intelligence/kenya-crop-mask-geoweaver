[{
  "history_id" : "wlv8yvn2vf6",
  "history_input" : "from pathlib import Path\nimport sys\nimport os\n\nsys.path.append(\"..\")\n\nfrom src_models_model import Model\nfrom src_analysis import plot_results\n\n\ndef kenya_crop_type_mapper():\n    data_dir = \"../data\"\n\n    test_folder = Path(\"../data/raw/earth_engine_plant_village_kenya/\")\n    test_files = test_folder.glob(\"*.tif\")\n    print(test_files)\n\n    list_of_models = list(Path('../data/lightning_logs/').glob('version*/checkpoints/*.ckpt'))\n    latest_model_path = str(max(list_of_models, key=os.path.getctime))\n    print(f\"Using model {latest_model_path}\")\n\n    model = Model.load_from_checkpoint(latest_model_path)\n\n    for test_path in test_files:\n\n        save_dir = Path(data_dir) / \"Autoencoder\"\n        save_dir.mkdir(exist_ok=True)\n\n        print(f\"Running for {test_path}\")\n\n        savepath = save_dir / f\"preds_{test_path.name}\"\n        if savepath.exists():\n            print(\"File already generated. Skipping\")\n            continue\n\n        out_forecasted = model.predict(test_path, with_forecaster=True)\n        plot_results(out_forecasted, test_path, savepath=save_dir, prefix=\"forecasted_\")\n\n        out_normal = model.predict(test_path, with_forecaster=False)\n        plot_results(out_normal, test_path, savepath=save_dir, prefix=\"full_input_\")\n\n        out_forecasted.to_netcdf(save_dir / f\"preds_forecasted_{test_path.name}.nc\")\n        out_normal.to_netcdf(save_dir / f\"preds_normal_{test_path.name}.nc\")\n\n\nif __name__ == \"__main__\":\n    print(\"Starting...predict.py\")\n    kenya_crop_type_mapper()\n",
  "history_output" : "",
  "history_begin_time" : 1666118340036,
  "history_end_time" : 1666118344061,
  "history_notes" : null,
  "history_process" : "delykw",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "j41rcc56axe",
  "history_input" : "from pathlib import Path\nimport sys\nimport os\n\nsys.path.append(\"..\")\n\nfrom src_models_model import Model\nfrom src_analysis import plot_results\n\n\ndef kenya_crop_type_mapper():\n    data_dir = \"../data\"\n\n    test_folder = Path(\"../data/raw/earth_engine_plant_village_kenya/\")\n    test_files = test_folder.glob(\"*.tif\")\n    print(test_files)\n\n    list_of_models = list(Path('../data/lightning_logs/').glob('version*/checkpoints/*.ckpt'))\n    latest_model_path = str(max(list_of_models, key=os.path.getctime))\n    print(f\"Using model {latest_model_path}\")\n\n    model = Model.load_from_checkpoint(latest_model_path)\n\n    for test_path in test_files:\n\n        save_dir = Path(data_dir) / \"Autoencoder\"\n        save_dir.mkdir(exist_ok=True)\n\n        print(f\"Running for {test_path}\")\n\n        savepath = save_dir / f\"preds_{test_path.name}\"\n        if savepath.exists():\n            print(\"File already generated. Skipping\")\n            continue\n\n        out_forecasted = model.predict(test_path, with_forecaster=True)\n        plot_results(out_forecasted, test_path, savepath=save_dir, prefix=\"forecasted_\")\n\n        out_normal = model.predict(test_path, with_forecaster=False)\n        plot_results(out_normal, test_path, savepath=save_dir, prefix=\"full_input_\")\n\n        out_forecasted.to_netcdf(save_dir / f\"preds_forecasted_{test_path.name}.nc\")\n        out_normal.to_netcdf(save_dir / f\"preds_normal_{test_path.name}.nc\")\n\n\nif __name__ == \"__main__\":\n    print(\"Starting...predict.py\")\n    kenya_crop_type_mapper()\n",
  "history_output" : "ERROR 1: PROJ: proj_identify: /opt/anaconda3/share/proj/proj.db lacks DATABASE.LAYOUT.VERSION.MAJOR / DATABASE.LAYOUT.VERSION.MINOR metadata. It comes from another PROJ installation.\n  0%|          | 0/288 [00:00<?, ?it/s]\n 89%|████████▉ | 256/288 [00:00<00:00, 2310.06it/s]ERROR 1: PROJ: proj_identify: /opt/anaconda3/share/proj/proj.db lacks DATABASE.LAYOUT.VERSION.MAJOR / DATABASE.LAYOUT.VERSION.MINOR metadata. It comes from another PROJ installation.\n320it [00:00, 837.54it/s]                          ERROR 1: PROJ: proj_identify: /opt/anaconda3/share/proj/proj.db lacks DATABASE.LAYOUT.VERSION.MAJOR / DATABASE.LAYOUT.VERSION.MINOR metadata. It comes from another PROJ installation.\n  0%|          | 0/288 [00:00<?, ?it/s]ERROR 1: PROJ: proj_identify: /opt/anaconda3/share/proj/proj.db lacks DATABASE.LAYOUT.VERSION.MAJOR / DATABASE.LAYOUT.VERSION.MINOR metadata. It comes from another PROJ installation.\n320it [00:00, 1242.42it/s]             ERROR 1: PROJ: proj_identify: /opt/anaconda3/share/proj/proj.db lacks DATABASE.LAYOUT.VERSION.MAJOR / DATABASE.LAYOUT.VERSION.MINOR metadata. It comes from another PROJ installation.\n  0%|          | 0/288 [00:00<?, ?it/s]ERROR 1: PROJ: proj_identify: /opt/anaconda3/share/proj/proj.db lacks DATABASE.LAYOUT.VERSION.MAJOR / DATABASE.LAYOUT.VERSION.MINOR metadata. It comes from another PROJ installation.\n320it [00:00, 1037.72it/s]             ERROR 1: PROJ: proj_identify: /opt/anaconda3/share/proj/proj.db lacks DATABASE.LAYOUT.VERSION.MAJOR / DATABASE.LAYOUT.VERSION.MINOR metadata. It comes from another PROJ installation.\n  0%|          | 0/288 [00:00<?, ?it/s]ERROR 1: PROJ: proj_identify: /opt/anaconda3/share/proj/proj.db lacks DATABASE.LAYOUT.VERSION.MAJOR / DATABASE.LAYOUT.VERSION.MINOR metadata. It comes from another PROJ installation.\n320it [00:00, 1262.64it/s]             ERROR 1: PROJ: proj_identify: /opt/anaconda3/share/proj/proj.db lacks DATABASE.LAYOUT.VERSION.MAJOR / DATABASE.LAYOUT.VERSION.MINOR metadata. It comes from another PROJ installation.\n  0%|          | 0/288 [00:00<?, ?it/s]ERROR 1: PROJ: proj_identify: /opt/anaconda3/share/proj/proj.db lacks DATABASE.LAYOUT.VERSION.MAJOR / DATABASE.LAYOUT.VERSION.MINOR metadata. It comes from another PROJ installation.\n320it [00:00, 1056.46it/s]             ERROR 1: PROJ: proj_identify: /opt/anaconda3/share/proj/proj.db lacks DATABASE.LAYOUT.VERSION.MAJOR / DATABASE.LAYOUT.VERSION.MINOR metadata. It comes from another PROJ installation.\n  0%|          | 0/288 [00:00<?, ?it/s]ERROR 1: PROJ: proj_identify: /opt/anaconda3/share/proj/proj.db lacks DATABASE.LAYOUT.VERSION.MAJOR / DATABASE.LAYOUT.VERSION.MINOR metadata. It comes from another PROJ installation.\n320it [00:00, 1335.17it/s]             ERROR 1: PROJ: proj_identify: /opt/anaconda3/share/proj/proj.db lacks DATABASE.LAYOUT.VERSION.MAJOR / DATABASE.LAYOUT.VERSION.MINOR metadata. It comes from another PROJ installation.\n  0%|          | 0/288 [00:00<?, ?it/s]\n320it [00:00, 2931.06it/s]             ERROR 1: PROJ: proj_identify: /opt/anaconda3/share/proj/proj.db lacks DATABASE.LAYOUT.VERSION.MAJOR / DATABASE.LAYOUT.VERSION.MINOR metadata. It comes from another PROJ installation.\n320it [00:00, 896.97it/s] ERROR 1: PROJ: proj_identify: /opt/anaconda3/share/proj/proj.db lacks DATABASE.LAYOUT.VERSION.MAJOR / DATABASE.LAYOUT.VERSION.MINOR metadata. It comes from another PROJ installation.\n  0%|          | 0/288 [00:00<?, ?it/s]ERROR 1: PROJ: proj_identify: /opt/anaconda3/share/proj/proj.db lacks DATABASE.LAYOUT.VERSION.MAJOR / DATABASE.LAYOUT.VERSION.MINOR metadata. It comes from another PROJ installation.\n320it [00:00, 1267.80it/s]             ERROR 1: PROJ: proj_identify: /opt/anaconda3/share/proj/proj.db lacks DATABASE.LAYOUT.VERSION.MAJOR / DATABASE.LAYOUT.VERSION.MINOR metadata. It comes from another PROJ installation.\n  0%|          | 0/288 [00:00<?, ?it/s]\n320it [00:00, 3192.30it/s]             ERROR 1: PROJ: proj_identify: /opt/anaconda3/share/proj/proj.db lacks DATABASE.LAYOUT.VERSION.MAJOR / DATABASE.LAYOUT.VERSION.MINOR metadata. It comes from another PROJ installation.\n320it [00:00, 1022.72it/s]ERROR 1: PROJ: proj_identify: /opt/anaconda3/share/proj/proj.db lacks DATABASE.LAYOUT.VERSION.MAJOR / DATABASE.LAYOUT.VERSION.MINOR metadata. It comes from another PROJ installation.\n  0%|          | 0/288 [00:00<?, ?it/s]ERROR 1: PROJ: proj_identify: /opt/anaconda3/share/proj/proj.db lacks DATABASE.LAYOUT.VERSION.MAJOR / DATABASE.LAYOUT.VERSION.MINOR metadata. It comes from another PROJ installation.\n320it [00:00, 1259.57it/s]             ERROR 1: PROJ: proj_identify: /opt/anaconda3/share/proj/proj.db lacks DATABASE.LAYOUT.VERSION.MAJOR / DATABASE.LAYOUT.VERSION.MINOR metadata. It comes from another PROJ installation.\n  0%|          | 0/288 [00:00<?, ?it/s]ERROR 1: PROJ: proj_identify: /opt/anaconda3/share/proj/proj.db lacks DATABASE.LAYOUT.VERSION.MAJOR / DATABASE.LAYOUT.VERSION.MINOR metadata. It comes from another PROJ installation.\n320it [00:00, 998.95it/s]              ERROR 1: PROJ: proj_identify: /opt/anaconda3/share/proj/proj.db lacks DATABASE.LAYOUT.VERSION.MAJOR / DATABASE.LAYOUT.VERSION.MINOR metadata. It comes from another PROJ installation.\n  0%|          | 0/288 [00:00<?, ?it/s]ERROR 1: PROJ: proj_identify: /opt/anaconda3/share/proj/proj.db lacks DATABASE.LAYOUT.VERSION.MAJOR / DATABASE.LAYOUT.VERSION.MINOR metadata. It comes from another PROJ installation.\n320it [00:00, 1329.32it/s]             ERROR 1: PROJ: proj_identify: /opt/anaconda3/share/proj/proj.db lacks DATABASE.LAYOUT.VERSION.MAJOR / DATABASE.LAYOUT.VERSION.MINOR metadata. It comes from another PROJ installation.\n  0%|          | 0/288 [00:00<?, ?it/s]\n320it [00:00, 2802.27it/s]             ERROR 1: PROJ: proj_identify: /opt/anaconda3/share/proj/proj.db lacks DATABASE.LAYOUT.VERSION.MAJOR / DATABASE.LAYOUT.VERSION.MINOR metadata. It comes from another PROJ installation.\n320it [00:00, 928.57it/s] ERROR 1: PROJ: proj_identify: /opt/anaconda3/share/proj/proj.db lacks DATABASE.LAYOUT.VERSION.MAJOR / DATABASE.LAYOUT.VERSION.MINOR metadata. It comes from another PROJ installation.\n  0%|          | 0/288 [00:00<?, ?it/s]ERROR 1: PROJ: proj_identify: /opt/anaconda3/share/proj/proj.db lacks DATABASE.LAYOUT.VERSION.MAJOR / DATABASE.LAYOUT.VERSION.MINOR metadata. It comes from another PROJ installation.\n320it [00:00, 1305.04it/s]             ERROR 1: PROJ: proj_identify: /opt/anaconda3/share/proj/proj.db lacks DATABASE.LAYOUT.VERSION.MAJOR / DATABASE.LAYOUT.VERSION.MINOR metadata. It comes from another PROJ installation.\n  0%|          | 0/288 [00:00<?, ?it/s]ERROR 1: PROJ: proj_identify: /opt/anaconda3/share/proj/proj.db lacks DATABASE.LAYOUT.VERSION.MAJOR / DATABASE.LAYOUT.VERSION.MINOR metadata. It comes from another PROJ installation.\n320it [00:00, 1076.79it/s]             ERROR 1: PROJ: proj_identify: /opt/anaconda3/share/proj/proj.db lacks DATABASE.LAYOUT.VERSION.MAJOR / DATABASE.LAYOUT.VERSION.MINOR metadata. It comes from another PROJ installation.\n  0%|          | 0/288 [00:00<?, ?it/s]ERROR 1: PROJ: proj_identify: /opt/anaconda3/share/proj/proj.db lacks DATABASE.LAYOUT.VERSION.MAJOR / DATABASE.LAYOUT.VERSION.MINOR metadata. It comes from another PROJ installation.\n320it [00:00, 1378.40it/s]             ERROR 1: PROJ: proj_identify: /opt/anaconda3/share/proj/proj.db lacks DATABASE.LAYOUT.VERSION.MAJOR / DATABASE.LAYOUT.VERSION.MINOR metadata. It comes from another PROJ installation.\n  0%|          | 0/305 [00:00<?, ?it/s]\n320it [00:00, 2884.70it/s]             ERROR 1: PROJ: proj_identify: /opt/anaconda3/share/proj/proj.db lacks DATABASE.LAYOUT.VERSION.MAJOR / DATABASE.LAYOUT.VERSION.MINOR metadata. It comes from another PROJ installation.\n320it [00:00, 954.97it/s] ERROR 1: PROJ: proj_identify: /opt/anaconda3/share/proj/proj.db lacks DATABASE.LAYOUT.VERSION.MAJOR / DATABASE.LAYOUT.VERSION.MINOR metadata. It comes from another PROJ installation.\n  0%|          | 0/305 [00:00<?, ?it/s]ERROR 1: PROJ: proj_identify: /opt/anaconda3/share/proj/proj.db lacks DATABASE.LAYOUT.VERSION.MAJOR / DATABASE.LAYOUT.VERSION.MINOR metadata. It comes from another PROJ installation.\n320it [00:00, 1370.33it/s]             ERROR 1: PROJ: proj_identify: /opt/anaconda3/share/proj/proj.db lacks DATABASE.LAYOUT.VERSION.MAJOR / DATABASE.LAYOUT.VERSION.MINOR metadata. It comes from another PROJ installation.\n  0%|          | 0/288 [00:00<?, ?it/s]ERROR 1: PROJ: proj_identify: /opt/anaconda3/share/proj/proj.db lacks DATABASE.LAYOUT.VERSION.MAJOR / DATABASE.LAYOUT.VERSION.MINOR metadata. It comes from another PROJ installation.\n320it [00:00, 1015.83it/s]             ERROR 1: PROJ: proj_identify: /opt/anaconda3/share/proj/proj.db lacks DATABASE.LAYOUT.VERSION.MAJOR / DATABASE.LAYOUT.VERSION.MINOR metadata. It comes from another PROJ installation.\n  0%|          | 0/288 [00:00<?, ?it/s]ERROR 1: PROJ: proj_identify: /opt/anaconda3/share/proj/proj.db lacks DATABASE.LAYOUT.VERSION.MAJOR / DATABASE.LAYOUT.VERSION.MINOR metadata. It comes from another PROJ installation.\n320it [00:00, 1163.93it/s]             \nStarting...predict.py\n<generator object Path.glob at 0x7fb9b95a6270>\nUsing model ../data/lightning_logs/version_1/checkpoints/epoch=165.ckpt\nPredicting 7 timesteps in the forecaster\nUsing 1 layers for the global classifier\nUsing 2 layers for the local classifier\nRunning for ../data/raw/earth_engine_plant_village_kenya/1_2019-04-22_2020-04-16.tif\nNo GPU - not using one\nNo GPU - not using one\nRunning for ../data/raw/earth_engine_plant_village_kenya/9_2019-04-22_2020-04-16.tif\nNo GPU - not using one\nNo GPU - not using one\nRunning for ../data/raw/earth_engine_plant_village_kenya/6_2019-04-22_2020-04-16.tif\nNo GPU - not using one\nNo GPU - not using one\nRunning for ../data/raw/earth_engine_plant_village_kenya/3_2019-04-22_2020-04-16.tif\nNo GPU - not using one\nNo GPU - not using one\nRunning for ../data/raw/earth_engine_plant_village_kenya/4_2019-04-22_2020-04-16.tif\nNo GPU - not using one\nNo GPU - not using one\nRunning for ../data/raw/earth_engine_plant_village_kenya/5_2019-04-22_2020-04-16.tif\nNo GPU - not using one\nNo GPU - not using one\nRunning for ../data/raw/earth_engine_plant_village_kenya/0_2018-04-21_2019-04-16.tif\nNo GPU - not using one\nNo GPU - not using one\nRunning for ../data/raw/earth_engine_plant_village_kenya/2_2019-04-22_2020-04-16.tif\nNo GPU - not using one\nNo GPU - not using one\nRunning for ../data/raw/earth_engine_plant_village_kenya/7_2019-04-22_2020-04-16.tif\nNo GPU - not using one\nNo GPU - not using one\nRunning for ../data/raw/earth_engine_plant_village_kenya/8_2019-04-22_2020-04-16.tif\nNo GPU - not using one\nNo GPU - not using one\n",
  "history_begin_time" : 1655909920637,
  "history_end_time" : 1655909965527,
  "history_notes" : null,
  "history_process" : "delykw",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "vynr7p349wz",
  "history_input" : "from pathlib import Path\nimport sys\nimport os\n\nsys.path.append(\"..\")\n\nfrom src_models_model import Model\nfrom src_analysis import plot_results\n\n\ndef kenya_crop_type_mapper():\n    data_dir = \"../data\"\n\n    test_folder = Path(\"../data/raw/earth_engine_plant_village_kenya/\")\n    test_files = test_folder.glob(\"*.tif\")\n    print(test_files)\n\n    list_of_models = list(Path('../data/lightning_logs/').glob('version*/checkpoints/*.ckpt'))\n    latest_model_path = str(max(list_of_models, key=os.path.getctime))\n    print(f\"Using model {latest_model_path}\")\n\n    model = Model.load_from_checkpoint(latest_model_path)\n\n    for test_path in test_files:\n\n        save_dir = Path(data_dir) / \"Autoencoder\"\n        save_dir.mkdir(exist_ok=True)\n\n        print(f\"Running for {test_path}\")\n\n        savepath = save_dir / f\"preds_{test_path.name}\"\n        if savepath.exists():\n            print(\"File already generated. Skipping\")\n            continue\n\n        out_forecasted = model.predict(test_path, with_forecaster=True)\n        plot_results(out_forecasted, test_path, savepath=save_dir, prefix=\"forecasted_\")\n\n        out_normal = model.predict(test_path, with_forecaster=False)\n        plot_results(out_normal, test_path, savepath=save_dir, prefix=\"full_input_\")\n\n        out_forecasted.to_netcdf(save_dir / f\"preds_forecasted_{test_path.name}.nc\")\n        out_normal.to_netcdf(save_dir / f\"preds_normal_{test_path.name}.nc\")\n\n\nif __name__ == \"__main__\":\n    print(\"Starting...predict.py\")\n    kenya_crop_type_mapper()\n",
  "history_output" : "",
  "history_begin_time" : 1655908835205,
  "history_end_time" : 1655908835646,
  "history_notes" : null,
  "history_process" : "delykw",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "g29ed0i3wf0",
  "history_input" : "from pathlib import Path\nimport sys\nimport os\n\nsys.path.append(\"..\")\n\nfrom src_models_model import Model\nfrom src_analysis import plot_results\n\n\ndef kenya_crop_type_mapper():\n    data_dir = \"../data\"\n\n    test_folder = Path(\"../data/raw/earth_engine_plant_village_kenya/\")\n    test_files = test_folder.glob(\"*.tif\")\n    print(test_files)\n\n    list_of_models = list(Path('../data/lightning_logs/').glob('version*/checkpoints/*.ckpt'))\n    latest_model_path = str(max(list_of_models, key=os.path.getctime))\n    print(f\"Using model {latest_model_path}\")\n\n    model = Model.load_from_checkpoint(latest_model_path)\n\n    for test_path in test_files:\n\n        save_dir = Path(data_dir) / \"Autoencoder\"\n        save_dir.mkdir(exist_ok=True)\n\n        print(f\"Running for {test_path}\")\n\n        savepath = save_dir / f\"preds_{test_path.name}\"\n        if savepath.exists():\n            print(\"File already generated. Skipping\")\n            continue\n\n        out_forecasted = model.predict(test_path, with_forecaster=True)\n        plot_results(out_forecasted, test_path, savepath=save_dir, prefix=\"forecasted_\")\n\n        out_normal = model.predict(test_path, with_forecaster=False)\n        plot_results(out_normal, test_path, savepath=save_dir, prefix=\"full_input_\")\n\n        out_forecasted.to_netcdf(save_dir / f\"preds_forecasted_{test_path.name}.nc\")\n        out_normal.to_netcdf(save_dir / f\"preds_normal_{test_path.name}.nc\")\n\n\nif __name__ == \"__main__\":\n    print(\"Starting...predict.py\")\n    kenya_crop_type_mapper()\n",
  "history_output" : "Traceback (most recent call last):\n  File \"scripts_predict.py\", line 7, in <module>\n    from src_models_model import Model\n  File \"/Users/uhhmed/gw-workspace/g29ed0i3wf0/src_models_model.py\", line 22, in <module>\n    from src_models_data import CropDataset\n  File \"/Users/uhhmed/gw-workspace/g29ed0i3wf0/src_models_data.py\", line 4, in <module>\n    import geopandas\n  File \"/opt/anaconda3/lib/python3.8/site-packages/geopandas/__init__.py\", line 1, in <module>\n    from geopandas._config import options  # noqa\n  File \"/opt/anaconda3/lib/python3.8/site-packages/geopandas/_config.py\", line 109, in <module>\n    default_value=_default_use_pygeos(),\n  File \"/opt/anaconda3/lib/python3.8/site-packages/geopandas/_config.py\", line 95, in _default_use_pygeos\n    import geopandas._compat as compat\n  File \"/opt/anaconda3/lib/python3.8/site-packages/geopandas/_compat.py\", line 9, in <module>\n    import pyproj\n  File \"/opt/anaconda3/lib/python3.8/site-packages/pyproj/__init__.py\", line 81, in <module>\n    from pyproj.crs import CRS  # noqa: F401\n  File \"/opt/anaconda3/lib/python3.8/site-packages/pyproj/crs/__init__.py\", line 16, in <module>\n    from pyproj.crs.crs import (  # noqa: F401  pylint: disable=unused-import\n  File \"/opt/anaconda3/lib/python3.8/site-packages/pyproj/crs/crs.py\", line 13, in <module>\n    from pyproj._crs import (\nImportError: cannot import name 'AuthorityMatchInfo' from 'pyproj._crs' (/opt/anaconda3/lib/python3.8/site-packages/pyproj/_crs.cpython-38-darwin.so)\n",
  "history_begin_time" : 1655907448346,
  "history_end_time" : 1655907452386,
  "history_notes" : null,
  "history_process" : "delykw",
  "host_id" : "100001",
  "indicator" : "Failed"
},{
  "history_id" : "cwwrilhp2zc",
  "history_input" : "from pathlib import Path\nimport sys\nimport os\n\nsys.path.append(\"..\")\n\nfrom src_models_model import Model\nfrom src_analysis import plot_results\n\n\ndef kenya_crop_type_mapper():\n    data_dir = \"../data\"\n\n    test_folder = Path(\"../data/raw/earth_engine_plant_village_kenya/\")\n    test_files = test_folder.glob(\"*.tif\")\n    print(test_files)\n\n    list_of_models = list(Path('../data/lightning_logs/').glob('version*/checkpoints/*.ckpt'))\n    latest_model_path = str(max(list_of_models, key=os.path.getctime))\n    print(f\"Using model {latest_model_path}\")\n\n    model = Model.load_from_checkpoint(latest_model_path)\n\n    for test_path in test_files:\n\n        save_dir = Path(data_dir) / \"Autoencoder\"\n        save_dir.mkdir(exist_ok=True)\n\n        print(f\"Running for {test_path}\")\n\n        savepath = save_dir / f\"preds_{test_path.name}\"\n        if savepath.exists():\n            print(\"File already generated. Skipping\")\n            continue\n\n        out_forecasted = model.predict(test_path, with_forecaster=True)\n        plot_results(out_forecasted, test_path, savepath=save_dir, prefix=\"forecasted_\")\n\n        out_normal = model.predict(test_path, with_forecaster=False)\n        plot_results(out_normal, test_path, savepath=save_dir, prefix=\"full_input_\")\n\n        out_forecasted.to_netcdf(save_dir / f\"preds_forecasted_{test_path.name}.nc\")\n        out_normal.to_netcdf(save_dir / f\"preds_normal_{test_path.name}.nc\")\n\n\nif __name__ == \"__main__\":\n    print(\"Starting...predict.py\")\n    kenya_crop_type_mapper()\n",
  "history_output" : "",
  "history_begin_time" : 1655907401758,
  "history_end_time" : 1655907403095,
  "history_notes" : null,
  "history_process" : "delykw",
  "host_id" : "100001",
  "indicator" : "Stopped"
},{
  "history_id" : "oc2cz4tckqy",
  "history_input" : "from pathlib import Path\nimport sys\nimport os\n\nsys.path.append(\"..\")\n\nfrom src_models_model import Model\nfrom src_analysis import plot_results\n\n\ndef kenya_crop_type_mapper():\n    data_dir = \"../data\"\n\n    test_folder = Path(\"../data/raw/earth_engine_plant_village_kenya/\")\n    test_files = test_folder.glob(\"*.tif\")\n    print(test_files)\n\n    list_of_models = list(Path('../data/lightning_logs/').glob('version*/checkpoints/*.ckpt'))\n    latest_model_path = str(max(list_of_models, key=os.path.getctime))\n    print(f\"Using model {latest_model_path}\")\n\n    model = Model.load_from_checkpoint(latest_model_path)\n\n    for test_path in test_files:\n\n        save_dir = Path(data_dir) / \"Autoencoder\"\n        save_dir.mkdir(exist_ok=True)\n\n        print(f\"Running for {test_path}\")\n\n        savepath = save_dir / f\"preds_{test_path.name}\"\n        if savepath.exists():\n            print(\"File already generated. Skipping\")\n            continue\n\n        out_forecasted = model.predict(test_path, with_forecaster=True)\n        plot_results(out_forecasted, test_path, savepath=save_dir, prefix=\"forecasted_\")\n\n        out_normal = model.predict(test_path, with_forecaster=False)\n        plot_results(out_normal, test_path, savepath=save_dir, prefix=\"full_input_\")\n\n        out_forecasted.to_netcdf(save_dir / f\"preds_forecasted_{test_path.name}.nc\")\n        out_normal.to_netcdf(save_dir / f\"preds_normal_{test_path.name}.nc\")\n\n\nif __name__ == \"__main__\":\n    print(\"Starting...predict.py\")\n    kenya_crop_type_mapper()\n",
  "history_output" : "Traceback (most recent call last):\n  File \"scripts_predict.py\", line 7, in <module>\n    from src_models_model import Model\n  File \"/Users/uhhmed/gw-workspace/oc2cz4tckqy/src_models_model.py\", line 3, in <module>\n    import numpy as np\nModuleNotFoundError: No module named 'numpy'\n",
  "history_begin_time" : 1655865866275,
  "history_end_time" : 1655865866462,
  "history_notes" : null,
  "history_process" : "delykw",
  "host_id" : "100001",
  "indicator" : "Failed"
},{
  "history_id" : "nqk6y1y3gg2",
  "history_input" : "from pathlib import Path\nimport sys\nimport os\n\nsys.path.append(\"..\")\n\nfrom src_models_model import Model\nfrom src_analysis import plot_results\n\n\ndef kenya_crop_type_mapper():\n    data_dir = \"../data\"\n\n    test_folder = Path(\"../data/raw/earth_engine_plant_village_kenya/\")\n    test_files = test_folder.glob(\"*.tif\")\n    print(test_files)\n\n    list_of_models = list(Path('../data/lightning_logs/').glob('version*/checkpoints/*.ckpt'))\n    latest_model_path = str(max(list_of_models, key=os.path.getctime))\n    print(f\"Using model {latest_model_path}\")\n\n    model = Model.load_from_checkpoint(latest_model_path)\n\n    for test_path in test_files:\n\n        save_dir = Path(data_dir) / \"Autoencoder\"\n        save_dir.mkdir(exist_ok=True)\n\n        print(f\"Running for {test_path}\")\n\n        savepath = save_dir / f\"preds_{test_path.name}\"\n        if savepath.exists():\n            print(\"File already generated. Skipping\")\n            continue\n\n        out_forecasted = model.predict(test_path, with_forecaster=True)\n        plot_results(out_forecasted, test_path, savepath=save_dir, prefix=\"forecasted_\")\n\n        out_normal = model.predict(test_path, with_forecaster=False)\n        plot_results(out_normal, test_path, savepath=save_dir, prefix=\"full_input_\")\n\n        out_forecasted.to_netcdf(save_dir / f\"preds_forecasted_{test_path.name}.nc\")\n        out_normal.to_netcdf(save_dir / f\"preds_normal_{test_path.name}.nc\")\n\n\nif __name__ == \"__main__\":\n    print(\"Starting...predict.py\")\n    kenya_crop_type_mapper()\n",
  "history_output" : "Traceback (most recent call last):\n  File \"scripts_predict.py\", line 7, in <module>\n    from src_models_model import Model\n  File \"/Users/uhhmed/gw-workspace/nqk6y1y3gg2/src_models_model.py\", line 22, in <module>\n    from src_models_data import CropDataset\n  File \"/Users/uhhmed/gw-workspace/nqk6y1y3gg2/src_models_data.py\", line 4, in <module>\n    import geopandas\n  File \"/opt/anaconda3/lib/python3.8/site-packages/geopandas/__init__.py\", line 1, in <module>\n    from geopandas._config import options  # noqa\n  File \"/opt/anaconda3/lib/python3.8/site-packages/geopandas/_config.py\", line 109, in <module>\n    default_value=_default_use_pygeos(),\n  File \"/opt/anaconda3/lib/python3.8/site-packages/geopandas/_config.py\", line 95, in _default_use_pygeos\n    import geopandas._compat as compat\n  File \"/opt/anaconda3/lib/python3.8/site-packages/geopandas/_compat.py\", line 9, in <module>\n    import pyproj\n  File \"/opt/anaconda3/lib/python3.8/site-packages/pyproj/__init__.py\", line 81, in <module>\n    from pyproj.crs import CRS  # noqa: F401\n  File \"/opt/anaconda3/lib/python3.8/site-packages/pyproj/crs/__init__.py\", line 16, in <module>\n    from pyproj.crs.crs import (  # noqa: F401  pylint: disable=unused-import\n  File \"/opt/anaconda3/lib/python3.8/site-packages/pyproj/crs/crs.py\", line 13, in <module>\n    from pyproj._crs import (\nImportError: cannot import name 'AuthorityMatchInfo' from 'pyproj._crs' (/opt/anaconda3/lib/python3.8/site-packages/pyproj/_crs.cpython-38-darwin.so)\n",
  "history_begin_time" : 1655865101703,
  "history_end_time" : 1655865106413,
  "history_notes" : null,
  "history_process" : "delykw",
  "host_id" : "100001",
  "indicator" : "Failed"
},{
  "history_id" : "o6esrks4ou6",
  "history_input" : "from pathlib import Path\nimport sys\nimport os\n\nsys.path.append(\"..\")\n\nfrom src_models_model import Model\nfrom src_analysis import plot_results\n\n\ndef kenya_crop_type_mapper():\n    data_dir = \"../data\"\n\n    test_folder = Path(\"../data/raw/earth_engine_plant_village_kenya/\")\n    test_files = test_folder.glob(\"*.tif\")\n    print(test_files)\n\n    list_of_models = list(Path('../data/lightning_logs/').glob('version*/checkpoints/*.ckpt'))\n    latest_model_path = str(max(list_of_models, key=os.path.getctime))\n    print(f\"Using model {latest_model_path}\")\n\n    model = Model.load_from_checkpoint(latest_model_path)\n\n    for test_path in test_files:\n\n        save_dir = Path(data_dir) / \"Autoencoder\"\n        save_dir.mkdir(exist_ok=True)\n\n        print(f\"Running for {test_path}\")\n\n        savepath = save_dir / f\"preds_{test_path.name}\"\n        if savepath.exists():\n            print(\"File already generated. Skipping\")\n            continue\n\n        out_forecasted = model.predict(test_path, with_forecaster=True)\n        plot_results(out_forecasted, test_path, savepath=save_dir, prefix=\"forecasted_\")\n\n        out_normal = model.predict(test_path, with_forecaster=False)\n        plot_results(out_normal, test_path, savepath=save_dir, prefix=\"full_input_\")\n\n        out_forecasted.to_netcdf(save_dir / f\"preds_forecasted_{test_path.name}.nc\")\n        out_normal.to_netcdf(save_dir / f\"preds_normal_{test_path.name}.nc\")\n\n\nif __name__ == \"__main__\":\n    print(\"Starting...predict.py\")\n    kenya_crop_type_mapper()\n",
  "history_output" : "",
  "history_begin_time" : 1647347437345,
  "history_end_time" : 1647347437804,
  "history_notes" : null,
  "history_process" : "delykw",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "zo7yx9dkkh5",
  "history_input" : "from pathlib import Path\nimport sys\nimport os\n\nsys.path.append(\"..\")\n\nfrom src_models_model import Model\nfrom src_analysis import plot_results\n\n\ndef kenya_crop_type_mapper():\n    data_dir = \"../data\"\n\n    test_folder = Path(\"../data/raw/earth_engine_plant_village_kenya/\")\n    test_files = test_folder.glob(\"*.tif\")\n    print(test_files)\n\n    list_of_models = list(Path('../data/lightning_logs/').glob('version*/checkpoints/*.ckpt'))\n    latest_model_path = str(max(list_of_models, key=os.path.getctime))\n    print(f\"Using model {latest_model_path}\")\n\n    model = Model.load_from_checkpoint(latest_model_path)\n\n    for test_path in test_files:\n\n        save_dir = Path(data_dir) / \"Autoencoder\"\n        save_dir.mkdir(exist_ok=True)\n\n        print(f\"Running for {test_path}\")\n\n        savepath = save_dir / f\"preds_{test_path.name}\"\n        if savepath.exists():\n            print(\"File already generated. Skipping\")\n            continue\n\n        out_forecasted = model.predict(test_path, with_forecaster=True)\n        plot_results(out_forecasted, test_path, savepath=save_dir, prefix=\"forecasted_\")\n\n        out_normal = model.predict(test_path, with_forecaster=False)\n        plot_results(out_normal, test_path, savepath=save_dir, prefix=\"full_input_\")\n\n        out_forecasted.to_netcdf(save_dir / f\"preds_forecasted_{test_path.name}.nc\")\n        out_normal.to_netcdf(save_dir / f\"preds_normal_{test_path.name}.nc\")\n\n\nif __name__ == \"__main__\":\n    print(\"Starting...predict.py\")\n    kenya_crop_type_mapper()\n",
  "history_output" : "ERROR 1: PROJ: proj_identify: /opt/anaconda3/share/proj/proj.db lacks DATABASE.LAYOUT.VERSION.MAJOR / DATABASE.LAYOUT.VERSION.MINOR metadata. It comes from another PROJ installation.\n  0%|          | 0/288 [00:00<?, ?it/s]ERROR 1: PROJ: proj_identify: /opt/anaconda3/share/proj/proj.db lacks DATABASE.LAYOUT.VERSION.MAJOR / DATABASE.LAYOUT.VERSION.MINOR metadata. It comes from another PROJ installation.\n320it [00:00, 974.60it/s]              ERROR 1: PROJ: proj_identify: /opt/anaconda3/share/proj/proj.db lacks DATABASE.LAYOUT.VERSION.MAJOR / DATABASE.LAYOUT.VERSION.MINOR metadata. It comes from another PROJ installation.\n  0%|          | 0/288 [00:00<?, ?it/s]ERROR 1: PROJ: proj_identify: /opt/anaconda3/share/proj/proj.db lacks DATABASE.LAYOUT.VERSION.MAJOR / DATABASE.LAYOUT.VERSION.MINOR metadata. It comes from another PROJ installation.\n320it [00:00, 1507.58it/s]             ERROR 1: PROJ: proj_identify: /opt/anaconda3/share/proj/proj.db lacks DATABASE.LAYOUT.VERSION.MAJOR / DATABASE.LAYOUT.VERSION.MINOR metadata. It comes from another PROJ installation.\n  0%|          | 0/288 [00:00<?, ?it/s]ERROR 1: PROJ: proj_identify: /opt/anaconda3/share/proj/proj.db lacks DATABASE.LAYOUT.VERSION.MAJOR / DATABASE.LAYOUT.VERSION.MINOR metadata. It comes from another PROJ installation.\n320it [00:00, 1172.59it/s]             ERROR 1: PROJ: proj_identify: /opt/anaconda3/share/proj/proj.db lacks DATABASE.LAYOUT.VERSION.MAJOR / DATABASE.LAYOUT.VERSION.MINOR metadata. It comes from another PROJ installation.\n  0%|          | 0/288 [00:00<?, ?it/s]ERROR 1: PROJ: proj_identify: /opt/anaconda3/share/proj/proj.db lacks DATABASE.LAYOUT.VERSION.MAJOR / DATABASE.LAYOUT.VERSION.MINOR metadata. It comes from another PROJ installation.\n320it [00:00, 1608.04it/s]             ERROR 1: PROJ: proj_identify: /opt/anaconda3/share/proj/proj.db lacks DATABASE.LAYOUT.VERSION.MAJOR / DATABASE.LAYOUT.VERSION.MINOR metadata. It comes from another PROJ installation.\n  0%|          | 0/288 [00:00<?, ?it/s]ERROR 1: PROJ: proj_identify: /opt/anaconda3/share/proj/proj.db lacks DATABASE.LAYOUT.VERSION.MAJOR / DATABASE.LAYOUT.VERSION.MINOR metadata. It comes from another PROJ installation.\n320it [00:00, 1383.68it/s]             ERROR 1: PROJ: proj_identify: /opt/anaconda3/share/proj/proj.db lacks DATABASE.LAYOUT.VERSION.MAJOR / DATABASE.LAYOUT.VERSION.MINOR metadata. It comes from another PROJ installation.\n  0%|          | 0/288 [00:00<?, ?it/s]ERROR 1: PROJ: proj_identify: /opt/anaconda3/share/proj/proj.db lacks DATABASE.LAYOUT.VERSION.MAJOR / DATABASE.LAYOUT.VERSION.MINOR metadata. It comes from another PROJ installation.\n320it [00:00, 1707.96it/s]             ERROR 1: PROJ: proj_identify: /opt/anaconda3/share/proj/proj.db lacks DATABASE.LAYOUT.VERSION.MAJOR / DATABASE.LAYOUT.VERSION.MINOR metadata. It comes from another PROJ installation.\n  0%|          | 0/288 [00:00<?, ?it/s]ERROR 1: PROJ: proj_identify: /opt/anaconda3/share/proj/proj.db lacks DATABASE.LAYOUT.VERSION.MAJOR / DATABASE.LAYOUT.VERSION.MINOR metadata. It comes from another PROJ installation.\n320it [00:00, 1350.56it/s]             ERROR 1: PROJ: proj_identify: /opt/anaconda3/share/proj/proj.db lacks DATABASE.LAYOUT.VERSION.MAJOR / DATABASE.LAYOUT.VERSION.MINOR metadata. It comes from another PROJ installation.\n  0%|          | 0/288 [00:00<?, ?it/s]ERROR 1: PROJ: proj_identify: /opt/anaconda3/share/proj/proj.db lacks DATABASE.LAYOUT.VERSION.MAJOR / DATABASE.LAYOUT.VERSION.MINOR metadata. It comes from another PROJ installation.\n320it [00:00, 1698.12it/s]             ERROR 1: PROJ: proj_identify: /opt/anaconda3/share/proj/proj.db lacks DATABASE.LAYOUT.VERSION.MAJOR / DATABASE.LAYOUT.VERSION.MINOR metadata. It comes from another PROJ installation.\n  0%|          | 0/288 [00:00<?, ?it/s]ERROR 1: PROJ: proj_identify: /opt/anaconda3/share/proj/proj.db lacks DATABASE.LAYOUT.VERSION.MAJOR / DATABASE.LAYOUT.VERSION.MINOR metadata. It comes from another PROJ installation.\n320it [00:00, 1180.29it/s]             ERROR 1: PROJ: proj_identify: /opt/anaconda3/share/proj/proj.db lacks DATABASE.LAYOUT.VERSION.MAJOR / DATABASE.LAYOUT.VERSION.MINOR metadata. It comes from another PROJ installation.\n  0%|          | 0/288 [00:00<?, ?it/s]ERROR 1: PROJ: proj_identify: /opt/anaconda3/share/proj/proj.db lacks DATABASE.LAYOUT.VERSION.MAJOR / DATABASE.LAYOUT.VERSION.MINOR metadata. It comes from another PROJ installation.\n320it [00:00, 1642.95it/s]             ERROR 1: PROJ: proj_identify: /opt/anaconda3/share/proj/proj.db lacks DATABASE.LAYOUT.VERSION.MAJOR / DATABASE.LAYOUT.VERSION.MINOR metadata. It comes from another PROJ installation.\n  0%|          | 0/288 [00:00<?, ?it/s]ERROR 1: PROJ: proj_identify: /opt/anaconda3/share/proj/proj.db lacks DATABASE.LAYOUT.VERSION.MAJOR / DATABASE.LAYOUT.VERSION.MINOR metadata. It comes from another PROJ installation.\n320it [00:00, 1286.87it/s]             ERROR 1: PROJ: proj_identify: /opt/anaconda3/share/proj/proj.db lacks DATABASE.LAYOUT.VERSION.MAJOR / DATABASE.LAYOUT.VERSION.MINOR metadata. It comes from another PROJ installation.\n  0%|          | 0/288 [00:00<?, ?it/s]ERROR 1: PROJ: proj_identify: /opt/anaconda3/share/proj/proj.db lacks DATABASE.LAYOUT.VERSION.MAJOR / DATABASE.LAYOUT.VERSION.MINOR metadata. It comes from another PROJ installation.\n320it [00:00, 1794.26it/s]             ERROR 1: PROJ: proj_identify: /opt/anaconda3/share/proj/proj.db lacks DATABASE.LAYOUT.VERSION.MAJOR / DATABASE.LAYOUT.VERSION.MINOR metadata. It comes from another PROJ installation.\n  0%|          | 0/288 [00:00<?, ?it/s]ERROR 1: PROJ: proj_identify: /opt/anaconda3/share/proj/proj.db lacks DATABASE.LAYOUT.VERSION.MAJOR / DATABASE.LAYOUT.VERSION.MINOR metadata. It comes from another PROJ installation.\n320it [00:00, 1402.01it/s]             ERROR 1: PROJ: proj_identify: /opt/anaconda3/share/proj/proj.db lacks DATABASE.LAYOUT.VERSION.MAJOR / DATABASE.LAYOUT.VERSION.MINOR metadata. It comes from another PROJ installation.\n  0%|          | 0/288 [00:00<?, ?it/s]ERROR 1: PROJ: proj_identify: /opt/anaconda3/share/proj/proj.db lacks DATABASE.LAYOUT.VERSION.MAJOR / DATABASE.LAYOUT.VERSION.MINOR metadata. It comes from another PROJ installation.\n320it [00:00, 1809.06it/s]             ERROR 1: PROJ: proj_identify: /opt/anaconda3/share/proj/proj.db lacks DATABASE.LAYOUT.VERSION.MAJOR / DATABASE.LAYOUT.VERSION.MINOR metadata. It comes from another PROJ installation.\n  0%|          | 0/288 [00:00<?, ?it/s]ERROR 1: PROJ: proj_identify: /opt/anaconda3/share/proj/proj.db lacks DATABASE.LAYOUT.VERSION.MAJOR / DATABASE.LAYOUT.VERSION.MINOR metadata. It comes from another PROJ installation.\n320it [00:00, 1256.67it/s]             ERROR 1: PROJ: proj_identify: /opt/anaconda3/share/proj/proj.db lacks DATABASE.LAYOUT.VERSION.MAJOR / DATABASE.LAYOUT.VERSION.MINOR metadata. It comes from another PROJ installation.\n  0%|          | 0/288 [00:00<?, ?it/s]ERROR 1: PROJ: proj_identify: /opt/anaconda3/share/proj/proj.db lacks DATABASE.LAYOUT.VERSION.MAJOR / DATABASE.LAYOUT.VERSION.MINOR metadata. It comes from another PROJ installation.\n320it [00:00, 1634.24it/s]             ERROR 1: PROJ: proj_identify: /opt/anaconda3/share/proj/proj.db lacks DATABASE.LAYOUT.VERSION.MAJOR / DATABASE.LAYOUT.VERSION.MINOR metadata. It comes from another PROJ installation.\n  0%|          | 0/305 [00:00<?, ?it/s]ERROR 1: PROJ: proj_identify: /opt/anaconda3/share/proj/proj.db lacks DATABASE.LAYOUT.VERSION.MAJOR / DATABASE.LAYOUT.VERSION.MINOR metadata. It comes from another PROJ installation.\n320it [00:00, 1279.74it/s]             ERROR 1: PROJ: proj_identify: /opt/anaconda3/share/proj/proj.db lacks DATABASE.LAYOUT.VERSION.MAJOR / DATABASE.LAYOUT.VERSION.MINOR metadata. It comes from another PROJ installation.\n  0%|          | 0/305 [00:00<?, ?it/s]ERROR 1: PROJ: proj_identify: /opt/anaconda3/share/proj/proj.db lacks DATABASE.LAYOUT.VERSION.MAJOR / DATABASE.LAYOUT.VERSION.MINOR metadata. It comes from another PROJ installation.\n320it [00:00, 1703.46it/s]             ERROR 1: PROJ: proj_identify: /opt/anaconda3/share/proj/proj.db lacks DATABASE.LAYOUT.VERSION.MAJOR / DATABASE.LAYOUT.VERSION.MINOR metadata. It comes from another PROJ installation.\n  0%|          | 0/288 [00:00<?, ?it/s]ERROR 1: PROJ: proj_identify: /opt/anaconda3/share/proj/proj.db lacks DATABASE.LAYOUT.VERSION.MAJOR / DATABASE.LAYOUT.VERSION.MINOR metadata. It comes from another PROJ installation.\n320it [00:00, 1245.74it/s]             ERROR 1: PROJ: proj_identify: /opt/anaconda3/share/proj/proj.db lacks DATABASE.LAYOUT.VERSION.MAJOR / DATABASE.LAYOUT.VERSION.MINOR metadata. It comes from another PROJ installation.\n  0%|          | 0/288 [00:00<?, ?it/s]ERROR 1: PROJ: proj_identify: /opt/anaconda3/share/proj/proj.db lacks DATABASE.LAYOUT.VERSION.MAJOR / DATABASE.LAYOUT.VERSION.MINOR metadata. It comes from another PROJ installation.\n320it [00:00, 1615.48it/s]             \nStarting...predict.py\n<generator object Path.glob at 0x7fbdc3a9e120>\nUsing model ../data/lightning_logs/version_0/checkpoints/epoch=165.ckpt\nPredicting 7 timesteps in the forecaster\nUsing 1 layers for the global classifier\nUsing 2 layers for the local classifier\nRunning for ../data/raw/earth_engine_plant_village_kenya/1_2019-04-22_2020-04-16.tif\nNo GPU - not using one\nNo GPU - not using one\nRunning for ../data/raw/earth_engine_plant_village_kenya/9_2019-04-22_2020-04-16.tif\nNo GPU - not using one\nNo GPU - not using one\nRunning for ../data/raw/earth_engine_plant_village_kenya/6_2019-04-22_2020-04-16.tif\nNo GPU - not using one\nNo GPU - not using one\nRunning for ../data/raw/earth_engine_plant_village_kenya/3_2019-04-22_2020-04-16.tif\nNo GPU - not using one\nNo GPU - not using one\nRunning for ../data/raw/earth_engine_plant_village_kenya/4_2019-04-22_2020-04-16.tif\nNo GPU - not using one\nNo GPU - not using one\nRunning for ../data/raw/earth_engine_plant_village_kenya/5_2019-04-22_2020-04-16.tif\nNo GPU - not using one\nNo GPU - not using one\nRunning for ../data/raw/earth_engine_plant_village_kenya/0_2018-04-21_2019-04-16.tif\nNo GPU - not using one\nNo GPU - not using one\nRunning for ../data/raw/earth_engine_plant_village_kenya/2_2019-04-22_2020-04-16.tif\nNo GPU - not using one\nNo GPU - not using one\nRunning for ../data/raw/earth_engine_plant_village_kenya/7_2019-04-22_2020-04-16.tif\nNo GPU - not using one\nNo GPU - not using one\nRunning for ../data/raw/earth_engine_plant_village_kenya/8_2019-04-22_2020-04-16.tif\nNo GPU - not using one\nNo GPU - not using one\n",
  "history_begin_time" : 1647347368199,
  "history_end_time" : 1647347399926,
  "history_notes" : null,
  "history_process" : "delykw",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "8e4g0k2h6tg",
  "history_input" : "from pathlib import Path\nimport sys\nimport os\n\nsys.path.append(\"..\")\n\nfrom src_models_model import Model\nfrom src_analysis import plot_results\n\n\ndef kenya_crop_type_mapper():\n    data_dir = \"../data\"\n\n    test_folder = Path(\"../data/raw/earth_engine_plant_village_kenya/\")\n    test_files = test_folder.glob(\"*.tif\")\n    print(test_files)\n\n    list_of_models = list(Path('../data/lightning_logs/').glob('version*/checkpoints/*.ckpt'))\n    latest_model_path = str(max(list_of_models, key=os.path.getctime))\n    print(f\"Using model {latest_model_path}\")\n\n    model = Model.load_from_checkpoint(latest_model_path)\n\n    for test_path in test_files:\n\n        save_dir = Path(data_dir) / \"Autoencoder\"\n        save_dir.mkdir(exist_ok=True)\n\n        print(f\"Running for {test_path}\")\n\n        savepath = save_dir / f\"preds_{test_path.name}\"\n        if savepath.exists():\n            print(\"File already generated. Skipping\")\n            continue\n\n        out_forecasted = model.predict(test_path, with_forecaster=True)\n        plot_results(out_forecasted, test_path, savepath=save_dir, prefix=\"forecasted_\")\n\n        out_normal = model.predict(test_path, with_forecaster=False)\n        plot_results(out_normal, test_path, savepath=save_dir, prefix=\"full_input_\")\n\n        out_forecasted.to_netcdf(save_dir / f\"preds_forecasted_{test_path.name}.nc\")\n        out_normal.to_netcdf(save_dir / f\"preds_normal_{test_path.name}.nc\")\n\n\nif __name__ == \"__main__\":\n    print(\"Starting...predict.py\")\n    kenya_crop_type_mapper()\n",
  "history_output" : "Starting...predict.py\n<generator object Path.glob at 0x7fcadba9e120>\nTraceback (most recent call last):\n  File \"scripts_predict.py\", line 48, in <module>\n    kenya_crop_type_mapper()\n  File \"scripts_predict.py\", line 19, in kenya_crop_type_mapper\n    latest_model_path = str(max(list_of_models, key=os.path.getctime))\nValueError: max() arg is an empty sequence\n",
  "history_begin_time" : 1647347280272,
  "history_end_time" : 1647347284366,
  "history_notes" : null,
  "history_process" : "delykw",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "kgglgxya5xw",
  "history_input" : "from pathlib import Path\nimport sys\nimport os\n\nsys.path.append(\"..\")\n\nfrom src_models_model import Model\nfrom src_analysis import plot_results\n\n\ndef kenya_crop_type_mapper():\n    data_dir = \"../data\"\n\n    test_folder = Path(\"../data/raw/earth_engine_plant_village_kenya/\")\n    test_files = test_folder.glob(\"*.tif\")\n    print(test_files)\n\n    list_of_models = list(Path('../data/lightning_logs/').glob('version*/checkpoints/*.ckpt'))\n    latest_model_path = str(max(list_of_models, key=os.path.getctime))\n    print(f\"Using model {latest_model_path}\")\n\n    model = Model.load_from_checkpoint(latest_model_path)\n\n    for test_path in test_files:\n\n        save_dir = Path(data_dir) / \"Autoencoder\"\n        save_dir.mkdir(exist_ok=True)\n\n        print(f\"Running for {test_path}\")\n\n        savepath = save_dir / f\"preds_{test_path.name}\"\n        if savepath.exists():\n            print(\"File already generated. Skipping\")\n            continue\n\n        out_forecasted = model.predict(test_path, with_forecaster=True)\n        plot_results(out_forecasted, test_path, savepath=save_dir, prefix=\"forecasted_\")\n\n        out_normal = model.predict(test_path, with_forecaster=False)\n        plot_results(out_normal, test_path, savepath=save_dir, prefix=\"full_input_\")\n\n        out_forecasted.to_netcdf(save_dir / f\"preds_forecasted_{test_path.name}.nc\")\n        out_normal.to_netcdf(save_dir / f\"preds_normal_{test_path.name}.nc\")\n\n\nif __name__ == \"__main__\":\n    print(\"Starting...predict.py\")\n    kenya_crop_type_mapper()\n",
  "history_output" : "Starting...predict.py\n<generator object Path.glob at 0x7fbc5da26f20>\nTraceback (most recent call last):\n  File \"scripts_predict.py\", line 48, in <module>\n    kenya_crop_type_mapper()\n  File \"scripts_predict.py\", line 19, in kenya_crop_type_mapper\n    latest_model_path = str(max(list_of_models, key=os.path.getctime))\nValueError: max() arg is an empty sequence\n",
  "history_begin_time" : 1647347140898,
  "history_end_time" : 1647347144356,
  "history_notes" : null,
  "history_process" : "delykw",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "ixrj5zz7o7y",
  "history_input" : "from pathlib import Path\nimport sys\nimport os\n\nsys.path.append(\"..\")\n\nfrom src_models_model import Model\nfrom src_analysis import plot_results\n\n\ndef kenya_crop_type_mapper():\n    data_dir = \"../data\"\n\n    test_folder = Path(\"../data/raw/earth_engine_plant_village_kenya/\")\n    test_files = test_folder.glob(\"*.tif\")\n    print(test_files)\n\n    list_of_models = list(Path('../data/lightning_logs/').glob('version*/checkpoints/*.ckpt'))\n    latest_model_path = str(max(list_of_models, key=os.path.getctime))\n    print(f\"Using model {latest_model_path}\")\n\n    model = Model.load_from_checkpoint(latest_model_path)\n\n    for test_path in test_files:\n\n        save_dir = Path(data_dir) / \"Autoencoder\"\n        save_dir.mkdir(exist_ok=True)\n\n        print(f\"Running for {test_path}\")\n\n        savepath = save_dir / f\"preds_{test_path.name}\"\n        if savepath.exists():\n            print(\"File already generated. Skipping\")\n            continue\n\n        out_forecasted = model.predict(test_path, with_forecaster=True)\n        plot_results(out_forecasted, test_path, savepath=save_dir, prefix=\"forecasted_\")\n\n        out_normal = model.predict(test_path, with_forecaster=False)\n        plot_results(out_normal, test_path, savepath=save_dir, prefix=\"full_input_\")\n\n        out_forecasted.to_netcdf(save_dir / f\"preds_forecasted_{test_path.name}.nc\")\n        out_normal.to_netcdf(save_dir / f\"preds_normal_{test_path.name}.nc\")\n\n\nif __name__ == \"__main__\":\n    print(\"Starting...predict.py\")\n    kenya_crop_type_mapper()\n",
  "history_output" : "",
  "history_begin_time" : 1647346838978,
  "history_end_time" : 1647346840984,
  "history_notes" : null,
  "history_process" : "delykw",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "jtwhjtjndrf",
  "history_input" : "from pathlib import Path\nimport sys\nimport os\n\nsys.path.append(\"..\")\n\nfrom src_models_model import Model\nfrom src_analysis import plot_results\n\n\ndef kenya_crop_type_mapper():\n    data_dir = \"../data\"\n\n    test_folder = Path(\"../data/raw/earth_engine_plant_village_kenya/\")\n    test_files = test_folder.glob(\"*.tif\")\n    print(test_files)\n\n    list_of_models = list(Path('../data/lightning_logs/').glob('version*/checkpoints/*.ckpt'))\n    latest_model_path = str(max(list_of_models, key=os.path.getctime))\n    print(f\"Using model {latest_model_path}\")\n\n    model = Model.load_from_checkpoint(latest_model_path)\n\n    for test_path in test_files:\n\n        save_dir = Path(data_dir) / \"Autoencoder\"\n        save_dir.mkdir(exist_ok=True)\n\n        print(f\"Running for {test_path}\")\n\n        savepath = save_dir / f\"preds_{test_path.name}\"\n        if savepath.exists():\n            print(\"File already generated. Skipping\")\n            continue\n\n        out_forecasted = model.predict(test_path, with_forecaster=True)\n        plot_results(out_forecasted, test_path, savepath=save_dir, prefix=\"forecasted_\")\n\n        out_normal = model.predict(test_path, with_forecaster=False)\n        plot_results(out_normal, test_path, savepath=save_dir, prefix=\"full_input_\")\n\n        out_forecasted.to_netcdf(save_dir / f\"preds_forecasted_{test_path.name}.nc\")\n        out_normal.to_netcdf(save_dir / f\"preds_normal_{test_path.name}.nc\")\n\n\nif __name__ == \"__main__\":\n    print(\"Starting...predict.py\")\n    kenya_crop_type_mapper()\n",
  "history_output" : "ERROR 1: PROJ: proj_identify: /opt/anaconda3/share/proj/proj.db lacks DATABASE.LAYOUT.VERSION.MAJOR / DATABASE.LAYOUT.VERSION.MINOR metadata. It comes from another PROJ installation.\n  0%|          | 0/288 [00:00<?, ?it/s]ERROR 1: PROJ: proj_identify: /opt/anaconda3/share/proj/proj.db lacks DATABASE.LAYOUT.VERSION.MAJOR / DATABASE.LAYOUT.VERSION.MINOR metadata. It comes from another PROJ installation.\n320it [00:00, 1145.92it/s]             ERROR 1: PROJ: proj_identify: /opt/anaconda3/share/proj/proj.db lacks DATABASE.LAYOUT.VERSION.MAJOR / DATABASE.LAYOUT.VERSION.MINOR metadata. It comes from another PROJ installation.\n  0%|          | 0/288 [00:00<?, ?it/s]ERROR 1: PROJ: proj_identify: /opt/anaconda3/share/proj/proj.db lacks DATABASE.LAYOUT.VERSION.MAJOR / DATABASE.LAYOUT.VERSION.MINOR metadata. It comes from another PROJ installation.\n320it [00:00, 1276.63it/s]             ERROR 1: PROJ: proj_identify: /opt/anaconda3/share/proj/proj.db lacks DATABASE.LAYOUT.VERSION.MAJOR / DATABASE.LAYOUT.VERSION.MINOR metadata. It comes from another PROJ installation.\n  0%|          | 0/288 [00:00<?, ?it/s]ERROR 1: PROJ: proj_identify: /opt/anaconda3/share/proj/proj.db lacks DATABASE.LAYOUT.VERSION.MAJOR / DATABASE.LAYOUT.VERSION.MINOR metadata. It comes from another PROJ installation.\n320it [00:00, 1309.53it/s]             ERROR 1: PROJ: proj_identify: /opt/anaconda3/share/proj/proj.db lacks DATABASE.LAYOUT.VERSION.MAJOR / DATABASE.LAYOUT.VERSION.MINOR metadata. It comes from another PROJ installation.\n  0%|          | 0/288 [00:00<?, ?it/s]ERROR 1: PROJ: proj_identify: /opt/anaconda3/share/proj/proj.db lacks DATABASE.LAYOUT.VERSION.MAJOR / DATABASE.LAYOUT.VERSION.MINOR metadata. It comes from another PROJ installation.\n320it [00:00, 1650.60it/s]             ERROR 1: PROJ: proj_identify: /opt/anaconda3/share/proj/proj.db lacks DATABASE.LAYOUT.VERSION.MAJOR / DATABASE.LAYOUT.VERSION.MINOR metadata. It comes from another PROJ installation.\n  0%|          | 0/288 [00:00<?, ?it/s]ERROR 1: PROJ: proj_identify: /opt/anaconda3/share/proj/proj.db lacks DATABASE.LAYOUT.VERSION.MAJOR / DATABASE.LAYOUT.VERSION.MINOR metadata. It comes from another PROJ installation.\n320it [00:00, 1211.35it/s]             ERROR 1: PROJ: proj_identify: /opt/anaconda3/share/proj/proj.db lacks DATABASE.LAYOUT.VERSION.MAJOR / DATABASE.LAYOUT.VERSION.MINOR metadata. It comes from another PROJ installation.\n  0%|          | 0/288 [00:00<?, ?it/s]ERROR 1: PROJ: proj_identify: /opt/anaconda3/share/proj/proj.db lacks DATABASE.LAYOUT.VERSION.MAJOR / DATABASE.LAYOUT.VERSION.MINOR metadata. It comes from another PROJ installation.\n320it [00:00, 1641.91it/s]             ERROR 1: PROJ: proj_identify: /opt/anaconda3/share/proj/proj.db lacks DATABASE.LAYOUT.VERSION.MAJOR / DATABASE.LAYOUT.VERSION.MINOR metadata. It comes from another PROJ installation.\n  0%|          | 0/288 [00:00<?, ?it/s]ERROR 1: PROJ: proj_identify: /opt/anaconda3/share/proj/proj.db lacks DATABASE.LAYOUT.VERSION.MAJOR / DATABASE.LAYOUT.VERSION.MINOR metadata. It comes from another PROJ installation.\n320it [00:00, 1358.52it/s]             ERROR 1: PROJ: proj_identify: /opt/anaconda3/share/proj/proj.db lacks DATABASE.LAYOUT.VERSION.MAJOR / DATABASE.LAYOUT.VERSION.MINOR metadata. It comes from another PROJ installation.\n  0%|          | 0/288 [00:00<?, ?it/s]ERROR 1: PROJ: proj_identify: /opt/anaconda3/share/proj/proj.db lacks DATABASE.LAYOUT.VERSION.MAJOR / DATABASE.LAYOUT.VERSION.MINOR metadata. It comes from another PROJ installation.\n320it [00:00, 1339.65it/s]             ERROR 1: PROJ: proj_identify: /opt/anaconda3/share/proj/proj.db lacks DATABASE.LAYOUT.VERSION.MAJOR / DATABASE.LAYOUT.VERSION.MINOR metadata. It comes from another PROJ installation.\n  0%|          | 0/288 [00:00<?, ?it/s]ERROR 1: PROJ: proj_identify: /opt/anaconda3/share/proj/proj.db lacks DATABASE.LAYOUT.VERSION.MAJOR / DATABASE.LAYOUT.VERSION.MINOR metadata. It comes from another PROJ installation.\n320it [00:00, 1189.92it/s]             ERROR 1: PROJ: proj_identify: /opt/anaconda3/share/proj/proj.db lacks DATABASE.LAYOUT.VERSION.MAJOR / DATABASE.LAYOUT.VERSION.MINOR metadata. It comes from another PROJ installation.\n  0%|          | 0/288 [00:00<?, ?it/s]ERROR 1: PROJ: proj_identify: /opt/anaconda3/share/proj/proj.db lacks DATABASE.LAYOUT.VERSION.MAJOR / DATABASE.LAYOUT.VERSION.MINOR metadata. It comes from another PROJ installation.\n320it [00:00, 1721.57it/s]             ERROR 1: PROJ: proj_identify: /opt/anaconda3/share/proj/proj.db lacks DATABASE.LAYOUT.VERSION.MAJOR / DATABASE.LAYOUT.VERSION.MINOR metadata. It comes from another PROJ installation.\n  0%|          | 0/288 [00:00<?, ?it/s]ERROR 1: PROJ: proj_identify: /opt/anaconda3/share/proj/proj.db lacks DATABASE.LAYOUT.VERSION.MAJOR / DATABASE.LAYOUT.VERSION.MINOR metadata. It comes from another PROJ installation.\n320it [00:00, 1227.37it/s]             ERROR 1: PROJ: proj_identify: /opt/anaconda3/share/proj/proj.db lacks DATABASE.LAYOUT.VERSION.MAJOR / DATABASE.LAYOUT.VERSION.MINOR metadata. It comes from another PROJ installation.\n  0%|          | 0/288 [00:00<?, ?it/s]ERROR 1: PROJ: proj_identify: /opt/anaconda3/share/proj/proj.db lacks DATABASE.LAYOUT.VERSION.MAJOR / DATABASE.LAYOUT.VERSION.MINOR metadata. It comes from another PROJ installation.\n320it [00:00, 1665.59it/s]             ERROR 1: PROJ: proj_identify: /opt/anaconda3/share/proj/proj.db lacks DATABASE.LAYOUT.VERSION.MAJOR / DATABASE.LAYOUT.VERSION.MINOR metadata. It comes from another PROJ installation.\n  0%|          | 0/288 [00:00<?, ?it/s]ERROR 1: PROJ: proj_identify: /opt/anaconda3/share/proj/proj.db lacks DATABASE.LAYOUT.VERSION.MAJOR / DATABASE.LAYOUT.VERSION.MINOR metadata. It comes from another PROJ installation.\n320it [00:00, 1144.59it/s]             ERROR 1: PROJ: proj_identify: /opt/anaconda3/share/proj/proj.db lacks DATABASE.LAYOUT.VERSION.MAJOR / DATABASE.LAYOUT.VERSION.MINOR metadata. It comes from another PROJ installation.\n  0%|          | 0/288 [00:00<?, ?it/s]ERROR 1: PROJ: proj_identify: /opt/anaconda3/share/proj/proj.db lacks DATABASE.LAYOUT.VERSION.MAJOR / DATABASE.LAYOUT.VERSION.MINOR metadata. It comes from another PROJ installation.\n320it [00:00, 1350.47it/s]             ERROR 1: PROJ: proj_identify: /opt/anaconda3/share/proj/proj.db lacks DATABASE.LAYOUT.VERSION.MAJOR / DATABASE.LAYOUT.VERSION.MINOR metadata. It comes from another PROJ installation.\n  0%|          | 0/288 [00:00<?, ?it/s]ERROR 1: PROJ: proj_identify: /opt/anaconda3/share/proj/proj.db lacks DATABASE.LAYOUT.VERSION.MAJOR / DATABASE.LAYOUT.VERSION.MINOR metadata. It comes from another PROJ installation.\n320it [00:00, 1273.66it/s]             ERROR 1: PROJ: proj_identify: /opt/anaconda3/share/proj/proj.db lacks DATABASE.LAYOUT.VERSION.MAJOR / DATABASE.LAYOUT.VERSION.MINOR metadata. It comes from another PROJ installation.\n  0%|          | 0/288 [00:00<?, ?it/s]ERROR 1: PROJ: proj_identify: /opt/anaconda3/share/proj/proj.db lacks DATABASE.LAYOUT.VERSION.MAJOR / DATABASE.LAYOUT.VERSION.MINOR metadata. It comes from another PROJ installation.\n320it [00:00, 1713.57it/s]             ERROR 1: PROJ: proj_identify: /opt/anaconda3/share/proj/proj.db lacks DATABASE.LAYOUT.VERSION.MAJOR / DATABASE.LAYOUT.VERSION.MINOR metadata. It comes from another PROJ installation.\n  0%|          | 0/305 [00:00<?, ?it/s]ERROR 1: PROJ: proj_identify: /opt/anaconda3/share/proj/proj.db lacks DATABASE.LAYOUT.VERSION.MAJOR / DATABASE.LAYOUT.VERSION.MINOR metadata. It comes from another PROJ installation.\n320it [00:00, 1375.46it/s]             ERROR 1: PROJ: proj_identify: /opt/anaconda3/share/proj/proj.db lacks DATABASE.LAYOUT.VERSION.MAJOR / DATABASE.LAYOUT.VERSION.MINOR metadata. It comes from another PROJ installation.\n  0%|          | 0/305 [00:00<?, ?it/s]ERROR 1: PROJ: proj_identify: /opt/anaconda3/share/proj/proj.db lacks DATABASE.LAYOUT.VERSION.MAJOR / DATABASE.LAYOUT.VERSION.MINOR metadata. It comes from another PROJ installation.\n320it [00:00, 1773.83it/s]             ERROR 1: PROJ: proj_identify: /opt/anaconda3/share/proj/proj.db lacks DATABASE.LAYOUT.VERSION.MAJOR / DATABASE.LAYOUT.VERSION.MINOR metadata. It comes from another PROJ installation.\n  0%|          | 0/288 [00:00<?, ?it/s]ERROR 1: PROJ: proj_identify: /opt/anaconda3/share/proj/proj.db lacks DATABASE.LAYOUT.VERSION.MAJOR / DATABASE.LAYOUT.VERSION.MINOR metadata. It comes from another PROJ installation.\n320it [00:00, 1272.73it/s]             ERROR 1: PROJ: proj_identify: /opt/anaconda3/share/proj/proj.db lacks DATABASE.LAYOUT.VERSION.MAJOR / DATABASE.LAYOUT.VERSION.MINOR metadata. It comes from another PROJ installation.\n  0%|          | 0/288 [00:00<?, ?it/s]ERROR 1: PROJ: proj_identify: /opt/anaconda3/share/proj/proj.db lacks DATABASE.LAYOUT.VERSION.MAJOR / DATABASE.LAYOUT.VERSION.MINOR metadata. It comes from another PROJ installation.\n320it [00:00, 1724.73it/s]             \nStarting...predict.py\n<generator object Path.glob at 0x7fac09121120>\nUsing model ../data/lightning_logs/version_14/checkpoints/epoch=165.ckpt\nPredicting 7 timesteps in the forecaster\nUsing 1 layers for the global classifier\nUsing 2 layers for the local classifier\nRunning for ../data/raw/earth_engine_plant_village_kenya/1_2019-04-22_2020-04-16.tif\nNo GPU - not using one\nNo GPU - not using one\nRunning for ../data/raw/earth_engine_plant_village_kenya/9_2019-04-22_2020-04-16.tif\nNo GPU - not using one\nNo GPU - not using one\nRunning for ../data/raw/earth_engine_plant_village_kenya/6_2019-04-22_2020-04-16.tif\nNo GPU - not using one\nNo GPU - not using one\nRunning for ../data/raw/earth_engine_plant_village_kenya/3_2019-04-22_2020-04-16.tif\nNo GPU - not using one\nNo GPU - not using one\nRunning for ../data/raw/earth_engine_plant_village_kenya/4_2019-04-22_2020-04-16.tif\nNo GPU - not using one\nNo GPU - not using one\nRunning for ../data/raw/earth_engine_plant_village_kenya/5_2019-04-22_2020-04-16.tif\nNo GPU - not using one\nNo GPU - not using one\nRunning for ../data/raw/earth_engine_plant_village_kenya/0_2018-04-21_2019-04-16.tif\nNo GPU - not using one\nNo GPU - not using one\nRunning for ../data/raw/earth_engine_plant_village_kenya/2_2019-04-22_2020-04-16.tif\nNo GPU - not using one\nNo GPU - not using one\nRunning for ../data/raw/earth_engine_plant_village_kenya/7_2019-04-22_2020-04-16.tif\nNo GPU - not using one\nNo GPU - not using one\nRunning for ../data/raw/earth_engine_plant_village_kenya/8_2019-04-22_2020-04-16.tif\nNo GPU - not using one\nNo GPU - not using one\n",
  "history_begin_time" : 1647346680415,
  "history_end_time" : 1647346712890,
  "history_notes" : null,
  "history_process" : "delykw",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "ipyp7fbqivj",
  "history_input" : "from pathlib import Path\nimport sys\nimport os\n\nsys.path.append(\"..\")\n\nfrom src_models_model import Model\nfrom src_analysis import plot_results\n\n\ndef kenya_crop_type_mapper():\n    data_dir = \"../data\"\n\n    test_folder = Path(\"../data/raw/earth_engine_plant_village_kenya/\")\n    test_files = test_folder.glob(\"*.tif\")\n    print(test_files)\n\n    list_of_models = list(Path('../data/lightning_logs/').glob('version*/checkpoints/*.ckpt'))\n    latest_model_path = str(max(list_of_models, key=os.path.getctime))\n    print(f\"Using model {latest_model_path}\")\n\n    model = Model.load_from_checkpoint(latest_model_path)\n\n    for test_path in test_files:\n\n        save_dir = Path(data_dir) / \"Autoencoder\"\n        save_dir.mkdir(exist_ok=True)\n\n        print(f\"Running for {test_path}\")\n\n        savepath = save_dir / f\"preds_{test_path.name}\"\n        if savepath.exists():\n            print(\"File already generated. Skipping\")\n            continue\n\n        out_forecasted = model.predict(test_path, with_forecaster=True)\n        plot_results(out_forecasted, test_path, savepath=save_dir, prefix=\"forecasted_\")\n\n        out_normal = model.predict(test_path, with_forecaster=False)\n        plot_results(out_normal, test_path, savepath=save_dir, prefix=\"full_input_\")\n\n        out_forecasted.to_netcdf(save_dir / f\"preds_forecasted_{test_path.name}.nc\")\n        out_normal.to_netcdf(save_dir / f\"preds_normal_{test_path.name}.nc\")\n\n\nif __name__ == \"__main__\":\n    print(\"Starting...predict.py\")\n    kenya_crop_type_mapper()\n",
  "history_output" : "",
  "history_begin_time" : 1647345856797,
  "history_end_time" : 1647345856884,
  "history_notes" : null,
  "history_process" : "delykw",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "7e4e5er2tu2",
  "history_input" : "from pathlib import Path\nimport sys\nimport os\n\nsys.path.append(\"..\")\n\nfrom src_models_model import Model\nfrom src_analysis import plot_results\n\n\ndef kenya_crop_type_mapper():\n    data_dir = \"../data\"\n\n    test_folder = Path(\"../data/raw/earth_engine_plant_village_kenya/\")\n    test_files = test_folder.glob(\"*.tif\")\n    print(test_files)\n\n    list_of_models = list(Path('../data/lightning_logs/').glob('version*/checkpoints/*.ckpt'))\n    latest_model_path = str(max(list_of_models, key=os.path.getctime))\n    print(f\"Using model {latest_model_path}\")\n\n    model = Model.load_from_checkpoint(latest_model_path)\n\n    for test_path in test_files:\n\n        save_dir = Path(data_dir) / \"Autoencoder\"\n        save_dir.mkdir(exist_ok=True)\n\n        print(f\"Running for {test_path}\")\n\n        savepath = save_dir / f\"preds_{test_path.name}\"\n        if savepath.exists():\n            print(\"File already generated. Skipping\")\n            continue\n\n        out_forecasted = model.predict(test_path, with_forecaster=True)\n        plot_results(out_forecasted, test_path, savepath=save_dir, prefix=\"forecasted_\")\n\n        out_normal = model.predict(test_path, with_forecaster=False)\n        plot_results(out_normal, test_path, savepath=save_dir, prefix=\"full_input_\")\n\n        out_forecasted.to_netcdf(save_dir / f\"preds_forecasted_{test_path.name}.nc\")\n        out_normal.to_netcdf(save_dir / f\"preds_normal_{test_path.name}.nc\")\n\n\nif __name__ == \"__main__\":\n    print(\"Starting...predict.py\")\n    kenya_crop_type_mapper()\n",
  "history_output" : "ERROR 1: PROJ: proj_identify: /opt/anaconda3/share/proj/proj.db lacks DATABASE.LAYOUT.VERSION.MAJOR / DATABASE.LAYOUT.VERSION.MINOR metadata. It comes from another PROJ installation.\n  0%|          | 0/288 [00:00<?, ?it/s]ERROR 1: PROJ: proj_identify: /opt/anaconda3/share/proj/proj.db lacks DATABASE.LAYOUT.VERSION.MAJOR / DATABASE.LAYOUT.VERSION.MINOR metadata. It comes from another PROJ installation.\n320it [00:00, 1186.70it/s]             ERROR 1: PROJ: proj_identify: /opt/anaconda3/share/proj/proj.db lacks DATABASE.LAYOUT.VERSION.MAJOR / DATABASE.LAYOUT.VERSION.MINOR metadata. It comes from another PROJ installation.\n  0%|          | 0/288 [00:00<?, ?it/s]ERROR 1: PROJ: proj_identify: /opt/anaconda3/share/proj/proj.db lacks DATABASE.LAYOUT.VERSION.MAJOR / DATABASE.LAYOUT.VERSION.MINOR metadata. It comes from another PROJ installation.\n320it [00:00, 1321.39it/s]             ERROR 1: PROJ: proj_identify: /opt/anaconda3/share/proj/proj.db lacks DATABASE.LAYOUT.VERSION.MAJOR / DATABASE.LAYOUT.VERSION.MINOR metadata. It comes from another PROJ installation.\n  0%|          | 0/288 [00:00<?, ?it/s]ERROR 1: PROJ: proj_identify: /opt/anaconda3/share/proj/proj.db lacks DATABASE.LAYOUT.VERSION.MAJOR / DATABASE.LAYOUT.VERSION.MINOR metadata. It comes from another PROJ installation.\n320it [00:00, 1010.88it/s]             ERROR 1: PROJ: proj_identify: /opt/anaconda3/share/proj/proj.db lacks DATABASE.LAYOUT.VERSION.MAJOR / DATABASE.LAYOUT.VERSION.MINOR metadata. It comes from another PROJ installation.\n  0%|          | 0/288 [00:00<?, ?it/s]ERROR 1: PROJ: proj_identify: /opt/anaconda3/share/proj/proj.db lacks DATABASE.LAYOUT.VERSION.MAJOR / DATABASE.LAYOUT.VERSION.MINOR metadata. It comes from another PROJ installation.\n320it [00:00, 1124.82it/s]             ERROR 1: PROJ: proj_identify: /opt/anaconda3/share/proj/proj.db lacks DATABASE.LAYOUT.VERSION.MAJOR / DATABASE.LAYOUT.VERSION.MINOR metadata. It comes from another PROJ installation.\n  0%|          | 0/288 [00:00<?, ?it/s]\n 22%|██▏       | 64/288 [00:00<00:00, 362.09it/s]ERROR 1: PROJ: proj_identify: /opt/anaconda3/share/proj/proj.db lacks DATABASE.LAYOUT.VERSION.MAJOR / DATABASE.LAYOUT.VERSION.MINOR metadata. It comes from another PROJ installation.\n320it [00:00, 640.92it/s]                        ERROR 1: PROJ: proj_identify: /opt/anaconda3/share/proj/proj.db lacks DATABASE.LAYOUT.VERSION.MAJOR / DATABASE.LAYOUT.VERSION.MINOR metadata. It comes from another PROJ installation.\n  0%|          | 0/288 [00:00<?, ?it/s]ERROR 1: PROJ: proj_identify: /opt/anaconda3/share/proj/proj.db lacks DATABASE.LAYOUT.VERSION.MAJOR / DATABASE.LAYOUT.VERSION.MINOR metadata. It comes from another PROJ installation.\n320it [00:00, 1337.99it/s]             ERROR 1: PROJ: proj_identify: /opt/anaconda3/share/proj/proj.db lacks DATABASE.LAYOUT.VERSION.MAJOR / DATABASE.LAYOUT.VERSION.MINOR metadata. It comes from another PROJ installation.\n  0%|          | 0/288 [00:00<?, ?it/s]ERROR 1: PROJ: proj_identify: /opt/anaconda3/share/proj/proj.db lacks DATABASE.LAYOUT.VERSION.MAJOR / DATABASE.LAYOUT.VERSION.MINOR metadata. It comes from another PROJ installation.\n320it [00:00, 1192.50it/s]             ERROR 1: PROJ: proj_identify: /opt/anaconda3/share/proj/proj.db lacks DATABASE.LAYOUT.VERSION.MAJOR / DATABASE.LAYOUT.VERSION.MINOR metadata. It comes from another PROJ installation.\n  0%|          | 0/288 [00:00<?, ?it/s]ERROR 1: PROJ: proj_identify: /opt/anaconda3/share/proj/proj.db lacks DATABASE.LAYOUT.VERSION.MAJOR / DATABASE.LAYOUT.VERSION.MINOR metadata. It comes from another PROJ installation.\n320it [00:00, 1665.41it/s]             ERROR 1: PROJ: proj_identify: /opt/anaconda3/share/proj/proj.db lacks DATABASE.LAYOUT.VERSION.MAJOR / DATABASE.LAYOUT.VERSION.MINOR metadata. It comes from another PROJ installation.\n  0%|          | 0/288 [00:00<?, ?it/s]ERROR 1: PROJ: proj_identify: /opt/anaconda3/share/proj/proj.db lacks DATABASE.LAYOUT.VERSION.MAJOR / DATABASE.LAYOUT.VERSION.MINOR metadata. It comes from another PROJ installation.\n320it [00:00, 1293.15it/s]             ERROR 1: PROJ: proj_identify: /opt/anaconda3/share/proj/proj.db lacks DATABASE.LAYOUT.VERSION.MAJOR / DATABASE.LAYOUT.VERSION.MINOR metadata. It comes from another PROJ installation.\n  0%|          | 0/288 [00:00<?, ?it/s]ERROR 1: PROJ: proj_identify: /opt/anaconda3/share/proj/proj.db lacks DATABASE.LAYOUT.VERSION.MAJOR / DATABASE.LAYOUT.VERSION.MINOR metadata. It comes from another PROJ installation.\n320it [00:00, 1696.97it/s]             ERROR 1: PROJ: proj_identify: /opt/anaconda3/share/proj/proj.db lacks DATABASE.LAYOUT.VERSION.MAJOR / DATABASE.LAYOUT.VERSION.MINOR metadata. It comes from another PROJ installation.\n  0%|          | 0/288 [00:00<?, ?it/s]ERROR 1: PROJ: proj_identify: /opt/anaconda3/share/proj/proj.db lacks DATABASE.LAYOUT.VERSION.MAJOR / DATABASE.LAYOUT.VERSION.MINOR metadata. It comes from another PROJ installation.\n320it [00:00, 1319.50it/s]             ERROR 1: PROJ: proj_identify: /opt/anaconda3/share/proj/proj.db lacks DATABASE.LAYOUT.VERSION.MAJOR / DATABASE.LAYOUT.VERSION.MINOR metadata. It comes from another PROJ installation.\n  0%|          | 0/288 [00:00<?, ?it/s]ERROR 1: PROJ: proj_identify: /opt/anaconda3/share/proj/proj.db lacks DATABASE.LAYOUT.VERSION.MAJOR / DATABASE.LAYOUT.VERSION.MINOR metadata. It comes from another PROJ installation.\n320it [00:00, 1648.38it/s]             ERROR 1: PROJ: proj_identify: /opt/anaconda3/share/proj/proj.db lacks DATABASE.LAYOUT.VERSION.MAJOR / DATABASE.LAYOUT.VERSION.MINOR metadata. It comes from another PROJ installation.\n  0%|          | 0/288 [00:00<?, ?it/s]ERROR 1: PROJ: proj_identify: /opt/anaconda3/share/proj/proj.db lacks DATABASE.LAYOUT.VERSION.MAJOR / DATABASE.LAYOUT.VERSION.MINOR metadata. It comes from another PROJ installation.\n320it [00:00, 1263.61it/s]             ERROR 1: PROJ: proj_identify: /opt/anaconda3/share/proj/proj.db lacks DATABASE.LAYOUT.VERSION.MAJOR / DATABASE.LAYOUT.VERSION.MINOR metadata. It comes from another PROJ installation.\n  0%|          | 0/288 [00:00<?, ?it/s]ERROR 1: PROJ: proj_identify: /opt/anaconda3/share/proj/proj.db lacks DATABASE.LAYOUT.VERSION.MAJOR / DATABASE.LAYOUT.VERSION.MINOR metadata. It comes from another PROJ installation.\n320it [00:00, 1677.02it/s]             ERROR 1: PROJ: proj_identify: /opt/anaconda3/share/proj/proj.db lacks DATABASE.LAYOUT.VERSION.MAJOR / DATABASE.LAYOUT.VERSION.MINOR metadata. It comes from another PROJ installation.\n  0%|          | 0/288 [00:00<?, ?it/s]ERROR 1: PROJ: proj_identify: /opt/anaconda3/share/proj/proj.db lacks DATABASE.LAYOUT.VERSION.MAJOR / DATABASE.LAYOUT.VERSION.MINOR metadata. It comes from another PROJ installation.\n320it [00:00, 1227.45it/s]             ERROR 1: PROJ: proj_identify: /opt/anaconda3/share/proj/proj.db lacks DATABASE.LAYOUT.VERSION.MAJOR / DATABASE.LAYOUT.VERSION.MINOR metadata. It comes from another PROJ installation.\n  0%|          | 0/288 [00:00<?, ?it/s]ERROR 1: PROJ: proj_identify: /opt/anaconda3/share/proj/proj.db lacks DATABASE.LAYOUT.VERSION.MAJOR / DATABASE.LAYOUT.VERSION.MINOR metadata. It comes from another PROJ installation.\n320it [00:00, 1660.26it/s]             ERROR 1: PROJ: proj_identify: /opt/anaconda3/share/proj/proj.db lacks DATABASE.LAYOUT.VERSION.MAJOR / DATABASE.LAYOUT.VERSION.MINOR metadata. It comes from another PROJ installation.\n  0%|          | 0/305 [00:00<?, ?it/s]ERROR 1: PROJ: proj_identify: /opt/anaconda3/share/proj/proj.db lacks DATABASE.LAYOUT.VERSION.MAJOR / DATABASE.LAYOUT.VERSION.MINOR metadata. It comes from another PROJ installation.\n320it [00:00, 1295.17it/s]             ERROR 1: PROJ: proj_identify: /opt/anaconda3/share/proj/proj.db lacks DATABASE.LAYOUT.VERSION.MAJOR / DATABASE.LAYOUT.VERSION.MINOR metadata. It comes from another PROJ installation.\n  0%|          | 0/305 [00:00<?, ?it/s]ERROR 1: PROJ: proj_identify: /opt/anaconda3/share/proj/proj.db lacks DATABASE.LAYOUT.VERSION.MAJOR / DATABASE.LAYOUT.VERSION.MINOR metadata. It comes from another PROJ installation.\n320it [00:00, 1683.16it/s]             ERROR 1: PROJ: proj_identify: /opt/anaconda3/share/proj/proj.db lacks DATABASE.LAYOUT.VERSION.MAJOR / DATABASE.LAYOUT.VERSION.MINOR metadata. It comes from another PROJ installation.\n  0%|          | 0/288 [00:00<?, ?it/s]ERROR 1: PROJ: proj_identify: /opt/anaconda3/share/proj/proj.db lacks DATABASE.LAYOUT.VERSION.MAJOR / DATABASE.LAYOUT.VERSION.MINOR metadata. It comes from another PROJ installation.\n320it [00:00, 1265.43it/s]             ERROR 1: PROJ: proj_identify: /opt/anaconda3/share/proj/proj.db lacks DATABASE.LAYOUT.VERSION.MAJOR / DATABASE.LAYOUT.VERSION.MINOR metadata. It comes from another PROJ installation.\n  0%|          | 0/288 [00:00<?, ?it/s]ERROR 1: PROJ: proj_identify: /opt/anaconda3/share/proj/proj.db lacks DATABASE.LAYOUT.VERSION.MAJOR / DATABASE.LAYOUT.VERSION.MINOR metadata. It comes from another PROJ installation.\n320it [00:00, 1671.71it/s]             \nStarting...predict.py\n<generator object Path.glob at 0x7f82a1025f20>\nUsing model ../data/lightning_logs/version_13/checkpoints/epoch=165.ckpt\nPredicting 7 timesteps in the forecaster\nUsing 1 layers for the global classifier\nUsing 2 layers for the local classifier\nRunning for ../data/raw/earth_engine_plant_village_kenya/1_2019-04-22_2020-04-16.tif\nNo GPU - not using one\nNo GPU - not using one\nRunning for ../data/raw/earth_engine_plant_village_kenya/9_2019-04-22_2020-04-16.tif\nNo GPU - not using one\nNo GPU - not using one\nRunning for ../data/raw/earth_engine_plant_village_kenya/6_2019-04-22_2020-04-16.tif\nNo GPU - not using one\nNo GPU - not using one\nRunning for ../data/raw/earth_engine_plant_village_kenya/3_2019-04-22_2020-04-16.tif\nNo GPU - not using one\nNo GPU - not using one\nRunning for ../data/raw/earth_engine_plant_village_kenya/4_2019-04-22_2020-04-16.tif\nNo GPU - not using one\nNo GPU - not using one\nRunning for ../data/raw/earth_engine_plant_village_kenya/5_2019-04-22_2020-04-16.tif\nNo GPU - not using one\nNo GPU - not using one\nRunning for ../data/raw/earth_engine_plant_village_kenya/0_2018-04-21_2019-04-16.tif\nNo GPU - not using one\nNo GPU - not using one\nRunning for ../data/raw/earth_engine_plant_village_kenya/2_2019-04-22_2020-04-16.tif\nNo GPU - not using one\nNo GPU - not using one\nRunning for ../data/raw/earth_engine_plant_village_kenya/7_2019-04-22_2020-04-16.tif\nNo GPU - not using one\nNo GPU - not using one\nRunning for ../data/raw/earth_engine_plant_village_kenya/8_2019-04-22_2020-04-16.tif\nNo GPU - not using one\nNo GPU - not using one\n",
  "history_begin_time" : 1647345661897,
  "history_end_time" : 1647345695105,
  "history_notes" : null,
  "history_process" : "delykw",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "c5ylKQGnrD6s",
  "history_input" : "from pathlib import Path\nimport sys\nimport os\n\nsys.path.append(\"..\")\n\nfrom src_models_model import Model\nfrom src_analysis import plot_results\n\n\ndef kenya_crop_type_mapper():\n    data_dir = \"../data\"\n\n    test_folder = Path(\"../data/raw/earth_engine_plant_village_kenya/\")\n    test_files = test_folder.glob(\"*.tif\")\n    print(test_files)\n\n    list_of_models = list(Path('../data/lightning_logs/').glob('version*/checkpoints/*.ckpt'))\n    latest_model_path = str(max(list_of_models, key=os.path.getctime))\n    print(f\"Using model {latest_model_path}\")\n\n    model = Model.load_from_checkpoint(latest_model_path)\n\n    for test_path in test_files:\n\n        save_dir = Path(data_dir) / \"Autoencoder\"\n        save_dir.mkdir(exist_ok=True)\n\n        print(f\"Running for {test_path}\")\n\n        savepath = save_dir / f\"preds_{test_path.name}\"\n        if savepath.exists():\n            print(\"File already generated. Skipping\")\n            continue\n\n        out_forecasted = model.predict(test_path, with_forecaster=True)\n        plot_results(out_forecasted, test_path, savepath=save_dir, prefix=\"forecasted_\")\n\n        out_normal = model.predict(test_path, with_forecaster=False)\n        plot_results(out_normal, test_path, savepath=save_dir, prefix=\"full_input_\")\n\n        out_forecasted.to_netcdf(save_dir / f\"preds_forecasted_{test_path.name}.nc\")\n        out_normal.to_netcdf(save_dir / f\"preds_normal_{test_path.name}.nc\")\n\n\nif __name__ == \"__main__\":\n    print(\"Starting...predict.py\")\n    kenya_crop_type_mapper()\n",
  "history_output" : "ERROR 1: PROJ: proj_identify: /opt/anaconda3/share/proj/proj.db lacks DATABASE.LAYOUT.VERSION.MAJOR / DATABASE.LAYOUT.VERSION.MINOR metadata. It comes from another PROJ installation.\n  0%|          | 0/288 [00:00<?, ?it/s]\n 89%|████████▉ | 256/288 [00:00<00:00, 2427.32it/s]ERROR 1: PROJ: proj_identify: /opt/anaconda3/share/proj/proj.db lacks DATABASE.LAYOUT.VERSION.MAJOR / DATABASE.LAYOUT.VERSION.MINOR metadata. It comes from another PROJ installation.\n320it [00:00, 996.52it/s]                          ERROR 1: PROJ: proj_identify: /opt/anaconda3/share/proj/proj.db lacks DATABASE.LAYOUT.VERSION.MAJOR / DATABASE.LAYOUT.VERSION.MINOR metadata. It comes from another PROJ installation.\n  0%|          | 0/288 [00:00<?, ?it/s]ERROR 1: PROJ: proj_identify: /opt/anaconda3/share/proj/proj.db lacks DATABASE.LAYOUT.VERSION.MAJOR / DATABASE.LAYOUT.VERSION.MINOR metadata. It comes from another PROJ installation.\n320it [00:00, 1646.63it/s]             ERROR 1: PROJ: proj_identify: /opt/anaconda3/share/proj/proj.db lacks DATABASE.LAYOUT.VERSION.MAJOR / DATABASE.LAYOUT.VERSION.MINOR metadata. It comes from another PROJ installation.\n  0%|          | 0/288 [00:00<?, ?it/s]ERROR 1: PROJ: proj_identify: /opt/anaconda3/share/proj/proj.db lacks DATABASE.LAYOUT.VERSION.MAJOR / DATABASE.LAYOUT.VERSION.MINOR metadata. It comes from another PROJ installation.\n320it [00:00, 1270.84it/s]             ERROR 1: PROJ: proj_identify: /opt/anaconda3/share/proj/proj.db lacks DATABASE.LAYOUT.VERSION.MAJOR / DATABASE.LAYOUT.VERSION.MINOR metadata. It comes from another PROJ installation.\n  0%|          | 0/288 [00:00<?, ?it/s]ERROR 1: PROJ: proj_identify: /opt/anaconda3/share/proj/proj.db lacks DATABASE.LAYOUT.VERSION.MAJOR / DATABASE.LAYOUT.VERSION.MINOR metadata. It comes from another PROJ installation.\n320it [00:00, 1696.19it/s]             ERROR 1: PROJ: proj_identify: /opt/anaconda3/share/proj/proj.db lacks DATABASE.LAYOUT.VERSION.MAJOR / DATABASE.LAYOUT.VERSION.MINOR metadata. It comes from another PROJ installation.\n  0%|          | 0/288 [00:00<?, ?it/s]ERROR 1: PROJ: proj_identify: /opt/anaconda3/share/proj/proj.db lacks DATABASE.LAYOUT.VERSION.MAJOR / DATABASE.LAYOUT.VERSION.MINOR metadata. It comes from another PROJ installation.\n320it [00:00, 1310.98it/s]             ERROR 1: PROJ: proj_identify: /opt/anaconda3/share/proj/proj.db lacks DATABASE.LAYOUT.VERSION.MAJOR / DATABASE.LAYOUT.VERSION.MINOR metadata. It comes from another PROJ installation.\n  0%|          | 0/288 [00:00<?, ?it/s]ERROR 1: PROJ: proj_identify: /opt/anaconda3/share/proj/proj.db lacks DATABASE.LAYOUT.VERSION.MAJOR / DATABASE.LAYOUT.VERSION.MINOR metadata. It comes from another PROJ installation.\n320it [00:00, 1774.60it/s]             ERROR 1: PROJ: proj_identify: /opt/anaconda3/share/proj/proj.db lacks DATABASE.LAYOUT.VERSION.MAJOR / DATABASE.LAYOUT.VERSION.MINOR metadata. It comes from another PROJ installation.\n  0%|          | 0/288 [00:00<?, ?it/s]ERROR 1: PROJ: proj_identify: /opt/anaconda3/share/proj/proj.db lacks DATABASE.LAYOUT.VERSION.MAJOR / DATABASE.LAYOUT.VERSION.MINOR metadata. It comes from another PROJ installation.\n320it [00:00, 1390.27it/s]             ERROR 1: PROJ: proj_identify: /opt/anaconda3/share/proj/proj.db lacks DATABASE.LAYOUT.VERSION.MAJOR / DATABASE.LAYOUT.VERSION.MINOR metadata. It comes from another PROJ installation.\n  0%|          | 0/288 [00:00<?, ?it/s]ERROR 1: PROJ: proj_identify: /opt/anaconda3/share/proj/proj.db lacks DATABASE.LAYOUT.VERSION.MAJOR / DATABASE.LAYOUT.VERSION.MINOR metadata. It comes from another PROJ installation.\n320it [00:00, 1676.31it/s]             ERROR 1: PROJ: proj_identify: /opt/anaconda3/share/proj/proj.db lacks DATABASE.LAYOUT.VERSION.MAJOR / DATABASE.LAYOUT.VERSION.MINOR metadata. It comes from another PROJ installation.\n  0%|          | 0/288 [00:00<?, ?it/s]ERROR 1: PROJ: proj_identify: /opt/anaconda3/share/proj/proj.db lacks DATABASE.LAYOUT.VERSION.MAJOR / DATABASE.LAYOUT.VERSION.MINOR metadata. It comes from another PROJ installation.\n320it [00:00, 1224.37it/s]             ERROR 1: PROJ: proj_identify: /opt/anaconda3/share/proj/proj.db lacks DATABASE.LAYOUT.VERSION.MAJOR / DATABASE.LAYOUT.VERSION.MINOR metadata. It comes from another PROJ installation.\n  0%|          | 0/288 [00:00<?, ?it/s]ERROR 1: PROJ: proj_identify: /opt/anaconda3/share/proj/proj.db lacks DATABASE.LAYOUT.VERSION.MAJOR / DATABASE.LAYOUT.VERSION.MINOR metadata. It comes from another PROJ installation.\n320it [00:00, 1739.48it/s]             ERROR 1: PROJ: proj_identify: /opt/anaconda3/share/proj/proj.db lacks DATABASE.LAYOUT.VERSION.MAJOR / DATABASE.LAYOUT.VERSION.MINOR metadata. It comes from another PROJ installation.\n  0%|          | 0/288 [00:00<?, ?it/s]ERROR 1: PROJ: proj_identify: /opt/anaconda3/share/proj/proj.db lacks DATABASE.LAYOUT.VERSION.MAJOR / DATABASE.LAYOUT.VERSION.MINOR metadata. It comes from another PROJ installation.\n320it [00:00, 1392.16it/s]             ERROR 1: PROJ: proj_identify: /opt/anaconda3/share/proj/proj.db lacks DATABASE.LAYOUT.VERSION.MAJOR / DATABASE.LAYOUT.VERSION.MINOR metadata. It comes from another PROJ installation.\n  0%|          | 0/288 [00:00<?, ?it/s]ERROR 1: PROJ: proj_identify: /opt/anaconda3/share/proj/proj.db lacks DATABASE.LAYOUT.VERSION.MAJOR / DATABASE.LAYOUT.VERSION.MINOR metadata. It comes from another PROJ installation.\n320it [00:00, 1787.47it/s]             ERROR 1: PROJ: proj_identify: /opt/anaconda3/share/proj/proj.db lacks DATABASE.LAYOUT.VERSION.MAJOR / DATABASE.LAYOUT.VERSION.MINOR metadata. It comes from another PROJ installation.\n  0%|          | 0/288 [00:00<?, ?it/s]ERROR 1: PROJ: proj_identify: /opt/anaconda3/share/proj/proj.db lacks DATABASE.LAYOUT.VERSION.MAJOR / DATABASE.LAYOUT.VERSION.MINOR metadata. It comes from another PROJ installation.\n320it [00:00, 1430.02it/s]             ERROR 1: PROJ: proj_identify: /opt/anaconda3/share/proj/proj.db lacks DATABASE.LAYOUT.VERSION.MAJOR / DATABASE.LAYOUT.VERSION.MINOR metadata. It comes from another PROJ installation.\n  0%|          | 0/288 [00:00<?, ?it/s]ERROR 1: PROJ: proj_identify: /opt/anaconda3/share/proj/proj.db lacks DATABASE.LAYOUT.VERSION.MAJOR / DATABASE.LAYOUT.VERSION.MINOR metadata. It comes from another PROJ installation.\n320it [00:00, 1688.93it/s]             ERROR 1: PROJ: proj_identify: /opt/anaconda3/share/proj/proj.db lacks DATABASE.LAYOUT.VERSION.MAJOR / DATABASE.LAYOUT.VERSION.MINOR metadata. It comes from another PROJ installation.\n  0%|          | 0/288 [00:00<?, ?it/s]ERROR 1: PROJ: proj_identify: /opt/anaconda3/share/proj/proj.db lacks DATABASE.LAYOUT.VERSION.MAJOR / DATABASE.LAYOUT.VERSION.MINOR metadata. It comes from another PROJ installation.\n320it [00:00, 1451.21it/s]             ERROR 1: PROJ: proj_identify: /opt/anaconda3/share/proj/proj.db lacks DATABASE.LAYOUT.VERSION.MAJOR / DATABASE.LAYOUT.VERSION.MINOR metadata. It comes from another PROJ installation.\n  0%|          | 0/288 [00:00<?, ?it/s]ERROR 1: PROJ: proj_identify: /opt/anaconda3/share/proj/proj.db lacks DATABASE.LAYOUT.VERSION.MAJOR / DATABASE.LAYOUT.VERSION.MINOR metadata. It comes from another PROJ installation.\n320it [00:00, 1805.54it/s]             ERROR 1: PROJ: proj_identify: /opt/anaconda3/share/proj/proj.db lacks DATABASE.LAYOUT.VERSION.MAJOR / DATABASE.LAYOUT.VERSION.MINOR metadata. It comes from another PROJ installation.\n  0%|          | 0/305 [00:00<?, ?it/s]ERROR 1: PROJ: proj_identify: /opt/anaconda3/share/proj/proj.db lacks DATABASE.LAYOUT.VERSION.MAJOR / DATABASE.LAYOUT.VERSION.MINOR metadata. It comes from another PROJ installation.\n320it [00:00, 1416.07it/s]             ERROR 1: PROJ: proj_identify: /opt/anaconda3/share/proj/proj.db lacks DATABASE.LAYOUT.VERSION.MAJOR / DATABASE.LAYOUT.VERSION.MINOR metadata. It comes from another PROJ installation.\n  0%|          | 0/305 [00:00<?, ?it/s]ERROR 1: PROJ: proj_identify: /opt/anaconda3/share/proj/proj.db lacks DATABASE.LAYOUT.VERSION.MAJOR / DATABASE.LAYOUT.VERSION.MINOR metadata. It comes from another PROJ installation.\n320it [00:00, 1839.96it/s]             ERROR 1: PROJ: proj_identify: /opt/anaconda3/share/proj/proj.db lacks DATABASE.LAYOUT.VERSION.MAJOR / DATABASE.LAYOUT.VERSION.MINOR metadata. It comes from another PROJ installation.\n  0%|          | 0/288 [00:00<?, ?it/s]ERROR 1: PROJ: proj_identify: /opt/anaconda3/share/proj/proj.db lacks DATABASE.LAYOUT.VERSION.MAJOR / DATABASE.LAYOUT.VERSION.MINOR metadata. It comes from another PROJ installation.\n320it [00:00, 1428.96it/s]             ERROR 1: PROJ: proj_identify: /opt/anaconda3/share/proj/proj.db lacks DATABASE.LAYOUT.VERSION.MAJOR / DATABASE.LAYOUT.VERSION.MINOR metadata. It comes from another PROJ installation.\n  0%|          | 0/288 [00:00<?, ?it/s]ERROR 1: PROJ: proj_identify: /opt/anaconda3/share/proj/proj.db lacks DATABASE.LAYOUT.VERSION.MAJOR / DATABASE.LAYOUT.VERSION.MINOR metadata. It comes from another PROJ installation.\n320it [00:00, 1767.08it/s]             \nStarting...predict.py\n<generator object Path.glob at 0x7fbc34a9f120>\nUsing model ../data/lightning_logs/version_13/checkpoints/epoch=165.ckpt\nPredicting 7 timesteps in the forecaster\nUsing 1 layers for the global classifier\nUsing 2 layers for the local classifier\nRunning for ../data/raw/earth_engine_plant_village_kenya/1_2019-04-22_2020-04-16.tif\nNo GPU - not using one\nNo GPU - not using one\nRunning for ../data/raw/earth_engine_plant_village_kenya/9_2019-04-22_2020-04-16.tif\nNo GPU - not using one\nNo GPU - not using one\nRunning for ../data/raw/earth_engine_plant_village_kenya/6_2019-04-22_2020-04-16.tif\nNo GPU - not using one\nNo GPU - not using one\nRunning for ../data/raw/earth_engine_plant_village_kenya/3_2019-04-22_2020-04-16.tif\nNo GPU - not using one\nNo GPU - not using one\nRunning for ../data/raw/earth_engine_plant_village_kenya/4_2019-04-22_2020-04-16.tif\nNo GPU - not using one\nNo GPU - not using one\nRunning for ../data/raw/earth_engine_plant_village_kenya/5_2019-04-22_2020-04-16.tif\nNo GPU - not using one\nNo GPU - not using one\nRunning for ../data/raw/earth_engine_plant_village_kenya/0_2018-04-21_2019-04-16.tif\nNo GPU - not using one\nNo GPU - not using one\nRunning for ../data/raw/earth_engine_plant_village_kenya/2_2019-04-22_2020-04-16.tif\nNo GPU - not using one\nNo GPU - not using one\nRunning for ../data/raw/earth_engine_plant_village_kenya/7_2019-04-22_2020-04-16.tif\nNo GPU - not using one\nNo GPU - not using one\nRunning for ../data/raw/earth_engine_plant_village_kenya/8_2019-04-22_2020-04-16.tif\nNo GPU - not using one\nNo GPU - not using one\n",
  "history_begin_time" : 1647345506260,
  "history_end_time" : 1647345538694,
  "history_notes" : null,
  "history_process" : "delykw",
  "host_id" : null,
  "indicator" : "Done"
},{
  "history_id" : "3D68RCE17eVc",
  "history_input" : "from pathlib import Path\nimport sys\n\nsys.path.append(\"..\")\n\nfrom src_models_model import Model\nfrom src_analysis import plot_results\n\n\ndef kenya_crop_type_mapper():\n    data_dir = \"../data\"\n\n    test_folder = Path(\"../data/raw/earth_engine_plant_village_kenya/\")\n    test_files = test_folder.glob(\"*.tif\")\n    print(test_files)\n\n    list_of_models = list(Path('../data/lightning_logs/').glob('version*/checkpoints/*.ckpt'))\n    latest_model_path = str(max(list_of_models, key=os.path.getctime))\n    print(f\"Using model {latest_model_path}\")\n\n    model = Model.load_from_checkpoint(latest_model_path)\n\n    for test_path in test_files:\n\n        save_dir = Path(data_dir) / \"Autoencoder\"\n        save_dir.mkdir(exist_ok=True)\n\n        print(f\"Running for {test_path}\")\n\n        savepath = save_dir / f\"preds_{test_path.name}\"\n        if savepath.exists():\n            print(\"File already generated. Skipping\")\n            continue\n\n        out_forecasted = model.predict(test_path, with_forecaster=True)\n        plot_results(out_forecasted, test_path, savepath=save_dir, prefix=\"forecasted_\")\n\n        out_normal = model.predict(test_path, with_forecaster=False)\n        plot_results(out_normal, test_path, savepath=save_dir, prefix=\"full_input_\")\n\n        out_forecasted.to_netcdf(save_dir / f\"preds_forecasted_{test_path.name}.nc\")\n        out_normal.to_netcdf(save_dir / f\"preds_normal_{test_path.name}.nc\")\n\n\nif __name__ == \"__main__\":\n    print(\"Starting...predict.py\")\n    kenya_crop_type_mapper()\n",
  "history_output" : "Starting...predict.py\n<generator object Path.glob at 0x7fa29ea9e120>\nTraceback (most recent call last):\n  File \"scripts_predict.py\", line 47, in <module>\n    kenya_crop_type_mapper()\n  File \"scripts_predict.py\", line 18, in kenya_crop_type_mapper\n    latest_model_path = str(max(list_of_models, key=os.path.getctime))\nNameError: name 'os' is not defined\n",
  "history_begin_time" : 1647345489698,
  "history_end_time" : 1647345492925,
  "history_notes" : null,
  "history_process" : "delykw",
  "host_id" : null,
  "indicator" : "Done"
},{
  "history_id" : "iBr0ZQ2hsPa8",
  "history_input" : "from pathlib import Path\nimport sys\n\nsys.path.append(\"..\")\n\nfrom src_models_model import Model\nfrom src_analysis import plot_results\n\n\ndef kenya_crop_type_mapper():\n    data_dir = \"../data\"\n\n    test_folder = Path(\"../data/raw/earth_engine_plant_village_kenya/\")\n    test_files = test_folder.glob(\"*.tif\")\n    print(test_files)\n\n    list_of_models = list(Path('../data/lightning_logs/').glob('version*/checkpoints/*.ckpt'))\n    latest_model_path = str(max(list_of_checkpoints, key=os.path.getctime))\n    print(f\"Using model {latest_model_path}\")\n\n    model = Model.load_from_checkpoint(latest_model_path)\n\n    for test_path in test_files:\n\n        save_dir = Path(data_dir) / \"Autoencoder\"\n        save_dir.mkdir(exist_ok=True)\n\n        print(f\"Running for {test_path}\")\n\n        savepath = save_dir / f\"preds_{test_path.name}\"\n        if savepath.exists():\n            print(\"File already generated. Skipping\")\n            continue\n\n        out_forecasted = model.predict(test_path, with_forecaster=True)\n        plot_results(out_forecasted, test_path, savepath=save_dir, prefix=\"forecasted_\")\n\n        out_normal = model.predict(test_path, with_forecaster=False)\n        plot_results(out_normal, test_path, savepath=save_dir, prefix=\"full_input_\")\n\n        out_forecasted.to_netcdf(save_dir / f\"preds_forecasted_{test_path.name}.nc\")\n        out_normal.to_netcdf(save_dir / f\"preds_normal_{test_path.name}.nc\")\n\n\nif __name__ == \"__main__\":\n    print(\"Starting...predict.py\")\n    kenya_crop_type_mapper()\n",
  "history_output" : "Starting...predict.py\n<generator object Path.glob at 0x7fbf1e39e120>\nTraceback (most recent call last):\n  File \"scripts_predict.py\", line 47, in <module>\n    kenya_crop_type_mapper()\n  File \"scripts_predict.py\", line 18, in kenya_crop_type_mapper\n    latest_model_path = str(max(list_of_checkpoints, key=os.path.getctime))\nNameError: name 'list_of_checkpoints' is not defined\n",
  "history_begin_time" : 1647345467945,
  "history_end_time" : 1647345473633,
  "history_notes" : null,
  "history_process" : "delykw",
  "host_id" : null,
  "indicator" : "Done"
},{
  "history_id" : "xlbgvgpuqq7",
  "history_input" : "from pathlib import Path\nimport sys\n\nsys.path.append(\"..\")\n\nfrom src_models_model import Model\nfrom src_analysis import plot_results\n\n\ndef kenya_crop_type_mapper():\n    data_dir = \"../data\"\n\n    test_folder = Path(\"../data/raw/earth_engine_plant_village_kenya/\")\n    test_files = test_folder.glob(\"*.tif\")\n    print(test_files)\n\n    model_path = \"../data/lightning_logs/version_8/checkpoints/epoch=165.ckpt\"\n    print(f\"Using model {model_path}\")\n\n    model = Model.load_from_checkpoint(model_path)\n\n    for test_path in test_files:\n\n        save_dir = Path(data_dir) / \"Autoencoder\"\n        save_dir.mkdir(exist_ok=True)\n\n        print(f\"Running for {test_path}\")\n\n        savepath = save_dir / f\"preds_{test_path.name}\"\n        if savepath.exists():\n            print(\"File already generated. Skipping\")\n            continue\n\n        out_forecasted = model.predict(test_path, with_forecaster=True)\n        plot_results(out_forecasted, test_path, savepath=save_dir, prefix=\"forecasted_\")\n\n        out_normal = model.predict(test_path, with_forecaster=False)\n        plot_results(out_normal, test_path, savepath=save_dir, prefix=\"full_input_\")\n\n        out_forecasted.to_netcdf(save_dir / f\"preds_forecasted_{test_path.name}.nc\")\n        out_normal.to_netcdf(save_dir / f\"preds_normal_{test_path.name}.nc\")\n\n\nif __name__ == \"__main__\":\n    print(\"Starting...predict.py\")\n    kenya_crop_type_mapper()\n",
  "history_output" : "",
  "history_begin_time" : 1647340172206,
  "history_end_time" : 1647340174334,
  "history_notes" : null,
  "history_process" : "delykw",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "78hlq0442nu",
  "history_input" : "from pathlib import Path\nimport sys\n\nsys.path.append(\"..\")\n\nfrom src_models_model import Model\nfrom src_analysis import plot_results\n\n\ndef kenya_crop_type_mapper():\n    data_dir = \"../data\"\n\n    test_folder = Path(\"../data/raw/earth_engine_plant_village_kenya/\")\n    test_files = test_folder.glob(\"*.tif\")\n    print(test_files)\n\n    model_path = \"../data/lightning_logs/version_8/checkpoints/epoch=165.ckpt\"\n    print(f\"Using model {model_path}\")\n\n    model = Model.load_from_checkpoint(model_path)\n\n    for test_path in test_files:\n\n        save_dir = Path(data_dir) / \"Autoencoder\"\n        save_dir.mkdir(exist_ok=True)\n\n        print(f\"Running for {test_path}\")\n\n        savepath = save_dir / f\"preds_{test_path.name}\"\n        if savepath.exists():\n            print(\"File already generated. Skipping\")\n            continue\n\n        out_forecasted = model.predict(test_path, with_forecaster=True)\n        plot_results(out_forecasted, test_path, savepath=save_dir, prefix=\"forecasted_\")\n\n        out_normal = model.predict(test_path, with_forecaster=False)\n        plot_results(out_normal, test_path, savepath=save_dir, prefix=\"full_input_\")\n\n        out_forecasted.to_netcdf(save_dir / f\"preds_forecasted_{test_path.name}.nc\")\n        out_normal.to_netcdf(save_dir / f\"preds_normal_{test_path.name}.nc\")\n\n\nif __name__ == \"__main__\":\n    print(\"Starting...predict.py\")\n    kenya_crop_type_mapper()\n",
  "history_output" : "",
  "history_begin_time" : 1646147754204,
  "history_end_time" : 1646147756996,
  "history_notes" : null,
  "history_process" : "delykw",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "9g6yk0rnee3",
  "history_input" : "from pathlib import Path\nimport sys\n\nsys.path.append(\"..\")\n\nfrom src_models_model import Model\nfrom src_analysis import plot_results\n\n\ndef kenya_crop_type_mapper():\n    data_dir = \"../data\"\n\n    test_folder = Path(\"../data/raw/earth_engine_plant_village_kenya/\")\n    test_files = test_folder.glob(\"*.tif\")\n    print(test_files)\n\n    model_path = \"../data/lightning_logs/version_8/checkpoints/epoch=165.ckpt\"\n    print(f\"Using model {model_path}\")\n\n    model = Model.load_from_checkpoint(model_path)\n\n    for test_path in test_files:\n\n        save_dir = Path(data_dir) / \"Autoencoder\"\n        save_dir.mkdir(exist_ok=True)\n\n        print(f\"Running for {test_path}\")\n\n        savepath = save_dir / f\"preds_{test_path.name}\"\n        if savepath.exists():\n            print(\"File already generated. Skipping\")\n            continue\n\n        out_forecasted = model.predict(test_path, with_forecaster=True)\n        plot_results(out_forecasted, test_path, savepath=save_dir, prefix=\"forecasted_\")\n\n        out_normal = model.predict(test_path, with_forecaster=False)\n        plot_results(out_normal, test_path, savepath=save_dir, prefix=\"full_input_\")\n\n        out_forecasted.to_netcdf(save_dir / f\"preds_forecasted_{test_path.name}.nc\")\n        out_normal.to_netcdf(save_dir / f\"preds_normal_{test_path.name}.nc\")\n\n\nif __name__ == \"__main__\":\n    print(\"Starting...predict.py\")\n    kenya_crop_type_mapper()\n",
  "history_output" : "  0%|          | 0/288 [00:00<?, ?it/s]\n 67%|██████▋   | 192/288 [00:00<00:00, 1896.41it/s]\n320it [00:00, 1235.33it/s]                         \n  0%|          | 0/288 [00:00<?, ?it/s]\n320it [00:00, 2256.37it/s]             \n  0%|          | 0/288 [00:00<?, ?it/s]\n320it [00:00, 1680.58it/s]             \n  0%|          | 0/288 [00:00<?, ?it/s]\n320it [00:00, 2096.89it/s]             \n  0%|          | 0/288 [00:00<?, ?it/s]\n320it [00:00, 1633.60it/s]             \n  0%|          | 0/288 [00:00<?, ?it/s]\n320it [00:00, 2211.34it/s]             \n  0%|          | 0/288 [00:00<?, ?it/s]\n320it [00:00, 1659.17it/s]             \n  0%|          | 0/288 [00:00<?, ?it/s]\n320it [00:00, 1901.12it/s]             \n  0%|          | 0/288 [00:00<?, ?it/s]\n320it [00:00, 1628.67it/s]             \n  0%|          | 0/288 [00:00<?, ?it/s]\n320it [00:00, 2178.00it/s]             \n  0%|          | 0/288 [00:00<?, ?it/s]\n320it [00:00, 1465.99it/s]             \n  0%|          | 0/288 [00:00<?, ?it/s]\n320it [00:00, 2286.42it/s]             \n  0%|          | 0/288 [00:00<?, ?it/s]\n320it [00:00, 1384.55it/s]             \n  0%|          | 0/288 [00:00<?, ?it/s]\n320it [00:00, 2043.76it/s]             \n  0%|          | 0/288 [00:00<?, ?it/s]\n320it [00:00, 1619.01it/s]             \n  0%|          | 0/288 [00:00<?, ?it/s]\n320it [00:00, 2269.52it/s]             \n  0%|          | 0/305 [00:00<?, ?it/s]\n320it [00:00, 1565.40it/s]             \n  0%|          | 0/305 [00:00<?, ?it/s]\n320it [00:00, 2311.94it/s]             \n  0%|          | 0/288 [00:00<?, ?it/s]\n320it [00:00, 1621.36it/s]             \n  0%|          | 0/288 [00:00<?, ?it/s]\n320it [00:00, 2303.35it/s]             \nStarting...predict.py\n<generator object Path.glob at 0x7ffe2781c200>\nUsing model ../data/lightning_logs/version_8/checkpoints/epoch=165.ckpt\nPredicting 7 timesteps in the forecaster\nUsing 1 layers for the global classifier\nUsing 2 layers for the local classifier\nRunning for ../data/raw/earth_engine_plant_village_kenya/1_2019-04-22_2020-04-16.tif\nNo GPU - not using one\nNo GPU - not using one\nRunning for ../data/raw/earth_engine_plant_village_kenya/9_2019-04-22_2020-04-16.tif\nNo GPU - not using one\nNo GPU - not using one\nRunning for ../data/raw/earth_engine_plant_village_kenya/6_2019-04-22_2020-04-16.tif\nNo GPU - not using one\nNo GPU - not using one\nRunning for ../data/raw/earth_engine_plant_village_kenya/3_2019-04-22_2020-04-16.tif\nNo GPU - not using one\nNo GPU - not using one\nRunning for ../data/raw/earth_engine_plant_village_kenya/4_2019-04-22_2020-04-16.tif\nNo GPU - not using one\nNo GPU - not using one\nRunning for ../data/raw/earth_engine_plant_village_kenya/5_2019-04-22_2020-04-16.tif\nNo GPU - not using one\nNo GPU - not using one\nRunning for ../data/raw/earth_engine_plant_village_kenya/0_2018-04-21_2019-04-16.tif\nNo GPU - not using one\nNo GPU - not using one\nRunning for ../data/raw/earth_engine_plant_village_kenya/2_2019-04-22_2020-04-16.tif\nNo GPU - not using one\nNo GPU - not using one\nRunning for ../data/raw/earth_engine_plant_village_kenya/7_2019-04-22_2020-04-16.tif\nNo GPU - not using one\nNo GPU - not using one\nRunning for ../data/raw/earth_engine_plant_village_kenya/8_2019-04-22_2020-04-16.tif\nNo GPU - not using one\nNo GPU - not using one\n",
  "history_begin_time" : 1646145452688,
  "history_end_time" : 1646145483423,
  "history_notes" : null,
  "history_process" : "delykw",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "q2g6i0vymhv",
  "history_input" : "from pathlib import Path\nimport sys\n\nsys.path.append(\"..\")\n\nfrom src_models_model import Model\nfrom src_analysis import plot_results\n\n\ndef kenya_crop_type_mapper():\n    data_dir = \"../data\"\n\n    test_folder = Path(\"../data/raw/earth_engine_plant_village_kenya/\")\n    test_files = test_folder.glob(\"*.tif\")\n    print(test_files)\n\n    model_path = \"../data/lightning_logs/version_8/checkpoints/epoch=165.ckpt\"\n    print(f\"Using model {model_path}\")\n\n    model = Model.load_from_checkpoint(model_path)\n\n    for test_path in test_files:\n\n        save_dir = Path(data_dir) / \"Autoencoder\"\n        save_dir.mkdir(exist_ok=True)\n\n        print(f\"Running for {test_path}\")\n\n        savepath = save_dir / f\"preds_{test_path.name}\"\n        if savepath.exists():\n            print(\"File already generated. Skipping\")\n            continue\n\n        out_forecasted = model.predict(test_path, with_forecaster=True)\n        plot_results(out_forecasted, test_path, savepath=save_dir, prefix=\"forecasted_\")\n\n        out_normal = model.predict(test_path, with_forecaster=False)\n        plot_results(out_normal, test_path, savepath=save_dir, prefix=\"full_input_\")\n\n        out_forecasted.to_netcdf(save_dir / f\"preds_forecasted_{test_path.name}.nc\")\n        out_normal.to_netcdf(save_dir / f\"preds_normal_{test_path.name}.nc\")\n\n\nif __name__ == \"__main__\":\n    print(\"Starting...predict.py\")\n    kenya_crop_type_mapper()\n",
  "history_output" : "  0%|          | 0/288 [00:00<?, ?it/s]\n320it [00:00, 1596.69it/s]             \n  0%|          | 0/288 [00:00<?, ?it/s]\n320it [00:00, 1654.08it/s]             \n  0%|          | 0/288 [00:00<?, ?it/s]\n320it [00:00, 1626.51it/s]             \n  0%|          | 0/288 [00:00<?, ?it/s]\n320it [00:00, 2314.16it/s]             \n  0%|          | 0/288 [00:00<?, ?it/s]\n320it [00:00, 3199.36it/s]             \n320it [00:00, 1463.39it/s]\n  0%|          | 0/288 [00:00<?, ?it/s]\n320it [00:00, 2016.10it/s]             \n  0%|          | 0/288 [00:00<?, ?it/s]\n320it [00:00, 1630.42it/s]             \n  0%|          | 0/288 [00:00<?, ?it/s]\n320it [00:00, 2285.99it/s]             \n  0%|          | 0/288 [00:00<?, ?it/s]\n320it [00:00, 1591.15it/s]             \n  0%|          | 0/288 [00:00<?, ?it/s]\n320it [00:00, 2363.15it/s]             \n  0%|          | 0/288 [00:00<?, ?it/s]\n320it [00:00, 2913.64it/s]             \n320it [00:00, 1236.83it/s]\n  0%|          | 0/288 [00:00<?, ?it/s]\n320it [00:00, 2136.64it/s]             \n  0%|          | 0/288 [00:00<?, ?it/s]\n320it [00:00, 1500.30it/s]             \n  0%|          | 0/288 [00:00<?, ?it/s]\n320it [00:00, 2061.24it/s]             \n  0%|          | 0/288 [00:00<?, ?it/s]\n320it [00:00, 1433.04it/s]             \n  0%|          | 0/288 [00:00<?, ?it/s]\n320it [00:00, 2250.16it/s]             \n  0%|          | 0/305 [00:00<?, ?it/s]\n320it [00:00, 1662.94it/s]             \n  0%|          | 0/305 [00:00<?, ?it/s]\n320it [00:00, 2189.92it/s]             \n  0%|          | 0/288 [00:00<?, ?it/s]\n320it [00:00, 1707.62it/s]             \n  0%|          | 0/288 [00:00<?, ?it/s]\n320it [00:00, 2308.74it/s]             \nStarting...predict.py\n<generator object Path.glob at 0x7fdf0019b200>\nUsing model ../data/lightning_logs/version_8/checkpoints/epoch=165.ckpt\nPredicting 7 timesteps in the forecaster\nUsing 1 layers for the global classifier\nUsing 2 layers for the local classifier\nRunning for ../data/raw/earth_engine_plant_village_kenya/1_2019-04-22_2020-04-16.tif\nNo GPU - not using one\nNo GPU - not using one\nRunning for ../data/raw/earth_engine_plant_village_kenya/9_2019-04-22_2020-04-16.tif\nNo GPU - not using one\nNo GPU - not using one\nRunning for ../data/raw/earth_engine_plant_village_kenya/6_2019-04-22_2020-04-16.tif\nNo GPU - not using one\nNo GPU - not using one\nRunning for ../data/raw/earth_engine_plant_village_kenya/3_2019-04-22_2020-04-16.tif\nNo GPU - not using one\nNo GPU - not using one\nRunning for ../data/raw/earth_engine_plant_village_kenya/4_2019-04-22_2020-04-16.tif\nNo GPU - not using one\nNo GPU - not using one\nRunning for ../data/raw/earth_engine_plant_village_kenya/5_2019-04-22_2020-04-16.tif\nNo GPU - not using one\nNo GPU - not using one\nRunning for ../data/raw/earth_engine_plant_village_kenya/0_2018-04-21_2019-04-16.tif\nNo GPU - not using one\nNo GPU - not using one\nRunning for ../data/raw/earth_engine_plant_village_kenya/2_2019-04-22_2020-04-16.tif\nNo GPU - not using one\nNo GPU - not using one\nRunning for ../data/raw/earth_engine_plant_village_kenya/7_2019-04-22_2020-04-16.tif\nNo GPU - not using one\nNo GPU - not using one\nRunning for ../data/raw/earth_engine_plant_village_kenya/8_2019-04-22_2020-04-16.tif\nNo GPU - not using one\nNo GPU - not using one\n",
  "history_begin_time" : 1646145239467,
  "history_end_time" : 1646145269732,
  "history_notes" : null,
  "history_process" : "delykw",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "76z9d4it3iq",
  "history_input" : "from pathlib import Path\nimport sys\n\nsys.path.append(\"..\")\n\nfrom src_models_model import Model\nfrom src_analysis import plot_results\n\n\ndef kenya_crop_type_mapper():\n    data_dir = \"../data\"\n\n    test_folder = Path(\"../data/raw/earth_engine_plant_village_kenya/\")\n    test_files = test_folder.glob(\"*.tif\")\n    print(test_files)\n\n    model_path = \"../data/lightning_logs/version_8/checkpoints/epoch=165.ckpt\"\n    print(f\"Using model {model_path}\")\n\n    model = Model.load_from_checkpoint(model_path)\n\n    for test_path in test_files:\n\n        save_dir = Path(data_dir) / \"Autoencoder\"\n        save_dir.mkdir(exist_ok=True)\n\n        print(f\"Running for {test_path}\")\n\n        savepath = save_dir / f\"preds_{test_path.name}\"\n        if savepath.exists():\n            print(\"File already generated. Skipping\")\n            continue\n\n        out_forecasted = model.predict(test_path, with_forecaster=True)\n        plot_results(out_forecasted, test_path, savepath=save_dir, prefix=\"forecasted_\")\n\n        out_normal = model.predict(test_path, with_forecaster=False)\n        plot_results(out_normal, test_path, savepath=save_dir, prefix=\"full_input_\")\n\n        out_forecasted.to_netcdf(save_dir / f\"preds_forecasted_{test_path.name}.nc\")\n        out_normal.to_netcdf(save_dir / f\"preds_normal_{test_path.name}.nc\")\n\n\nif __name__ == \"__main__\":\n    print(\"Starting...predict.py\")\n    kenya_crop_type_mapper()\n",
  "history_output" : "  0%|          | 0/288 [00:00<?, ?it/s]\n 89%|████████▉ | 256/288 [00:00<00:00, 2548.30it/s]\n320it [00:00, 1339.84it/s]                         \n  0%|          | 0/288 [00:00<?, ?it/s]\n320it [00:00, 2182.87it/s]             \n  0%|          | 0/288 [00:00<?, ?it/s]\n320it [00:00, 1609.84it/s]             \n  0%|          | 0/288 [00:00<?, ?it/s]\n320it [00:00, 2264.73it/s]             \n  0%|          | 0/288 [00:00<?, ?it/s]\n320it [00:00, 1627.03it/s]             \n  0%|          | 0/288 [00:00<?, ?it/s]\n320it [00:00, 2183.51it/s]             \n  0%|          | 0/288 [00:00<?, ?it/s]\n320it [00:00, 1623.84it/s]             \n  0%|          | 0/288 [00:00<?, ?it/s]\n320it [00:00, 2312.87it/s]             \n  0%|          | 0/288 [00:00<?, ?it/s]\n320it [00:00, 1393.75it/s]             \n  0%|          | 0/288 [00:00<?, ?it/s]\n320it [00:00, 2220.46it/s]             \n  0%|          | 0/288 [00:00<?, ?it/s]\n320it [00:00, 1602.59it/s]             \n  0%|          | 0/288 [00:00<?, ?it/s]\n320it [00:00, 2300.45it/s]             \n  0%|          | 0/288 [00:00<?, ?it/s]\n320it [00:00, 1635.25it/s]             \n  0%|          | 0/288 [00:00<?, ?it/s]\n320it [00:00, 2374.81it/s]             \n  0%|          | 0/288 [00:00<?, ?it/s]\n320it [00:00, 1660.34it/s]             \n  0%|          | 0/288 [00:00<?, ?it/s]\n320it [00:00, 2323.12it/s]             \n  0%|          | 0/305 [00:00<?, ?it/s]\n320it [00:00, 1322.31it/s]             \n  0%|          | 0/305 [00:00<?, ?it/s]\n320it [00:00, 2248.38it/s]             \n  0%|          | 0/288 [00:00<?, ?it/s]\n320it [00:00, 1622.86it/s]             \n  0%|          | 0/288 [00:00<?, ?it/s]\n320it [00:00, 2291.11it/s]             \nStarting...predict.py\n<generator object Path.glob at 0x7f92c4818200>\nUsing model ../data/lightning_logs/version_8/checkpoints/epoch=165.ckpt\nPredicting 7 timesteps in the forecaster\nUsing 1 layers for the global classifier\nUsing 2 layers for the local classifier\nRunning for ../data/raw/earth_engine_plant_village_kenya/1_2019-04-22_2020-04-16.tif\nNo GPU - not using one\nNo GPU - not using one\nRunning for ../data/raw/earth_engine_plant_village_kenya/9_2019-04-22_2020-04-16.tif\nNo GPU - not using one\nNo GPU - not using one\nRunning for ../data/raw/earth_engine_plant_village_kenya/6_2019-04-22_2020-04-16.tif\nNo GPU - not using one\nNo GPU - not using one\nRunning for ../data/raw/earth_engine_plant_village_kenya/3_2019-04-22_2020-04-16.tif\nNo GPU - not using one\nNo GPU - not using one\nRunning for ../data/raw/earth_engine_plant_village_kenya/4_2019-04-22_2020-04-16.tif\nNo GPU - not using one\nNo GPU - not using one\nRunning for ../data/raw/earth_engine_plant_village_kenya/5_2019-04-22_2020-04-16.tif\nNo GPU - not using one\nNo GPU - not using one\nRunning for ../data/raw/earth_engine_plant_village_kenya/0_2018-04-21_2019-04-16.tif\nNo GPU - not using one\nNo GPU - not using one\nRunning for ../data/raw/earth_engine_plant_village_kenya/2_2019-04-22_2020-04-16.tif\nNo GPU - not using one\nNo GPU - not using one\nRunning for ../data/raw/earth_engine_plant_village_kenya/7_2019-04-22_2020-04-16.tif\nNo GPU - not using one\nNo GPU - not using one\nRunning for ../data/raw/earth_engine_plant_village_kenya/8_2019-04-22_2020-04-16.tif\nNo GPU - not using one\nNo GPU - not using one\n",
  "history_begin_time" : 1646144630814,
  "history_end_time" : 1646144661933,
  "history_notes" : null,
  "history_process" : "delykw",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "nh2wd3ebrxz",
  "history_input" : "from pathlib import Path\nimport sys\n\nsys.path.append(\"..\")\n\nfrom src_models_model import Model\nfrom src_analysis import plot_results\n\n\ndef kenya_crop_type_mapper():\n    data_dir = \"../data\"\n\n    test_folder = Path(\"../data/raw/earth_engine_plant_village_kenya/\")\n    test_files = test_folder.glob(\"*.tif\")\n    print(test_files)\n\n    model_path = \"../data/lightning_logs/version_0/checkpoints/\"\n    checkpoint = list(model_path.glob(\"*.ckpt\"))\n    print(f\"Using model {str(checkpoint[0])}\")\n\n    model = Model.load_from_checkpoint(str(checkpoint[0]))\n\n    for test_path in test_files:\n\n        save_dir = Path(data_dir) / \"Autoencoder\"\n        save_dir.mkdir(exist_ok=True)\n\n        print(f\"Running for {test_path}\")\n\n        savepath = save_dir / f\"preds_{test_path.name}\"\n        if savepath.exists():\n            print(\"File already generated. Skipping\")\n            continue\n\n        out_forecasted = model.predict(test_path, with_forecaster=True)\n        plot_results(out_forecasted, test_path, savepath=save_dir, prefix=\"forecasted_\")\n\n        out_normal = model.predict(test_path, with_forecaster=False)\n        plot_results(out_normal, test_path, savepath=save_dir, prefix=\"full_input_\")\n\n        out_forecasted.to_netcdf(save_dir / f\"preds_forecasted_{test_path.name}.nc\")\n        out_normal.to_netcdf(save_dir / f\"preds_normal_{test_path.name}.nc\")\n\n\nif __name__ == \"__main__\":\n    print(\"Starting...predict.py\")\n    kenya_crop_type_mapper()\n",
  "history_output" : "Starting...predict.py\n<generator object Path.glob at 0x7feb73118200>\nTraceback (most recent call last):\n  File \"scripts_predict.py\", line 47, in <module>\n    kenya_crop_type_mapper()\n  File \"scripts_predict.py\", line 18, in kenya_crop_type_mapper\n    checkpoint = list(model_path.glob(\"*.ckpt\"))\nAttributeError: 'str' object has no attribute 'glob'\n",
  "history_begin_time" : 1646144409721,
  "history_end_time" : 1646144413274,
  "history_notes" : null,
  "history_process" : "delykw",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "3i2ztb84umm",
  "history_input" : "from pathlib import Path\nimport sys\n\nsys.path.append(\"..\")\n\nfrom src_models_model import Model\nfrom src_analysis import plot_results\n\n\ndef kenya_crop_type_mapper():\n    data_dir = \"../data\"\n\n    test_folder = Path(\"../data/raw/earth_engine_plant_village_kenya/\")\n    test_files = test_folder.glob(\"*.tif\")\n    print(test_files)\n\n    model_path = \"../data/lightning_logs/version_0/checkpoints/\"\n    checkpoint = list(log_folder.glob(\"*.ckpt\"))\n    print(f\"Using model {str(checkpoint[0])}\")\n\n    model = Model.load_from_checkpoint(str(checkpoint[0]))\n\n    for test_path in test_files:\n\n        save_dir = Path(data_dir) / \"Autoencoder\"\n        save_dir.mkdir(exist_ok=True)\n\n        print(f\"Running for {test_path}\")\n\n        savepath = save_dir / f\"preds_{test_path.name}\"\n        if savepath.exists():\n            print(\"File already generated. Skipping\")\n            continue\n\n        out_forecasted = model.predict(test_path, with_forecaster=True)\n        plot_results(out_forecasted, test_path, savepath=save_dir, prefix=\"forecasted_\")\n\n        out_normal = model.predict(test_path, with_forecaster=False)\n        plot_results(out_normal, test_path, savepath=save_dir, prefix=\"full_input_\")\n\n        out_forecasted.to_netcdf(save_dir / f\"preds_forecasted_{test_path.name}.nc\")\n        out_normal.to_netcdf(save_dir / f\"preds_normal_{test_path.name}.nc\")\n\n\nif __name__ == \"__main__\":\n    print(\"Starting...predict.py\")\n    kenya_crop_type_mapper()\n",
  "history_output" : "Starting...predict.py\n<generator object Path.glob at 0x7fa8a929b200>\nTraceback (most recent call last):\n  File \"scripts_predict.py\", line 47, in <module>\n    kenya_crop_type_mapper()\n  File \"scripts_predict.py\", line 18, in kenya_crop_type_mapper\n    checkpoint = list(log_folder.glob(\"*.ckpt\"))\nNameError: name 'log_folder' is not defined\n",
  "history_begin_time" : 1646144338527,
  "history_end_time" : 1646144341984,
  "history_notes" : null,
  "history_process" : "delykw",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "6cgotf8omek",
  "history_input" : "from pathlib import Path\nimport sys\n\nsys.path.append(\"..\")\n\nfrom src_models_model import Model\nfrom src_analysis import plot_results\n\n\ndef kenya_crop_type_mapper():\n    data_dir = \"../data\"\n\n    test_folder = Path(\"../data/raw/earth_engine_plant_village_kenya/\")\n    test_files = test_folder.glob(\"*.tif\")\n    print(test_files)\n\n    model_path = Path(\"../data/lightning_logs/version_0/checkpoints/\")\n    checkpoint_file = model_path.glob(\"*.ckpt\")\n    print(f\"Using model {checkpoint_file[-1]}\")\n\n    model = Model.load_from_checkpoint(checkpoint_file[-1])\n\n    for test_path in test_files:\n\n        save_dir = Path(data_dir) / \"Autoencoder\"\n        save_dir.mkdir(exist_ok=True)\n\n        print(f\"Running for {test_path}\")\n\n        savepath = save_dir / f\"preds_{test_path.name}\"\n        if savepath.exists():\n            print(\"File already generated. Skipping\")\n            continue\n\n        out_forecasted = model.predict(test_path, with_forecaster=True)\n        plot_results(out_forecasted, test_path, savepath=save_dir, prefix=\"forecasted_\")\n\n        out_normal = model.predict(test_path, with_forecaster=False)\n        plot_results(out_normal, test_path, savepath=save_dir, prefix=\"full_input_\")\n\n        out_forecasted.to_netcdf(save_dir / f\"preds_forecasted_{test_path.name}.nc\")\n        out_normal.to_netcdf(save_dir / f\"preds_normal_{test_path.name}.nc\")\n\n\nif __name__ == \"__main__\":\n    print(\"Starting...predict.py\")\n    kenya_crop_type_mapper()\n",
  "history_output" : "Starting...predict.py\n<generator object Path.glob at 0x7fdc7ba1c270>\nTraceback (most recent call last):\n  File \"scripts_predict.py\", line 47, in <module>\n    kenya_crop_type_mapper()\n  File \"scripts_predict.py\", line 19, in kenya_crop_type_mapper\n    print(f\"Using model {checkpoint_file[-1]}\")\nTypeError: 'generator' object is not subscriptable\n",
  "history_begin_time" : 1646143439547,
  "history_end_time" : 1646143443677,
  "history_notes" : null,
  "history_process" : "delykw",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "oz88df6fusb",
  "history_input" : "from pathlib import Path\nimport sys\n\nsys.path.append(\"..\")\n\nfrom src_models_model import Model\nfrom src_analysis import plot_results\n\n\ndef kenya_crop_type_mapper():\n    data_dir = \"../data\"\n\n    test_folder = Path(\"../data/raw/earth_engine_plant_village_kenya/\")\n    test_files = test_folder.glob(\"*.tif\")\n    print(test_files)\n\n    model_path = \"/data/lightning_logs/version_0/checkpoints/\"\n    checkpoint_file = model_path.glob(\"*.ckpt\")\n    print(f\"Using model {checkpoint_file[0]}\")\n\n    model = Model.load_from_checkpoint(checkpoint_file[0])\n\n    for test_path in test_files:\n\n        save_dir = Path(data_dir) / \"Autoencoder\"\n        save_dir.mkdir(exist_ok=True)\n\n        print(f\"Running for {test_path}\")\n\n        savepath = save_dir / f\"preds_{test_path.name}\"\n        if savepath.exists():\n            print(\"File already generated. Skipping\")\n            continue\n\n        out_forecasted = model.predict(test_path, with_forecaster=True)\n        plot_results(out_forecasted, test_path, savepath=save_dir, prefix=\"forecasted_\")\n\n        out_normal = model.predict(test_path, with_forecaster=False)\n        plot_results(out_normal, test_path, savepath=save_dir, prefix=\"full_input_\")\n\n        out_forecasted.to_netcdf(save_dir / f\"preds_forecasted_{test_path.name}.nc\")\n        out_normal.to_netcdf(save_dir / f\"preds_normal_{test_path.name}.nc\")\n\n\nif __name__ == \"__main__\":\n    print(\"Starting...predict.py\")\n    kenya_crop_type_mapper()\n",
  "history_output" : "Starting...predict.py\n<generator object Path.glob at 0x7faa5c01c270>\nTraceback (most recent call last):\n  File \"scripts_predict.py\", line 47, in <module>\n    kenya_crop_type_mapper()\n  File \"scripts_predict.py\", line 18, in kenya_crop_type_mapper\n    checkpoint_file = model_path.glob(\"*.ckpt\")\nAttributeError: 'str' object has no attribute 'glob'\n",
  "history_begin_time" : 1646143290125,
  "history_end_time" : 1646143294695,
  "history_notes" : null,
  "history_process" : "delykw",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "f6rnrbmsprb",
  "history_input" : "from pathlib import Path\nimport sys\n\nsys.path.append(\"..\")\n\nfrom src_models_model import Model\nfrom src_analysis import plot_results\n\n\ndef kenya_crop_type_mapper():\n    data_dir = \"../data\"\n\n    test_folder = Path(\"../data/raw/earth_engine_plant_village_kenya/\")\n    test_files = test_folder.glob(\"*.tif\")\n    print(test_files)\n\n    model_path = \"/data/lightning_logs/version_0/checkpoints/\"\n    checkpoint_file = model_path.glob(\"*.ckpt\")\n    print(f\"Using model {checkpoint_file[0]}\")\n\n    model = Model.load_from_checkpoint(checkpoint_file[0])\n\n    for test_path in test_files:\n\n        save_dir = Path(data_dir) / \"Autoencoder\"\n        save_dir.mkdir(exist_ok=True)\n\n        print(f\"Running for {test_path}\")\n\n        savepath = save_dir / f\"preds_{test_path.name}\"\n        if savepath.exists():\n            print(\"File already generated. Skipping\")\n            continue\n\n        out_forecasted = model.predict(test_path, with_forecaster=True)\n        plot_results(out_forecasted, test_path, savepath=save_dir, prefix=\"forecasted_\")\n\n        out_normal = model.predict(test_path, with_forecaster=False)\n        plot_results(out_normal, test_path, savepath=save_dir, prefix=\"full_input_\")\n\n        out_forecasted.to_netcdf(save_dir / f\"preds_forecasted_{test_path.name}.nc\")\n        out_normal.to_netcdf(save_dir / f\"preds_normal_{test_path.name}.nc\")\n\n\nif __name__ == \"__main__\":\n    print(\"Starting...predict.py\")\n    kenya_crop_type_mapper()\n",
  "history_output" : "",
  "history_begin_time" : 1646138298082,
  "history_end_time" : 1646138300666,
  "history_notes" : null,
  "history_process" : "delykw",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "z41nymfwoye",
  "history_input" : "from pathlib import Path\nimport sys\n\nsys.path.append(\"..\")\n\nfrom src_models_model import Model\nfrom src_analysis import plot_results\n\n\ndef kenya_crop_type_mapper():\n    data_dir = \"../data\"\n\n    test_folder = Path(\"../data/raw/earth_engine_plant_village_kenya/\")\n    test_files = test_folder.glob(\"*.tif\")\n    print(test_files)\n\n    model_path = \"/data/lightning_logs/version_0/checkpoints/\"\n    checkpoint_file = model_path.glob(\"*.ckpt\")\n    print(f\"Using model {checkpoint_file[0]}\")\n\n    model = Model.load_from_checkpoint(checkpoint_file[0])\n\n    for test_path in test_files:\n\n        save_dir = Path(data_dir) / \"Autoencoder\"\n        save_dir.mkdir(exist_ok=True)\n\n        print(f\"Running for {test_path}\")\n\n        savepath = save_dir / f\"preds_{test_path.name}\"\n        if savepath.exists():\n            print(\"File already generated. Skipping\")\n            continue\n\n        out_forecasted = model.predict(test_path, with_forecaster=True)\n        plot_results(out_forecasted, test_path, savepath=save_dir, prefix=\"forecasted_\")\n\n        out_normal = model.predict(test_path, with_forecaster=False)\n        plot_results(out_normal, test_path, savepath=save_dir, prefix=\"full_input_\")\n\n        out_forecasted.to_netcdf(save_dir / f\"preds_forecasted_{test_path.name}.nc\")\n        out_normal.to_netcdf(save_dir / f\"preds_normal_{test_path.name}.nc\")\n\n\nif __name__ == \"__main__\":\n    print(\"Starting...predict.py\")\n    kenya_crop_type_mapper()\n",
  "history_output" : "",
  "history_begin_time" : 1646138200205,
  "history_end_time" : 1646138201672,
  "history_notes" : null,
  "history_process" : "delykw",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "hd1bhs3lxpx",
  "history_input" : "from pathlib import Path\nimport sys\n\nsys.path.append(\"..\")\n\nfrom src_models_model import Model\nfrom src_analysis import plot_results\n\n\ndef kenya_crop_type_mapper():\n    data_dir = \"../data\"\n\n    test_folder = Path(\"../data/raw/earth_engine_plant_village_kenya/\")\n    test_files = test_folder.glob(\"*.tif\")\n    print(test_files)\n\n    model_path = \"/data/lightning_logs/version_0/checkpoints/\"\n    checkpoint_file = model_path.glob(\"*.ckpt\")\n    print(f\"Using model {checkpoint_file[0]}\")\n\n    model = Model.load_from_checkpoint(checkpoint_file[0])\n\n    for test_path in test_files:\n\n        save_dir = Path(data_dir) / \"Autoencoder\"\n        save_dir.mkdir(exist_ok=True)\n\n        print(f\"Running for {test_path}\")\n\n        savepath = save_dir / f\"preds_{test_path.name}\"\n        if savepath.exists():\n            print(\"File already generated. Skipping\")\n            continue\n\n        out_forecasted = model.predict(test_path, with_forecaster=True)\n        plot_results(out_forecasted, test_path, savepath=save_dir, prefix=\"forecasted_\")\n\n        out_normal = model.predict(test_path, with_forecaster=False)\n        plot_results(out_normal, test_path, savepath=save_dir, prefix=\"full_input_\")\n\n        out_forecasted.to_netcdf(save_dir / f\"preds_forecasted_{test_path.name}.nc\")\n        out_normal.to_netcdf(save_dir / f\"preds_normal_{test_path.name}.nc\")\n\n\nif __name__ == \"__main__\":\n    print(\"Starting...predict.py\")\n    kenya_crop_type_mapper()\n",
  "history_output" : "",
  "history_begin_time" : 1646138113354,
  "history_end_time" : 1646138114967,
  "history_notes" : null,
  "history_process" : "delykw",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "aqzkceku2t6",
  "history_input" : "from pathlib import Path\nimport sys\n\nsys.path.append(\"..\")\n\nfrom src_models_model import Model\nfrom src_analysis import plot_results\n\n\ndef kenya_crop_type_mapper():\n    data_dir = \"../data\"\n\n    test_folder = Path(\"../data/raw/earth_engine_plant_village_kenya/\")\n    test_files = test_folder.glob(\"*.tif\")\n    print(test_files)\n\n    model_path = \"/data/lightning_logs/version_0/checkpoints/\"\n    checkpoint_file = model_path.glob(\"*.ckpt\")\n    print(f\"Using model {checkpoint_file[0]}\")\n\n    model = Model.load_from_checkpoint(checkpoint_file[0])\n\n    for test_path in test_files:\n\n        save_dir = Path(data_dir) / \"Autoencoder\"\n        save_dir.mkdir(exist_ok=True)\n\n        print(f\"Running for {test_path}\")\n\n        savepath = save_dir / f\"preds_{test_path.name}\"\n        if savepath.exists():\n            print(\"File already generated. Skipping\")\n            continue\n\n        out_forecasted = model.predict(test_path, with_forecaster=True)\n        plot_results(out_forecasted, test_path, savepath=save_dir, prefix=\"forecasted_\")\n\n        out_normal = model.predict(test_path, with_forecaster=False)\n        plot_results(out_normal, test_path, savepath=save_dir, prefix=\"full_input_\")\n\n        out_forecasted.to_netcdf(save_dir / f\"preds_forecasted_{test_path.name}.nc\")\n        out_normal.to_netcdf(save_dir / f\"preds_normal_{test_path.name}.nc\")\n\n\nif __name__ == \"__main__\":\n    kenya_crop_type_mapper()\n",
  "history_output" : "",
  "history_begin_time" : 1646137798547,
  "history_end_time" : 1646137800317,
  "history_notes" : null,
  "history_process" : "delykw",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "6uhgrx6v7x5",
  "history_input" : "from pathlib import Path\nimport sys\n\nsys.path.append(\"..\")\n\nfrom src_models_model import Model\nfrom src_analysis import plot_results\n\n\ndef kenya_crop_type_mapper():\n    data_dir = \"../data\"\n\n    test_folder = Path(\"../data/raw/earth_engine_plant_village_kenya/\")\n    test_files = test_folder.glob(\"*.tif\")\n    print(test_files)\n\n    model_path = \"/data/lightning_logs/version_0/checkpoints/\"\n    checkpoint_file = model_path.glob(\"*.ckpt\")\n    print(f\"Using model {checkpoint_file[0]}\")\n\n    model = Model.load_from_checkpoint(checkpoint_file[0])\n\n    for test_path in test_files:\n\n        save_dir = Path(data_dir) / \"Autoencoder\"\n        save_dir.mkdir(exist_ok=True)\n\n        print(f\"Running for {test_path}\")\n\n        savepath = save_dir / f\"preds_{test_path.name}\"\n        if savepath.exists():\n            print(\"File already generated. Skipping\")\n            continue\n\n        out_forecasted = model.predict(test_path, with_forecaster=True)\n        plot_results(out_forecasted, test_path, savepath=save_dir, prefix=\"forecasted_\")\n\n        out_normal = model.predict(test_path, with_forecaster=False)\n        plot_results(out_normal, test_path, savepath=save_dir, prefix=\"full_input_\")\n\n        out_forecasted.to_netcdf(save_dir / f\"preds_forecasted_{test_path.name}.nc\")\n        out_normal.to_netcdf(save_dir / f\"preds_normal_{test_path.name}.nc\")\n\n\nif __name__ == \"__main__\":\n    kenya_crop_type_mapper()\n",
  "history_output" : "<generator object Path.glob at 0x7faef4aab660>\nTraceback (most recent call last):\n  File \"scripts_predict.py\", line 46, in <module>\n    kenya_crop_type_mapper()\n  File \"scripts_predict.py\", line 18, in kenya_crop_type_mapper\n    checkpoint_file = model_path.glob(\"*.ckpt\")\nAttributeError: 'str' object has no attribute 'glob'\n",
  "history_begin_time" : 1646137705030,
  "history_end_time" : 1646137709648,
  "history_notes" : null,
  "history_process" : "delykw",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "sk6aodi5ez8",
  "history_input" : "from pathlib import Path\nimport sys\n\nsys.path.append(\"..\")\n\nfrom src_models_model import Model\nfrom src_analysis import plot_results\n\n\ndef kenya_crop_type_mapper():\n    data_dir = \"../data\"\n\n    test_folder = Path(\"../data/raw/earth_engine_plant_village_kenya/\")\n    test_files = test_folder.glob(\"*.tif\")\n    print(test_files)\n\n    model_path = \"/data/lightning_logs/version_0/checkpoints/\"\n\tcheckpoint_file = model_path.glob(\"*.ckpt\")\n    print(f\"Using model {checkpoint_file[0]}\")\n\n    model = Model.load_from_checkpoint(checkpoint_file[0])\n\n    for test_path in test_files:\n\n        save_dir = Path(data_dir) / \"Autoencoder\"\n        save_dir.mkdir(exist_ok=True)\n\n        print(f\"Running for {test_path}\")\n\n        savepath = save_dir / f\"preds_{test_path.name}\"\n        if savepath.exists():\n            print(\"File already generated. Skipping\")\n            continue\n\n        out_forecasted = model.predict(test_path, with_forecaster=True)\n        plot_results(out_forecasted, test_path, savepath=save_dir, prefix=\"forecasted_\")\n\n        out_normal = model.predict(test_path, with_forecaster=False)\n        plot_results(out_normal, test_path, savepath=save_dir, prefix=\"full_input_\")\n\n        out_forecasted.to_netcdf(save_dir / f\"preds_forecasted_{test_path.name}.nc\")\n        out_normal.to_netcdf(save_dir / f\"preds_normal_{test_path.name}.nc\")\n\n\nif __name__ == \"__main__\":\n    kenya_crop_type_mapper()\n",
  "history_output" : "  File \"scripts_predict.py\", line 18\n    checkpoint_file = model_path.glob(\"*.ckpt\")\n                                              ^\nTabError: inconsistent use of tabs and spaces in indentation\n",
  "history_begin_time" : 1646137596505,
  "history_end_time" : 1646137596636,
  "history_notes" : null,
  "history_process" : "delykw",
  "host_id" : "100001",
  "indicator" : "Done"
},]
