[{
  "history_id" : "ybr4xkz9udl",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1666167825388,
  "history_end_time" : 1666167825388,
  "history_notes" : null,
  "history_process" : "9ardvx",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "cqecz37m4br",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1666167772376,
  "history_end_time" : 1666167772376,
  "history_notes" : null,
  "history_process" : "9ardvx",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "hpm9uc0q88s",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1666166465613,
  "history_end_time" : 1666166465613,
  "history_notes" : null,
  "history_process" : "9ardvx",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "xtpyjudxt2x",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1666166410294,
  "history_end_time" : 1666166419946,
  "history_notes" : null,
  "history_process" : "9ardvx",
  "host_id" : "100001",
  "indicator" : "Stopped"
},{
  "history_id" : "fvwzwjm6h34",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1666164233102,
  "history_end_time" : 1666164233102,
  "history_notes" : null,
  "history_process" : "9ardvx",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "wtevsdm3x3h",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1666163607321,
  "history_end_time" : 1666163607321,
  "history_notes" : null,
  "history_process" : "9ardvx",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "uujixa3vhre",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1666137012967,
  "history_end_time" : 1666137012967,
  "history_notes" : null,
  "history_process" : "9ardvx",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "pj4upriphoj",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1666136593517,
  "history_end_time" : 1666136593517,
  "history_notes" : null,
  "history_process" : "9ardvx",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "zj4u06hbhjr",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1666136435897,
  "history_end_time" : 1666136435897,
  "history_notes" : null,
  "history_process" : "9ardvx",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "q80814tmwlr",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1666134110807,
  "history_end_time" : 1666134110807,
  "history_notes" : null,
  "history_process" : "9ardvx",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "ygu4uiijqh5",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1666134036957,
  "history_end_time" : 1666134036957,
  "history_notes" : null,
  "history_process" : "9ardvx",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "nfijgzchxvr",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1666134009001,
  "history_end_time" : 1666134009001,
  "history_notes" : null,
  "history_process" : "9ardvx",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "yw05gs5lpl4",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1666131993233,
  "history_end_time" : 1666131993233,
  "history_notes" : null,
  "history_process" : "9ardvx",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "w61afd633wb",
  "history_input" : "from argparse import ArgumentParser, Namespace\nfrom pathlib import Path\nimport numpy as np\nimport xarray as xr\nfrom tqdm import tqdm\n\nimport torch\nfrom torch.nn import functional as F\nfrom torch.utils.data import DataLoader\n\nimport pytorch_lightning as pl\n\nfrom sklearn.metrics import (\n    roc_auc_score,\n    accuracy_score,\n    precision_score,\n    recall_score,\n    f1_score,\n    mean_absolute_error,\n)\n\nfrom src_models_data import CropDataset\nfrom src_models_utils import tif_to_np, preds_to_xr\nfrom src_utils import set_seed\nfrom src_models_forecaster import Forecaster\nfrom src_models_classifier import Classifier\nfrom src_config import PROBABILITY_THRESHOLD\n\nfrom typing import cast, Callable, Tuple, Dict, Any, Type, Optional, List, Union\n\n\nclass Model(pl.LightningModule):\n    r\"\"\"\n    An model for annual and in-season crop mapping. This model consists of a\n    forecaster.Forecaster and a classifier.Classifier - it will require the arguments\n    required by those models too.\n\n    hparams\n    --------\n    The default values for these parameters are set in add_model_specific_args\n\n    :param hparams.data_folder: The path to the data. Default (assumes the model\n        is being run from the scripts directory) = \"../data\"\n    :param hparams.learning_rate: The learning rate. Default = 0.001\n    :param hparams.batch_size: The batch size. Default = 64\n    :param hparams.input_months: The number of input months to pass to the model. If\n        hparams.forecast is True, the remaining months will be forecasted. Otherwise, only the\n        partial timeseries will be passed to the classifier. Default = 5\n    :param hparams.alpha: The weight to use when adding the global and local losses. This\n        parameter is only used if hparams.multi_headed is True. Default = 10\n    :param hparams.noise_factor: The standard deviation of the random noise to add to the\n        raw inputs to the classifier. Default = 0.1\n    :param hparams.remove_b1_b10: Whether or not to remove the B1 and B10 bands. Default = True\n    :param hparams.forecast: Whether or not to forecast the partial time series. Default = True\n    :param hparams.cache: Whether to load all the data into memory during training. Default = True\n    :param hparams.include_geowiki: Whether to include the global GeoWiki dataset during\n        training. Default = True\n    :param hparams.upsample: Whether to oversample the under-represented class so that each class\n        is equally represented in the training and validation dataset. Default = True\n    \"\"\"\n\n    def __init__(self, hparams: Namespace) -> None:\n        super().__init__()\n        set_seed()\n        self.hparams = hparams\n\n        self.data_folder = Path(hparams.data_folder)\n\n        dataset = self.get_dataset(subset=\"training\", cache=False)\n        self.num_outputs = dataset.num_output_classes\n        self.num_timesteps = dataset.num_timesteps\n        self.input_size = dataset.num_input_features\n\n        # we save the normalizing dict because we calculate weighted\n        # normalization values based on the datasets we combine.\n        # The number of instances per dataset (and therefore the weights) can\n        # vary between the train / test / val sets - this ensures the normalizing\n        # dict stays constant between them\n        self.normalizing_dict = dataset.normalizing_dict\n\n        if self.hparams.forecast:\n            num_output_timesteps = self.num_timesteps - self.hparams.input_months\n            print(\n                f\"Predicting {num_output_timesteps} timesteps in the forecaster\")\n            self.forecaster = Forecaster(\n                num_bands=self.input_size, output_timesteps=num_output_timesteps, hparams=hparams,\n            )\n\n            self.forecaster_loss = F.smooth_l1_loss\n\n        self.classifier = Classifier(\n            input_size=self.input_size, hparams=hparams)\n        self.global_loss_function: Callable = F.binary_cross_entropy\n        self.local_loss_function: Callable = F.binary_cross_entropy\n\n    def forward(self, x: torch.Tensor) -> Union[torch.Tensor, Tuple[torch.Tensor, torch.Tensor]]:\n        # To keep the ABC happy\n        return self.classifier(x)\n\n    def configure_optimizers(self):\n        return torch.optim.Adam(self.parameters(), lr=self.hparams.learning_rate)\n\n    def get_dataset(\n        self, subset: str, normalizing_dict: Optional[Dict] = None, cache: Optional[bool] = None,\n    ) -> CropDataset:\n        return CropDataset(\n            data_folder=self.data_folder,\n            subset=subset,\n            remove_b1_b10=self.hparams.remove_b1_b10,\n            normalizing_dict=normalizing_dict,\n            include_geowiki=self.hparams.include_geowiki if subset != \"testing\" else False,\n            cache=self.hparams.cache if cache is None else cache,\n            upsample=self.hparams.upsample if subset != \"testing\" else False,\n            noise_factor=self.hparams.noise_factor if subset != \"testing\" else 0,\n        )\n\n    def train_dataloader(self):\n        return DataLoader(\n            self.get_dataset(subset=\"training\"), shuffle=True, batch_size=self.hparams.batch_size,\n        )\n\n    def val_dataloader(self):\n        return DataLoader(\n            self.get_dataset(subset=\"validation\",\n                             normalizing_dict=self.normalizing_dict,),\n            batch_size=self.hparams.batch_size,\n        )\n\n    def test_dataloader(self):\n        return DataLoader(\n            self.get_dataset(subset=\"testing\",\n                             normalizing_dict=self.normalizing_dict,),\n            batch_size=self.hparams.batch_size,\n        )\n\n    def predict(\n        self,\n        path_to_file: Path,\n        with_forecaster: bool,\n        batch_size: int = 64,\n        add_ndvi: bool = True,\n        add_ndwi: bool = False,\n        nan_fill: float = 0,\n        days_per_timestep: int = 30,\n        local_head: bool = True,\n        use_gpu: bool = True,\n    ) -> xr.Dataset:\n\n        # check if a GPU is available, and if it is\n        # move the model onto the GPU\n        device: Optional[torch.device] = None\n        if use_gpu:\n            use_cuda = torch.cuda.is_available()\n            if not use_cuda:\n                print(\"No GPU - not using one\")\n            device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n            self.to(device)\n\n        self.eval()\n\n        input_data = tif_to_np(\n            path_to_file,\n            add_ndvi=add_ndvi,\n            add_ndwi=add_ndwi,\n            nan=nan_fill,\n            normalizing_dict=self.normalizing_dict,\n            days_per_timestep=days_per_timestep,\n        )\n\n        if with_forecaster:\n            input_data.x = input_data.x[:, : self.hparams.input_months, :]\n\n        predictions: List[np.ndarray] = []\n        cur_i = 0\n\n        pbar = tqdm(total=input_data.x.shape[0] - 1)\n        while cur_i < (input_data.x.shape[0] - 1):\n\n            batch_x_np = input_data.x[cur_i: cur_i + batch_size]\n            if self.hparams.remove_b1_b10:\n                batch_x_np = CropDataset._remove_bands(batch_x_np)\n            batch_x = torch.from_numpy(batch_x_np).float()\n\n            if use_gpu and (device is not None):\n                batch_x = batch_x.to(device)\n\n            with torch.no_grad():\n                if with_forecaster:\n                    batch_x_next = self.forecaster(batch_x)\n                    batch_x = torch.cat((batch_x, batch_x_next), dim=1)\n\n                batch_preds = self.classifier(batch_x)\n\n                if self.hparams.multi_headed:\n                    global_preds, local_preds = batch_preds\n\n                    if local_head:\n                        batch_preds = local_preds\n                    else:\n                        batch_preds = global_preds\n\n                # back to the CPU, if necessary\n                batch_preds = batch_preds.cpu()\n\n            predictions.append(cast(torch.Tensor, batch_preds).numpy())\n            cur_i += batch_size\n            pbar.update(batch_size)\n\n        all_preds = np.concatenate(predictions, axis=0)\n        if len(all_preds.shape) == 1:\n            all_preds = np.expand_dims(all_preds, axis=-1)\n\n        return preds_to_xr(all_preds, lats=input_data.lat, lons=input_data.lon,)\n\n    def _output_metrics(\n        self, preds: np.ndarray, labels: np.ndarray, prefix: str = \"\"\n    ) -> Dict[str, float]:\n\n        if len(preds) == 0:\n            # sometimes this happens in the warmup\n            return {}\n\n        output_dict: Dict[str, float] = {}\n        if not (labels == labels[0]).all():\n            # This can happen when lightning does its warm up on a subset of the\n            # validation data\n            output_dict[f\"{prefix}roc_auc_score\"] = roc_auc_score(\n                labels, preds)\n\n        preds = (preds > PROBABILITY_THRESHOLD).astype(int)\n\n        output_dict[f\"{prefix}precision_score\"] = precision_score(\n            labels, preds)\n        output_dict[f\"{prefix}recall_score\"] = recall_score(labels, preds)\n        output_dict[f\"{prefix}f1_score\"] = f1_score(labels, preds)\n        output_dict[f\"{prefix}accuracy\"] = accuracy_score(labels, preds)\n\n        return output_dict\n\n    def add_noise(self, x: torch.Tensor, training: bool) -> torch.Tensor:\n        if (self.hparams.noise_factor == 0) or (not training):\n            return x\n\n        # expect input to be of shape [timesteps, bands]\n        # and to be normalized with mean 0, std=1\n        # if its not, it means no norm_dict was passed, so lets\n        # just assume std=1\n        noise = torch.normal(0, 1, size=x.shape).float() * \\\n            self.hparams.noise_factor\n\n        # the added noise is the same per band, so that the temporal relationships\n        # are preserved\n        # noise_per_timesteps = noise.repeat(x.shape[0], 1)\n        return x + noise\n\n    def _split_preds_and_get_loss(\n        self, batch, add_preds: bool, loss_label: str, log_loss: bool, training: bool\n    ) -> Dict:\n\n        x, label, is_global = batch\n\n        input_to_encode = x[:, : self.hparams.input_months, :]\n\n        if self.hparams.forecast:\n            # we will predict every timestep except the first one\n            output_to_predict = x[:, 1:, :]\n            encoder_output = self.forecaster(input_to_encode)\n            encoder_loss = self.forecaster_loss(\n                encoder_output, output_to_predict)\n            loss: Union[float, torch.Tensor] = encoder_loss\n\n            final_encoded_input = torch.cat(\n                (\n                    (\n                        self.add_noise(input_to_encode, training),\n                        # -1 because the encoder output has no value for the 0th\n                        # timestep\n                        encoder_output[:, self.hparams.input_months - 1:, :],\n                    )\n                ),\n                dim=1,\n            )\n\n            output_dict = {}\n            if add_preds:\n                output_dict.update(\n                    {\"encoder_prediction\": encoder_output,\n                        \"encoder_target\": output_to_predict, }\n                )\n            if log_loss:\n                output_dict[\"log\"] = {}\n\n            # we now repeat label and is_global\n            x = torch.cat((self.add_noise(x, training),\n                          final_encoded_input), dim=0)\n            label = torch.cat((label, label), dim=0)\n            is_global = torch.cat((is_global, is_global), dim=0)\n        else:\n            loss = 0\n            output_dict = {}\n            if log_loss:\n                output_dict[\"log\"] = {}\n            x = self.add_noise(input_to_encode, training=training)\n\n        if self.hparams.multi_headed:\n            org_global_preds, local_preds = self.classifier(x)\n            global_preds = org_global_preds[is_global != 0]\n            global_labels = label[is_global != 0]\n\n            local_preds = local_preds[is_global == 0]\n            local_labels = label[is_global == 0]\n\n            if local_preds.shape[0] > 0:\n                local_loss = self.local_loss_function(\n                    local_preds.squeeze(-1), local_labels,)\n                loss += local_loss\n\n            if global_preds.shape[0] > 0:\n                global_loss = self.global_loss_function(\n                    global_preds.squeeze(-1), global_labels,)\n\n                num_local_labels = local_preds.shape[0]\n                if num_local_labels == 0:\n                    alpha = 1\n                else:\n                    ratio = global_preds.shape[0] / num_local_labels\n                    alpha = ratio / self.hparams.alpha\n                loss += alpha * global_loss\n\n            output_dict[loss_label] = loss\n            if log_loss:\n                output_dict[\"log\"][loss_label] = loss\n            if add_preds:\n                output_dict.update(\n                    {\n                        \"global_pred\": global_preds,\n                        \"global_label\": global_labels,\n                        \"kenya_pred\": local_preds,\n                        \"kenya_label\": local_labels,\n                    }\n                )\n            return output_dict\n        else:\n            preds = cast(torch.Tensor, self.classifier(x))\n\n            loss += self.global_loss_function(\n                input=preds.squeeze(-1), target=label,)\n\n            output_dict = {loss_label: loss}\n            if log_loss:\n                output_dict[\"log\"][loss_label] = loss\n            if add_preds:\n                output_dict.update({\"pred\": preds, \"label\": label})\n            return output_dict\n\n    def training_step(self, batch, batch_idx):\n        return self._split_preds_and_get_loss(\n            batch, add_preds=False, loss_label=\"loss\", log_loss=True, training=True\n        )\n\n    def validation_step(self, batch, batch_idx):\n        return self._split_preds_and_get_loss(\n            batch, add_preds=True, loss_label=\"val_loss\", log_loss=True, training=False\n        )\n\n    def test_step(self, batch, batch_idx):\n        return self._split_preds_and_get_loss(\n            batch, add_preds=True, loss_label=\"test_loss\", log_loss=True, training=False\n        )\n\n    @staticmethod\n    def _split_tensor(outputs, label) -> Tuple[np.ndarray, np.ndarray]:\n        encoded_all, unencoded_all = [], []\n        for x in outputs:\n            # the first half is unencoded, the second is encoded\n            total = x[label]\n            unencoded_all.append(total[: total.shape[0] // 2])\n            encoded_all.append(total[total.shape[0] // 2:])\n        return (\n            torch.cat(unencoded_all).detach().cpu().numpy(),\n            torch.cat(encoded_all).detach().cpu().numpy(),\n        )\n\n    def _interpretable_metrics(self, outputs, input_prefix: str, output_prefix: str) -> Dict:\n\n        output_dict = {}\n\n        if self.hparams.forecast:\n            u_labels, e_labels = self._split_tensor(\n                outputs, f\"{input_prefix}label\")\n\n            u_preds, e_preds = self._split_tensor(\n                outputs, f\"{input_prefix}pred\")\n        else:\n            u_preds = torch.cat([x[f\"{input_prefix}pred\"]\n                                for x in outputs]).detach().cpu().numpy()\n            u_labels = (\n                torch.cat([x[f\"{input_prefix}label\"]\n                          for x in outputs]).detach().cpu().numpy()\n            )\n\n        output_dict.update(\n            self._output_metrics(\n                u_preds, u_labels, f\"unencoded_{output_prefix}{input_prefix}\")\n        )\n\n        if self.hparams.forecast:\n            output_dict.update(\n                self._output_metrics(\n                    e_preds, e_labels, f\"encoded_{output_prefix}{input_prefix}\")\n            )\n\n        return output_dict\n\n    def validation_epoch_end(self, outputs):\n        avg_loss = torch.stack([x[\"val_loss\"] for x in outputs]).mean()\n        logs = {\"val_loss\": avg_loss}\n        if self.hparams.forecast:\n            encoder_pred = (\n                torch.cat(\n                    [torch.flatten(x[\"encoder_prediction\"], start_dim=1) for x in outputs], dim=0,\n                )\n                .detach()\n                .cpu()\n                .numpy()\n            )\n            encoder_target = (\n                torch.cat(\n                    [torch.flatten(x[\"encoder_target\"], start_dim=1) for x in outputs], dim=0,\n                )\n                .detach()\n                .cpu()\n                .numpy()\n            )\n\n            logs[\"val_encoder_mae\"] = mean_absolute_error(\n                encoder_target, encoder_pred)\n\n        if self.hparams.multi_headed:\n            logs.update(self._interpretable_metrics(\n                outputs, \"global_\", \"val_\"))\n            logs.update(self._interpretable_metrics(outputs, \"kenya_\", \"val_\"))\n        else:\n            logs.update(self._interpretable_metrics(outputs, \"\", \"val_\"))\n        return {\"val_loss\": avg_loss, \"log\": logs}\n\n    def test_epoch_end(self, outputs):\n\n        avg_loss = torch.stack([x[\"test_loss\"] for x in outputs]).mean().item()\n        output_dict = {\"val_loss\": avg_loss}\n\n        if self.hparams.forecast:\n            encoder_pred = (\n                torch.cat(\n                    [torch.flatten(x[\"encoder_prediction\"], start_dim=1) for x in outputs], dim=0,\n                )\n                .detach()\n                .cpu()\n                .numpy()\n            )\n            encoder_target = (\n                torch.cat(\n                    [torch.flatten(x[\"encoder_target\"], start_dim=1) for x in outputs], dim=0,\n                )\n                .detach()\n                .cpu()\n                .numpy()\n            )\n\n            output_dict[\"test_encoder_mae\"] = mean_absolute_error(\n                encoder_target, encoder_pred)\n\n        if self.hparams.multi_headed:\n            output_dict.update(self._interpretable_metrics(\n                outputs, \"global_\", \"test_\"))\n            output_dict.update(self._interpretable_metrics(\n                outputs, \"kenya_\", \"test_\"))\n        else:\n            output_dict.update(\n                self._interpretable_metrics(outputs, \"\", \"test_\"))\n\n        return {\"progress_bar\": output_dict}\n\n    @staticmethod\n    def add_model_specific_args(parent_parser: ArgumentParser) -> ArgumentParser:\n\n        parser = ArgumentParser(parents=[parent_parser], add_help=False)\n\n        parser_args: Dict[str, Tuple[Type, Any]] = {\n            # assumes this is being run from \"scripts\"\n            \"--data_folder\": (str, str(Path(\"../data\"))),\n            \"--learning_rate\": (float, 0.001),\n            \"--batch_size\": (int, 64),\n            \"--input_months\": (int, 5),\n            \"--alpha\": (float, 10),\n            \"--noise_factor\": (float, 0.1),\n        }\n\n        for key, val in parser_args.items():\n            parser.add_argument(key, type=val[0], default=val[1])\n\n        parser.add_argument(\"--remove_b1_b10\",\n                            dest=\"remove_b1_b10\", action=\"store_true\")\n        parser.add_argument(\n            \"--keep_b1_b10\", dest=\"remove_b1_b10\", action=\"store_false\")\n        parser.set_defaults(remove_b1_b10=True)\n\n        parser.add_argument(\"--forecast\", dest=\"forecast\", action=\"store_true\")\n        parser.add_argument(\"--do_not_forecast\",\n                            dest=\"forecast\", action=\"store_false\")\n        parser.set_defaults(forecast=True)\n\n        parser.add_argument(\"--cache\", dest=\"cache\", action=\"store_true\")\n        parser.add_argument(\"--do_not_cache\", dest=\"cache\",\n                            action=\"store_false\")\n        parser.set_defaults(cache=True)\n\n        parser.add_argument(\"--include_geowiki\",\n                            dest=\"include_geowiki\", action=\"store_true\")\n        parser.add_argument(\"--exclude_geowiki\",\n                            dest=\"include_geowiki\", action=\"store_false\")\n        parser.set_defaults(include_geowiki=True)\n\n        parser.add_argument(\"--upsample\", dest=\"upsample\", action=\"store_true\")\n        parser.add_argument(\"--do_not_upsample\",\n                            dest=\"upsample\", action=\"store_false\")\n        parser.set_defaults(upsample=True)\n\n        classifier_parser = Classifier.add_model_specific_args(parser)\n        return Forecaster.add_model_specific_args(classifier_parser)\n",
  "history_output" : "",
  "history_begin_time" : 1666118278490,
  "history_end_time" : 1666118282146,
  "history_notes" : null,
  "history_process" : "9ardvx",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "s7si5g64tg6",
  "history_input" : "from argparse import ArgumentParser, Namespace\nfrom pathlib import Path\nimport numpy as np\nimport xarray as xr\nfrom tqdm import tqdm\n\nimport torch\nfrom torch.nn import functional as F\nfrom torch.utils.data import DataLoader\n\nimport pytorch_lightning as pl\n\nfrom sklearn.metrics import (\n    roc_auc_score,\n    accuracy_score,\n    precision_score,\n    recall_score,\n    f1_score,\n    mean_absolute_error,\n)\n\nfrom src_models_data import CropDataset\nfrom src_models_utils import tif_to_np, preds_to_xr\nfrom src_utils import set_seed\nfrom src_models_forecaster import Forecaster\nfrom src_models_classifier import Classifier\nfrom src_config import PROBABILITY_THRESHOLD\n\nfrom typing import cast, Callable, Tuple, Dict, Any, Type, Optional, List, Union\n\n\nclass Model(pl.LightningModule):\n    r\"\"\"\n    An model for annual and in-season crop mapping. This model consists of a\n    forecaster.Forecaster and a classifier.Classifier - it will require the arguments\n    required by those models too.\n\n    hparams\n    --------\n    The default values for these parameters are set in add_model_specific_args\n\n    :param hparams.data_folder: The path to the data. Default (assumes the model\n        is being run from the scripts directory) = \"../data\"\n    :param hparams.learning_rate: The learning rate. Default = 0.001\n    :param hparams.batch_size: The batch size. Default = 64\n    :param hparams.input_months: The number of input months to pass to the model. If\n        hparams.forecast is True, the remaining months will be forecasted. Otherwise, only the\n        partial timeseries will be passed to the classifier. Default = 5\n    :param hparams.alpha: The weight to use when adding the global and local losses. This\n        parameter is only used if hparams.multi_headed is True. Default = 10\n    :param hparams.noise_factor: The standard deviation of the random noise to add to the\n        raw inputs to the classifier. Default = 0.1\n    :param hparams.remove_b1_b10: Whether or not to remove the B1 and B10 bands. Default = True\n    :param hparams.forecast: Whether or not to forecast the partial time series. Default = True\n    :param hparams.cache: Whether to load all the data into memory during training. Default = True\n    :param hparams.include_geowiki: Whether to include the global GeoWiki dataset during\n        training. Default = True\n    :param hparams.upsample: Whether to oversample the under-represented class so that each class\n        is equally represented in the training and validation dataset. Default = True\n    \"\"\"\n\n    def __init__(self, hparams: Namespace) -> None:\n        super().__init__()\n        set_seed()\n        self.hparams = hparams\n\n        self.data_folder = Path(hparams.data_folder)\n\n        dataset = self.get_dataset(subset=\"training\", cache=False)\n        self.num_outputs = dataset.num_output_classes\n        self.num_timesteps = dataset.num_timesteps\n        self.input_size = dataset.num_input_features\n\n        # we save the normalizing dict because we calculate weighted\n        # normalization values based on the datasets we combine.\n        # The number of instances per dataset (and therefore the weights) can\n        # vary between the train / test / val sets - this ensures the normalizing\n        # dict stays constant between them\n        self.normalizing_dict = dataset.normalizing_dict\n\n        if self.hparams.forecast:\n            num_output_timesteps = self.num_timesteps - self.hparams.input_months\n            print(\n                f\"Predicting {num_output_timesteps} timesteps in the forecaster\")\n            self.forecaster = Forecaster(\n                num_bands=self.input_size, output_timesteps=num_output_timesteps, hparams=hparams,\n            )\n\n            self.forecaster_loss = F.smooth_l1_loss\n\n        self.classifier = Classifier(\n            input_size=self.input_size, hparams=hparams)\n        self.global_loss_function: Callable = F.binary_cross_entropy\n        self.local_loss_function: Callable = F.binary_cross_entropy\n\n    def forward(self, x: torch.Tensor) -> Union[torch.Tensor, Tuple[torch.Tensor, torch.Tensor]]:\n        # To keep the ABC happy\n        return self.classifier(x)\n\n    def configure_optimizers(self):\n        return torch.optim.Adam(self.parameters(), lr=self.hparams.learning_rate)\n\n    def get_dataset(\n        self, subset: str, normalizing_dict: Optional[Dict] = None, cache: Optional[bool] = None,\n    ) -> CropDataset:\n        return CropDataset(\n            data_folder=self.data_folder,\n            subset=subset,\n            remove_b1_b10=self.hparams.remove_b1_b10,\n            normalizing_dict=normalizing_dict,\n            include_geowiki=self.hparams.include_geowiki if subset != \"testing\" else False,\n            cache=self.hparams.cache if cache is None else cache,\n            upsample=self.hparams.upsample if subset != \"testing\" else False,\n            noise_factor=self.hparams.noise_factor if subset != \"testing\" else 0,\n        )\n\n    def train_dataloader(self):\n        return DataLoader(\n            self.get_dataset(subset=\"training\"), shuffle=True, batch_size=self.hparams.batch_size,\n        )\n\n    def val_dataloader(self):\n        return DataLoader(\n            self.get_dataset(subset=\"validation\",\n                             normalizing_dict=self.normalizing_dict,),\n            batch_size=self.hparams.batch_size,\n        )\n\n    def test_dataloader(self):\n        return DataLoader(\n            self.get_dataset(subset=\"testing\",\n                             normalizing_dict=self.normalizing_dict,),\n            batch_size=self.hparams.batch_size,\n        )\n\n    def predict(\n        self,\n        path_to_file: Path,\n        with_forecaster: bool,\n        batch_size: int = 64,\n        add_ndvi: bool = True,\n        add_ndwi: bool = False,\n        nan_fill: float = 0,\n        days_per_timestep: int = 30,\n        local_head: bool = True,\n        use_gpu: bool = True,\n    ) -> xr.Dataset:\n\n        # check if a GPU is available, and if it is\n        # move the model onto the GPU\n        device: Optional[torch.device] = None\n        if use_gpu:\n            use_cuda = torch.cuda.is_available()\n            if not use_cuda:\n                print(\"No GPU - not using one\")\n            device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n            self.to(device)\n\n        self.eval()\n\n        input_data = tif_to_np(\n            path_to_file,\n            add_ndvi=add_ndvi,\n            add_ndwi=add_ndwi,\n            nan=nan_fill,\n            normalizing_dict=self.normalizing_dict,\n            days_per_timestep=days_per_timestep,\n        )\n\n        if with_forecaster:\n            input_data.x = input_data.x[:, : self.hparams.input_months, :]\n\n        predictions: List[np.ndarray] = []\n        cur_i = 0\n\n        pbar = tqdm(total=input_data.x.shape[0] - 1)\n        while cur_i < (input_data.x.shape[0] - 1):\n\n            batch_x_np = input_data.x[cur_i: cur_i + batch_size]\n            if self.hparams.remove_b1_b10:\n                batch_x_np = CropDataset._remove_bands(batch_x_np)\n            batch_x = torch.from_numpy(batch_x_np).float()\n\n            if use_gpu and (device is not None):\n                batch_x = batch_x.to(device)\n\n            with torch.no_grad():\n                if with_forecaster:\n                    batch_x_next = self.forecaster(batch_x)\n                    batch_x = torch.cat((batch_x, batch_x_next), dim=1)\n\n                batch_preds = self.classifier(batch_x)\n\n                if self.hparams.multi_headed:\n                    global_preds, local_preds = batch_preds\n\n                    if local_head:\n                        batch_preds = local_preds\n                    else:\n                        batch_preds = global_preds\n\n                # back to the CPU, if necessary\n                batch_preds = batch_preds.cpu()\n\n            predictions.append(cast(torch.Tensor, batch_preds).numpy())\n            cur_i += batch_size\n            pbar.update(batch_size)\n\n        all_preds = np.concatenate(predictions, axis=0)\n        if len(all_preds.shape) == 1:\n            all_preds = np.expand_dims(all_preds, axis=-1)\n\n        return preds_to_xr(all_preds, lats=input_data.lat, lons=input_data.lon,)\n\n    def _output_metrics(\n        self, preds: np.ndarray, labels: np.ndarray, prefix: str = \"\"\n    ) -> Dict[str, float]:\n\n        if len(preds) == 0:\n            # sometimes this happens in the warmup\n            return {}\n\n        output_dict: Dict[str, float] = {}\n        if not (labels == labels[0]).all():\n            # This can happen when lightning does its warm up on a subset of the\n            # validation data\n            output_dict[f\"{prefix}roc_auc_score\"] = roc_auc_score(\n                labels, preds)\n\n        preds = (preds > PROBABILITY_THRESHOLD).astype(int)\n\n        output_dict[f\"{prefix}precision_score\"] = precision_score(\n            labels, preds)\n        output_dict[f\"{prefix}recall_score\"] = recall_score(labels, preds)\n        output_dict[f\"{prefix}f1_score\"] = f1_score(labels, preds)\n        output_dict[f\"{prefix}accuracy\"] = accuracy_score(labels, preds)\n\n        return output_dict\n\n    def add_noise(self, x: torch.Tensor, training: bool) -> torch.Tensor:\n        if (self.hparams.noise_factor == 0) or (not training):\n            return x\n\n        # expect input to be of shape [timesteps, bands]\n        # and to be normalized with mean 0, std=1\n        # if its not, it means no norm_dict was passed, so lets\n        # just assume std=1\n        noise = torch.normal(0, 1, size=x.shape).float() * \\\n            self.hparams.noise_factor\n\n        # the added noise is the same per band, so that the temporal relationships\n        # are preserved\n        # noise_per_timesteps = noise.repeat(x.shape[0], 1)\n        return x + noise\n\n    def _split_preds_and_get_loss(\n        self, batch, add_preds: bool, loss_label: str, log_loss: bool, training: bool\n    ) -> Dict:\n\n        x, label, is_global = batch\n\n        input_to_encode = x[:, : self.hparams.input_months, :]\n\n        if self.hparams.forecast:\n            # we will predict every timestep except the first one\n            output_to_predict = x[:, 1:, :]\n            encoder_output = self.forecaster(input_to_encode)\n            encoder_loss = self.forecaster_loss(\n                encoder_output, output_to_predict)\n            loss: Union[float, torch.Tensor] = encoder_loss\n\n            final_encoded_input = torch.cat(\n                (\n                    (\n                        self.add_noise(input_to_encode, training),\n                        # -1 because the encoder output has no value for the 0th\n                        # timestep\n                        encoder_output[:, self.hparams.input_months - 1:, :],\n                    )\n                ),\n                dim=1,\n            )\n\n            output_dict = {}\n            if add_preds:\n                output_dict.update(\n                    {\"encoder_prediction\": encoder_output,\n                        \"encoder_target\": output_to_predict, }\n                )\n            if log_loss:\n                output_dict[\"log\"] = {}\n\n            # we now repeat label and is_global\n            x = torch.cat((self.add_noise(x, training),\n                          final_encoded_input), dim=0)\n            label = torch.cat((label, label), dim=0)\n            is_global = torch.cat((is_global, is_global), dim=0)\n        else:\n            loss = 0\n            output_dict = {}\n            if log_loss:\n                output_dict[\"log\"] = {}\n            x = self.add_noise(input_to_encode, training=training)\n\n        if self.hparams.multi_headed:\n            org_global_preds, local_preds = self.classifier(x)\n            global_preds = org_global_preds[is_global != 0]\n            global_labels = label[is_global != 0]\n\n            local_preds = local_preds[is_global == 0]\n            local_labels = label[is_global == 0]\n\n            if local_preds.shape[0] > 0:\n                local_loss = self.local_loss_function(\n                    local_preds.squeeze(-1), local_labels,)\n                loss += local_loss\n\n            if global_preds.shape[0] > 0:\n                global_loss = self.global_loss_function(\n                    global_preds.squeeze(-1), global_labels,)\n\n                num_local_labels = local_preds.shape[0]\n                if num_local_labels == 0:\n                    alpha = 1\n                else:\n                    ratio = global_preds.shape[0] / num_local_labels\n                    alpha = ratio / self.hparams.alpha\n                loss += alpha * global_loss\n\n            output_dict[loss_label] = loss\n            if log_loss:\n                output_dict[\"log\"][loss_label] = loss\n            if add_preds:\n                output_dict.update(\n                    {\n                        \"global_pred\": global_preds,\n                        \"global_label\": global_labels,\n                        \"kenya_pred\": local_preds,\n                        \"kenya_label\": local_labels,\n                    }\n                )\n            return output_dict\n        else:\n            preds = cast(torch.Tensor, self.classifier(x))\n\n            loss += self.global_loss_function(\n                input=preds.squeeze(-1), target=label,)\n\n            output_dict = {loss_label: loss}\n            if log_loss:\n                output_dict[\"log\"][loss_label] = loss\n            if add_preds:\n                output_dict.update({\"pred\": preds, \"label\": label})\n            return output_dict\n\n    def training_step(self, batch, batch_idx):\n        return self._split_preds_and_get_loss(\n            batch, add_preds=False, loss_label=\"loss\", log_loss=True, training=True\n        )\n\n    def validation_step(self, batch, batch_idx):\n        return self._split_preds_and_get_loss(\n            batch, add_preds=True, loss_label=\"val_loss\", log_loss=True, training=False\n        )\n\n    def test_step(self, batch, batch_idx):\n        return self._split_preds_and_get_loss(\n            batch, add_preds=True, loss_label=\"test_loss\", log_loss=True, training=False\n        )\n\n    @staticmethod\n    def _split_tensor(outputs, label) -> Tuple[np.ndarray, np.ndarray]:\n        encoded_all, unencoded_all = [], []\n        for x in outputs:\n            # the first half is unencoded, the second is encoded\n            total = x[label]\n            unencoded_all.append(total[: total.shape[0] // 2])\n            encoded_all.append(total[total.shape[0] // 2:])\n        return (\n            torch.cat(unencoded_all).detach().cpu().numpy(),\n            torch.cat(encoded_all).detach().cpu().numpy(),\n        )\n\n    def _interpretable_metrics(self, outputs, input_prefix: str, output_prefix: str) -> Dict:\n\n        output_dict = {}\n\n        if self.hparams.forecast:\n            u_labels, e_labels = self._split_tensor(\n                outputs, f\"{input_prefix}label\")\n\n            u_preds, e_preds = self._split_tensor(\n                outputs, f\"{input_prefix}pred\")\n        else:\n            u_preds = torch.cat([x[f\"{input_prefix}pred\"]\n                                for x in outputs]).detach().cpu().numpy()\n            u_labels = (\n                torch.cat([x[f\"{input_prefix}label\"]\n                          for x in outputs]).detach().cpu().numpy()\n            )\n\n        output_dict.update(\n            self._output_metrics(\n                u_preds, u_labels, f\"unencoded_{output_prefix}{input_prefix}\")\n        )\n\n        if self.hparams.forecast:\n            output_dict.update(\n                self._output_metrics(\n                    e_preds, e_labels, f\"encoded_{output_prefix}{input_prefix}\")\n            )\n\n        return output_dict\n\n    def validation_epoch_end(self, outputs):\n        avg_loss = torch.stack([x[\"val_loss\"] for x in outputs]).mean()\n        logs = {\"val_loss\": avg_loss}\n        if self.hparams.forecast:\n            encoder_pred = (\n                torch.cat(\n                    [torch.flatten(x[\"encoder_prediction\"], start_dim=1) for x in outputs], dim=0,\n                )\n                .detach()\n                .cpu()\n                .numpy()\n            )\n            encoder_target = (\n                torch.cat(\n                    [torch.flatten(x[\"encoder_target\"], start_dim=1) for x in outputs], dim=0,\n                )\n                .detach()\n                .cpu()\n                .numpy()\n            )\n\n            logs[\"val_encoder_mae\"] = mean_absolute_error(\n                encoder_target, encoder_pred)\n\n        if self.hparams.multi_headed:\n            logs.update(self._interpretable_metrics(\n                outputs, \"global_\", \"val_\"))\n            logs.update(self._interpretable_metrics(outputs, \"kenya_\", \"val_\"))\n        else:\n            logs.update(self._interpretable_metrics(outputs, \"\", \"val_\"))\n        return {\"val_loss\": avg_loss, \"log\": logs}\n\n    def test_epoch_end(self, outputs):\n\n        avg_loss = torch.stack([x[\"test_loss\"] for x in outputs]).mean().item()\n        output_dict = {\"val_loss\": avg_loss}\n\n        if self.hparams.forecast:\n            encoder_pred = (\n                torch.cat(\n                    [torch.flatten(x[\"encoder_prediction\"], start_dim=1) for x in outputs], dim=0,\n                )\n                .detach()\n                .cpu()\n                .numpy()\n            )\n            encoder_target = (\n                torch.cat(\n                    [torch.flatten(x[\"encoder_target\"], start_dim=1) for x in outputs], dim=0,\n                )\n                .detach()\n                .cpu()\n                .numpy()\n            )\n\n            output_dict[\"test_encoder_mae\"] = mean_absolute_error(\n                encoder_target, encoder_pred)\n\n        if self.hparams.multi_headed:\n            output_dict.update(self._interpretable_metrics(\n                outputs, \"global_\", \"test_\"))\n            output_dict.update(self._interpretable_metrics(\n                outputs, \"kenya_\", \"test_\"))\n        else:\n            output_dict.update(\n                self._interpretable_metrics(outputs, \"\", \"test_\"))\n\n        return {\"progress_bar\": output_dict}\n\n    @staticmethod\n    def add_model_specific_args(parent_parser: ArgumentParser) -> ArgumentParser:\n\n        parser = ArgumentParser(parents=[parent_parser], add_help=False)\n\n        parser_args: Dict[str, Tuple[Type, Any]] = {\n            # assumes this is being run from \"scripts\"\n            \"--data_folder\": (str, str(Path(\"../data\"))),\n            \"--learning_rate\": (float, 0.001),\n            \"--batch_size\": (int, 64),\n            \"--input_months\": (int, 5),\n            \"--alpha\": (float, 10),\n            \"--noise_factor\": (float, 0.1),\n        }\n\n        for key, val in parser_args.items():\n            parser.add_argument(key, type=val[0], default=val[1])\n\n        parser.add_argument(\"--remove_b1_b10\",\n                            dest=\"remove_b1_b10\", action=\"store_true\")\n        parser.add_argument(\n            \"--keep_b1_b10\", dest=\"remove_b1_b10\", action=\"store_false\")\n        parser.set_defaults(remove_b1_b10=True)\n\n        parser.add_argument(\"--forecast\", dest=\"forecast\", action=\"store_true\")\n        parser.add_argument(\"--do_not_forecast\",\n                            dest=\"forecast\", action=\"store_false\")\n        parser.set_defaults(forecast=True)\n\n        parser.add_argument(\"--cache\", dest=\"cache\", action=\"store_true\")\n        parser.add_argument(\"--do_not_cache\", dest=\"cache\",\n                            action=\"store_false\")\n        parser.set_defaults(cache=True)\n\n        parser.add_argument(\"--include_geowiki\",\n                            dest=\"include_geowiki\", action=\"store_true\")\n        parser.add_argument(\"--exclude_geowiki\",\n                            dest=\"include_geowiki\", action=\"store_false\")\n        parser.set_defaults(include_geowiki=True)\n\n        parser.add_argument(\"--upsample\", dest=\"upsample\", action=\"store_true\")\n        parser.add_argument(\"--do_not_upsample\",\n                            dest=\"upsample\", action=\"store_false\")\n        parser.set_defaults(upsample=True)\n\n        classifier_parser = Classifier.add_model_specific_args(parser)\n        return Forecaster.add_model_specific_args(classifier_parser)\n",
  "history_output" : "",
  "history_begin_time" : 1655909878845,
  "history_end_time" : 1655909884239,
  "history_notes" : null,
  "history_process" : "9ardvx",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "l48r0imyg0o",
  "history_input" : "from argparse import ArgumentParser, Namespace\nfrom pathlib import Path\nimport numpy as np\nimport xarray as xr\nfrom tqdm import tqdm\n\nimport torch\nfrom torch.nn import functional as F\nfrom torch.utils.data import DataLoader\n\nimport pytorch_lightning as pl\n\nfrom sklearn.metrics import (\n    roc_auc_score,\n    accuracy_score,\n    precision_score,\n    recall_score,\n    f1_score,\n    mean_absolute_error,\n)\n\nfrom src_models_data import CropDataset\nfrom src_models_utils import tif_to_np, preds_to_xr\nfrom src_utils import set_seed\nfrom src_models_forecaster import Forecaster\nfrom src_models_classifier import Classifier\nfrom src_config import PROBABILITY_THRESHOLD\n\nfrom typing import cast, Callable, Tuple, Dict, Any, Type, Optional, List, Union\n\n\nclass Model(pl.LightningModule):\n    r\"\"\"\n    An model for annual and in-season crop mapping. This model consists of a\n    forecaster.Forecaster and a classifier.Classifier - it will require the arguments\n    required by those models too.\n\n    hparams\n    --------\n    The default values for these parameters are set in add_model_specific_args\n\n    :param hparams.data_folder: The path to the data. Default (assumes the model\n        is being run from the scripts directory) = \"../data\"\n    :param hparams.learning_rate: The learning rate. Default = 0.001\n    :param hparams.batch_size: The batch size. Default = 64\n    :param hparams.input_months: The number of input months to pass to the model. If\n        hparams.forecast is True, the remaining months will be forecasted. Otherwise, only the\n        partial timeseries will be passed to the classifier. Default = 5\n    :param hparams.alpha: The weight to use when adding the global and local losses. This\n        parameter is only used if hparams.multi_headed is True. Default = 10\n    :param hparams.noise_factor: The standard deviation of the random noise to add to the\n        raw inputs to the classifier. Default = 0.1\n    :param hparams.remove_b1_b10: Whether or not to remove the B1 and B10 bands. Default = True\n    :param hparams.forecast: Whether or not to forecast the partial time series. Default = True\n    :param hparams.cache: Whether to load all the data into memory during training. Default = True\n    :param hparams.include_geowiki: Whether to include the global GeoWiki dataset during\n        training. Default = True\n    :param hparams.upsample: Whether to oversample the under-represented class so that each class\n        is equally represented in the training and validation dataset. Default = True\n    \"\"\"\n\n    def __init__(self, hparams: Namespace) -> None:\n        super().__init__()\n        set_seed()\n        self.hparams = hparams\n\n        self.data_folder = Path(hparams.data_folder)\n\n        dataset = self.get_dataset(subset=\"training\", cache=False)\n        self.num_outputs = dataset.num_output_classes\n        self.num_timesteps = dataset.num_timesteps\n        self.input_size = dataset.num_input_features\n\n        # we save the normalizing dict because we calculate weighted\n        # normalization values based on the datasets we combine.\n        # The number of instances per dataset (and therefore the weights) can\n        # vary between the train / test / val sets - this ensures the normalizing\n        # dict stays constant between them\n        self.normalizing_dict = dataset.normalizing_dict\n\n        if self.hparams.forecast:\n            num_output_timesteps = self.num_timesteps - self.hparams.input_months\n            print(\n                f\"Predicting {num_output_timesteps} timesteps in the forecaster\")\n            self.forecaster = Forecaster(\n                num_bands=self.input_size, output_timesteps=num_output_timesteps, hparams=hparams,\n            )\n\n            self.forecaster_loss = F.smooth_l1_loss\n\n        self.classifier = Classifier(\n            input_size=self.input_size, hparams=hparams)\n        self.global_loss_function: Callable = F.binary_cross_entropy\n        self.local_loss_function: Callable = F.binary_cross_entropy\n\n    def forward(self, x: torch.Tensor) -> Union[torch.Tensor, Tuple[torch.Tensor, torch.Tensor]]:\n        # To keep the ABC happy\n        return self.classifier(x)\n\n    def configure_optimizers(self):\n        return torch.optim.Adam(self.parameters(), lr=self.hparams.learning_rate)\n\n    def get_dataset(\n        self, subset: str, normalizing_dict: Optional[Dict] = None, cache: Optional[bool] = None,\n    ) -> CropDataset:\n        return CropDataset(\n            data_folder=self.data_folder,\n            subset=subset,\n            remove_b1_b10=self.hparams.remove_b1_b10,\n            normalizing_dict=normalizing_dict,\n            include_geowiki=self.hparams.include_geowiki if subset != \"testing\" else False,\n            cache=self.hparams.cache if cache is None else cache,\n            upsample=self.hparams.upsample if subset != \"testing\" else False,\n            noise_factor=self.hparams.noise_factor if subset != \"testing\" else 0,\n        )\n\n    def train_dataloader(self):\n        return DataLoader(\n            self.get_dataset(subset=\"training\"), shuffle=True, batch_size=self.hparams.batch_size,\n        )\n\n    def val_dataloader(self):\n        return DataLoader(\n            self.get_dataset(subset=\"validation\",\n                             normalizing_dict=self.normalizing_dict,),\n            batch_size=self.hparams.batch_size,\n        )\n\n    def test_dataloader(self):\n        return DataLoader(\n            self.get_dataset(subset=\"testing\",\n                             normalizing_dict=self.normalizing_dict,),\n            batch_size=self.hparams.batch_size,\n        )\n\n    def predict(\n        self,\n        path_to_file: Path,\n        with_forecaster: bool,\n        batch_size: int = 64,\n        add_ndvi: bool = True,\n        add_ndwi: bool = False,\n        nan_fill: float = 0,\n        days_per_timestep: int = 30,\n        local_head: bool = True,\n        use_gpu: bool = True,\n    ) -> xr.Dataset:\n\n        # check if a GPU is available, and if it is\n        # move the model onto the GPU\n        device: Optional[torch.device] = None\n        if use_gpu:\n            use_cuda = torch.cuda.is_available()\n            if not use_cuda:\n                print(\"No GPU - not using one\")\n            device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n            self.to(device)\n\n        self.eval()\n\n        input_data = tif_to_np(\n            path_to_file,\n            add_ndvi=add_ndvi,\n            add_ndwi=add_ndwi,\n            nan=nan_fill,\n            normalizing_dict=self.normalizing_dict,\n            days_per_timestep=days_per_timestep,\n        )\n\n        if with_forecaster:\n            input_data.x = input_data.x[:, : self.hparams.input_months, :]\n\n        predictions: List[np.ndarray] = []\n        cur_i = 0\n\n        pbar = tqdm(total=input_data.x.shape[0] - 1)\n        while cur_i < (input_data.x.shape[0] - 1):\n\n            batch_x_np = input_data.x[cur_i: cur_i + batch_size]\n            if self.hparams.remove_b1_b10:\n                batch_x_np = CropDataset._remove_bands(batch_x_np)\n            batch_x = torch.from_numpy(batch_x_np).float()\n\n            if use_gpu and (device is not None):\n                batch_x = batch_x.to(device)\n\n            with torch.no_grad():\n                if with_forecaster:\n                    batch_x_next = self.forecaster(batch_x)\n                    batch_x = torch.cat((batch_x, batch_x_next), dim=1)\n\n                batch_preds = self.classifier(batch_x)\n\n                if self.hparams.multi_headed:\n                    global_preds, local_preds = batch_preds\n\n                    if local_head:\n                        batch_preds = local_preds\n                    else:\n                        batch_preds = global_preds\n\n                # back to the CPU, if necessary\n                batch_preds = batch_preds.cpu()\n\n            predictions.append(cast(torch.Tensor, batch_preds).numpy())\n            cur_i += batch_size\n            pbar.update(batch_size)\n\n        all_preds = np.concatenate(predictions, axis=0)\n        if len(all_preds.shape) == 1:\n            all_preds = np.expand_dims(all_preds, axis=-1)\n\n        return preds_to_xr(all_preds, lats=input_data.lat, lons=input_data.lon,)\n\n    def _output_metrics(\n        self, preds: np.ndarray, labels: np.ndarray, prefix: str = \"\"\n    ) -> Dict[str, float]:\n\n        if len(preds) == 0:\n            # sometimes this happens in the warmup\n            return {}\n\n        output_dict: Dict[str, float] = {}\n        if not (labels == labels[0]).all():\n            # This can happen when lightning does its warm up on a subset of the\n            # validation data\n            output_dict[f\"{prefix}roc_auc_score\"] = roc_auc_score(\n                labels, preds)\n\n        preds = (preds > PROBABILITY_THRESHOLD).astype(int)\n\n        output_dict[f\"{prefix}precision_score\"] = precision_score(\n            labels, preds)\n        output_dict[f\"{prefix}recall_score\"] = recall_score(labels, preds)\n        output_dict[f\"{prefix}f1_score\"] = f1_score(labels, preds)\n        output_dict[f\"{prefix}accuracy\"] = accuracy_score(labels, preds)\n\n        return output_dict\n\n    def add_noise(self, x: torch.Tensor, training: bool) -> torch.Tensor:\n        if (self.hparams.noise_factor == 0) or (not training):\n            return x\n\n        # expect input to be of shape [timesteps, bands]\n        # and to be normalized with mean 0, std=1\n        # if its not, it means no norm_dict was passed, so lets\n        # just assume std=1\n        noise = torch.normal(0, 1, size=x.shape).float() * \\\n            self.hparams.noise_factor\n\n        # the added noise is the same per band, so that the temporal relationships\n        # are preserved\n        # noise_per_timesteps = noise.repeat(x.shape[0], 1)\n        return x + noise\n\n    def _split_preds_and_get_loss(\n        self, batch, add_preds: bool, loss_label: str, log_loss: bool, training: bool\n    ) -> Dict:\n\n        x, label, is_global = batch\n\n        input_to_encode = x[:, : self.hparams.input_months, :]\n\n        if self.hparams.forecast:\n            # we will predict every timestep except the first one\n            output_to_predict = x[:, 1:, :]\n            encoder_output = self.forecaster(input_to_encode)\n            encoder_loss = self.forecaster_loss(\n                encoder_output, output_to_predict)\n            loss: Union[float, torch.Tensor] = encoder_loss\n\n            final_encoded_input = torch.cat(\n                (\n                    (\n                        self.add_noise(input_to_encode, training),\n                        # -1 because the encoder output has no value for the 0th\n                        # timestep\n                        encoder_output[:, self.hparams.input_months - 1:, :],\n                    )\n                ),\n                dim=1,\n            )\n\n            output_dict = {}\n            if add_preds:\n                output_dict.update(\n                    {\"encoder_prediction\": encoder_output,\n                        \"encoder_target\": output_to_predict, }\n                )\n            if log_loss:\n                output_dict[\"log\"] = {}\n\n            # we now repeat label and is_global\n            x = torch.cat((self.add_noise(x, training),\n                          final_encoded_input), dim=0)\n            label = torch.cat((label, label), dim=0)\n            is_global = torch.cat((is_global, is_global), dim=0)\n        else:\n            loss = 0\n            output_dict = {}\n            if log_loss:\n                output_dict[\"log\"] = {}\n            x = self.add_noise(input_to_encode, training=training)\n\n        if self.hparams.multi_headed:\n            org_global_preds, local_preds = self.classifier(x)\n            global_preds = org_global_preds[is_global != 0]\n            global_labels = label[is_global != 0]\n\n            local_preds = local_preds[is_global == 0]\n            local_labels = label[is_global == 0]\n\n            if local_preds.shape[0] > 0:\n                local_loss = self.local_loss_function(\n                    local_preds.squeeze(-1), local_labels,)\n                loss += local_loss\n\n            if global_preds.shape[0] > 0:\n                global_loss = self.global_loss_function(\n                    global_preds.squeeze(-1), global_labels,)\n\n                num_local_labels = local_preds.shape[0]\n                if num_local_labels == 0:\n                    alpha = 1\n                else:\n                    ratio = global_preds.shape[0] / num_local_labels\n                    alpha = ratio / self.hparams.alpha\n                loss += alpha * global_loss\n\n            output_dict[loss_label] = loss\n            if log_loss:\n                output_dict[\"log\"][loss_label] = loss\n            if add_preds:\n                output_dict.update(\n                    {\n                        \"global_pred\": global_preds,\n                        \"global_label\": global_labels,\n                        \"kenya_pred\": local_preds,\n                        \"kenya_label\": local_labels,\n                    }\n                )\n            return output_dict\n        else:\n            preds = cast(torch.Tensor, self.classifier(x))\n\n            loss += self.global_loss_function(\n                input=preds.squeeze(-1), target=label,)\n\n            output_dict = {loss_label: loss}\n            if log_loss:\n                output_dict[\"log\"][loss_label] = loss\n            if add_preds:\n                output_dict.update({\"pred\": preds, \"label\": label})\n            return output_dict\n\n    def training_step(self, batch, batch_idx):\n        return self._split_preds_and_get_loss(\n            batch, add_preds=False, loss_label=\"loss\", log_loss=True, training=True\n        )\n\n    def validation_step(self, batch, batch_idx):\n        return self._split_preds_and_get_loss(\n            batch, add_preds=True, loss_label=\"val_loss\", log_loss=True, training=False\n        )\n\n    def test_step(self, batch, batch_idx):\n        return self._split_preds_and_get_loss(\n            batch, add_preds=True, loss_label=\"test_loss\", log_loss=True, training=False\n        )\n\n    @staticmethod\n    def _split_tensor(outputs, label) -> Tuple[np.ndarray, np.ndarray]:\n        encoded_all, unencoded_all = [], []\n        for x in outputs:\n            # the first half is unencoded, the second is encoded\n            total = x[label]\n            unencoded_all.append(total[: total.shape[0] // 2])\n            encoded_all.append(total[total.shape[0] // 2:])\n        return (\n            torch.cat(unencoded_all).detach().cpu().numpy(),\n            torch.cat(encoded_all).detach().cpu().numpy(),\n        )\n\n    def _interpretable_metrics(self, outputs, input_prefix: str, output_prefix: str) -> Dict:\n\n        output_dict = {}\n\n        if self.hparams.forecast:\n            u_labels, e_labels = self._split_tensor(\n                outputs, f\"{input_prefix}label\")\n\n            u_preds, e_preds = self._split_tensor(\n                outputs, f\"{input_prefix}pred\")\n        else:\n            u_preds = torch.cat([x[f\"{input_prefix}pred\"]\n                                for x in outputs]).detach().cpu().numpy()\n            u_labels = (\n                torch.cat([x[f\"{input_prefix}label\"]\n                          for x in outputs]).detach().cpu().numpy()\n            )\n\n        output_dict.update(\n            self._output_metrics(\n                u_preds, u_labels, f\"unencoded_{output_prefix}{input_prefix}\")\n        )\n\n        if self.hparams.forecast:\n            output_dict.update(\n                self._output_metrics(\n                    e_preds, e_labels, f\"encoded_{output_prefix}{input_prefix}\")\n            )\n\n        return output_dict\n\n    def validation_epoch_end(self, outputs):\n        avg_loss = torch.stack([x[\"val_loss\"] for x in outputs]).mean()\n        logs = {\"val_loss\": avg_loss}\n        if self.hparams.forecast:\n            encoder_pred = (\n                torch.cat(\n                    [torch.flatten(x[\"encoder_prediction\"], start_dim=1) for x in outputs], dim=0,\n                )\n                .detach()\n                .cpu()\n                .numpy()\n            )\n            encoder_target = (\n                torch.cat(\n                    [torch.flatten(x[\"encoder_target\"], start_dim=1) for x in outputs], dim=0,\n                )\n                .detach()\n                .cpu()\n                .numpy()\n            )\n\n            logs[\"val_encoder_mae\"] = mean_absolute_error(\n                encoder_target, encoder_pred)\n\n        if self.hparams.multi_headed:\n            logs.update(self._interpretable_metrics(\n                outputs, \"global_\", \"val_\"))\n            logs.update(self._interpretable_metrics(outputs, \"kenya_\", \"val_\"))\n        else:\n            logs.update(self._interpretable_metrics(outputs, \"\", \"val_\"))\n        return {\"val_loss\": avg_loss, \"log\": logs}\n\n    def test_epoch_end(self, outputs):\n\n        avg_loss = torch.stack([x[\"test_loss\"] for x in outputs]).mean().item()\n        output_dict = {\"val_loss\": avg_loss}\n\n        if self.hparams.forecast:\n            encoder_pred = (\n                torch.cat(\n                    [torch.flatten(x[\"encoder_prediction\"], start_dim=1) for x in outputs], dim=0,\n                )\n                .detach()\n                .cpu()\n                .numpy()\n            )\n            encoder_target = (\n                torch.cat(\n                    [torch.flatten(x[\"encoder_target\"], start_dim=1) for x in outputs], dim=0,\n                )\n                .detach()\n                .cpu()\n                .numpy()\n            )\n\n            output_dict[\"test_encoder_mae\"] = mean_absolute_error(\n                encoder_target, encoder_pred)\n\n        if self.hparams.multi_headed:\n            output_dict.update(self._interpretable_metrics(\n                outputs, \"global_\", \"test_\"))\n            output_dict.update(self._interpretable_metrics(\n                outputs, \"kenya_\", \"test_\"))\n        else:\n            output_dict.update(\n                self._interpretable_metrics(outputs, \"\", \"test_\"))\n\n        return {\"progress_bar\": output_dict}\n\n    @staticmethod\n    def add_model_specific_args(parent_parser: ArgumentParser) -> ArgumentParser:\n\n        parser = ArgumentParser(parents=[parent_parser], add_help=False)\n\n        parser_args: Dict[str, Tuple[Type, Any]] = {\n            # assumes this is being run from \"scripts\"\n            \"--data_folder\": (str, str(Path(\"../data\"))),\n            \"--learning_rate\": (float, 0.001),\n            \"--batch_size\": (int, 64),\n            \"--input_months\": (int, 5),\n            \"--alpha\": (float, 10),\n            \"--noise_factor\": (float, 0.1),\n        }\n\n        for key, val in parser_args.items():\n            parser.add_argument(key, type=val[0], default=val[1])\n\n        parser.add_argument(\"--remove_b1_b10\",\n                            dest=\"remove_b1_b10\", action=\"store_true\")\n        parser.add_argument(\n            \"--keep_b1_b10\", dest=\"remove_b1_b10\", action=\"store_false\")\n        parser.set_defaults(remove_b1_b10=True)\n\n        parser.add_argument(\"--forecast\", dest=\"forecast\", action=\"store_true\")\n        parser.add_argument(\"--do_not_forecast\",\n                            dest=\"forecast\", action=\"store_false\")\n        parser.set_defaults(forecast=True)\n\n        parser.add_argument(\"--cache\", dest=\"cache\", action=\"store_true\")\n        parser.add_argument(\"--do_not_cache\", dest=\"cache\",\n                            action=\"store_false\")\n        parser.set_defaults(cache=True)\n\n        parser.add_argument(\"--include_geowiki\",\n                            dest=\"include_geowiki\", action=\"store_true\")\n        parser.add_argument(\"--exclude_geowiki\",\n                            dest=\"include_geowiki\", action=\"store_false\")\n        parser.set_defaults(include_geowiki=True)\n\n        parser.add_argument(\"--upsample\", dest=\"upsample\", action=\"store_true\")\n        parser.add_argument(\"--do_not_upsample\",\n                            dest=\"upsample\", action=\"store_false\")\n        parser.set_defaults(upsample=True)\n\n        classifier_parser = Classifier.add_model_specific_args(parser)\n        return Forecaster.add_model_specific_args(classifier_parser)\n",
  "history_output" : "",
  "history_begin_time" : 1655908836652,
  "history_end_time" : 1655908836955,
  "history_notes" : null,
  "history_process" : "9ardvx",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "u64kevk6p7d",
  "history_input" : "from argparse import ArgumentParser, Namespace\nfrom pathlib import Path\nimport numpy as np\nimport xarray as xr\nfrom tqdm import tqdm\n\nimport torch\nfrom torch.nn import functional as F\nfrom torch.utils.data import DataLoader\n\nimport pytorch_lightning as pl\n\nfrom sklearn.metrics import (\n    roc_auc_score,\n    accuracy_score,\n    precision_score,\n    recall_score,\n    f1_score,\n    mean_absolute_error,\n)\n\nfrom src_models_data import CropDataset\nfrom src_models_utils import tif_to_np, preds_to_xr\nfrom src_utils import set_seed\nfrom src_models_forecaster import Forecaster\nfrom src_models_classifier import Classifier\nfrom src_config import PROBABILITY_THRESHOLD\n\nfrom typing import cast, Callable, Tuple, Dict, Any, Type, Optional, List, Union\n\n\nclass Model(pl.LightningModule):\n    r\"\"\"\n    An model for annual and in-season crop mapping. This model consists of a\n    forecaster.Forecaster and a classifier.Classifier - it will require the arguments\n    required by those models too.\n\n    hparams\n    --------\n    The default values for these parameters are set in add_model_specific_args\n\n    :param hparams.data_folder: The path to the data. Default (assumes the model\n        is being run from the scripts directory) = \"../data\"\n    :param hparams.learning_rate: The learning rate. Default = 0.001\n    :param hparams.batch_size: The batch size. Default = 64\n    :param hparams.input_months: The number of input months to pass to the model. If\n        hparams.forecast is True, the remaining months will be forecasted. Otherwise, only the\n        partial timeseries will be passed to the classifier. Default = 5\n    :param hparams.alpha: The weight to use when adding the global and local losses. This\n        parameter is only used if hparams.multi_headed is True. Default = 10\n    :param hparams.noise_factor: The standard deviation of the random noise to add to the\n        raw inputs to the classifier. Default = 0.1\n    :param hparams.remove_b1_b10: Whether or not to remove the B1 and B10 bands. Default = True\n    :param hparams.forecast: Whether or not to forecast the partial time series. Default = True\n    :param hparams.cache: Whether to load all the data into memory during training. Default = True\n    :param hparams.include_geowiki: Whether to include the global GeoWiki dataset during\n        training. Default = True\n    :param hparams.upsample: Whether to oversample the under-represented class so that each class\n        is equally represented in the training and validation dataset. Default = True\n    \"\"\"\n\n    def __init__(self, hparams: Namespace) -> None:\n        super().__init__()\n        set_seed()\n        self.hparams = hparams\n\n        self.data_folder = Path(hparams.data_folder)\n\n        dataset = self.get_dataset(subset=\"training\", cache=False)\n        self.num_outputs = dataset.num_output_classes\n        self.num_timesteps = dataset.num_timesteps\n        self.input_size = dataset.num_input_features\n\n        # we save the normalizing dict because we calculate weighted\n        # normalization values based on the datasets we combine.\n        # The number of instances per dataset (and therefore the weights) can\n        # vary between the train / test / val sets - this ensures the normalizing\n        # dict stays constant between them\n        self.normalizing_dict = dataset.normalizing_dict\n\n        if self.hparams.forecast:\n            num_output_timesteps = self.num_timesteps - self.hparams.input_months\n            print(\n                f\"Predicting {num_output_timesteps} timesteps in the forecaster\")\n            self.forecaster = Forecaster(\n                num_bands=self.input_size, output_timesteps=num_output_timesteps, hparams=hparams,\n            )\n\n            self.forecaster_loss = F.smooth_l1_loss\n\n        self.classifier = Classifier(\n            input_size=self.input_size, hparams=hparams)\n        self.global_loss_function: Callable = F.binary_cross_entropy\n        self.local_loss_function: Callable = F.binary_cross_entropy\n\n    def forward(self, x: torch.Tensor) -> Union[torch.Tensor, Tuple[torch.Tensor, torch.Tensor]]:\n        # To keep the ABC happy\n        return self.classifier(x)\n\n    def configure_optimizers(self):\n        return torch.optim.Adam(self.parameters(), lr=self.hparams.learning_rate)\n\n    def get_dataset(\n        self, subset: str, normalizing_dict: Optional[Dict] = None, cache: Optional[bool] = None,\n    ) -> CropDataset:\n        return CropDataset(\n            data_folder=self.data_folder,\n            subset=subset,\n            remove_b1_b10=self.hparams.remove_b1_b10,\n            normalizing_dict=normalizing_dict,\n            include_geowiki=self.hparams.include_geowiki if subset != \"testing\" else False,\n            cache=self.hparams.cache if cache is None else cache,\n            upsample=self.hparams.upsample if subset != \"testing\" else False,\n            noise_factor=self.hparams.noise_factor if subset != \"testing\" else 0,\n        )\n\n    def train_dataloader(self):\n        return DataLoader(\n            self.get_dataset(subset=\"training\"), shuffle=True, batch_size=self.hparams.batch_size,\n        )\n\n    def val_dataloader(self):\n        return DataLoader(\n            self.get_dataset(subset=\"validation\",\n                             normalizing_dict=self.normalizing_dict,),\n            batch_size=self.hparams.batch_size,\n        )\n\n    def test_dataloader(self):\n        return DataLoader(\n            self.get_dataset(subset=\"testing\",\n                             normalizing_dict=self.normalizing_dict,),\n            batch_size=self.hparams.batch_size,\n        )\n\n    def predict(\n        self,\n        path_to_file: Path,\n        with_forecaster: bool,\n        batch_size: int = 64,\n        add_ndvi: bool = True,\n        add_ndwi: bool = False,\n        nan_fill: float = 0,\n        days_per_timestep: int = 30,\n        local_head: bool = True,\n        use_gpu: bool = True,\n    ) -> xr.Dataset:\n\n        # check if a GPU is available, and if it is\n        # move the model onto the GPU\n        device: Optional[torch.device] = None\n        if use_gpu:\n            use_cuda = torch.cuda.is_available()\n            if not use_cuda:\n                print(\"No GPU - not using one\")\n            device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n            self.to(device)\n\n        self.eval()\n\n        input_data = tif_to_np(\n            path_to_file,\n            add_ndvi=add_ndvi,\n            add_ndwi=add_ndwi,\n            nan=nan_fill,\n            normalizing_dict=self.normalizing_dict,\n            days_per_timestep=days_per_timestep,\n        )\n\n        if with_forecaster:\n            input_data.x = input_data.x[:, : self.hparams.input_months, :]\n\n        predictions: List[np.ndarray] = []\n        cur_i = 0\n\n        pbar = tqdm(total=input_data.x.shape[0] - 1)\n        while cur_i < (input_data.x.shape[0] - 1):\n\n            batch_x_np = input_data.x[cur_i: cur_i + batch_size]\n            if self.hparams.remove_b1_b10:\n                batch_x_np = CropDataset._remove_bands(batch_x_np)\n            batch_x = torch.from_numpy(batch_x_np).float()\n\n            if use_gpu and (device is not None):\n                batch_x = batch_x.to(device)\n\n            with torch.no_grad():\n                if with_forecaster:\n                    batch_x_next = self.forecaster(batch_x)\n                    batch_x = torch.cat((batch_x, batch_x_next), dim=1)\n\n                batch_preds = self.classifier(batch_x)\n\n                if self.hparams.multi_headed:\n                    global_preds, local_preds = batch_preds\n\n                    if local_head:\n                        batch_preds = local_preds\n                    else:\n                        batch_preds = global_preds\n\n                # back to the CPU, if necessary\n                batch_preds = batch_preds.cpu()\n\n            predictions.append(cast(torch.Tensor, batch_preds).numpy())\n            cur_i += batch_size\n            pbar.update(batch_size)\n\n        all_preds = np.concatenate(predictions, axis=0)\n        if len(all_preds.shape) == 1:\n            all_preds = np.expand_dims(all_preds, axis=-1)\n\n        return preds_to_xr(all_preds, lats=input_data.lat, lons=input_data.lon,)\n\n    def _output_metrics(\n        self, preds: np.ndarray, labels: np.ndarray, prefix: str = \"\"\n    ) -> Dict[str, float]:\n\n        if len(preds) == 0:\n            # sometimes this happens in the warmup\n            return {}\n\n        output_dict: Dict[str, float] = {}\n        if not (labels == labels[0]).all():\n            # This can happen when lightning does its warm up on a subset of the\n            # validation data\n            output_dict[f\"{prefix}roc_auc_score\"] = roc_auc_score(\n                labels, preds)\n\n        preds = (preds > PROBABILITY_THRESHOLD).astype(int)\n\n        output_dict[f\"{prefix}precision_score\"] = precision_score(\n            labels, preds)\n        output_dict[f\"{prefix}recall_score\"] = recall_score(labels, preds)\n        output_dict[f\"{prefix}f1_score\"] = f1_score(labels, preds)\n        output_dict[f\"{prefix}accuracy\"] = accuracy_score(labels, preds)\n\n        return output_dict\n\n    def add_noise(self, x: torch.Tensor, training: bool) -> torch.Tensor:\n        if (self.hparams.noise_factor == 0) or (not training):\n            return x\n\n        # expect input to be of shape [timesteps, bands]\n        # and to be normalized with mean 0, std=1\n        # if its not, it means no norm_dict was passed, so lets\n        # just assume std=1\n        noise = torch.normal(0, 1, size=x.shape).float() * \\\n            self.hparams.noise_factor\n\n        # the added noise is the same per band, so that the temporal relationships\n        # are preserved\n        # noise_per_timesteps = noise.repeat(x.shape[0], 1)\n        return x + noise\n\n    def _split_preds_and_get_loss(\n        self, batch, add_preds: bool, loss_label: str, log_loss: bool, training: bool\n    ) -> Dict:\n\n        x, label, is_global = batch\n\n        input_to_encode = x[:, : self.hparams.input_months, :]\n\n        if self.hparams.forecast:\n            # we will predict every timestep except the first one\n            output_to_predict = x[:, 1:, :]\n            encoder_output = self.forecaster(input_to_encode)\n            encoder_loss = self.forecaster_loss(\n                encoder_output, output_to_predict)\n            loss: Union[float, torch.Tensor] = encoder_loss\n\n            final_encoded_input = torch.cat(\n                (\n                    (\n                        self.add_noise(input_to_encode, training),\n                        # -1 because the encoder output has no value for the 0th\n                        # timestep\n                        encoder_output[:, self.hparams.input_months - 1:, :],\n                    )\n                ),\n                dim=1,\n            )\n\n            output_dict = {}\n            if add_preds:\n                output_dict.update(\n                    {\"encoder_prediction\": encoder_output,\n                        \"encoder_target\": output_to_predict, }\n                )\n            if log_loss:\n                output_dict[\"log\"] = {}\n\n            # we now repeat label and is_global\n            x = torch.cat((self.add_noise(x, training),\n                          final_encoded_input), dim=0)\n            label = torch.cat((label, label), dim=0)\n            is_global = torch.cat((is_global, is_global), dim=0)\n        else:\n            loss = 0\n            output_dict = {}\n            if log_loss:\n                output_dict[\"log\"] = {}\n            x = self.add_noise(input_to_encode, training=training)\n\n        if self.hparams.multi_headed:\n            org_global_preds, local_preds = self.classifier(x)\n            global_preds = org_global_preds[is_global != 0]\n            global_labels = label[is_global != 0]\n\n            local_preds = local_preds[is_global == 0]\n            local_labels = label[is_global == 0]\n\n            if local_preds.shape[0] > 0:\n                local_loss = self.local_loss_function(\n                    local_preds.squeeze(-1), local_labels,)\n                loss += local_loss\n\n            if global_preds.shape[0] > 0:\n                global_loss = self.global_loss_function(\n                    global_preds.squeeze(-1), global_labels,)\n\n                num_local_labels = local_preds.shape[0]\n                if num_local_labels == 0:\n                    alpha = 1\n                else:\n                    ratio = global_preds.shape[0] / num_local_labels\n                    alpha = ratio / self.hparams.alpha\n                loss += alpha * global_loss\n\n            output_dict[loss_label] = loss\n            if log_loss:\n                output_dict[\"log\"][loss_label] = loss\n            if add_preds:\n                output_dict.update(\n                    {\n                        \"global_pred\": global_preds,\n                        \"global_label\": global_labels,\n                        \"kenya_pred\": local_preds,\n                        \"kenya_label\": local_labels,\n                    }\n                )\n            return output_dict\n        else:\n            preds = cast(torch.Tensor, self.classifier(x))\n\n            loss += self.global_loss_function(\n                input=preds.squeeze(-1), target=label,)\n\n            output_dict = {loss_label: loss}\n            if log_loss:\n                output_dict[\"log\"][loss_label] = loss\n            if add_preds:\n                output_dict.update({\"pred\": preds, \"label\": label})\n            return output_dict\n\n    def training_step(self, batch, batch_idx):\n        return self._split_preds_and_get_loss(\n            batch, add_preds=False, loss_label=\"loss\", log_loss=True, training=True\n        )\n\n    def validation_step(self, batch, batch_idx):\n        return self._split_preds_and_get_loss(\n            batch, add_preds=True, loss_label=\"val_loss\", log_loss=True, training=False\n        )\n\n    def test_step(self, batch, batch_idx):\n        return self._split_preds_and_get_loss(\n            batch, add_preds=True, loss_label=\"test_loss\", log_loss=True, training=False\n        )\n\n    @staticmethod\n    def _split_tensor(outputs, label) -> Tuple[np.ndarray, np.ndarray]:\n        encoded_all, unencoded_all = [], []\n        for x in outputs:\n            # the first half is unencoded, the second is encoded\n            total = x[label]\n            unencoded_all.append(total[: total.shape[0] // 2])\n            encoded_all.append(total[total.shape[0] // 2:])\n        return (\n            torch.cat(unencoded_all).detach().cpu().numpy(),\n            torch.cat(encoded_all).detach().cpu().numpy(),\n        )\n\n    def _interpretable_metrics(self, outputs, input_prefix: str, output_prefix: str) -> Dict:\n\n        output_dict = {}\n\n        if self.hparams.forecast:\n            u_labels, e_labels = self._split_tensor(\n                outputs, f\"{input_prefix}label\")\n\n            u_preds, e_preds = self._split_tensor(\n                outputs, f\"{input_prefix}pred\")\n        else:\n            u_preds = torch.cat([x[f\"{input_prefix}pred\"]\n                                for x in outputs]).detach().cpu().numpy()\n            u_labels = (\n                torch.cat([x[f\"{input_prefix}label\"]\n                          for x in outputs]).detach().cpu().numpy()\n            )\n\n        output_dict.update(\n            self._output_metrics(\n                u_preds, u_labels, f\"unencoded_{output_prefix}{input_prefix}\")\n        )\n\n        if self.hparams.forecast:\n            output_dict.update(\n                self._output_metrics(\n                    e_preds, e_labels, f\"encoded_{output_prefix}{input_prefix}\")\n            )\n\n        return output_dict\n\n    def validation_epoch_end(self, outputs):\n        avg_loss = torch.stack([x[\"val_loss\"] for x in outputs]).mean()\n        logs = {\"val_loss\": avg_loss}\n        if self.hparams.forecast:\n            encoder_pred = (\n                torch.cat(\n                    [torch.flatten(x[\"encoder_prediction\"], start_dim=1) for x in outputs], dim=0,\n                )\n                .detach()\n                .cpu()\n                .numpy()\n            )\n            encoder_target = (\n                torch.cat(\n                    [torch.flatten(x[\"encoder_target\"], start_dim=1) for x in outputs], dim=0,\n                )\n                .detach()\n                .cpu()\n                .numpy()\n            )\n\n            logs[\"val_encoder_mae\"] = mean_absolute_error(\n                encoder_target, encoder_pred)\n\n        if self.hparams.multi_headed:\n            logs.update(self._interpretable_metrics(\n                outputs, \"global_\", \"val_\"))\n            logs.update(self._interpretable_metrics(outputs, \"kenya_\", \"val_\"))\n        else:\n            logs.update(self._interpretable_metrics(outputs, \"\", \"val_\"))\n        return {\"val_loss\": avg_loss, \"log\": logs}\n\n    def test_epoch_end(self, outputs):\n\n        avg_loss = torch.stack([x[\"test_loss\"] for x in outputs]).mean().item()\n        output_dict = {\"val_loss\": avg_loss}\n\n        if self.hparams.forecast:\n            encoder_pred = (\n                torch.cat(\n                    [torch.flatten(x[\"encoder_prediction\"], start_dim=1) for x in outputs], dim=0,\n                )\n                .detach()\n                .cpu()\n                .numpy()\n            )\n            encoder_target = (\n                torch.cat(\n                    [torch.flatten(x[\"encoder_target\"], start_dim=1) for x in outputs], dim=0,\n                )\n                .detach()\n                .cpu()\n                .numpy()\n            )\n\n            output_dict[\"test_encoder_mae\"] = mean_absolute_error(\n                encoder_target, encoder_pred)\n\n        if self.hparams.multi_headed:\n            output_dict.update(self._interpretable_metrics(\n                outputs, \"global_\", \"test_\"))\n            output_dict.update(self._interpretable_metrics(\n                outputs, \"kenya_\", \"test_\"))\n        else:\n            output_dict.update(\n                self._interpretable_metrics(outputs, \"\", \"test_\"))\n\n        return {\"progress_bar\": output_dict}\n\n    @staticmethod\n    def add_model_specific_args(parent_parser: ArgumentParser) -> ArgumentParser:\n\n        parser = ArgumentParser(parents=[parent_parser], add_help=False)\n\n        parser_args: Dict[str, Tuple[Type, Any]] = {\n            # assumes this is being run from \"scripts\"\n            \"--data_folder\": (str, str(Path(\"../data\"))),\n            \"--learning_rate\": (float, 0.001),\n            \"--batch_size\": (int, 64),\n            \"--input_months\": (int, 5),\n            \"--alpha\": (float, 10),\n            \"--noise_factor\": (float, 0.1),\n        }\n\n        for key, val in parser_args.items():\n            parser.add_argument(key, type=val[0], default=val[1])\n\n        parser.add_argument(\"--remove_b1_b10\",\n                            dest=\"remove_b1_b10\", action=\"store_true\")\n        parser.add_argument(\n            \"--keep_b1_b10\", dest=\"remove_b1_b10\", action=\"store_false\")\n        parser.set_defaults(remove_b1_b10=True)\n\n        parser.add_argument(\"--forecast\", dest=\"forecast\", action=\"store_true\")\n        parser.add_argument(\"--do_not_forecast\",\n                            dest=\"forecast\", action=\"store_false\")\n        parser.set_defaults(forecast=True)\n\n        parser.add_argument(\"--cache\", dest=\"cache\", action=\"store_true\")\n        parser.add_argument(\"--do_not_cache\", dest=\"cache\",\n                            action=\"store_false\")\n        parser.set_defaults(cache=True)\n\n        parser.add_argument(\"--include_geowiki\",\n                            dest=\"include_geowiki\", action=\"store_true\")\n        parser.add_argument(\"--exclude_geowiki\",\n                            dest=\"include_geowiki\", action=\"store_false\")\n        parser.set_defaults(include_geowiki=True)\n\n        parser.add_argument(\"--upsample\", dest=\"upsample\", action=\"store_true\")\n        parser.add_argument(\"--do_not_upsample\",\n                            dest=\"upsample\", action=\"store_false\")\n        parser.set_defaults(upsample=True)\n\n        classifier_parser = Classifier.add_model_specific_args(parser)\n        return Forecaster.add_model_specific_args(classifier_parser)\n",
  "history_output" : "",
  "history_begin_time" : 1655907427310,
  "history_end_time" : 1655907428299,
  "history_notes" : null,
  "history_process" : "9ardvx",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "q08rl146af7",
  "history_input" : "from argparse import ArgumentParser, Namespace\nfrom pathlib import Path\nimport numpy as np\nimport xarray as xr\nfrom tqdm import tqdm\n\nimport torch\nfrom torch.nn import functional as F\nfrom torch.utils.data import DataLoader\n\nimport pytorch_lightning as pl\n\nfrom sklearn.metrics import (\n    roc_auc_score,\n    accuracy_score,\n    precision_score,\n    recall_score,\n    f1_score,\n    mean_absolute_error,\n)\n\nfrom src_models_data import CropDataset\nfrom src_models_utils import tif_to_np, preds_to_xr\nfrom src_utils import set_seed\nfrom src_models_forecaster import Forecaster\nfrom src_models_classifier import Classifier\nfrom src_config import PROBABILITY_THRESHOLD\n\nfrom typing import cast, Callable, Tuple, Dict, Any, Type, Optional, List, Union\n\n\nclass Model(pl.LightningModule):\n    r\"\"\"\n    An model for annual and in-season crop mapping. This model consists of a\n    forecaster.Forecaster and a classifier.Classifier - it will require the arguments\n    required by those models too.\n\n    hparams\n    --------\n    The default values for these parameters are set in add_model_specific_args\n\n    :param hparams.data_folder: The path to the data. Default (assumes the model\n        is being run from the scripts directory) = \"../data\"\n    :param hparams.learning_rate: The learning rate. Default = 0.001\n    :param hparams.batch_size: The batch size. Default = 64\n    :param hparams.input_months: The number of input months to pass to the model. If\n        hparams.forecast is True, the remaining months will be forecasted. Otherwise, only the\n        partial timeseries will be passed to the classifier. Default = 5\n    :param hparams.alpha: The weight to use when adding the global and local losses. This\n        parameter is only used if hparams.multi_headed is True. Default = 10\n    :param hparams.noise_factor: The standard deviation of the random noise to add to the\n        raw inputs to the classifier. Default = 0.1\n    :param hparams.remove_b1_b10: Whether or not to remove the B1 and B10 bands. Default = True\n    :param hparams.forecast: Whether or not to forecast the partial time series. Default = True\n    :param hparams.cache: Whether to load all the data into memory during training. Default = True\n    :param hparams.include_geowiki: Whether to include the global GeoWiki dataset during\n        training. Default = True\n    :param hparams.upsample: Whether to oversample the under-represented class so that each class\n        is equally represented in the training and validation dataset. Default = True\n    \"\"\"\n\n    def __init__(self, hparams: Namespace) -> None:\n        super().__init__()\n        set_seed()\n        self.hparams = hparams\n\n        self.data_folder = Path(hparams.data_folder)\n\n        dataset = self.get_dataset(subset=\"training\", cache=False)\n        self.num_outputs = dataset.num_output_classes\n        self.num_timesteps = dataset.num_timesteps\n        self.input_size = dataset.num_input_features\n\n        # we save the normalizing dict because we calculate weighted\n        # normalization values based on the datasets we combine.\n        # The number of instances per dataset (and therefore the weights) can\n        # vary between the train / test / val sets - this ensures the normalizing\n        # dict stays constant between them\n        self.normalizing_dict = dataset.normalizing_dict\n\n        if self.hparams.forecast:\n            num_output_timesteps = self.num_timesteps - self.hparams.input_months\n            print(\n                f\"Predicting {num_output_timesteps} timesteps in the forecaster\")\n            self.forecaster = Forecaster(\n                num_bands=self.input_size, output_timesteps=num_output_timesteps, hparams=hparams,\n            )\n\n            self.forecaster_loss = F.smooth_l1_loss\n\n        self.classifier = Classifier(\n            input_size=self.input_size, hparams=hparams)\n        self.global_loss_function: Callable = F.binary_cross_entropy\n        self.local_loss_function: Callable = F.binary_cross_entropy\n\n    def forward(self, x: torch.Tensor) -> Union[torch.Tensor, Tuple[torch.Tensor, torch.Tensor]]:\n        # To keep the ABC happy\n        return self.classifier(x)\n\n    def configure_optimizers(self):\n        return torch.optim.Adam(self.parameters(), lr=self.hparams.learning_rate)\n\n    def get_dataset(\n        self, subset: str, normalizing_dict: Optional[Dict] = None, cache: Optional[bool] = None,\n    ) -> CropDataset:\n        return CropDataset(\n            data_folder=self.data_folder,\n            subset=subset,\n            remove_b1_b10=self.hparams.remove_b1_b10,\n            normalizing_dict=normalizing_dict,\n            include_geowiki=self.hparams.include_geowiki if subset != \"testing\" else False,\n            cache=self.hparams.cache if cache is None else cache,\n            upsample=self.hparams.upsample if subset != \"testing\" else False,\n            noise_factor=self.hparams.noise_factor if subset != \"testing\" else 0,\n        )\n\n    def train_dataloader(self):\n        return DataLoader(\n            self.get_dataset(subset=\"training\"), shuffle=True, batch_size=self.hparams.batch_size,\n        )\n\n    def val_dataloader(self):\n        return DataLoader(\n            self.get_dataset(subset=\"validation\",\n                             normalizing_dict=self.normalizing_dict,),\n            batch_size=self.hparams.batch_size,\n        )\n\n    def test_dataloader(self):\n        return DataLoader(\n            self.get_dataset(subset=\"testing\",\n                             normalizing_dict=self.normalizing_dict,),\n            batch_size=self.hparams.batch_size,\n        )\n\n    def predict(\n        self,\n        path_to_file: Path,\n        with_forecaster: bool,\n        batch_size: int = 64,\n        add_ndvi: bool = True,\n        add_ndwi: bool = False,\n        nan_fill: float = 0,\n        days_per_timestep: int = 30,\n        local_head: bool = True,\n        use_gpu: bool = True,\n    ) -> xr.Dataset:\n\n        # check if a GPU is available, and if it is\n        # move the model onto the GPU\n        device: Optional[torch.device] = None\n        if use_gpu:\n            use_cuda = torch.cuda.is_available()\n            if not use_cuda:\n                print(\"No GPU - not using one\")\n            device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n            self.to(device)\n\n        self.eval()\n\n        input_data = tif_to_np(\n            path_to_file,\n            add_ndvi=add_ndvi,\n            add_ndwi=add_ndwi,\n            nan=nan_fill,\n            normalizing_dict=self.normalizing_dict,\n            days_per_timestep=days_per_timestep,\n        )\n\n        if with_forecaster:\n            input_data.x = input_data.x[:, : self.hparams.input_months, :]\n\n        predictions: List[np.ndarray] = []\n        cur_i = 0\n\n        pbar = tqdm(total=input_data.x.shape[0] - 1)\n        while cur_i < (input_data.x.shape[0] - 1):\n\n            batch_x_np = input_data.x[cur_i: cur_i + batch_size]\n            if self.hparams.remove_b1_b10:\n                batch_x_np = CropDataset._remove_bands(batch_x_np)\n            batch_x = torch.from_numpy(batch_x_np).float()\n\n            if use_gpu and (device is not None):\n                batch_x = batch_x.to(device)\n\n            with torch.no_grad():\n                if with_forecaster:\n                    batch_x_next = self.forecaster(batch_x)\n                    batch_x = torch.cat((batch_x, batch_x_next), dim=1)\n\n                batch_preds = self.classifier(batch_x)\n\n                if self.hparams.multi_headed:\n                    global_preds, local_preds = batch_preds\n\n                    if local_head:\n                        batch_preds = local_preds\n                    else:\n                        batch_preds = global_preds\n\n                # back to the CPU, if necessary\n                batch_preds = batch_preds.cpu()\n\n            predictions.append(cast(torch.Tensor, batch_preds).numpy())\n            cur_i += batch_size\n            pbar.update(batch_size)\n\n        all_preds = np.concatenate(predictions, axis=0)\n        if len(all_preds.shape) == 1:\n            all_preds = np.expand_dims(all_preds, axis=-1)\n\n        return preds_to_xr(all_preds, lats=input_data.lat, lons=input_data.lon,)\n\n    def _output_metrics(\n        self, preds: np.ndarray, labels: np.ndarray, prefix: str = \"\"\n    ) -> Dict[str, float]:\n\n        if len(preds) == 0:\n            # sometimes this happens in the warmup\n            return {}\n\n        output_dict: Dict[str, float] = {}\n        if not (labels == labels[0]).all():\n            # This can happen when lightning does its warm up on a subset of the\n            # validation data\n            output_dict[f\"{prefix}roc_auc_score\"] = roc_auc_score(\n                labels, preds)\n\n        preds = (preds > PROBABILITY_THRESHOLD).astype(int)\n\n        output_dict[f\"{prefix}precision_score\"] = precision_score(\n            labels, preds)\n        output_dict[f\"{prefix}recall_score\"] = recall_score(labels, preds)\n        output_dict[f\"{prefix}f1_score\"] = f1_score(labels, preds)\n        output_dict[f\"{prefix}accuracy\"] = accuracy_score(labels, preds)\n\n        return output_dict\n\n    def add_noise(self, x: torch.Tensor, training: bool) -> torch.Tensor:\n        if (self.hparams.noise_factor == 0) or (not training):\n            return x\n\n        # expect input to be of shape [timesteps, bands]\n        # and to be normalized with mean 0, std=1\n        # if its not, it means no norm_dict was passed, so lets\n        # just assume std=1\n        noise = torch.normal(0, 1, size=x.shape).float() * \\\n            self.hparams.noise_factor\n\n        # the added noise is the same per band, so that the temporal relationships\n        # are preserved\n        # noise_per_timesteps = noise.repeat(x.shape[0], 1)\n        return x + noise\n\n    def _split_preds_and_get_loss(\n        self, batch, add_preds: bool, loss_label: str, log_loss: bool, training: bool\n    ) -> Dict:\n\n        x, label, is_global = batch\n\n        input_to_encode = x[:, : self.hparams.input_months, :]\n\n        if self.hparams.forecast:\n            # we will predict every timestep except the first one\n            output_to_predict = x[:, 1:, :]\n            encoder_output = self.forecaster(input_to_encode)\n            encoder_loss = self.forecaster_loss(\n                encoder_output, output_to_predict)\n            loss: Union[float, torch.Tensor] = encoder_loss\n\n            final_encoded_input = torch.cat(\n                (\n                    (\n                        self.add_noise(input_to_encode, training),\n                        # -1 because the encoder output has no value for the 0th\n                        # timestep\n                        encoder_output[:, self.hparams.input_months - 1:, :],\n                    )\n                ),\n                dim=1,\n            )\n\n            output_dict = {}\n            if add_preds:\n                output_dict.update(\n                    {\"encoder_prediction\": encoder_output,\n                        \"encoder_target\": output_to_predict, }\n                )\n            if log_loss:\n                output_dict[\"log\"] = {}\n\n            # we now repeat label and is_global\n            x = torch.cat((self.add_noise(x, training),\n                          final_encoded_input), dim=0)\n            label = torch.cat((label, label), dim=0)\n            is_global = torch.cat((is_global, is_global), dim=0)\n        else:\n            loss = 0\n            output_dict = {}\n            if log_loss:\n                output_dict[\"log\"] = {}\n            x = self.add_noise(input_to_encode, training=training)\n\n        if self.hparams.multi_headed:\n            org_global_preds, local_preds = self.classifier(x)\n            global_preds = org_global_preds[is_global != 0]\n            global_labels = label[is_global != 0]\n\n            local_preds = local_preds[is_global == 0]\n            local_labels = label[is_global == 0]\n\n            if local_preds.shape[0] > 0:\n                local_loss = self.local_loss_function(\n                    local_preds.squeeze(-1), local_labels,)\n                loss += local_loss\n\n            if global_preds.shape[0] > 0:\n                global_loss = self.global_loss_function(\n                    global_preds.squeeze(-1), global_labels,)\n\n                num_local_labels = local_preds.shape[0]\n                if num_local_labels == 0:\n                    alpha = 1\n                else:\n                    ratio = global_preds.shape[0] / num_local_labels\n                    alpha = ratio / self.hparams.alpha\n                loss += alpha * global_loss\n\n            output_dict[loss_label] = loss\n            if log_loss:\n                output_dict[\"log\"][loss_label] = loss\n            if add_preds:\n                output_dict.update(\n                    {\n                        \"global_pred\": global_preds,\n                        \"global_label\": global_labels,\n                        \"kenya_pred\": local_preds,\n                        \"kenya_label\": local_labels,\n                    }\n                )\n            return output_dict\n        else:\n            preds = cast(torch.Tensor, self.classifier(x))\n\n            loss += self.global_loss_function(\n                input=preds.squeeze(-1), target=label,)\n\n            output_dict = {loss_label: loss}\n            if log_loss:\n                output_dict[\"log\"][loss_label] = loss\n            if add_preds:\n                output_dict.update({\"pred\": preds, \"label\": label})\n            return output_dict\n\n    def training_step(self, batch, batch_idx):\n        return self._split_preds_and_get_loss(\n            batch, add_preds=False, loss_label=\"loss\", log_loss=True, training=True\n        )\n\n    def validation_step(self, batch, batch_idx):\n        return self._split_preds_and_get_loss(\n            batch, add_preds=True, loss_label=\"val_loss\", log_loss=True, training=False\n        )\n\n    def test_step(self, batch, batch_idx):\n        return self._split_preds_and_get_loss(\n            batch, add_preds=True, loss_label=\"test_loss\", log_loss=True, training=False\n        )\n\n    @staticmethod\n    def _split_tensor(outputs, label) -> Tuple[np.ndarray, np.ndarray]:\n        encoded_all, unencoded_all = [], []\n        for x in outputs:\n            # the first half is unencoded, the second is encoded\n            total = x[label]\n            unencoded_all.append(total[: total.shape[0] // 2])\n            encoded_all.append(total[total.shape[0] // 2:])\n        return (\n            torch.cat(unencoded_all).detach().cpu().numpy(),\n            torch.cat(encoded_all).detach().cpu().numpy(),\n        )\n\n    def _interpretable_metrics(self, outputs, input_prefix: str, output_prefix: str) -> Dict:\n\n        output_dict = {}\n\n        if self.hparams.forecast:\n            u_labels, e_labels = self._split_tensor(\n                outputs, f\"{input_prefix}label\")\n\n            u_preds, e_preds = self._split_tensor(\n                outputs, f\"{input_prefix}pred\")\n        else:\n            u_preds = torch.cat([x[f\"{input_prefix}pred\"]\n                                for x in outputs]).detach().cpu().numpy()\n            u_labels = (\n                torch.cat([x[f\"{input_prefix}label\"]\n                          for x in outputs]).detach().cpu().numpy()\n            )\n\n        output_dict.update(\n            self._output_metrics(\n                u_preds, u_labels, f\"unencoded_{output_prefix}{input_prefix}\")\n        )\n\n        if self.hparams.forecast:\n            output_dict.update(\n                self._output_metrics(\n                    e_preds, e_labels, f\"encoded_{output_prefix}{input_prefix}\")\n            )\n\n        return output_dict\n\n    def validation_epoch_end(self, outputs):\n        avg_loss = torch.stack([x[\"val_loss\"] for x in outputs]).mean()\n        logs = {\"val_loss\": avg_loss}\n        if self.hparams.forecast:\n            encoder_pred = (\n                torch.cat(\n                    [torch.flatten(x[\"encoder_prediction\"], start_dim=1) for x in outputs], dim=0,\n                )\n                .detach()\n                .cpu()\n                .numpy()\n            )\n            encoder_target = (\n                torch.cat(\n                    [torch.flatten(x[\"encoder_target\"], start_dim=1) for x in outputs], dim=0,\n                )\n                .detach()\n                .cpu()\n                .numpy()\n            )\n\n            logs[\"val_encoder_mae\"] = mean_absolute_error(\n                encoder_target, encoder_pred)\n\n        if self.hparams.multi_headed:\n            logs.update(self._interpretable_metrics(\n                outputs, \"global_\", \"val_\"))\n            logs.update(self._interpretable_metrics(outputs, \"kenya_\", \"val_\"))\n        else:\n            logs.update(self._interpretable_metrics(outputs, \"\", \"val_\"))\n        return {\"val_loss\": avg_loss, \"log\": logs}\n\n    def test_epoch_end(self, outputs):\n\n        avg_loss = torch.stack([x[\"test_loss\"] for x in outputs]).mean().item()\n        output_dict = {\"val_loss\": avg_loss}\n\n        if self.hparams.forecast:\n            encoder_pred = (\n                torch.cat(\n                    [torch.flatten(x[\"encoder_prediction\"], start_dim=1) for x in outputs], dim=0,\n                )\n                .detach()\n                .cpu()\n                .numpy()\n            )\n            encoder_target = (\n                torch.cat(\n                    [torch.flatten(x[\"encoder_target\"], start_dim=1) for x in outputs], dim=0,\n                )\n                .detach()\n                .cpu()\n                .numpy()\n            )\n\n            output_dict[\"test_encoder_mae\"] = mean_absolute_error(\n                encoder_target, encoder_pred)\n\n        if self.hparams.multi_headed:\n            output_dict.update(self._interpretable_metrics(\n                outputs, \"global_\", \"test_\"))\n            output_dict.update(self._interpretable_metrics(\n                outputs, \"kenya_\", \"test_\"))\n        else:\n            output_dict.update(\n                self._interpretable_metrics(outputs, \"\", \"test_\"))\n\n        return {\"progress_bar\": output_dict}\n\n    @staticmethod\n    def add_model_specific_args(parent_parser: ArgumentParser) -> ArgumentParser:\n\n        parser = ArgumentParser(parents=[parent_parser], add_help=False)\n\n        parser_args: Dict[str, Tuple[Type, Any]] = {\n            # assumes this is being run from \"scripts\"\n            \"--data_folder\": (str, str(Path(\"../data\"))),\n            \"--learning_rate\": (float, 0.001),\n            \"--batch_size\": (int, 64),\n            \"--input_months\": (int, 5),\n            \"--alpha\": (float, 10),\n            \"--noise_factor\": (float, 0.1),\n        }\n\n        for key, val in parser_args.items():\n            parser.add_argument(key, type=val[0], default=val[1])\n\n        parser.add_argument(\"--remove_b1_b10\",\n                            dest=\"remove_b1_b10\", action=\"store_true\")\n        parser.add_argument(\n            \"--keep_b1_b10\", dest=\"remove_b1_b10\", action=\"store_false\")\n        parser.set_defaults(remove_b1_b10=True)\n\n        parser.add_argument(\"--forecast\", dest=\"forecast\", action=\"store_true\")\n        parser.add_argument(\"--do_not_forecast\",\n                            dest=\"forecast\", action=\"store_false\")\n        parser.set_defaults(forecast=True)\n\n        parser.add_argument(\"--cache\", dest=\"cache\", action=\"store_true\")\n        parser.add_argument(\"--do_not_cache\", dest=\"cache\",\n                            action=\"store_false\")\n        parser.set_defaults(cache=True)\n\n        parser.add_argument(\"--include_geowiki\",\n                            dest=\"include_geowiki\", action=\"store_true\")\n        parser.add_argument(\"--exclude_geowiki\",\n                            dest=\"include_geowiki\", action=\"store_false\")\n        parser.set_defaults(include_geowiki=True)\n\n        parser.add_argument(\"--upsample\", dest=\"upsample\", action=\"store_true\")\n        parser.add_argument(\"--do_not_upsample\",\n                            dest=\"upsample\", action=\"store_false\")\n        parser.set_defaults(upsample=True)\n\n        classifier_parser = Classifier.add_model_specific_args(parser)\n        return Forecaster.add_model_specific_args(classifier_parser)\n",
  "history_output" : "Traceback (most recent call last):\n  File \"src_models_model.py\", line 3, in <module>\n    import numpy as np\nModuleNotFoundError: No module named 'numpy'\n",
  "history_begin_time" : 1655907395297,
  "history_end_time" : 1655907403268,
  "history_notes" : null,
  "history_process" : "9ardvx",
  "host_id" : "100001",
  "indicator" : "Stopped"
},{
  "history_id" : "2le4pu2z3f0",
  "history_input" : "from argparse import ArgumentParser, Namespace\nfrom pathlib import Path\nimport numpy as np\nimport xarray as xr\nfrom tqdm import tqdm\n\nimport torch\nfrom torch.nn import functional as F\nfrom torch.utils.data import DataLoader\n\nimport pytorch_lightning as pl\n\nfrom sklearn.metrics import (\n    roc_auc_score,\n    accuracy_score,\n    precision_score,\n    recall_score,\n    f1_score,\n    mean_absolute_error,\n)\n\nfrom src_models_data import CropDataset\nfrom src_models_utils import tif_to_np, preds_to_xr\nfrom src_utils import set_seed\nfrom src_models_forecaster import Forecaster\nfrom src_models_classifier import Classifier\nfrom src_config import PROBABILITY_THRESHOLD\n\nfrom typing import cast, Callable, Tuple, Dict, Any, Type, Optional, List, Union\n\n\nclass Model(pl.LightningModule):\n    r\"\"\"\n    An model for annual and in-season crop mapping. This model consists of a\n    forecaster.Forecaster and a classifier.Classifier - it will require the arguments\n    required by those models too.\n\n    hparams\n    --------\n    The default values for these parameters are set in add_model_specific_args\n\n    :param hparams.data_folder: The path to the data. Default (assumes the model\n        is being run from the scripts directory) = \"../data\"\n    :param hparams.learning_rate: The learning rate. Default = 0.001\n    :param hparams.batch_size: The batch size. Default = 64\n    :param hparams.input_months: The number of input months to pass to the model. If\n        hparams.forecast is True, the remaining months will be forecasted. Otherwise, only the\n        partial timeseries will be passed to the classifier. Default = 5\n    :param hparams.alpha: The weight to use when adding the global and local losses. This\n        parameter is only used if hparams.multi_headed is True. Default = 10\n    :param hparams.noise_factor: The standard deviation of the random noise to add to the\n        raw inputs to the classifier. Default = 0.1\n    :param hparams.remove_b1_b10: Whether or not to remove the B1 and B10 bands. Default = True\n    :param hparams.forecast: Whether or not to forecast the partial time series. Default = True\n    :param hparams.cache: Whether to load all the data into memory during training. Default = True\n    :param hparams.include_geowiki: Whether to include the global GeoWiki dataset during\n        training. Default = True\n    :param hparams.upsample: Whether to oversample the under-represented class so that each class\n        is equally represented in the training and validation dataset. Default = True\n    \"\"\"\n\n    def __init__(self, hparams: Namespace) -> None:\n        super().__init__()\n        set_seed()\n        self.hparams = hparams\n\n        self.data_folder = Path(hparams.data_folder)\n\n        dataset = self.get_dataset(subset=\"training\", cache=False)\n        self.num_outputs = dataset.num_output_classes\n        self.num_timesteps = dataset.num_timesteps\n        self.input_size = dataset.num_input_features\n\n        # we save the normalizing dict because we calculate weighted\n        # normalization values based on the datasets we combine.\n        # The number of instances per dataset (and therefore the weights) can\n        # vary between the train / test / val sets - this ensures the normalizing\n        # dict stays constant between them\n        self.normalizing_dict = dataset.normalizing_dict\n\n        if self.hparams.forecast:\n            num_output_timesteps = self.num_timesteps - self.hparams.input_months\n            print(\n                f\"Predicting {num_output_timesteps} timesteps in the forecaster\")\n            self.forecaster = Forecaster(\n                num_bands=self.input_size, output_timesteps=num_output_timesteps, hparams=hparams,\n            )\n\n            self.forecaster_loss = F.smooth_l1_loss\n\n        self.classifier = Classifier(\n            input_size=self.input_size, hparams=hparams)\n        self.global_loss_function: Callable = F.binary_cross_entropy\n        self.local_loss_function: Callable = F.binary_cross_entropy\n\n    def forward(self, x: torch.Tensor) -> Union[torch.Tensor, Tuple[torch.Tensor, torch.Tensor]]:\n        # To keep the ABC happy\n        return self.classifier(x)\n\n    def configure_optimizers(self):\n        return torch.optim.Adam(self.parameters(), lr=self.hparams.learning_rate)\n\n    def get_dataset(\n        self, subset: str, normalizing_dict: Optional[Dict] = None, cache: Optional[bool] = None,\n    ) -> CropDataset:\n        return CropDataset(\n            data_folder=self.data_folder,\n            subset=subset,\n            remove_b1_b10=self.hparams.remove_b1_b10,\n            normalizing_dict=normalizing_dict,\n            include_geowiki=self.hparams.include_geowiki if subset != \"testing\" else False,\n            cache=self.hparams.cache if cache is None else cache,\n            upsample=self.hparams.upsample if subset != \"testing\" else False,\n            noise_factor=self.hparams.noise_factor if subset != \"testing\" else 0,\n        )\n\n    def train_dataloader(self):\n        return DataLoader(\n            self.get_dataset(subset=\"training\"), shuffle=True, batch_size=self.hparams.batch_size,\n        )\n\n    def val_dataloader(self):\n        return DataLoader(\n            self.get_dataset(subset=\"validation\",\n                             normalizing_dict=self.normalizing_dict,),\n            batch_size=self.hparams.batch_size,\n        )\n\n    def test_dataloader(self):\n        return DataLoader(\n            self.get_dataset(subset=\"testing\",\n                             normalizing_dict=self.normalizing_dict,),\n            batch_size=self.hparams.batch_size,\n        )\n\n    def predict(\n        self,\n        path_to_file: Path,\n        with_forecaster: bool,\n        batch_size: int = 64,\n        add_ndvi: bool = True,\n        add_ndwi: bool = False,\n        nan_fill: float = 0,\n        days_per_timestep: int = 30,\n        local_head: bool = True,\n        use_gpu: bool = True,\n    ) -> xr.Dataset:\n\n        # check if a GPU is available, and if it is\n        # move the model onto the GPU\n        device: Optional[torch.device] = None\n        if use_gpu:\n            use_cuda = torch.cuda.is_available()\n            if not use_cuda:\n                print(\"No GPU - not using one\")\n            device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n            self.to(device)\n\n        self.eval()\n\n        input_data = tif_to_np(\n            path_to_file,\n            add_ndvi=add_ndvi,\n            add_ndwi=add_ndwi,\n            nan=nan_fill,\n            normalizing_dict=self.normalizing_dict,\n            days_per_timestep=days_per_timestep,\n        )\n\n        if with_forecaster:\n            input_data.x = input_data.x[:, : self.hparams.input_months, :]\n\n        predictions: List[np.ndarray] = []\n        cur_i = 0\n\n        pbar = tqdm(total=input_data.x.shape[0] - 1)\n        while cur_i < (input_data.x.shape[0] - 1):\n\n            batch_x_np = input_data.x[cur_i: cur_i + batch_size]\n            if self.hparams.remove_b1_b10:\n                batch_x_np = CropDataset._remove_bands(batch_x_np)\n            batch_x = torch.from_numpy(batch_x_np).float()\n\n            if use_gpu and (device is not None):\n                batch_x = batch_x.to(device)\n\n            with torch.no_grad():\n                if with_forecaster:\n                    batch_x_next = self.forecaster(batch_x)\n                    batch_x = torch.cat((batch_x, batch_x_next), dim=1)\n\n                batch_preds = self.classifier(batch_x)\n\n                if self.hparams.multi_headed:\n                    global_preds, local_preds = batch_preds\n\n                    if local_head:\n                        batch_preds = local_preds\n                    else:\n                        batch_preds = global_preds\n\n                # back to the CPU, if necessary\n                batch_preds = batch_preds.cpu()\n\n            predictions.append(cast(torch.Tensor, batch_preds).numpy())\n            cur_i += batch_size\n            pbar.update(batch_size)\n\n        all_preds = np.concatenate(predictions, axis=0)\n        if len(all_preds.shape) == 1:\n            all_preds = np.expand_dims(all_preds, axis=-1)\n\n        return preds_to_xr(all_preds, lats=input_data.lat, lons=input_data.lon,)\n\n    def _output_metrics(\n        self, preds: np.ndarray, labels: np.ndarray, prefix: str = \"\"\n    ) -> Dict[str, float]:\n\n        if len(preds) == 0:\n            # sometimes this happens in the warmup\n            return {}\n\n        output_dict: Dict[str, float] = {}\n        if not (labels == labels[0]).all():\n            # This can happen when lightning does its warm up on a subset of the\n            # validation data\n            output_dict[f\"{prefix}roc_auc_score\"] = roc_auc_score(\n                labels, preds)\n\n        preds = (preds > PROBABILITY_THRESHOLD).astype(int)\n\n        output_dict[f\"{prefix}precision_score\"] = precision_score(\n            labels, preds)\n        output_dict[f\"{prefix}recall_score\"] = recall_score(labels, preds)\n        output_dict[f\"{prefix}f1_score\"] = f1_score(labels, preds)\n        output_dict[f\"{prefix}accuracy\"] = accuracy_score(labels, preds)\n\n        return output_dict\n\n    def add_noise(self, x: torch.Tensor, training: bool) -> torch.Tensor:\n        if (self.hparams.noise_factor == 0) or (not training):\n            return x\n\n        # expect input to be of shape [timesteps, bands]\n        # and to be normalized with mean 0, std=1\n        # if its not, it means no norm_dict was passed, so lets\n        # just assume std=1\n        noise = torch.normal(0, 1, size=x.shape).float() * \\\n            self.hparams.noise_factor\n\n        # the added noise is the same per band, so that the temporal relationships\n        # are preserved\n        # noise_per_timesteps = noise.repeat(x.shape[0], 1)\n        return x + noise\n\n    def _split_preds_and_get_loss(\n        self, batch, add_preds: bool, loss_label: str, log_loss: bool, training: bool\n    ) -> Dict:\n\n        x, label, is_global = batch\n\n        input_to_encode = x[:, : self.hparams.input_months, :]\n\n        if self.hparams.forecast:\n            # we will predict every timestep except the first one\n            output_to_predict = x[:, 1:, :]\n            encoder_output = self.forecaster(input_to_encode)\n            encoder_loss = self.forecaster_loss(\n                encoder_output, output_to_predict)\n            loss: Union[float, torch.Tensor] = encoder_loss\n\n            final_encoded_input = torch.cat(\n                (\n                    (\n                        self.add_noise(input_to_encode, training),\n                        # -1 because the encoder output has no value for the 0th\n                        # timestep\n                        encoder_output[:, self.hparams.input_months - 1:, :],\n                    )\n                ),\n                dim=1,\n            )\n\n            output_dict = {}\n            if add_preds:\n                output_dict.update(\n                    {\"encoder_prediction\": encoder_output,\n                        \"encoder_target\": output_to_predict, }\n                )\n            if log_loss:\n                output_dict[\"log\"] = {}\n\n            # we now repeat label and is_global\n            x = torch.cat((self.add_noise(x, training),\n                          final_encoded_input), dim=0)\n            label = torch.cat((label, label), dim=0)\n            is_global = torch.cat((is_global, is_global), dim=0)\n        else:\n            loss = 0\n            output_dict = {}\n            if log_loss:\n                output_dict[\"log\"] = {}\n            x = self.add_noise(input_to_encode, training=training)\n\n        if self.hparams.multi_headed:\n            org_global_preds, local_preds = self.classifier(x)\n            global_preds = org_global_preds[is_global != 0]\n            global_labels = label[is_global != 0]\n\n            local_preds = local_preds[is_global == 0]\n            local_labels = label[is_global == 0]\n\n            if local_preds.shape[0] > 0:\n                local_loss = self.local_loss_function(\n                    local_preds.squeeze(-1), local_labels,)\n                loss += local_loss\n\n            if global_preds.shape[0] > 0:\n                global_loss = self.global_loss_function(\n                    global_preds.squeeze(-1), global_labels,)\n\n                num_local_labels = local_preds.shape[0]\n                if num_local_labels == 0:\n                    alpha = 1\n                else:\n                    ratio = global_preds.shape[0] / num_local_labels\n                    alpha = ratio / self.hparams.alpha\n                loss += alpha * global_loss\n\n            output_dict[loss_label] = loss\n            if log_loss:\n                output_dict[\"log\"][loss_label] = loss\n            if add_preds:\n                output_dict.update(\n                    {\n                        \"global_pred\": global_preds,\n                        \"global_label\": global_labels,\n                        \"kenya_pred\": local_preds,\n                        \"kenya_label\": local_labels,\n                    }\n                )\n            return output_dict\n        else:\n            preds = cast(torch.Tensor, self.classifier(x))\n\n            loss += self.global_loss_function(\n                input=preds.squeeze(-1), target=label,)\n\n            output_dict = {loss_label: loss}\n            if log_loss:\n                output_dict[\"log\"][loss_label] = loss\n            if add_preds:\n                output_dict.update({\"pred\": preds, \"label\": label})\n            return output_dict\n\n    def training_step(self, batch, batch_idx):\n        return self._split_preds_and_get_loss(\n            batch, add_preds=False, loss_label=\"loss\", log_loss=True, training=True\n        )\n\n    def validation_step(self, batch, batch_idx):\n        return self._split_preds_and_get_loss(\n            batch, add_preds=True, loss_label=\"val_loss\", log_loss=True, training=False\n        )\n\n    def test_step(self, batch, batch_idx):\n        return self._split_preds_and_get_loss(\n            batch, add_preds=True, loss_label=\"test_loss\", log_loss=True, training=False\n        )\n\n    @staticmethod\n    def _split_tensor(outputs, label) -> Tuple[np.ndarray, np.ndarray]:\n        encoded_all, unencoded_all = [], []\n        for x in outputs:\n            # the first half is unencoded, the second is encoded\n            total = x[label]\n            unencoded_all.append(total[: total.shape[0] // 2])\n            encoded_all.append(total[total.shape[0] // 2:])\n        return (\n            torch.cat(unencoded_all).detach().cpu().numpy(),\n            torch.cat(encoded_all).detach().cpu().numpy(),\n        )\n\n    def _interpretable_metrics(self, outputs, input_prefix: str, output_prefix: str) -> Dict:\n\n        output_dict = {}\n\n        if self.hparams.forecast:\n            u_labels, e_labels = self._split_tensor(\n                outputs, f\"{input_prefix}label\")\n\n            u_preds, e_preds = self._split_tensor(\n                outputs, f\"{input_prefix}pred\")\n        else:\n            u_preds = torch.cat([x[f\"{input_prefix}pred\"]\n                                for x in outputs]).detach().cpu().numpy()\n            u_labels = (\n                torch.cat([x[f\"{input_prefix}label\"]\n                          for x in outputs]).detach().cpu().numpy()\n            )\n\n        output_dict.update(\n            self._output_metrics(\n                u_preds, u_labels, f\"unencoded_{output_prefix}{input_prefix}\")\n        )\n\n        if self.hparams.forecast:\n            output_dict.update(\n                self._output_metrics(\n                    e_preds, e_labels, f\"encoded_{output_prefix}{input_prefix}\")\n            )\n\n        return output_dict\n\n    def validation_epoch_end(self, outputs):\n        avg_loss = torch.stack([x[\"val_loss\"] for x in outputs]).mean()\n        logs = {\"val_loss\": avg_loss}\n        if self.hparams.forecast:\n            encoder_pred = (\n                torch.cat(\n                    [torch.flatten(x[\"encoder_prediction\"], start_dim=1) for x in outputs], dim=0,\n                )\n                .detach()\n                .cpu()\n                .numpy()\n            )\n            encoder_target = (\n                torch.cat(\n                    [torch.flatten(x[\"encoder_target\"], start_dim=1) for x in outputs], dim=0,\n                )\n                .detach()\n                .cpu()\n                .numpy()\n            )\n\n            logs[\"val_encoder_mae\"] = mean_absolute_error(\n                encoder_target, encoder_pred)\n\n        if self.hparams.multi_headed:\n            logs.update(self._interpretable_metrics(\n                outputs, \"global_\", \"val_\"))\n            logs.update(self._interpretable_metrics(outputs, \"kenya_\", \"val_\"))\n        else:\n            logs.update(self._interpretable_metrics(outputs, \"\", \"val_\"))\n        return {\"val_loss\": avg_loss, \"log\": logs}\n\n    def test_epoch_end(self, outputs):\n\n        avg_loss = torch.stack([x[\"test_loss\"] for x in outputs]).mean().item()\n        output_dict = {\"val_loss\": avg_loss}\n\n        if self.hparams.forecast:\n            encoder_pred = (\n                torch.cat(\n                    [torch.flatten(x[\"encoder_prediction\"], start_dim=1) for x in outputs], dim=0,\n                )\n                .detach()\n                .cpu()\n                .numpy()\n            )\n            encoder_target = (\n                torch.cat(\n                    [torch.flatten(x[\"encoder_target\"], start_dim=1) for x in outputs], dim=0,\n                )\n                .detach()\n                .cpu()\n                .numpy()\n            )\n\n            output_dict[\"test_encoder_mae\"] = mean_absolute_error(\n                encoder_target, encoder_pred)\n\n        if self.hparams.multi_headed:\n            output_dict.update(self._interpretable_metrics(\n                outputs, \"global_\", \"test_\"))\n            output_dict.update(self._interpretable_metrics(\n                outputs, \"kenya_\", \"test_\"))\n        else:\n            output_dict.update(\n                self._interpretable_metrics(outputs, \"\", \"test_\"))\n\n        return {\"progress_bar\": output_dict}\n\n    @staticmethod\n    def add_model_specific_args(parent_parser: ArgumentParser) -> ArgumentParser:\n\n        parser = ArgumentParser(parents=[parent_parser], add_help=False)\n\n        parser_args: Dict[str, Tuple[Type, Any]] = {\n            # assumes this is being run from \"scripts\"\n            \"--data_folder\": (str, str(Path(\"../data\"))),\n            \"--learning_rate\": (float, 0.001),\n            \"--batch_size\": (int, 64),\n            \"--input_months\": (int, 5),\n            \"--alpha\": (float, 10),\n            \"--noise_factor\": (float, 0.1),\n        }\n\n        for key, val in parser_args.items():\n            parser.add_argument(key, type=val[0], default=val[1])\n\n        parser.add_argument(\"--remove_b1_b10\",\n                            dest=\"remove_b1_b10\", action=\"store_true\")\n        parser.add_argument(\n            \"--keep_b1_b10\", dest=\"remove_b1_b10\", action=\"store_false\")\n        parser.set_defaults(remove_b1_b10=True)\n\n        parser.add_argument(\"--forecast\", dest=\"forecast\", action=\"store_true\")\n        parser.add_argument(\"--do_not_forecast\",\n                            dest=\"forecast\", action=\"store_false\")\n        parser.set_defaults(forecast=True)\n\n        parser.add_argument(\"--cache\", dest=\"cache\", action=\"store_true\")\n        parser.add_argument(\"--do_not_cache\", dest=\"cache\",\n                            action=\"store_false\")\n        parser.set_defaults(cache=True)\n\n        parser.add_argument(\"--include_geowiki\",\n                            dest=\"include_geowiki\", action=\"store_true\")\n        parser.add_argument(\"--exclude_geowiki\",\n                            dest=\"include_geowiki\", action=\"store_false\")\n        parser.set_defaults(include_geowiki=True)\n\n        parser.add_argument(\"--upsample\", dest=\"upsample\", action=\"store_true\")\n        parser.add_argument(\"--do_not_upsample\",\n                            dest=\"upsample\", action=\"store_false\")\n        parser.set_defaults(upsample=True)\n\n        classifier_parser = Classifier.add_model_specific_args(parser)\n        return Forecaster.add_model_specific_args(classifier_parser)\n",
  "history_output" : "Traceback (most recent call last):\n  File \"src_models_model.py\", line 3, in <module>\n    import numpy as np\nModuleNotFoundError: No module named 'numpy'\n",
  "history_begin_time" : 1655865870391,
  "history_end_time" : 1655865870568,
  "history_notes" : null,
  "history_process" : "9ardvx",
  "host_id" : "100001",
  "indicator" : "Failed"
},{
  "history_id" : "jvgeeepm5c3",
  "history_input" : "from argparse import ArgumentParser, Namespace\nfrom pathlib import Path\nimport numpy as np\nimport xarray as xr\nfrom tqdm import tqdm\n\nimport torch\nfrom torch.nn import functional as F\nfrom torch.utils.data import DataLoader\n\nimport pytorch_lightning as pl\n\nfrom sklearn.metrics import (\n    roc_auc_score,\n    accuracy_score,\n    precision_score,\n    recall_score,\n    f1_score,\n    mean_absolute_error,\n)\n\nfrom src_models_data import CropDataset\nfrom src_models_utils import tif_to_np, preds_to_xr\nfrom src_utils import set_seed\nfrom src_models_forecaster import Forecaster\nfrom src_models_classifier import Classifier\nfrom src_config import PROBABILITY_THRESHOLD\n\nfrom typing import cast, Callable, Tuple, Dict, Any, Type, Optional, List, Union\n\n\nclass Model(pl.LightningModule):\n    r\"\"\"\n    An model for annual and in-season crop mapping. This model consists of a\n    forecaster.Forecaster and a classifier.Classifier - it will require the arguments\n    required by those models too.\n\n    hparams\n    --------\n    The default values for these parameters are set in add_model_specific_args\n\n    :param hparams.data_folder: The path to the data. Default (assumes the model\n        is being run from the scripts directory) = \"../data\"\n    :param hparams.learning_rate: The learning rate. Default = 0.001\n    :param hparams.batch_size: The batch size. Default = 64\n    :param hparams.input_months: The number of input months to pass to the model. If\n        hparams.forecast is True, the remaining months will be forecasted. Otherwise, only the\n        partial timeseries will be passed to the classifier. Default = 5\n    :param hparams.alpha: The weight to use when adding the global and local losses. This\n        parameter is only used if hparams.multi_headed is True. Default = 10\n    :param hparams.noise_factor: The standard deviation of the random noise to add to the\n        raw inputs to the classifier. Default = 0.1\n    :param hparams.remove_b1_b10: Whether or not to remove the B1 and B10 bands. Default = True\n    :param hparams.forecast: Whether or not to forecast the partial time series. Default = True\n    :param hparams.cache: Whether to load all the data into memory during training. Default = True\n    :param hparams.include_geowiki: Whether to include the global GeoWiki dataset during\n        training. Default = True\n    :param hparams.upsample: Whether to oversample the under-represented class so that each class\n        is equally represented in the training and validation dataset. Default = True\n    \"\"\"\n\n    def __init__(self, hparams: Namespace) -> None:\n        super().__init__()\n        set_seed()\n        self.hparams = hparams\n\n        self.data_folder = Path(hparams.data_folder)\n\n        dataset = self.get_dataset(subset=\"training\", cache=False)\n        self.num_outputs = dataset.num_output_classes\n        self.num_timesteps = dataset.num_timesteps\n        self.input_size = dataset.num_input_features\n\n        # we save the normalizing dict because we calculate weighted\n        # normalization values based on the datasets we combine.\n        # The number of instances per dataset (and therefore the weights) can\n        # vary between the train / test / val sets - this ensures the normalizing\n        # dict stays constant between them\n        self.normalizing_dict = dataset.normalizing_dict\n\n        if self.hparams.forecast:\n            num_output_timesteps = self.num_timesteps - self.hparams.input_months\n            print(\n                f\"Predicting {num_output_timesteps} timesteps in the forecaster\")\n            self.forecaster = Forecaster(\n                num_bands=self.input_size, output_timesteps=num_output_timesteps, hparams=hparams,\n            )\n\n            self.forecaster_loss = F.smooth_l1_loss\n\n        self.classifier = Classifier(\n            input_size=self.input_size, hparams=hparams)\n        self.global_loss_function: Callable = F.binary_cross_entropy\n        self.local_loss_function: Callable = F.binary_cross_entropy\n\n    def forward(self, x: torch.Tensor) -> Union[torch.Tensor, Tuple[torch.Tensor, torch.Tensor]]:\n        # To keep the ABC happy\n        return self.classifier(x)\n\n    def configure_optimizers(self):\n        return torch.optim.Adam(self.parameters(), lr=self.hparams.learning_rate)\n\n    def get_dataset(\n        self, subset: str, normalizing_dict: Optional[Dict] = None, cache: Optional[bool] = None,\n    ) -> CropDataset:\n        return CropDataset(\n            data_folder=self.data_folder,\n            subset=subset,\n            remove_b1_b10=self.hparams.remove_b1_b10,\n            normalizing_dict=normalizing_dict,\n            include_geowiki=self.hparams.include_geowiki if subset != \"testing\" else False,\n            cache=self.hparams.cache if cache is None else cache,\n            upsample=self.hparams.upsample if subset != \"testing\" else False,\n            noise_factor=self.hparams.noise_factor if subset != \"testing\" else 0,\n        )\n\n    def train_dataloader(self):\n        return DataLoader(\n            self.get_dataset(subset=\"training\"), shuffle=True, batch_size=self.hparams.batch_size,\n        )\n\n    def val_dataloader(self):\n        return DataLoader(\n            self.get_dataset(subset=\"validation\",\n                             normalizing_dict=self.normalizing_dict,),\n            batch_size=self.hparams.batch_size,\n        )\n\n    def test_dataloader(self):\n        return DataLoader(\n            self.get_dataset(subset=\"testing\",\n                             normalizing_dict=self.normalizing_dict,),\n            batch_size=self.hparams.batch_size,\n        )\n\n    def predict(\n        self,\n        path_to_file: Path,\n        with_forecaster: bool,\n        batch_size: int = 64,\n        add_ndvi: bool = True,\n        add_ndwi: bool = False,\n        nan_fill: float = 0,\n        days_per_timestep: int = 30,\n        local_head: bool = True,\n        use_gpu: bool = True,\n    ) -> xr.Dataset:\n\n        # check if a GPU is available, and if it is\n        # move the model onto the GPU\n        device: Optional[torch.device] = None\n        if use_gpu:\n            use_cuda = torch.cuda.is_available()\n            if not use_cuda:\n                print(\"No GPU - not using one\")\n            device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n            self.to(device)\n\n        self.eval()\n\n        input_data = tif_to_np(\n            path_to_file,\n            add_ndvi=add_ndvi,\n            add_ndwi=add_ndwi,\n            nan=nan_fill,\n            normalizing_dict=self.normalizing_dict,\n            days_per_timestep=days_per_timestep,\n        )\n\n        if with_forecaster:\n            input_data.x = input_data.x[:, : self.hparams.input_months, :]\n\n        predictions: List[np.ndarray] = []\n        cur_i = 0\n\n        pbar = tqdm(total=input_data.x.shape[0] - 1)\n        while cur_i < (input_data.x.shape[0] - 1):\n\n            batch_x_np = input_data.x[cur_i: cur_i + batch_size]\n            if self.hparams.remove_b1_b10:\n                batch_x_np = CropDataset._remove_bands(batch_x_np)\n            batch_x = torch.from_numpy(batch_x_np).float()\n\n            if use_gpu and (device is not None):\n                batch_x = batch_x.to(device)\n\n            with torch.no_grad():\n                if with_forecaster:\n                    batch_x_next = self.forecaster(batch_x)\n                    batch_x = torch.cat((batch_x, batch_x_next), dim=1)\n\n                batch_preds = self.classifier(batch_x)\n\n                if self.hparams.multi_headed:\n                    global_preds, local_preds = batch_preds\n\n                    if local_head:\n                        batch_preds = local_preds\n                    else:\n                        batch_preds = global_preds\n\n                # back to the CPU, if necessary\n                batch_preds = batch_preds.cpu()\n\n            predictions.append(cast(torch.Tensor, batch_preds).numpy())\n            cur_i += batch_size\n            pbar.update(batch_size)\n\n        all_preds = np.concatenate(predictions, axis=0)\n        if len(all_preds.shape) == 1:\n            all_preds = np.expand_dims(all_preds, axis=-1)\n\n        return preds_to_xr(all_preds, lats=input_data.lat, lons=input_data.lon,)\n\n    def _output_metrics(\n        self, preds: np.ndarray, labels: np.ndarray, prefix: str = \"\"\n    ) -> Dict[str, float]:\n\n        if len(preds) == 0:\n            # sometimes this happens in the warmup\n            return {}\n\n        output_dict: Dict[str, float] = {}\n        if not (labels == labels[0]).all():\n            # This can happen when lightning does its warm up on a subset of the\n            # validation data\n            output_dict[f\"{prefix}roc_auc_score\"] = roc_auc_score(\n                labels, preds)\n\n        preds = (preds > PROBABILITY_THRESHOLD).astype(int)\n\n        output_dict[f\"{prefix}precision_score\"] = precision_score(\n            labels, preds)\n        output_dict[f\"{prefix}recall_score\"] = recall_score(labels, preds)\n        output_dict[f\"{prefix}f1_score\"] = f1_score(labels, preds)\n        output_dict[f\"{prefix}accuracy\"] = accuracy_score(labels, preds)\n\n        return output_dict\n\n    def add_noise(self, x: torch.Tensor, training: bool) -> torch.Tensor:\n        if (self.hparams.noise_factor == 0) or (not training):\n            return x\n\n        # expect input to be of shape [timesteps, bands]\n        # and to be normalized with mean 0, std=1\n        # if its not, it means no norm_dict was passed, so lets\n        # just assume std=1\n        noise = torch.normal(0, 1, size=x.shape).float() * \\\n            self.hparams.noise_factor\n\n        # the added noise is the same per band, so that the temporal relationships\n        # are preserved\n        # noise_per_timesteps = noise.repeat(x.shape[0], 1)\n        return x + noise\n\n    def _split_preds_and_get_loss(\n        self, batch, add_preds: bool, loss_label: str, log_loss: bool, training: bool\n    ) -> Dict:\n\n        x, label, is_global = batch\n\n        input_to_encode = x[:, : self.hparams.input_months, :]\n\n        if self.hparams.forecast:\n            # we will predict every timestep except the first one\n            output_to_predict = x[:, 1:, :]\n            encoder_output = self.forecaster(input_to_encode)\n            encoder_loss = self.forecaster_loss(\n                encoder_output, output_to_predict)\n            loss: Union[float, torch.Tensor] = encoder_loss\n\n            final_encoded_input = torch.cat(\n                (\n                    (\n                        self.add_noise(input_to_encode, training),\n                        # -1 because the encoder output has no value for the 0th\n                        # timestep\n                        encoder_output[:, self.hparams.input_months - 1:, :],\n                    )\n                ),\n                dim=1,\n            )\n\n            output_dict = {}\n            if add_preds:\n                output_dict.update(\n                    {\"encoder_prediction\": encoder_output,\n                        \"encoder_target\": output_to_predict, }\n                )\n            if log_loss:\n                output_dict[\"log\"] = {}\n\n            # we now repeat label and is_global\n            x = torch.cat((self.add_noise(x, training),\n                          final_encoded_input), dim=0)\n            label = torch.cat((label, label), dim=0)\n            is_global = torch.cat((is_global, is_global), dim=0)\n        else:\n            loss = 0\n            output_dict = {}\n            if log_loss:\n                output_dict[\"log\"] = {}\n            x = self.add_noise(input_to_encode, training=training)\n\n        if self.hparams.multi_headed:\n            org_global_preds, local_preds = self.classifier(x)\n            global_preds = org_global_preds[is_global != 0]\n            global_labels = label[is_global != 0]\n\n            local_preds = local_preds[is_global == 0]\n            local_labels = label[is_global == 0]\n\n            if local_preds.shape[0] > 0:\n                local_loss = self.local_loss_function(\n                    local_preds.squeeze(-1), local_labels,)\n                loss += local_loss\n\n            if global_preds.shape[0] > 0:\n                global_loss = self.global_loss_function(\n                    global_preds.squeeze(-1), global_labels,)\n\n                num_local_labels = local_preds.shape[0]\n                if num_local_labels == 0:\n                    alpha = 1\n                else:\n                    ratio = global_preds.shape[0] / num_local_labels\n                    alpha = ratio / self.hparams.alpha\n                loss += alpha * global_loss\n\n            output_dict[loss_label] = loss\n            if log_loss:\n                output_dict[\"log\"][loss_label] = loss\n            if add_preds:\n                output_dict.update(\n                    {\n                        \"global_pred\": global_preds,\n                        \"global_label\": global_labels,\n                        \"kenya_pred\": local_preds,\n                        \"kenya_label\": local_labels,\n                    }\n                )\n            return output_dict\n        else:\n            preds = cast(torch.Tensor, self.classifier(x))\n\n            loss += self.global_loss_function(\n                input=preds.squeeze(-1), target=label,)\n\n            output_dict = {loss_label: loss}\n            if log_loss:\n                output_dict[\"log\"][loss_label] = loss\n            if add_preds:\n                output_dict.update({\"pred\": preds, \"label\": label})\n            return output_dict\n\n    def training_step(self, batch, batch_idx):\n        return self._split_preds_and_get_loss(\n            batch, add_preds=False, loss_label=\"loss\", log_loss=True, training=True\n        )\n\n    def validation_step(self, batch, batch_idx):\n        return self._split_preds_and_get_loss(\n            batch, add_preds=True, loss_label=\"val_loss\", log_loss=True, training=False\n        )\n\n    def test_step(self, batch, batch_idx):\n        return self._split_preds_and_get_loss(\n            batch, add_preds=True, loss_label=\"test_loss\", log_loss=True, training=False\n        )\n\n    @staticmethod\n    def _split_tensor(outputs, label) -> Tuple[np.ndarray, np.ndarray]:\n        encoded_all, unencoded_all = [], []\n        for x in outputs:\n            # the first half is unencoded, the second is encoded\n            total = x[label]\n            unencoded_all.append(total[: total.shape[0] // 2])\n            encoded_all.append(total[total.shape[0] // 2:])\n        return (\n            torch.cat(unencoded_all).detach().cpu().numpy(),\n            torch.cat(encoded_all).detach().cpu().numpy(),\n        )\n\n    def _interpretable_metrics(self, outputs, input_prefix: str, output_prefix: str) -> Dict:\n\n        output_dict = {}\n\n        if self.hparams.forecast:\n            u_labels, e_labels = self._split_tensor(\n                outputs, f\"{input_prefix}label\")\n\n            u_preds, e_preds = self._split_tensor(\n                outputs, f\"{input_prefix}pred\")\n        else:\n            u_preds = torch.cat([x[f\"{input_prefix}pred\"]\n                                for x in outputs]).detach().cpu().numpy()\n            u_labels = (\n                torch.cat([x[f\"{input_prefix}label\"]\n                          for x in outputs]).detach().cpu().numpy()\n            )\n\n        output_dict.update(\n            self._output_metrics(\n                u_preds, u_labels, f\"unencoded_{output_prefix}{input_prefix}\")\n        )\n\n        if self.hparams.forecast:\n            output_dict.update(\n                self._output_metrics(\n                    e_preds, e_labels, f\"encoded_{output_prefix}{input_prefix}\")\n            )\n\n        return output_dict\n\n    def validation_epoch_end(self, outputs):\n        avg_loss = torch.stack([x[\"val_loss\"] for x in outputs]).mean()\n        logs = {\"val_loss\": avg_loss}\n        if self.hparams.forecast:\n            encoder_pred = (\n                torch.cat(\n                    [torch.flatten(x[\"encoder_prediction\"], start_dim=1) for x in outputs], dim=0,\n                )\n                .detach()\n                .cpu()\n                .numpy()\n            )\n            encoder_target = (\n                torch.cat(\n                    [torch.flatten(x[\"encoder_target\"], start_dim=1) for x in outputs], dim=0,\n                )\n                .detach()\n                .cpu()\n                .numpy()\n            )\n\n            logs[\"val_encoder_mae\"] = mean_absolute_error(\n                encoder_target, encoder_pred)\n\n        if self.hparams.multi_headed:\n            logs.update(self._interpretable_metrics(\n                outputs, \"global_\", \"val_\"))\n            logs.update(self._interpretable_metrics(outputs, \"kenya_\", \"val_\"))\n        else:\n            logs.update(self._interpretable_metrics(outputs, \"\", \"val_\"))\n        return {\"val_loss\": avg_loss, \"log\": logs}\n\n    def test_epoch_end(self, outputs):\n\n        avg_loss = torch.stack([x[\"test_loss\"] for x in outputs]).mean().item()\n        output_dict = {\"val_loss\": avg_loss}\n\n        if self.hparams.forecast:\n            encoder_pred = (\n                torch.cat(\n                    [torch.flatten(x[\"encoder_prediction\"], start_dim=1) for x in outputs], dim=0,\n                )\n                .detach()\n                .cpu()\n                .numpy()\n            )\n            encoder_target = (\n                torch.cat(\n                    [torch.flatten(x[\"encoder_target\"], start_dim=1) for x in outputs], dim=0,\n                )\n                .detach()\n                .cpu()\n                .numpy()\n            )\n\n            output_dict[\"test_encoder_mae\"] = mean_absolute_error(\n                encoder_target, encoder_pred)\n\n        if self.hparams.multi_headed:\n            output_dict.update(self._interpretable_metrics(\n                outputs, \"global_\", \"test_\"))\n            output_dict.update(self._interpretable_metrics(\n                outputs, \"kenya_\", \"test_\"))\n        else:\n            output_dict.update(\n                self._interpretable_metrics(outputs, \"\", \"test_\"))\n\n        return {\"progress_bar\": output_dict}\n\n    @staticmethod\n    def add_model_specific_args(parent_parser: ArgumentParser) -> ArgumentParser:\n\n        parser = ArgumentParser(parents=[parent_parser], add_help=False)\n\n        parser_args: Dict[str, Tuple[Type, Any]] = {\n            # assumes this is being run from \"scripts\"\n            \"--data_folder\": (str, str(Path(\"../data\"))),\n            \"--learning_rate\": (float, 0.001),\n            \"--batch_size\": (int, 64),\n            \"--input_months\": (int, 5),\n            \"--alpha\": (float, 10),\n            \"--noise_factor\": (float, 0.1),\n        }\n\n        for key, val in parser_args.items():\n            parser.add_argument(key, type=val[0], default=val[1])\n\n        parser.add_argument(\"--remove_b1_b10\",\n                            dest=\"remove_b1_b10\", action=\"store_true\")\n        parser.add_argument(\n            \"--keep_b1_b10\", dest=\"remove_b1_b10\", action=\"store_false\")\n        parser.set_defaults(remove_b1_b10=True)\n\n        parser.add_argument(\"--forecast\", dest=\"forecast\", action=\"store_true\")\n        parser.add_argument(\"--do_not_forecast\",\n                            dest=\"forecast\", action=\"store_false\")\n        parser.set_defaults(forecast=True)\n\n        parser.add_argument(\"--cache\", dest=\"cache\", action=\"store_true\")\n        parser.add_argument(\"--do_not_cache\", dest=\"cache\",\n                            action=\"store_false\")\n        parser.set_defaults(cache=True)\n\n        parser.add_argument(\"--include_geowiki\",\n                            dest=\"include_geowiki\", action=\"store_true\")\n        parser.add_argument(\"--exclude_geowiki\",\n                            dest=\"include_geowiki\", action=\"store_false\")\n        parser.set_defaults(include_geowiki=True)\n\n        parser.add_argument(\"--upsample\", dest=\"upsample\", action=\"store_true\")\n        parser.add_argument(\"--do_not_upsample\",\n                            dest=\"upsample\", action=\"store_false\")\n        parser.set_defaults(upsample=True)\n\n        classifier_parser = Classifier.add_model_specific_args(parser)\n        return Forecaster.add_model_specific_args(classifier_parser)\n",
  "history_output" : "Traceback (most recent call last):\n  File \"src_models_model.py\", line 22, in <module>\n    from src_models_data import CropDataset\n  File \"/Users/uhhmed/gw-workspace/jvgeeepm5c3/src_models_data.py\", line 4, in <module>\n    import geopandas\n  File \"/opt/anaconda3/lib/python3.8/site-packages/geopandas/__init__.py\", line 1, in <module>\n    from geopandas._config import options  # noqa\n  File \"/opt/anaconda3/lib/python3.8/site-packages/geopandas/_config.py\", line 109, in <module>\n    default_value=_default_use_pygeos(),\n  File \"/opt/anaconda3/lib/python3.8/site-packages/geopandas/_config.py\", line 95, in _default_use_pygeos\n    import geopandas._compat as compat\n  File \"/opt/anaconda3/lib/python3.8/site-packages/geopandas/_compat.py\", line 9, in <module>\n    import pyproj\n  File \"/opt/anaconda3/lib/python3.8/site-packages/pyproj/__init__.py\", line 81, in <module>\n    from pyproj.crs import CRS  # noqa: F401\n  File \"/opt/anaconda3/lib/python3.8/site-packages/pyproj/crs/__init__.py\", line 16, in <module>\n    from pyproj.crs.crs import (  # noqa: F401  pylint: disable=unused-import\n  File \"/opt/anaconda3/lib/python3.8/site-packages/pyproj/crs/crs.py\", line 13, in <module>\n    from pyproj._crs import (\nImportError: cannot import name 'AuthorityMatchInfo' from 'pyproj._crs' (/opt/anaconda3/lib/python3.8/site-packages/pyproj/_crs.cpython-38-darwin.so)\n",
  "history_begin_time" : 1655865090369,
  "history_end_time" : 1655865095705,
  "history_notes" : null,
  "history_process" : "9ardvx",
  "host_id" : "100001",
  "indicator" : "Failed"
},{
  "history_id" : "mnte543c5bo",
  "history_input" : "from argparse import ArgumentParser, Namespace\nfrom pathlib import Path\nimport numpy as np\nimport xarray as xr\nfrom tqdm import tqdm\n\nimport torch\nfrom torch.nn import functional as F\nfrom torch.utils.data import DataLoader\n\nimport pytorch_lightning as pl\n\nfrom sklearn.metrics import (\n    roc_auc_score,\n    accuracy_score,\n    precision_score,\n    recall_score,\n    f1_score,\n    mean_absolute_error,\n)\n\nfrom src_models_data import CropDataset\nfrom src_models_utils import tif_to_np, preds_to_xr\nfrom src_utils import set_seed\nfrom src_models_forecaster import Forecaster\nfrom src_models_classifier import Classifier\nfrom src_config import PROBABILITY_THRESHOLD\n\nfrom typing import cast, Callable, Tuple, Dict, Any, Type, Optional, List, Union\n\n\nclass Model(pl.LightningModule):\n    r\"\"\"\n    An model for annual and in-season crop mapping. This model consists of a\n    forecaster.Forecaster and a classifier.Classifier - it will require the arguments\n    required by those models too.\n\n    hparams\n    --------\n    The default values for these parameters are set in add_model_specific_args\n\n    :param hparams.data_folder: The path to the data. Default (assumes the model\n        is being run from the scripts directory) = \"../data\"\n    :param hparams.learning_rate: The learning rate. Default = 0.001\n    :param hparams.batch_size: The batch size. Default = 64\n    :param hparams.input_months: The number of input months to pass to the model. If\n        hparams.forecast is True, the remaining months will be forecasted. Otherwise, only the\n        partial timeseries will be passed to the classifier. Default = 5\n    :param hparams.alpha: The weight to use when adding the global and local losses. This\n        parameter is only used if hparams.multi_headed is True. Default = 10\n    :param hparams.noise_factor: The standard deviation of the random noise to add to the\n        raw inputs to the classifier. Default = 0.1\n    :param hparams.remove_b1_b10: Whether or not to remove the B1 and B10 bands. Default = True\n    :param hparams.forecast: Whether or not to forecast the partial time series. Default = True\n    :param hparams.cache: Whether to load all the data into memory during training. Default = True\n    :param hparams.include_geowiki: Whether to include the global GeoWiki dataset during\n        training. Default = True\n    :param hparams.upsample: Whether to oversample the under-represented class so that each class\n        is equally represented in the training and validation dataset. Default = True\n    \"\"\"\n\n    def __init__(self, hparams: Namespace) -> None:\n        super().__init__()\n        set_seed()\n        self.hparams = hparams\n\n        self.data_folder = Path(hparams.data_folder)\n\n        dataset = self.get_dataset(subset=\"training\", cache=False)\n        self.num_outputs = dataset.num_output_classes\n        self.num_timesteps = dataset.num_timesteps\n        self.input_size = dataset.num_input_features\n\n        # we save the normalizing dict because we calculate weighted\n        # normalization values based on the datasets we combine.\n        # The number of instances per dataset (and therefore the weights) can\n        # vary between the train / test / val sets - this ensures the normalizing\n        # dict stays constant between them\n        self.normalizing_dict = dataset.normalizing_dict\n\n        if self.hparams.forecast:\n            num_output_timesteps = self.num_timesteps - self.hparams.input_months\n            print(\n                f\"Predicting {num_output_timesteps} timesteps in the forecaster\")\n            self.forecaster = Forecaster(\n                num_bands=self.input_size, output_timesteps=num_output_timesteps, hparams=hparams,\n            )\n\n            self.forecaster_loss = F.smooth_l1_loss\n\n        self.classifier = Classifier(\n            input_size=self.input_size, hparams=hparams)\n        self.global_loss_function: Callable = F.binary_cross_entropy\n        self.local_loss_function: Callable = F.binary_cross_entropy\n\n    def forward(self, x: torch.Tensor) -> Union[torch.Tensor, Tuple[torch.Tensor, torch.Tensor]]:\n        # To keep the ABC happy\n        return self.classifier(x)\n\n    def configure_optimizers(self):\n        return torch.optim.Adam(self.parameters(), lr=self.hparams.learning_rate)\n\n    def get_dataset(\n        self, subset: str, normalizing_dict: Optional[Dict] = None, cache: Optional[bool] = None,\n    ) -> CropDataset:\n        return CropDataset(\n            data_folder=self.data_folder,\n            subset=subset,\n            remove_b1_b10=self.hparams.remove_b1_b10,\n            normalizing_dict=normalizing_dict,\n            include_geowiki=self.hparams.include_geowiki if subset != \"testing\" else False,\n            cache=self.hparams.cache if cache is None else cache,\n            upsample=self.hparams.upsample if subset != \"testing\" else False,\n            noise_factor=self.hparams.noise_factor if subset != \"testing\" else 0,\n        )\n\n    def train_dataloader(self):\n        return DataLoader(\n            self.get_dataset(subset=\"training\"), shuffle=True, batch_size=self.hparams.batch_size,\n        )\n\n    def val_dataloader(self):\n        return DataLoader(\n            self.get_dataset(subset=\"validation\",\n                             normalizing_dict=self.normalizing_dict,),\n            batch_size=self.hparams.batch_size,\n        )\n\n    def test_dataloader(self):\n        return DataLoader(\n            self.get_dataset(subset=\"testing\",\n                             normalizing_dict=self.normalizing_dict,),\n            batch_size=self.hparams.batch_size,\n        )\n\n    def predict(\n        self,\n        path_to_file: Path,\n        with_forecaster: bool,\n        batch_size: int = 64,\n        add_ndvi: bool = True,\n        add_ndwi: bool = False,\n        nan_fill: float = 0,\n        days_per_timestep: int = 30,\n        local_head: bool = True,\n        use_gpu: bool = True,\n    ) -> xr.Dataset:\n\n        # check if a GPU is available, and if it is\n        # move the model onto the GPU\n        device: Optional[torch.device] = None\n        if use_gpu:\n            use_cuda = torch.cuda.is_available()\n            if not use_cuda:\n                print(\"No GPU - not using one\")\n            device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n            self.to(device)\n\n        self.eval()\n\n        input_data = tif_to_np(\n            path_to_file,\n            add_ndvi=add_ndvi,\n            add_ndwi=add_ndwi,\n            nan=nan_fill,\n            normalizing_dict=self.normalizing_dict,\n            days_per_timestep=days_per_timestep,\n        )\n\n        if with_forecaster:\n            input_data.x = input_data.x[:, : self.hparams.input_months, :]\n\n        predictions: List[np.ndarray] = []\n        cur_i = 0\n\n        pbar = tqdm(total=input_data.x.shape[0] - 1)\n        while cur_i < (input_data.x.shape[0] - 1):\n\n            batch_x_np = input_data.x[cur_i: cur_i + batch_size]\n            if self.hparams.remove_b1_b10:\n                batch_x_np = CropDataset._remove_bands(batch_x_np)\n            batch_x = torch.from_numpy(batch_x_np).float()\n\n            if use_gpu and (device is not None):\n                batch_x = batch_x.to(device)\n\n            with torch.no_grad():\n                if with_forecaster:\n                    batch_x_next = self.forecaster(batch_x)\n                    batch_x = torch.cat((batch_x, batch_x_next), dim=1)\n\n                batch_preds = self.classifier(batch_x)\n\n                if self.hparams.multi_headed:\n                    global_preds, local_preds = batch_preds\n\n                    if local_head:\n                        batch_preds = local_preds\n                    else:\n                        batch_preds = global_preds\n\n                # back to the CPU, if necessary\n                batch_preds = batch_preds.cpu()\n\n            predictions.append(cast(torch.Tensor, batch_preds).numpy())\n            cur_i += batch_size\n            pbar.update(batch_size)\n\n        all_preds = np.concatenate(predictions, axis=0)\n        if len(all_preds.shape) == 1:\n            all_preds = np.expand_dims(all_preds, axis=-1)\n\n        return preds_to_xr(all_preds, lats=input_data.lat, lons=input_data.lon,)\n\n    def _output_metrics(\n        self, preds: np.ndarray, labels: np.ndarray, prefix: str = \"\"\n    ) -> Dict[str, float]:\n\n        if len(preds) == 0:\n            # sometimes this happens in the warmup\n            return {}\n\n        output_dict: Dict[str, float] = {}\n        if not (labels == labels[0]).all():\n            # This can happen when lightning does its warm up on a subset of the\n            # validation data\n            output_dict[f\"{prefix}roc_auc_score\"] = roc_auc_score(\n                labels, preds)\n\n        preds = (preds > PROBABILITY_THRESHOLD).astype(int)\n\n        output_dict[f\"{prefix}precision_score\"] = precision_score(\n            labels, preds)\n        output_dict[f\"{prefix}recall_score\"] = recall_score(labels, preds)\n        output_dict[f\"{prefix}f1_score\"] = f1_score(labels, preds)\n        output_dict[f\"{prefix}accuracy\"] = accuracy_score(labels, preds)\n\n        return output_dict\n\n    def add_noise(self, x: torch.Tensor, training: bool) -> torch.Tensor:\n        if (self.hparams.noise_factor == 0) or (not training):\n            return x\n\n        # expect input to be of shape [timesteps, bands]\n        # and to be normalized with mean 0, std=1\n        # if its not, it means no norm_dict was passed, so lets\n        # just assume std=1\n        noise = torch.normal(0, 1, size=x.shape).float() * \\\n            self.hparams.noise_factor\n\n        # the added noise is the same per band, so that the temporal relationships\n        # are preserved\n        # noise_per_timesteps = noise.repeat(x.shape[0], 1)\n        return x + noise\n\n    def _split_preds_and_get_loss(\n        self, batch, add_preds: bool, loss_label: str, log_loss: bool, training: bool\n    ) -> Dict:\n\n        x, label, is_global = batch\n\n        input_to_encode = x[:, : self.hparams.input_months, :]\n\n        if self.hparams.forecast:\n            # we will predict every timestep except the first one\n            output_to_predict = x[:, 1:, :]\n            encoder_output = self.forecaster(input_to_encode)\n            encoder_loss = self.forecaster_loss(\n                encoder_output, output_to_predict)\n            loss: Union[float, torch.Tensor] = encoder_loss\n\n            final_encoded_input = torch.cat(\n                (\n                    (\n                        self.add_noise(input_to_encode, training),\n                        # -1 because the encoder output has no value for the 0th\n                        # timestep\n                        encoder_output[:, self.hparams.input_months - 1:, :],\n                    )\n                ),\n                dim=1,\n            )\n\n            output_dict = {}\n            if add_preds:\n                output_dict.update(\n                    {\"encoder_prediction\": encoder_output,\n                        \"encoder_target\": output_to_predict, }\n                )\n            if log_loss:\n                output_dict[\"log\"] = {}\n\n            # we now repeat label and is_global\n            x = torch.cat((self.add_noise(x, training),\n                          final_encoded_input), dim=0)\n            label = torch.cat((label, label), dim=0)\n            is_global = torch.cat((is_global, is_global), dim=0)\n        else:\n            loss = 0\n            output_dict = {}\n            if log_loss:\n                output_dict[\"log\"] = {}\n            x = self.add_noise(input_to_encode, training=training)\n\n        if self.hparams.multi_headed:\n            org_global_preds, local_preds = self.classifier(x)\n            global_preds = org_global_preds[is_global != 0]\n            global_labels = label[is_global != 0]\n\n            local_preds = local_preds[is_global == 0]\n            local_labels = label[is_global == 0]\n\n            if local_preds.shape[0] > 0:\n                local_loss = self.local_loss_function(\n                    local_preds.squeeze(-1), local_labels,)\n                loss += local_loss\n\n            if global_preds.shape[0] > 0:\n                global_loss = self.global_loss_function(\n                    global_preds.squeeze(-1), global_labels,)\n\n                num_local_labels = local_preds.shape[0]\n                if num_local_labels == 0:\n                    alpha = 1\n                else:\n                    ratio = global_preds.shape[0] / num_local_labels\n                    alpha = ratio / self.hparams.alpha\n                loss += alpha * global_loss\n\n            output_dict[loss_label] = loss\n            if log_loss:\n                output_dict[\"log\"][loss_label] = loss\n            if add_preds:\n                output_dict.update(\n                    {\n                        \"global_pred\": global_preds,\n                        \"global_label\": global_labels,\n                        \"kenya_pred\": local_preds,\n                        \"kenya_label\": local_labels,\n                    }\n                )\n            return output_dict\n        else:\n            preds = cast(torch.Tensor, self.classifier(x))\n\n            loss += self.global_loss_function(\n                input=preds.squeeze(-1), target=label,)\n\n            output_dict = {loss_label: loss}\n            if log_loss:\n                output_dict[\"log\"][loss_label] = loss\n            if add_preds:\n                output_dict.update({\"pred\": preds, \"label\": label})\n            return output_dict\n\n    def training_step(self, batch, batch_idx):\n        return self._split_preds_and_get_loss(\n            batch, add_preds=False, loss_label=\"loss\", log_loss=True, training=True\n        )\n\n    def validation_step(self, batch, batch_idx):\n        return self._split_preds_and_get_loss(\n            batch, add_preds=True, loss_label=\"val_loss\", log_loss=True, training=False\n        )\n\n    def test_step(self, batch, batch_idx):\n        return self._split_preds_and_get_loss(\n            batch, add_preds=True, loss_label=\"test_loss\", log_loss=True, training=False\n        )\n\n    @staticmethod\n    def _split_tensor(outputs, label) -> Tuple[np.ndarray, np.ndarray]:\n        encoded_all, unencoded_all = [], []\n        for x in outputs:\n            # the first half is unencoded, the second is encoded\n            total = x[label]\n            unencoded_all.append(total[: total.shape[0] // 2])\n            encoded_all.append(total[total.shape[0] // 2:])\n        return (\n            torch.cat(unencoded_all).detach().cpu().numpy(),\n            torch.cat(encoded_all).detach().cpu().numpy(),\n        )\n\n    def _interpretable_metrics(self, outputs, input_prefix: str, output_prefix: str) -> Dict:\n\n        output_dict = {}\n\n        if self.hparams.forecast:\n            u_labels, e_labels = self._split_tensor(\n                outputs, f\"{input_prefix}label\")\n\n            u_preds, e_preds = self._split_tensor(\n                outputs, f\"{input_prefix}pred\")\n        else:\n            u_preds = torch.cat([x[f\"{input_prefix}pred\"]\n                                for x in outputs]).detach().cpu().numpy()\n            u_labels = (\n                torch.cat([x[f\"{input_prefix}label\"]\n                          for x in outputs]).detach().cpu().numpy()\n            )\n\n        output_dict.update(\n            self._output_metrics(\n                u_preds, u_labels, f\"unencoded_{output_prefix}{input_prefix}\")\n        )\n\n        if self.hparams.forecast:\n            output_dict.update(\n                self._output_metrics(\n                    e_preds, e_labels, f\"encoded_{output_prefix}{input_prefix}\")\n            )\n\n        return output_dict\n\n    def validation_epoch_end(self, outputs):\n        avg_loss = torch.stack([x[\"val_loss\"] for x in outputs]).mean()\n        logs = {\"val_loss\": avg_loss}\n        if self.hparams.forecast:\n            encoder_pred = (\n                torch.cat(\n                    [torch.flatten(x[\"encoder_prediction\"], start_dim=1) for x in outputs], dim=0,\n                )\n                .detach()\n                .cpu()\n                .numpy()\n            )\n            encoder_target = (\n                torch.cat(\n                    [torch.flatten(x[\"encoder_target\"], start_dim=1) for x in outputs], dim=0,\n                )\n                .detach()\n                .cpu()\n                .numpy()\n            )\n\n            logs[\"val_encoder_mae\"] = mean_absolute_error(\n                encoder_target, encoder_pred)\n\n        if self.hparams.multi_headed:\n            logs.update(self._interpretable_metrics(\n                outputs, \"global_\", \"val_\"))\n            logs.update(self._interpretable_metrics(outputs, \"kenya_\", \"val_\"))\n        else:\n            logs.update(self._interpretable_metrics(outputs, \"\", \"val_\"))\n        return {\"val_loss\": avg_loss, \"log\": logs}\n\n    def test_epoch_end(self, outputs):\n\n        avg_loss = torch.stack([x[\"test_loss\"] for x in outputs]).mean().item()\n        output_dict = {\"val_loss\": avg_loss}\n\n        if self.hparams.forecast:\n            encoder_pred = (\n                torch.cat(\n                    [torch.flatten(x[\"encoder_prediction\"], start_dim=1) for x in outputs], dim=0,\n                )\n                .detach()\n                .cpu()\n                .numpy()\n            )\n            encoder_target = (\n                torch.cat(\n                    [torch.flatten(x[\"encoder_target\"], start_dim=1) for x in outputs], dim=0,\n                )\n                .detach()\n                .cpu()\n                .numpy()\n            )\n\n            output_dict[\"test_encoder_mae\"] = mean_absolute_error(\n                encoder_target, encoder_pred)\n\n        if self.hparams.multi_headed:\n            output_dict.update(self._interpretable_metrics(\n                outputs, \"global_\", \"test_\"))\n            output_dict.update(self._interpretable_metrics(\n                outputs, \"kenya_\", \"test_\"))\n        else:\n            output_dict.update(\n                self._interpretable_metrics(outputs, \"\", \"test_\"))\n\n        return {\"progress_bar\": output_dict}\n\n    @staticmethod\n    def add_model_specific_args(parent_parser: ArgumentParser) -> ArgumentParser:\n\n        parser = ArgumentParser(parents=[parent_parser], add_help=False)\n\n        parser_args: Dict[str, Tuple[Type, Any]] = {\n            # assumes this is being run from \"scripts\"\n            \"--data_folder\": (str, str(Path(\"../data\"))),\n            \"--learning_rate\": (float, 0.001),\n            \"--batch_size\": (int, 64),\n            \"--input_months\": (int, 5),\n            \"--alpha\": (float, 10),\n            \"--noise_factor\": (float, 0.1),\n        }\n\n        for key, val in parser_args.items():\n            parser.add_argument(key, type=val[0], default=val[1])\n\n        parser.add_argument(\"--remove_b1_b10\",\n                            dest=\"remove_b1_b10\", action=\"store_true\")\n        parser.add_argument(\n            \"--keep_b1_b10\", dest=\"remove_b1_b10\", action=\"store_false\")\n        parser.set_defaults(remove_b1_b10=True)\n\n        parser.add_argument(\"--forecast\", dest=\"forecast\", action=\"store_true\")\n        parser.add_argument(\"--do_not_forecast\",\n                            dest=\"forecast\", action=\"store_false\")\n        parser.set_defaults(forecast=True)\n\n        parser.add_argument(\"--cache\", dest=\"cache\", action=\"store_true\")\n        parser.add_argument(\"--do_not_cache\", dest=\"cache\",\n                            action=\"store_false\")\n        parser.set_defaults(cache=True)\n\n        parser.add_argument(\"--include_geowiki\",\n                            dest=\"include_geowiki\", action=\"store_true\")\n        parser.add_argument(\"--exclude_geowiki\",\n                            dest=\"include_geowiki\", action=\"store_false\")\n        parser.set_defaults(include_geowiki=True)\n\n        parser.add_argument(\"--upsample\", dest=\"upsample\", action=\"store_true\")\n        parser.add_argument(\"--do_not_upsample\",\n                            dest=\"upsample\", action=\"store_false\")\n        parser.set_defaults(upsample=True)\n\n        classifier_parser = Classifier.add_model_specific_args(parser)\n        return Forecaster.add_model_specific_args(classifier_parser)\n",
  "history_output" : "",
  "history_begin_time" : 1647347434599,
  "history_end_time" : 1647347434853,
  "history_notes" : null,
  "history_process" : "9ardvx",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "31o2lbvyy3g",
  "history_input" : "from argparse import ArgumentParser, Namespace\nfrom pathlib import Path\nimport numpy as np\nimport xarray as xr\nfrom tqdm import tqdm\n\nimport torch\nfrom torch.nn import functional as F\nfrom torch.utils.data import DataLoader\n\nimport pytorch_lightning as pl\n\nfrom sklearn.metrics import (\n    roc_auc_score,\n    accuracy_score,\n    precision_score,\n    recall_score,\n    f1_score,\n    mean_absolute_error,\n)\n\nfrom src_models_data import CropDataset\nfrom src_models_utils import tif_to_np, preds_to_xr\nfrom src_utils import set_seed\nfrom src_models_forecaster import Forecaster\nfrom src_models_classifier import Classifier\nfrom src_config import PROBABILITY_THRESHOLD\n\nfrom typing import cast, Callable, Tuple, Dict, Any, Type, Optional, List, Union\n\n\nclass Model(pl.LightningModule):\n    r\"\"\"\n    An model for annual and in-season crop mapping. This model consists of a\n    forecaster.Forecaster and a classifier.Classifier - it will require the arguments\n    required by those models too.\n\n    hparams\n    --------\n    The default values for these parameters are set in add_model_specific_args\n\n    :param hparams.data_folder: The path to the data. Default (assumes the model\n        is being run from the scripts directory) = \"../data\"\n    :param hparams.learning_rate: The learning rate. Default = 0.001\n    :param hparams.batch_size: The batch size. Default = 64\n    :param hparams.input_months: The number of input months to pass to the model. If\n        hparams.forecast is True, the remaining months will be forecasted. Otherwise, only the\n        partial timeseries will be passed to the classifier. Default = 5\n    :param hparams.alpha: The weight to use when adding the global and local losses. This\n        parameter is only used if hparams.multi_headed is True. Default = 10\n    :param hparams.noise_factor: The standard deviation of the random noise to add to the\n        raw inputs to the classifier. Default = 0.1\n    :param hparams.remove_b1_b10: Whether or not to remove the B1 and B10 bands. Default = True\n    :param hparams.forecast: Whether or not to forecast the partial time series. Default = True\n    :param hparams.cache: Whether to load all the data into memory during training. Default = True\n    :param hparams.include_geowiki: Whether to include the global GeoWiki dataset during\n        training. Default = True\n    :param hparams.upsample: Whether to oversample the under-represented class so that each class\n        is equally represented in the training and validation dataset. Default = True\n    \"\"\"\n\n    def __init__(self, hparams: Namespace) -> None:\n        super().__init__()\n        set_seed()\n        self.hparams = hparams\n\n        self.data_folder = Path(hparams.data_folder)\n\n        dataset = self.get_dataset(subset=\"training\", cache=False)\n        self.num_outputs = dataset.num_output_classes\n        self.num_timesteps = dataset.num_timesteps\n        self.input_size = dataset.num_input_features\n\n        # we save the normalizing dict because we calculate weighted\n        # normalization values based on the datasets we combine.\n        # The number of instances per dataset (and therefore the weights) can\n        # vary between the train / test / val sets - this ensures the normalizing\n        # dict stays constant between them\n        self.normalizing_dict = dataset.normalizing_dict\n\n        if self.hparams.forecast:\n            num_output_timesteps = self.num_timesteps - self.hparams.input_months\n            print(\n                f\"Predicting {num_output_timesteps} timesteps in the forecaster\")\n            self.forecaster = Forecaster(\n                num_bands=self.input_size, output_timesteps=num_output_timesteps, hparams=hparams,\n            )\n\n            self.forecaster_loss = F.smooth_l1_loss\n\n        self.classifier = Classifier(\n            input_size=self.input_size, hparams=hparams)\n        self.global_loss_function: Callable = F.binary_cross_entropy\n        self.local_loss_function: Callable = F.binary_cross_entropy\n\n    def forward(self, x: torch.Tensor) -> Union[torch.Tensor, Tuple[torch.Tensor, torch.Tensor]]:\n        # To keep the ABC happy\n        return self.classifier(x)\n\n    def configure_optimizers(self):\n        return torch.optim.Adam(self.parameters(), lr=self.hparams.learning_rate)\n\n    def get_dataset(\n        self, subset: str, normalizing_dict: Optional[Dict] = None, cache: Optional[bool] = None,\n    ) -> CropDataset:\n        return CropDataset(\n            data_folder=self.data_folder,\n            subset=subset,\n            remove_b1_b10=self.hparams.remove_b1_b10,\n            normalizing_dict=normalizing_dict,\n            include_geowiki=self.hparams.include_geowiki if subset != \"testing\" else False,\n            cache=self.hparams.cache if cache is None else cache,\n            upsample=self.hparams.upsample if subset != \"testing\" else False,\n            noise_factor=self.hparams.noise_factor if subset != \"testing\" else 0,\n        )\n\n    def train_dataloader(self):\n        return DataLoader(\n            self.get_dataset(subset=\"training\"), shuffle=True, batch_size=self.hparams.batch_size,\n        )\n\n    def val_dataloader(self):\n        return DataLoader(\n            self.get_dataset(subset=\"validation\",\n                             normalizing_dict=self.normalizing_dict,),\n            batch_size=self.hparams.batch_size,\n        )\n\n    def test_dataloader(self):\n        return DataLoader(\n            self.get_dataset(subset=\"testing\",\n                             normalizing_dict=self.normalizing_dict,),\n            batch_size=self.hparams.batch_size,\n        )\n\n    def predict(\n        self,\n        path_to_file: Path,\n        with_forecaster: bool,\n        batch_size: int = 64,\n        add_ndvi: bool = True,\n        add_ndwi: bool = False,\n        nan_fill: float = 0,\n        days_per_timestep: int = 30,\n        local_head: bool = True,\n        use_gpu: bool = True,\n    ) -> xr.Dataset:\n\n        # check if a GPU is available, and if it is\n        # move the model onto the GPU\n        device: Optional[torch.device] = None\n        if use_gpu:\n            use_cuda = torch.cuda.is_available()\n            if not use_cuda:\n                print(\"No GPU - not using one\")\n            device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n            self.to(device)\n\n        self.eval()\n\n        input_data = tif_to_np(\n            path_to_file,\n            add_ndvi=add_ndvi,\n            add_ndwi=add_ndwi,\n            nan=nan_fill,\n            normalizing_dict=self.normalizing_dict,\n            days_per_timestep=days_per_timestep,\n        )\n\n        if with_forecaster:\n            input_data.x = input_data.x[:, : self.hparams.input_months, :]\n\n        predictions: List[np.ndarray] = []\n        cur_i = 0\n\n        pbar = tqdm(total=input_data.x.shape[0] - 1)\n        while cur_i < (input_data.x.shape[0] - 1):\n\n            batch_x_np = input_data.x[cur_i: cur_i + batch_size]\n            if self.hparams.remove_b1_b10:\n                batch_x_np = CropDataset._remove_bands(batch_x_np)\n            batch_x = torch.from_numpy(batch_x_np).float()\n\n            if use_gpu and (device is not None):\n                batch_x = batch_x.to(device)\n\n            with torch.no_grad():\n                if with_forecaster:\n                    batch_x_next = self.forecaster(batch_x)\n                    batch_x = torch.cat((batch_x, batch_x_next), dim=1)\n\n                batch_preds = self.classifier(batch_x)\n\n                if self.hparams.multi_headed:\n                    global_preds, local_preds = batch_preds\n\n                    if local_head:\n                        batch_preds = local_preds\n                    else:\n                        batch_preds = global_preds\n\n                # back to the CPU, if necessary\n                batch_preds = batch_preds.cpu()\n\n            predictions.append(cast(torch.Tensor, batch_preds).numpy())\n            cur_i += batch_size\n            pbar.update(batch_size)\n\n        all_preds = np.concatenate(predictions, axis=0)\n        if len(all_preds.shape) == 1:\n            all_preds = np.expand_dims(all_preds, axis=-1)\n\n        return preds_to_xr(all_preds, lats=input_data.lat, lons=input_data.lon,)\n\n    def _output_metrics(\n        self, preds: np.ndarray, labels: np.ndarray, prefix: str = \"\"\n    ) -> Dict[str, float]:\n\n        if len(preds) == 0:\n            # sometimes this happens in the warmup\n            return {}\n\n        output_dict: Dict[str, float] = {}\n        if not (labels == labels[0]).all():\n            # This can happen when lightning does its warm up on a subset of the\n            # validation data\n            output_dict[f\"{prefix}roc_auc_score\"] = roc_auc_score(\n                labels, preds)\n\n        preds = (preds > PROBABILITY_THRESHOLD).astype(int)\n\n        output_dict[f\"{prefix}precision_score\"] = precision_score(\n            labels, preds)\n        output_dict[f\"{prefix}recall_score\"] = recall_score(labels, preds)\n        output_dict[f\"{prefix}f1_score\"] = f1_score(labels, preds)\n        output_dict[f\"{prefix}accuracy\"] = accuracy_score(labels, preds)\n\n        return output_dict\n\n    def add_noise(self, x: torch.Tensor, training: bool) -> torch.Tensor:\n        if (self.hparams.noise_factor == 0) or (not training):\n            return x\n\n        # expect input to be of shape [timesteps, bands]\n        # and to be normalized with mean 0, std=1\n        # if its not, it means no norm_dict was passed, so lets\n        # just assume std=1\n        noise = torch.normal(0, 1, size=x.shape).float() * \\\n            self.hparams.noise_factor\n\n        # the added noise is the same per band, so that the temporal relationships\n        # are preserved\n        # noise_per_timesteps = noise.repeat(x.shape[0], 1)\n        return x + noise\n\n    def _split_preds_and_get_loss(\n        self, batch, add_preds: bool, loss_label: str, log_loss: bool, training: bool\n    ) -> Dict:\n\n        x, label, is_global = batch\n\n        input_to_encode = x[:, : self.hparams.input_months, :]\n\n        if self.hparams.forecast:\n            # we will predict every timestep except the first one\n            output_to_predict = x[:, 1:, :]\n            encoder_output = self.forecaster(input_to_encode)\n            encoder_loss = self.forecaster_loss(\n                encoder_output, output_to_predict)\n            loss: Union[float, torch.Tensor] = encoder_loss\n\n            final_encoded_input = torch.cat(\n                (\n                    (\n                        self.add_noise(input_to_encode, training),\n                        # -1 because the encoder output has no value for the 0th\n                        # timestep\n                        encoder_output[:, self.hparams.input_months - 1:, :],\n                    )\n                ),\n                dim=1,\n            )\n\n            output_dict = {}\n            if add_preds:\n                output_dict.update(\n                    {\"encoder_prediction\": encoder_output,\n                        \"encoder_target\": output_to_predict, }\n                )\n            if log_loss:\n                output_dict[\"log\"] = {}\n\n            # we now repeat label and is_global\n            x = torch.cat((self.add_noise(x, training),\n                          final_encoded_input), dim=0)\n            label = torch.cat((label, label), dim=0)\n            is_global = torch.cat((is_global, is_global), dim=0)\n        else:\n            loss = 0\n            output_dict = {}\n            if log_loss:\n                output_dict[\"log\"] = {}\n            x = self.add_noise(input_to_encode, training=training)\n\n        if self.hparams.multi_headed:\n            org_global_preds, local_preds = self.classifier(x)\n            global_preds = org_global_preds[is_global != 0]\n            global_labels = label[is_global != 0]\n\n            local_preds = local_preds[is_global == 0]\n            local_labels = label[is_global == 0]\n\n            if local_preds.shape[0] > 0:\n                local_loss = self.local_loss_function(\n                    local_preds.squeeze(-1), local_labels,)\n                loss += local_loss\n\n            if global_preds.shape[0] > 0:\n                global_loss = self.global_loss_function(\n                    global_preds.squeeze(-1), global_labels,)\n\n                num_local_labels = local_preds.shape[0]\n                if num_local_labels == 0:\n                    alpha = 1\n                else:\n                    ratio = global_preds.shape[0] / num_local_labels\n                    alpha = ratio / self.hparams.alpha\n                loss += alpha * global_loss\n\n            output_dict[loss_label] = loss\n            if log_loss:\n                output_dict[\"log\"][loss_label] = loss\n            if add_preds:\n                output_dict.update(\n                    {\n                        \"global_pred\": global_preds,\n                        \"global_label\": global_labels,\n                        \"kenya_pred\": local_preds,\n                        \"kenya_label\": local_labels,\n                    }\n                )\n            return output_dict\n        else:\n            preds = cast(torch.Tensor, self.classifier(x))\n\n            loss += self.global_loss_function(\n                input=preds.squeeze(-1), target=label,)\n\n            output_dict = {loss_label: loss}\n            if log_loss:\n                output_dict[\"log\"][loss_label] = loss\n            if add_preds:\n                output_dict.update({\"pred\": preds, \"label\": label})\n            return output_dict\n\n    def training_step(self, batch, batch_idx):\n        return self._split_preds_and_get_loss(\n            batch, add_preds=False, loss_label=\"loss\", log_loss=True, training=True\n        )\n\n    def validation_step(self, batch, batch_idx):\n        return self._split_preds_and_get_loss(\n            batch, add_preds=True, loss_label=\"val_loss\", log_loss=True, training=False\n        )\n\n    def test_step(self, batch, batch_idx):\n        return self._split_preds_and_get_loss(\n            batch, add_preds=True, loss_label=\"test_loss\", log_loss=True, training=False\n        )\n\n    @staticmethod\n    def _split_tensor(outputs, label) -> Tuple[np.ndarray, np.ndarray]:\n        encoded_all, unencoded_all = [], []\n        for x in outputs:\n            # the first half is unencoded, the second is encoded\n            total = x[label]\n            unencoded_all.append(total[: total.shape[0] // 2])\n            encoded_all.append(total[total.shape[0] // 2:])\n        return (\n            torch.cat(unencoded_all).detach().cpu().numpy(),\n            torch.cat(encoded_all).detach().cpu().numpy(),\n        )\n\n    def _interpretable_metrics(self, outputs, input_prefix: str, output_prefix: str) -> Dict:\n\n        output_dict = {}\n\n        if self.hparams.forecast:\n            u_labels, e_labels = self._split_tensor(\n                outputs, f\"{input_prefix}label\")\n\n            u_preds, e_preds = self._split_tensor(\n                outputs, f\"{input_prefix}pred\")\n        else:\n            u_preds = torch.cat([x[f\"{input_prefix}pred\"]\n                                for x in outputs]).detach().cpu().numpy()\n            u_labels = (\n                torch.cat([x[f\"{input_prefix}label\"]\n                          for x in outputs]).detach().cpu().numpy()\n            )\n\n        output_dict.update(\n            self._output_metrics(\n                u_preds, u_labels, f\"unencoded_{output_prefix}{input_prefix}\")\n        )\n\n        if self.hparams.forecast:\n            output_dict.update(\n                self._output_metrics(\n                    e_preds, e_labels, f\"encoded_{output_prefix}{input_prefix}\")\n            )\n\n        return output_dict\n\n    def validation_epoch_end(self, outputs):\n        avg_loss = torch.stack([x[\"val_loss\"] for x in outputs]).mean()\n        logs = {\"val_loss\": avg_loss}\n        if self.hparams.forecast:\n            encoder_pred = (\n                torch.cat(\n                    [torch.flatten(x[\"encoder_prediction\"], start_dim=1) for x in outputs], dim=0,\n                )\n                .detach()\n                .cpu()\n                .numpy()\n            )\n            encoder_target = (\n                torch.cat(\n                    [torch.flatten(x[\"encoder_target\"], start_dim=1) for x in outputs], dim=0,\n                )\n                .detach()\n                .cpu()\n                .numpy()\n            )\n\n            logs[\"val_encoder_mae\"] = mean_absolute_error(\n                encoder_target, encoder_pred)\n\n        if self.hparams.multi_headed:\n            logs.update(self._interpretable_metrics(\n                outputs, \"global_\", \"val_\"))\n            logs.update(self._interpretable_metrics(outputs, \"kenya_\", \"val_\"))\n        else:\n            logs.update(self._interpretable_metrics(outputs, \"\", \"val_\"))\n        return {\"val_loss\": avg_loss, \"log\": logs}\n\n    def test_epoch_end(self, outputs):\n\n        avg_loss = torch.stack([x[\"test_loss\"] for x in outputs]).mean().item()\n        output_dict = {\"val_loss\": avg_loss}\n\n        if self.hparams.forecast:\n            encoder_pred = (\n                torch.cat(\n                    [torch.flatten(x[\"encoder_prediction\"], start_dim=1) for x in outputs], dim=0,\n                )\n                .detach()\n                .cpu()\n                .numpy()\n            )\n            encoder_target = (\n                torch.cat(\n                    [torch.flatten(x[\"encoder_target\"], start_dim=1) for x in outputs], dim=0,\n                )\n                .detach()\n                .cpu()\n                .numpy()\n            )\n\n            output_dict[\"test_encoder_mae\"] = mean_absolute_error(\n                encoder_target, encoder_pred)\n\n        if self.hparams.multi_headed:\n            output_dict.update(self._interpretable_metrics(\n                outputs, \"global_\", \"test_\"))\n            output_dict.update(self._interpretable_metrics(\n                outputs, \"kenya_\", \"test_\"))\n        else:\n            output_dict.update(\n                self._interpretable_metrics(outputs, \"\", \"test_\"))\n\n        return {\"progress_bar\": output_dict}\n\n    @staticmethod\n    def add_model_specific_args(parent_parser: ArgumentParser) -> ArgumentParser:\n\n        parser = ArgumentParser(parents=[parent_parser], add_help=False)\n\n        parser_args: Dict[str, Tuple[Type, Any]] = {\n            # assumes this is being run from \"scripts\"\n            \"--data_folder\": (str, str(Path(\"../data\"))),\n            \"--learning_rate\": (float, 0.001),\n            \"--batch_size\": (int, 64),\n            \"--input_months\": (int, 5),\n            \"--alpha\": (float, 10),\n            \"--noise_factor\": (float, 0.1),\n        }\n\n        for key, val in parser_args.items():\n            parser.add_argument(key, type=val[0], default=val[1])\n\n        parser.add_argument(\"--remove_b1_b10\",\n                            dest=\"remove_b1_b10\", action=\"store_true\")\n        parser.add_argument(\n            \"--keep_b1_b10\", dest=\"remove_b1_b10\", action=\"store_false\")\n        parser.set_defaults(remove_b1_b10=True)\n\n        parser.add_argument(\"--forecast\", dest=\"forecast\", action=\"store_true\")\n        parser.add_argument(\"--do_not_forecast\",\n                            dest=\"forecast\", action=\"store_false\")\n        parser.set_defaults(forecast=True)\n\n        parser.add_argument(\"--cache\", dest=\"cache\", action=\"store_true\")\n        parser.add_argument(\"--do_not_cache\", dest=\"cache\",\n                            action=\"store_false\")\n        parser.set_defaults(cache=True)\n\n        parser.add_argument(\"--include_geowiki\",\n                            dest=\"include_geowiki\", action=\"store_true\")\n        parser.add_argument(\"--exclude_geowiki\",\n                            dest=\"include_geowiki\", action=\"store_false\")\n        parser.set_defaults(include_geowiki=True)\n\n        parser.add_argument(\"--upsample\", dest=\"upsample\", action=\"store_true\")\n        parser.add_argument(\"--do_not_upsample\",\n                            dest=\"upsample\", action=\"store_false\")\n        parser.set_defaults(upsample=True)\n\n        classifier_parser = Classifier.add_model_specific_args(parser)\n        return Forecaster.add_model_specific_args(classifier_parser)\n",
  "history_output" : "",
  "history_begin_time" : 1647347336009,
  "history_end_time" : 1647347339632,
  "history_notes" : null,
  "history_process" : "9ardvx",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "5igad68bvdx",
  "history_input" : "from argparse import ArgumentParser, Namespace\nfrom pathlib import Path\nimport numpy as np\nimport xarray as xr\nfrom tqdm import tqdm\n\nimport torch\nfrom torch.nn import functional as F\nfrom torch.utils.data import DataLoader\n\nimport pytorch_lightning as pl\n\nfrom sklearn.metrics import (\n    roc_auc_score,\n    accuracy_score,\n    precision_score,\n    recall_score,\n    f1_score,\n    mean_absolute_error,\n)\n\nfrom src_models_data import CropDataset\nfrom src_models_utils import tif_to_np, preds_to_xr\nfrom src_utils import set_seed\nfrom src_models_forecaster import Forecaster\nfrom src_models_classifier import Classifier\nfrom src_config import PROBABILITY_THRESHOLD\n\nfrom typing import cast, Callable, Tuple, Dict, Any, Type, Optional, List, Union\n\n\nclass Model(pl.LightningModule):\n    r\"\"\"\n    An model for annual and in-season crop mapping. This model consists of a\n    forecaster.Forecaster and a classifier.Classifier - it will require the arguments\n    required by those models too.\n\n    hparams\n    --------\n    The default values for these parameters are set in add_model_specific_args\n\n    :param hparams.data_folder: The path to the data. Default (assumes the model\n        is being run from the scripts directory) = \"../data\"\n    :param hparams.learning_rate: The learning rate. Default = 0.001\n    :param hparams.batch_size: The batch size. Default = 64\n    :param hparams.input_months: The number of input months to pass to the model. If\n        hparams.forecast is True, the remaining months will be forecasted. Otherwise, only the\n        partial timeseries will be passed to the classifier. Default = 5\n    :param hparams.alpha: The weight to use when adding the global and local losses. This\n        parameter is only used if hparams.multi_headed is True. Default = 10\n    :param hparams.noise_factor: The standard deviation of the random noise to add to the\n        raw inputs to the classifier. Default = 0.1\n    :param hparams.remove_b1_b10: Whether or not to remove the B1 and B10 bands. Default = True\n    :param hparams.forecast: Whether or not to forecast the partial time series. Default = True\n    :param hparams.cache: Whether to load all the data into memory during training. Default = True\n    :param hparams.include_geowiki: Whether to include the global GeoWiki dataset during\n        training. Default = True\n    :param hparams.upsample: Whether to oversample the under-represented class so that each class\n        is equally represented in the training and validation dataset. Default = True\n    \"\"\"\n\n    def __init__(self, hparams: Namespace) -> None:\n        super().__init__()\n        set_seed()\n        self.hparams = hparams\n\n        self.data_folder = Path(hparams.data_folder)\n\n        dataset = self.get_dataset(subset=\"training\", cache=False)\n        self.num_outputs = dataset.num_output_classes\n        self.num_timesteps = dataset.num_timesteps\n        self.input_size = dataset.num_input_features\n\n        # we save the normalizing dict because we calculate weighted\n        # normalization values based on the datasets we combine.\n        # The number of instances per dataset (and therefore the weights) can\n        # vary between the train / test / val sets - this ensures the normalizing\n        # dict stays constant between them\n        self.normalizing_dict = dataset.normalizing_dict\n\n        if self.hparams.forecast:\n            num_output_timesteps = self.num_timesteps - self.hparams.input_months\n            print(\n                f\"Predicting {num_output_timesteps} timesteps in the forecaster\")\n            self.forecaster = Forecaster(\n                num_bands=self.input_size, output_timesteps=num_output_timesteps, hparams=hparams,\n            )\n\n            self.forecaster_loss = F.smooth_l1_loss\n\n        self.classifier = Classifier(\n            input_size=self.input_size, hparams=hparams)\n        self.global_loss_function: Callable = F.binary_cross_entropy\n        self.local_loss_function: Callable = F.binary_cross_entropy\n\n    def forward(self, x: torch.Tensor) -> Union[torch.Tensor, Tuple[torch.Tensor, torch.Tensor]]:\n        # To keep the ABC happy\n        return self.classifier(x)\n\n    def configure_optimizers(self):\n        return torch.optim.Adam(self.parameters(), lr=self.hparams.learning_rate)\n\n    def get_dataset(\n        self, subset: str, normalizing_dict: Optional[Dict] = None, cache: Optional[bool] = None,\n    ) -> CropDataset:\n        return CropDataset(\n            data_folder=self.data_folder,\n            subset=subset,\n            remove_b1_b10=self.hparams.remove_b1_b10,\n            normalizing_dict=normalizing_dict,\n            include_geowiki=self.hparams.include_geowiki if subset != \"testing\" else False,\n            cache=self.hparams.cache if cache is None else cache,\n            upsample=self.hparams.upsample if subset != \"testing\" else False,\n            noise_factor=self.hparams.noise_factor if subset != \"testing\" else 0,\n        )\n\n    def train_dataloader(self):\n        return DataLoader(\n            self.get_dataset(subset=\"training\"), shuffle=True, batch_size=self.hparams.batch_size,\n        )\n\n    def val_dataloader(self):\n        return DataLoader(\n            self.get_dataset(subset=\"validation\",\n                             normalizing_dict=self.normalizing_dict,),\n            batch_size=self.hparams.batch_size,\n        )\n\n    def test_dataloader(self):\n        return DataLoader(\n            self.get_dataset(subset=\"testing\",\n                             normalizing_dict=self.normalizing_dict,),\n            batch_size=self.hparams.batch_size,\n        )\n\n    def predict(\n        self,\n        path_to_file: Path,\n        with_forecaster: bool,\n        batch_size: int = 64,\n        add_ndvi: bool = True,\n        add_ndwi: bool = False,\n        nan_fill: float = 0,\n        days_per_timestep: int = 30,\n        local_head: bool = True,\n        use_gpu: bool = True,\n    ) -> xr.Dataset:\n\n        # check if a GPU is available, and if it is\n        # move the model onto the GPU\n        device: Optional[torch.device] = None\n        if use_gpu:\n            use_cuda = torch.cuda.is_available()\n            if not use_cuda:\n                print(\"No GPU - not using one\")\n            device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n            self.to(device)\n\n        self.eval()\n\n        input_data = tif_to_np(\n            path_to_file,\n            add_ndvi=add_ndvi,\n            add_ndwi=add_ndwi,\n            nan=nan_fill,\n            normalizing_dict=self.normalizing_dict,\n            days_per_timestep=days_per_timestep,\n        )\n\n        if with_forecaster:\n            input_data.x = input_data.x[:, : self.hparams.input_months, :]\n\n        predictions: List[np.ndarray] = []\n        cur_i = 0\n\n        pbar = tqdm(total=input_data.x.shape[0] - 1)\n        while cur_i < (input_data.x.shape[0] - 1):\n\n            batch_x_np = input_data.x[cur_i: cur_i + batch_size]\n            if self.hparams.remove_b1_b10:\n                batch_x_np = CropDataset._remove_bands(batch_x_np)\n            batch_x = torch.from_numpy(batch_x_np).float()\n\n            if use_gpu and (device is not None):\n                batch_x = batch_x.to(device)\n\n            with torch.no_grad():\n                if with_forecaster:\n                    batch_x_next = self.forecaster(batch_x)\n                    batch_x = torch.cat((batch_x, batch_x_next), dim=1)\n\n                batch_preds = self.classifier(batch_x)\n\n                if self.hparams.multi_headed:\n                    global_preds, local_preds = batch_preds\n\n                    if local_head:\n                        batch_preds = local_preds\n                    else:\n                        batch_preds = global_preds\n\n                # back to the CPU, if necessary\n                batch_preds = batch_preds.cpu()\n\n            predictions.append(cast(torch.Tensor, batch_preds).numpy())\n            cur_i += batch_size\n            pbar.update(batch_size)\n\n        all_preds = np.concatenate(predictions, axis=0)\n        if len(all_preds.shape) == 1:\n            all_preds = np.expand_dims(all_preds, axis=-1)\n\n        return preds_to_xr(all_preds, lats=input_data.lat, lons=input_data.lon,)\n\n    def _output_metrics(\n        self, preds: np.ndarray, labels: np.ndarray, prefix: str = \"\"\n    ) -> Dict[str, float]:\n\n        if len(preds) == 0:\n            # sometimes this happens in the warmup\n            return {}\n\n        output_dict: Dict[str, float] = {}\n        if not (labels == labels[0]).all():\n            # This can happen when lightning does its warm up on a subset of the\n            # validation data\n            output_dict[f\"{prefix}roc_auc_score\"] = roc_auc_score(\n                labels, preds)\n\n        preds = (preds > PROBABILITY_THRESHOLD).astype(int)\n\n        output_dict[f\"{prefix}precision_score\"] = precision_score(\n            labels, preds)\n        output_dict[f\"{prefix}recall_score\"] = recall_score(labels, preds)\n        output_dict[f\"{prefix}f1_score\"] = f1_score(labels, preds)\n        output_dict[f\"{prefix}accuracy\"] = accuracy_score(labels, preds)\n\n        return output_dict\n\n    def add_noise(self, x: torch.Tensor, training: bool) -> torch.Tensor:\n        if (self.hparams.noise_factor == 0) or (not training):\n            return x\n\n        # expect input to be of shape [timesteps, bands]\n        # and to be normalized with mean 0, std=1\n        # if its not, it means no norm_dict was passed, so lets\n        # just assume std=1\n        noise = torch.normal(0, 1, size=x.shape).float() * \\\n            self.hparams.noise_factor\n\n        # the added noise is the same per band, so that the temporal relationships\n        # are preserved\n        # noise_per_timesteps = noise.repeat(x.shape[0], 1)\n        return x + noise\n\n    def _split_preds_and_get_loss(\n        self, batch, add_preds: bool, loss_label: str, log_loss: bool, training: bool\n    ) -> Dict:\n\n        x, label, is_global = batch\n\n        input_to_encode = x[:, : self.hparams.input_months, :]\n\n        if self.hparams.forecast:\n            # we will predict every timestep except the first one\n            output_to_predict = x[:, 1:, :]\n            encoder_output = self.forecaster(input_to_encode)\n            encoder_loss = self.forecaster_loss(\n                encoder_output, output_to_predict)\n            loss: Union[float, torch.Tensor] = encoder_loss\n\n            final_encoded_input = torch.cat(\n                (\n                    (\n                        self.add_noise(input_to_encode, training),\n                        # -1 because the encoder output has no value for the 0th\n                        # timestep\n                        encoder_output[:, self.hparams.input_months - 1:, :],\n                    )\n                ),\n                dim=1,\n            )\n\n            output_dict = {}\n            if add_preds:\n                output_dict.update(\n                    {\"encoder_prediction\": encoder_output,\n                        \"encoder_target\": output_to_predict, }\n                )\n            if log_loss:\n                output_dict[\"log\"] = {}\n\n            # we now repeat label and is_global\n            x = torch.cat((self.add_noise(x, training),\n                          final_encoded_input), dim=0)\n            label = torch.cat((label, label), dim=0)\n            is_global = torch.cat((is_global, is_global), dim=0)\n        else:\n            loss = 0\n            output_dict = {}\n            if log_loss:\n                output_dict[\"log\"] = {}\n            x = self.add_noise(input_to_encode, training=training)\n\n        if self.hparams.multi_headed:\n            org_global_preds, local_preds = self.classifier(x)\n            global_preds = org_global_preds[is_global != 0]\n            global_labels = label[is_global != 0]\n\n            local_preds = local_preds[is_global == 0]\n            local_labels = label[is_global == 0]\n\n            if local_preds.shape[0] > 0:\n                local_loss = self.local_loss_function(\n                    local_preds.squeeze(-1), local_labels,)\n                loss += local_loss\n\n            if global_preds.shape[0] > 0:\n                global_loss = self.global_loss_function(\n                    global_preds.squeeze(-1), global_labels,)\n\n                num_local_labels = local_preds.shape[0]\n                if num_local_labels == 0:\n                    alpha = 1\n                else:\n                    ratio = global_preds.shape[0] / num_local_labels\n                    alpha = ratio / self.hparams.alpha\n                loss += alpha * global_loss\n\n            output_dict[loss_label] = loss\n            if log_loss:\n                output_dict[\"log\"][loss_label] = loss\n            if add_preds:\n                output_dict.update(\n                    {\n                        \"global_pred\": global_preds,\n                        \"global_label\": global_labels,\n                        \"kenya_pred\": local_preds,\n                        \"kenya_label\": local_labels,\n                    }\n                )\n            return output_dict\n        else:\n            preds = cast(torch.Tensor, self.classifier(x))\n\n            loss += self.global_loss_function(\n                input=preds.squeeze(-1), target=label,)\n\n            output_dict = {loss_label: loss}\n            if log_loss:\n                output_dict[\"log\"][loss_label] = loss\n            if add_preds:\n                output_dict.update({\"pred\": preds, \"label\": label})\n            return output_dict\n\n    def training_step(self, batch, batch_idx):\n        return self._split_preds_and_get_loss(\n            batch, add_preds=False, loss_label=\"loss\", log_loss=True, training=True\n        )\n\n    def validation_step(self, batch, batch_idx):\n        return self._split_preds_and_get_loss(\n            batch, add_preds=True, loss_label=\"val_loss\", log_loss=True, training=False\n        )\n\n    def test_step(self, batch, batch_idx):\n        return self._split_preds_and_get_loss(\n            batch, add_preds=True, loss_label=\"test_loss\", log_loss=True, training=False\n        )\n\n    @staticmethod\n    def _split_tensor(outputs, label) -> Tuple[np.ndarray, np.ndarray]:\n        encoded_all, unencoded_all = [], []\n        for x in outputs:\n            # the first half is unencoded, the second is encoded\n            total = x[label]\n            unencoded_all.append(total[: total.shape[0] // 2])\n            encoded_all.append(total[total.shape[0] // 2:])\n        return (\n            torch.cat(unencoded_all).detach().cpu().numpy(),\n            torch.cat(encoded_all).detach().cpu().numpy(),\n        )\n\n    def _interpretable_metrics(self, outputs, input_prefix: str, output_prefix: str) -> Dict:\n\n        output_dict = {}\n\n        if self.hparams.forecast:\n            u_labels, e_labels = self._split_tensor(\n                outputs, f\"{input_prefix}label\")\n\n            u_preds, e_preds = self._split_tensor(\n                outputs, f\"{input_prefix}pred\")\n        else:\n            u_preds = torch.cat([x[f\"{input_prefix}pred\"]\n                                for x in outputs]).detach().cpu().numpy()\n            u_labels = (\n                torch.cat([x[f\"{input_prefix}label\"]\n                          for x in outputs]).detach().cpu().numpy()\n            )\n\n        output_dict.update(\n            self._output_metrics(\n                u_preds, u_labels, f\"unencoded_{output_prefix}{input_prefix}\")\n        )\n\n        if self.hparams.forecast:\n            output_dict.update(\n                self._output_metrics(\n                    e_preds, e_labels, f\"encoded_{output_prefix}{input_prefix}\")\n            )\n\n        return output_dict\n\n    def validation_epoch_end(self, outputs):\n        avg_loss = torch.stack([x[\"val_loss\"] for x in outputs]).mean()\n        logs = {\"val_loss\": avg_loss}\n        if self.hparams.forecast:\n            encoder_pred = (\n                torch.cat(\n                    [torch.flatten(x[\"encoder_prediction\"], start_dim=1) for x in outputs], dim=0,\n                )\n                .detach()\n                .cpu()\n                .numpy()\n            )\n            encoder_target = (\n                torch.cat(\n                    [torch.flatten(x[\"encoder_target\"], start_dim=1) for x in outputs], dim=0,\n                )\n                .detach()\n                .cpu()\n                .numpy()\n            )\n\n            logs[\"val_encoder_mae\"] = mean_absolute_error(\n                encoder_target, encoder_pred)\n\n        if self.hparams.multi_headed:\n            logs.update(self._interpretable_metrics(\n                outputs, \"global_\", \"val_\"))\n            logs.update(self._interpretable_metrics(outputs, \"kenya_\", \"val_\"))\n        else:\n            logs.update(self._interpretable_metrics(outputs, \"\", \"val_\"))\n        return {\"val_loss\": avg_loss, \"log\": logs}\n\n    def test_epoch_end(self, outputs):\n\n        avg_loss = torch.stack([x[\"test_loss\"] for x in outputs]).mean().item()\n        output_dict = {\"val_loss\": avg_loss}\n\n        if self.hparams.forecast:\n            encoder_pred = (\n                torch.cat(\n                    [torch.flatten(x[\"encoder_prediction\"], start_dim=1) for x in outputs], dim=0,\n                )\n                .detach()\n                .cpu()\n                .numpy()\n            )\n            encoder_target = (\n                torch.cat(\n                    [torch.flatten(x[\"encoder_target\"], start_dim=1) for x in outputs], dim=0,\n                )\n                .detach()\n                .cpu()\n                .numpy()\n            )\n\n            output_dict[\"test_encoder_mae\"] = mean_absolute_error(\n                encoder_target, encoder_pred)\n\n        if self.hparams.multi_headed:\n            output_dict.update(self._interpretable_metrics(\n                outputs, \"global_\", \"test_\"))\n            output_dict.update(self._interpretable_metrics(\n                outputs, \"kenya_\", \"test_\"))\n        else:\n            output_dict.update(\n                self._interpretable_metrics(outputs, \"\", \"test_\"))\n\n        return {\"progress_bar\": output_dict}\n\n    @staticmethod\n    def add_model_specific_args(parent_parser: ArgumentParser) -> ArgumentParser:\n\n        parser = ArgumentParser(parents=[parent_parser], add_help=False)\n\n        parser_args: Dict[str, Tuple[Type, Any]] = {\n            # assumes this is being run from \"scripts\"\n            \"--data_folder\": (str, str(Path(\"../data\"))),\n            \"--learning_rate\": (float, 0.001),\n            \"--batch_size\": (int, 64),\n            \"--input_months\": (int, 5),\n            \"--alpha\": (float, 10),\n            \"--noise_factor\": (float, 0.1),\n        }\n\n        for key, val in parser_args.items():\n            parser.add_argument(key, type=val[0], default=val[1])\n\n        parser.add_argument(\"--remove_b1_b10\",\n                            dest=\"remove_b1_b10\", action=\"store_true\")\n        parser.add_argument(\n            \"--keep_b1_b10\", dest=\"remove_b1_b10\", action=\"store_false\")\n        parser.set_defaults(remove_b1_b10=True)\n\n        parser.add_argument(\"--forecast\", dest=\"forecast\", action=\"store_true\")\n        parser.add_argument(\"--do_not_forecast\",\n                            dest=\"forecast\", action=\"store_false\")\n        parser.set_defaults(forecast=True)\n\n        parser.add_argument(\"--cache\", dest=\"cache\", action=\"store_true\")\n        parser.add_argument(\"--do_not_cache\", dest=\"cache\",\n                            action=\"store_false\")\n        parser.set_defaults(cache=True)\n\n        parser.add_argument(\"--include_geowiki\",\n                            dest=\"include_geowiki\", action=\"store_true\")\n        parser.add_argument(\"--exclude_geowiki\",\n                            dest=\"include_geowiki\", action=\"store_false\")\n        parser.set_defaults(include_geowiki=True)\n\n        parser.add_argument(\"--upsample\", dest=\"upsample\", action=\"store_true\")\n        parser.add_argument(\"--do_not_upsample\",\n                            dest=\"upsample\", action=\"store_false\")\n        parser.set_defaults(upsample=True)\n\n        classifier_parser = Classifier.add_model_specific_args(parser)\n        return Forecaster.add_model_specific_args(classifier_parser)\n",
  "history_output" : "",
  "history_begin_time" : 1647347273564,
  "history_end_time" : 1647347277513,
  "history_notes" : null,
  "history_process" : "9ardvx",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "tbg562spkpn",
  "history_input" : "from argparse import ArgumentParser, Namespace\nfrom pathlib import Path\nimport numpy as np\nimport xarray as xr\nfrom tqdm import tqdm\n\nimport torch\nfrom torch.nn import functional as F\nfrom torch.utils.data import DataLoader\n\nimport pytorch_lightning as pl\n\nfrom sklearn.metrics import (\n    roc_auc_score,\n    accuracy_score,\n    precision_score,\n    recall_score,\n    f1_score,\n    mean_absolute_error,\n)\n\nfrom src_models_data import CropDataset\nfrom src_models_utils import tif_to_np, preds_to_xr\nfrom src_utils import set_seed\nfrom src_models_forecaster import Forecaster\nfrom src_models_classifier import Classifier\nfrom src_config import PROBABILITY_THRESHOLD\n\nfrom typing import cast, Callable, Tuple, Dict, Any, Type, Optional, List, Union\n\n\nclass Model(pl.LightningModule):\n    r\"\"\"\n    An model for annual and in-season crop mapping. This model consists of a\n    forecaster.Forecaster and a classifier.Classifier - it will require the arguments\n    required by those models too.\n\n    hparams\n    --------\n    The default values for these parameters are set in add_model_specific_args\n\n    :param hparams.data_folder: The path to the data. Default (assumes the model\n        is being run from the scripts directory) = \"../data\"\n    :param hparams.learning_rate: The learning rate. Default = 0.001\n    :param hparams.batch_size: The batch size. Default = 64\n    :param hparams.input_months: The number of input months to pass to the model. If\n        hparams.forecast is True, the remaining months will be forecasted. Otherwise, only the\n        partial timeseries will be passed to the classifier. Default = 5\n    :param hparams.alpha: The weight to use when adding the global and local losses. This\n        parameter is only used if hparams.multi_headed is True. Default = 10\n    :param hparams.noise_factor: The standard deviation of the random noise to add to the\n        raw inputs to the classifier. Default = 0.1\n    :param hparams.remove_b1_b10: Whether or not to remove the B1 and B10 bands. Default = True\n    :param hparams.forecast: Whether or not to forecast the partial time series. Default = True\n    :param hparams.cache: Whether to load all the data into memory during training. Default = True\n    :param hparams.include_geowiki: Whether to include the global GeoWiki dataset during\n        training. Default = True\n    :param hparams.upsample: Whether to oversample the under-represented class so that each class\n        is equally represented in the training and validation dataset. Default = True\n    \"\"\"\n\n    def __init__(self, hparams: Namespace) -> None:\n        super().__init__()\n        set_seed()\n        self.hparams = hparams\n\n        self.data_folder = Path(hparams.data_folder)\n\n        dataset = self.get_dataset(subset=\"training\", cache=False)\n        self.num_outputs = dataset.num_output_classes\n        self.num_timesteps = dataset.num_timesteps\n        self.input_size = dataset.num_input_features\n\n        # we save the normalizing dict because we calculate weighted\n        # normalization values based on the datasets we combine.\n        # The number of instances per dataset (and therefore the weights) can\n        # vary between the train / test / val sets - this ensures the normalizing\n        # dict stays constant between them\n        self.normalizing_dict = dataset.normalizing_dict\n\n        if self.hparams.forecast:\n            num_output_timesteps = self.num_timesteps - self.hparams.input_months\n            print(\n                f\"Predicting {num_output_timesteps} timesteps in the forecaster\")\n            self.forecaster = Forecaster(\n                num_bands=self.input_size, output_timesteps=num_output_timesteps, hparams=hparams,\n            )\n\n            self.forecaster_loss = F.smooth_l1_loss\n\n        self.classifier = Classifier(\n            input_size=self.input_size, hparams=hparams)\n        self.global_loss_function: Callable = F.binary_cross_entropy\n        self.local_loss_function: Callable = F.binary_cross_entropy\n\n    def forward(self, x: torch.Tensor) -> Union[torch.Tensor, Tuple[torch.Tensor, torch.Tensor]]:\n        # To keep the ABC happy\n        return self.classifier(x)\n\n    def configure_optimizers(self):\n        return torch.optim.Adam(self.parameters(), lr=self.hparams.learning_rate)\n\n    def get_dataset(\n        self, subset: str, normalizing_dict: Optional[Dict] = None, cache: Optional[bool] = None,\n    ) -> CropDataset:\n        return CropDataset(\n            data_folder=self.data_folder,\n            subset=subset,\n            remove_b1_b10=self.hparams.remove_b1_b10,\n            normalizing_dict=normalizing_dict,\n            include_geowiki=self.hparams.include_geowiki if subset != \"testing\" else False,\n            cache=self.hparams.cache if cache is None else cache,\n            upsample=self.hparams.upsample if subset != \"testing\" else False,\n            noise_factor=self.hparams.noise_factor if subset != \"testing\" else 0,\n        )\n\n    def train_dataloader(self):\n        return DataLoader(\n            self.get_dataset(subset=\"training\"), shuffle=True, batch_size=self.hparams.batch_size,\n        )\n\n    def val_dataloader(self):\n        return DataLoader(\n            self.get_dataset(subset=\"validation\",\n                             normalizing_dict=self.normalizing_dict,),\n            batch_size=self.hparams.batch_size,\n        )\n\n    def test_dataloader(self):\n        return DataLoader(\n            self.get_dataset(subset=\"testing\",\n                             normalizing_dict=self.normalizing_dict,),\n            batch_size=self.hparams.batch_size,\n        )\n\n    def predict(\n        self,\n        path_to_file: Path,\n        with_forecaster: bool,\n        batch_size: int = 64,\n        add_ndvi: bool = True,\n        add_ndwi: bool = False,\n        nan_fill: float = 0,\n        days_per_timestep: int = 30,\n        local_head: bool = True,\n        use_gpu: bool = True,\n    ) -> xr.Dataset:\n\n        # check if a GPU is available, and if it is\n        # move the model onto the GPU\n        device: Optional[torch.device] = None\n        if use_gpu:\n            use_cuda = torch.cuda.is_available()\n            if not use_cuda:\n                print(\"No GPU - not using one\")\n            device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n            self.to(device)\n\n        self.eval()\n\n        input_data = tif_to_np(\n            path_to_file,\n            add_ndvi=add_ndvi,\n            add_ndwi=add_ndwi,\n            nan=nan_fill,\n            normalizing_dict=self.normalizing_dict,\n            days_per_timestep=days_per_timestep,\n        )\n\n        if with_forecaster:\n            input_data.x = input_data.x[:, : self.hparams.input_months, :]\n\n        predictions: List[np.ndarray] = []\n        cur_i = 0\n\n        pbar = tqdm(total=input_data.x.shape[0] - 1)\n        while cur_i < (input_data.x.shape[0] - 1):\n\n            batch_x_np = input_data.x[cur_i: cur_i + batch_size]\n            if self.hparams.remove_b1_b10:\n                batch_x_np = CropDataset._remove_bands(batch_x_np)\n            batch_x = torch.from_numpy(batch_x_np).float()\n\n            if use_gpu and (device is not None):\n                batch_x = batch_x.to(device)\n\n            with torch.no_grad():\n                if with_forecaster:\n                    batch_x_next = self.forecaster(batch_x)\n                    batch_x = torch.cat((batch_x, batch_x_next), dim=1)\n\n                batch_preds = self.classifier(batch_x)\n\n                if self.hparams.multi_headed:\n                    global_preds, local_preds = batch_preds\n\n                    if local_head:\n                        batch_preds = local_preds\n                    else:\n                        batch_preds = global_preds\n\n                # back to the CPU, if necessary\n                batch_preds = batch_preds.cpu()\n\n            predictions.append(cast(torch.Tensor, batch_preds).numpy())\n            cur_i += batch_size\n            pbar.update(batch_size)\n\n        all_preds = np.concatenate(predictions, axis=0)\n        if len(all_preds.shape) == 1:\n            all_preds = np.expand_dims(all_preds, axis=-1)\n\n        return preds_to_xr(all_preds, lats=input_data.lat, lons=input_data.lon,)\n\n    def _output_metrics(\n        self, preds: np.ndarray, labels: np.ndarray, prefix: str = \"\"\n    ) -> Dict[str, float]:\n\n        if len(preds) == 0:\n            # sometimes this happens in the warmup\n            return {}\n\n        output_dict: Dict[str, float] = {}\n        if not (labels == labels[0]).all():\n            # This can happen when lightning does its warm up on a subset of the\n            # validation data\n            output_dict[f\"{prefix}roc_auc_score\"] = roc_auc_score(\n                labels, preds)\n\n        preds = (preds > PROBABILITY_THRESHOLD).astype(int)\n\n        output_dict[f\"{prefix}precision_score\"] = precision_score(\n            labels, preds)\n        output_dict[f\"{prefix}recall_score\"] = recall_score(labels, preds)\n        output_dict[f\"{prefix}f1_score\"] = f1_score(labels, preds)\n        output_dict[f\"{prefix}accuracy\"] = accuracy_score(labels, preds)\n\n        return output_dict\n\n    def add_noise(self, x: torch.Tensor, training: bool) -> torch.Tensor:\n        if (self.hparams.noise_factor == 0) or (not training):\n            return x\n\n        # expect input to be of shape [timesteps, bands]\n        # and to be normalized with mean 0, std=1\n        # if its not, it means no norm_dict was passed, so lets\n        # just assume std=1\n        noise = torch.normal(0, 1, size=x.shape).float() * \\\n            self.hparams.noise_factor\n\n        # the added noise is the same per band, so that the temporal relationships\n        # are preserved\n        # noise_per_timesteps = noise.repeat(x.shape[0], 1)\n        return x + noise\n\n    def _split_preds_and_get_loss(\n        self, batch, add_preds: bool, loss_label: str, log_loss: bool, training: bool\n    ) -> Dict:\n\n        x, label, is_global = batch\n\n        input_to_encode = x[:, : self.hparams.input_months, :]\n\n        if self.hparams.forecast:\n            # we will predict every timestep except the first one\n            output_to_predict = x[:, 1:, :]\n            encoder_output = self.forecaster(input_to_encode)\n            encoder_loss = self.forecaster_loss(\n                encoder_output, output_to_predict)\n            loss: Union[float, torch.Tensor] = encoder_loss\n\n            final_encoded_input = torch.cat(\n                (\n                    (\n                        self.add_noise(input_to_encode, training),\n                        # -1 because the encoder output has no value for the 0th\n                        # timestep\n                        encoder_output[:, self.hparams.input_months - 1:, :],\n                    )\n                ),\n                dim=1,\n            )\n\n            output_dict = {}\n            if add_preds:\n                output_dict.update(\n                    {\"encoder_prediction\": encoder_output,\n                        \"encoder_target\": output_to_predict, }\n                )\n            if log_loss:\n                output_dict[\"log\"] = {}\n\n            # we now repeat label and is_global\n            x = torch.cat((self.add_noise(x, training),\n                          final_encoded_input), dim=0)\n            label = torch.cat((label, label), dim=0)\n            is_global = torch.cat((is_global, is_global), dim=0)\n        else:\n            loss = 0\n            output_dict = {}\n            if log_loss:\n                output_dict[\"log\"] = {}\n            x = self.add_noise(input_to_encode, training=training)\n\n        if self.hparams.multi_headed:\n            org_global_preds, local_preds = self.classifier(x)\n            global_preds = org_global_preds[is_global != 0]\n            global_labels = label[is_global != 0]\n\n            local_preds = local_preds[is_global == 0]\n            local_labels = label[is_global == 0]\n\n            if local_preds.shape[0] > 0:\n                local_loss = self.local_loss_function(\n                    local_preds.squeeze(-1), local_labels,)\n                loss += local_loss\n\n            if global_preds.shape[0] > 0:\n                global_loss = self.global_loss_function(\n                    global_preds.squeeze(-1), global_labels,)\n\n                num_local_labels = local_preds.shape[0]\n                if num_local_labels == 0:\n                    alpha = 1\n                else:\n                    ratio = global_preds.shape[0] / num_local_labels\n                    alpha = ratio / self.hparams.alpha\n                loss += alpha * global_loss\n\n            output_dict[loss_label] = loss\n            if log_loss:\n                output_dict[\"log\"][loss_label] = loss\n            if add_preds:\n                output_dict.update(\n                    {\n                        \"global_pred\": global_preds,\n                        \"global_label\": global_labels,\n                        \"kenya_pred\": local_preds,\n                        \"kenya_label\": local_labels,\n                    }\n                )\n            return output_dict\n        else:\n            preds = cast(torch.Tensor, self.classifier(x))\n\n            loss += self.global_loss_function(\n                input=preds.squeeze(-1), target=label,)\n\n            output_dict = {loss_label: loss}\n            if log_loss:\n                output_dict[\"log\"][loss_label] = loss\n            if add_preds:\n                output_dict.update({\"pred\": preds, \"label\": label})\n            return output_dict\n\n    def training_step(self, batch, batch_idx):\n        return self._split_preds_and_get_loss(\n            batch, add_preds=False, loss_label=\"loss\", log_loss=True, training=True\n        )\n\n    def validation_step(self, batch, batch_idx):\n        return self._split_preds_and_get_loss(\n            batch, add_preds=True, loss_label=\"val_loss\", log_loss=True, training=False\n        )\n\n    def test_step(self, batch, batch_idx):\n        return self._split_preds_and_get_loss(\n            batch, add_preds=True, loss_label=\"test_loss\", log_loss=True, training=False\n        )\n\n    @staticmethod\n    def _split_tensor(outputs, label) -> Tuple[np.ndarray, np.ndarray]:\n        encoded_all, unencoded_all = [], []\n        for x in outputs:\n            # the first half is unencoded, the second is encoded\n            total = x[label]\n            unencoded_all.append(total[: total.shape[0] // 2])\n            encoded_all.append(total[total.shape[0] // 2:])\n        return (\n            torch.cat(unencoded_all).detach().cpu().numpy(),\n            torch.cat(encoded_all).detach().cpu().numpy(),\n        )\n\n    def _interpretable_metrics(self, outputs, input_prefix: str, output_prefix: str) -> Dict:\n\n        output_dict = {}\n\n        if self.hparams.forecast:\n            u_labels, e_labels = self._split_tensor(\n                outputs, f\"{input_prefix}label\")\n\n            u_preds, e_preds = self._split_tensor(\n                outputs, f\"{input_prefix}pred\")\n        else:\n            u_preds = torch.cat([x[f\"{input_prefix}pred\"]\n                                for x in outputs]).detach().cpu().numpy()\n            u_labels = (\n                torch.cat([x[f\"{input_prefix}label\"]\n                          for x in outputs]).detach().cpu().numpy()\n            )\n\n        output_dict.update(\n            self._output_metrics(\n                u_preds, u_labels, f\"unencoded_{output_prefix}{input_prefix}\")\n        )\n\n        if self.hparams.forecast:\n            output_dict.update(\n                self._output_metrics(\n                    e_preds, e_labels, f\"encoded_{output_prefix}{input_prefix}\")\n            )\n\n        return output_dict\n\n    def validation_epoch_end(self, outputs):\n        avg_loss = torch.stack([x[\"val_loss\"] for x in outputs]).mean()\n        logs = {\"val_loss\": avg_loss}\n        if self.hparams.forecast:\n            encoder_pred = (\n                torch.cat(\n                    [torch.flatten(x[\"encoder_prediction\"], start_dim=1) for x in outputs], dim=0,\n                )\n                .detach()\n                .cpu()\n                .numpy()\n            )\n            encoder_target = (\n                torch.cat(\n                    [torch.flatten(x[\"encoder_target\"], start_dim=1) for x in outputs], dim=0,\n                )\n                .detach()\n                .cpu()\n                .numpy()\n            )\n\n            logs[\"val_encoder_mae\"] = mean_absolute_error(\n                encoder_target, encoder_pred)\n\n        if self.hparams.multi_headed:\n            logs.update(self._interpretable_metrics(\n                outputs, \"global_\", \"val_\"))\n            logs.update(self._interpretable_metrics(outputs, \"kenya_\", \"val_\"))\n        else:\n            logs.update(self._interpretable_metrics(outputs, \"\", \"val_\"))\n        return {\"val_loss\": avg_loss, \"log\": logs}\n\n    def test_epoch_end(self, outputs):\n\n        avg_loss = torch.stack([x[\"test_loss\"] for x in outputs]).mean().item()\n        output_dict = {\"val_loss\": avg_loss}\n\n        if self.hparams.forecast:\n            encoder_pred = (\n                torch.cat(\n                    [torch.flatten(x[\"encoder_prediction\"], start_dim=1) for x in outputs], dim=0,\n                )\n                .detach()\n                .cpu()\n                .numpy()\n            )\n            encoder_target = (\n                torch.cat(\n                    [torch.flatten(x[\"encoder_target\"], start_dim=1) for x in outputs], dim=0,\n                )\n                .detach()\n                .cpu()\n                .numpy()\n            )\n\n            output_dict[\"test_encoder_mae\"] = mean_absolute_error(\n                encoder_target, encoder_pred)\n\n        if self.hparams.multi_headed:\n            output_dict.update(self._interpretable_metrics(\n                outputs, \"global_\", \"test_\"))\n            output_dict.update(self._interpretable_metrics(\n                outputs, \"kenya_\", \"test_\"))\n        else:\n            output_dict.update(\n                self._interpretable_metrics(outputs, \"\", \"test_\"))\n\n        return {\"progress_bar\": output_dict}\n\n    @staticmethod\n    def add_model_specific_args(parent_parser: ArgumentParser) -> ArgumentParser:\n\n        parser = ArgumentParser(parents=[parent_parser], add_help=False)\n\n        parser_args: Dict[str, Tuple[Type, Any]] = {\n            # assumes this is being run from \"scripts\"\n            \"--data_folder\": (str, str(Path(\"../data\"))),\n            \"--learning_rate\": (float, 0.001),\n            \"--batch_size\": (int, 64),\n            \"--input_months\": (int, 5),\n            \"--alpha\": (float, 10),\n            \"--noise_factor\": (float, 0.1),\n        }\n\n        for key, val in parser_args.items():\n            parser.add_argument(key, type=val[0], default=val[1])\n\n        parser.add_argument(\"--remove_b1_b10\",\n                            dest=\"remove_b1_b10\", action=\"store_true\")\n        parser.add_argument(\n            \"--keep_b1_b10\", dest=\"remove_b1_b10\", action=\"store_false\")\n        parser.set_defaults(remove_b1_b10=True)\n\n        parser.add_argument(\"--forecast\", dest=\"forecast\", action=\"store_true\")\n        parser.add_argument(\"--do_not_forecast\",\n                            dest=\"forecast\", action=\"store_false\")\n        parser.set_defaults(forecast=True)\n\n        parser.add_argument(\"--cache\", dest=\"cache\", action=\"store_true\")\n        parser.add_argument(\"--do_not_cache\", dest=\"cache\",\n                            action=\"store_false\")\n        parser.set_defaults(cache=True)\n\n        parser.add_argument(\"--include_geowiki\",\n                            dest=\"include_geowiki\", action=\"store_true\")\n        parser.add_argument(\"--exclude_geowiki\",\n                            dest=\"include_geowiki\", action=\"store_false\")\n        parser.set_defaults(include_geowiki=True)\n\n        parser.add_argument(\"--upsample\", dest=\"upsample\", action=\"store_true\")\n        parser.add_argument(\"--do_not_upsample\",\n                            dest=\"upsample\", action=\"store_false\")\n        parser.set_defaults(upsample=True)\n\n        classifier_parser = Classifier.add_model_specific_args(parser)\n        return Forecaster.add_model_specific_args(classifier_parser)\n",
  "history_output" : "",
  "history_begin_time" : 1647347143698,
  "history_end_time" : 1647347144362,
  "history_notes" : null,
  "history_process" : "9ardvx",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "7zubzwup863",
  "history_input" : "from argparse import ArgumentParser, Namespace\nfrom pathlib import Path\nimport numpy as np\nimport xarray as xr\nfrom tqdm import tqdm\n\nimport torch\nfrom torch.nn import functional as F\nfrom torch.utils.data import DataLoader\n\nimport pytorch_lightning as pl\n\nfrom sklearn.metrics import (\n    roc_auc_score,\n    accuracy_score,\n    precision_score,\n    recall_score,\n    f1_score,\n    mean_absolute_error,\n)\n\nfrom src_models_data import CropDataset\nfrom src_models_utils import tif_to_np, preds_to_xr\nfrom src_utils import set_seed\nfrom src_models_forecaster import Forecaster\nfrom src_models_classifier import Classifier\nfrom src_config import PROBABILITY_THRESHOLD\n\nfrom typing import cast, Callable, Tuple, Dict, Any, Type, Optional, List, Union\n\n\nclass Model(pl.LightningModule):\n    r\"\"\"\n    An model for annual and in-season crop mapping. This model consists of a\n    forecaster.Forecaster and a classifier.Classifier - it will require the arguments\n    required by those models too.\n\n    hparams\n    --------\n    The default values for these parameters are set in add_model_specific_args\n\n    :param hparams.data_folder: The path to the data. Default (assumes the model\n        is being run from the scripts directory) = \"../data\"\n    :param hparams.learning_rate: The learning rate. Default = 0.001\n    :param hparams.batch_size: The batch size. Default = 64\n    :param hparams.input_months: The number of input months to pass to the model. If\n        hparams.forecast is True, the remaining months will be forecasted. Otherwise, only the\n        partial timeseries will be passed to the classifier. Default = 5\n    :param hparams.alpha: The weight to use when adding the global and local losses. This\n        parameter is only used if hparams.multi_headed is True. Default = 10\n    :param hparams.noise_factor: The standard deviation of the random noise to add to the\n        raw inputs to the classifier. Default = 0.1\n    :param hparams.remove_b1_b10: Whether or not to remove the B1 and B10 bands. Default = True\n    :param hparams.forecast: Whether or not to forecast the partial time series. Default = True\n    :param hparams.cache: Whether to load all the data into memory during training. Default = True\n    :param hparams.include_geowiki: Whether to include the global GeoWiki dataset during\n        training. Default = True\n    :param hparams.upsample: Whether to oversample the under-represented class so that each class\n        is equally represented in the training and validation dataset. Default = True\n    \"\"\"\n\n    def __init__(self, hparams: Namespace) -> None:\n        super().__init__()\n        set_seed()\n        self.hparams = hparams\n\n        self.data_folder = Path(hparams.data_folder)\n\n        dataset = self.get_dataset(subset=\"training\", cache=False)\n        self.num_outputs = dataset.num_output_classes\n        self.num_timesteps = dataset.num_timesteps\n        self.input_size = dataset.num_input_features\n\n        # we save the normalizing dict because we calculate weighted\n        # normalization values based on the datasets we combine.\n        # The number of instances per dataset (and therefore the weights) can\n        # vary between the train / test / val sets - this ensures the normalizing\n        # dict stays constant between them\n        self.normalizing_dict = dataset.normalizing_dict\n\n        if self.hparams.forecast:\n            num_output_timesteps = self.num_timesteps - self.hparams.input_months\n            print(\n                f\"Predicting {num_output_timesteps} timesteps in the forecaster\")\n            self.forecaster = Forecaster(\n                num_bands=self.input_size, output_timesteps=num_output_timesteps, hparams=hparams,\n            )\n\n            self.forecaster_loss = F.smooth_l1_loss\n\n        self.classifier = Classifier(\n            input_size=self.input_size, hparams=hparams)\n        self.global_loss_function: Callable = F.binary_cross_entropy\n        self.local_loss_function: Callable = F.binary_cross_entropy\n\n    def forward(self, x: torch.Tensor) -> Union[torch.Tensor, Tuple[torch.Tensor, torch.Tensor]]:\n        # To keep the ABC happy\n        return self.classifier(x)\n\n    def configure_optimizers(self):\n        return torch.optim.Adam(self.parameters(), lr=self.hparams.learning_rate)\n\n    def get_dataset(\n        self, subset: str, normalizing_dict: Optional[Dict] = None, cache: Optional[bool] = None,\n    ) -> CropDataset:\n        return CropDataset(\n            data_folder=self.data_folder,\n            subset=subset,\n            remove_b1_b10=self.hparams.remove_b1_b10,\n            normalizing_dict=normalizing_dict,\n            include_geowiki=self.hparams.include_geowiki if subset != \"testing\" else False,\n            cache=self.hparams.cache if cache is None else cache,\n            upsample=self.hparams.upsample if subset != \"testing\" else False,\n            noise_factor=self.hparams.noise_factor if subset != \"testing\" else 0,\n        )\n\n    def train_dataloader(self):\n        return DataLoader(\n            self.get_dataset(subset=\"training\"), shuffle=True, batch_size=self.hparams.batch_size,\n        )\n\n    def val_dataloader(self):\n        return DataLoader(\n            self.get_dataset(subset=\"validation\",\n                             normalizing_dict=self.normalizing_dict,),\n            batch_size=self.hparams.batch_size,\n        )\n\n    def test_dataloader(self):\n        return DataLoader(\n            self.get_dataset(subset=\"testing\",\n                             normalizing_dict=self.normalizing_dict,),\n            batch_size=self.hparams.batch_size,\n        )\n\n    def predict(\n        self,\n        path_to_file: Path,\n        with_forecaster: bool,\n        batch_size: int = 64,\n        add_ndvi: bool = True,\n        add_ndwi: bool = False,\n        nan_fill: float = 0,\n        days_per_timestep: int = 30,\n        local_head: bool = True,\n        use_gpu: bool = True,\n    ) -> xr.Dataset:\n\n        # check if a GPU is available, and if it is\n        # move the model onto the GPU\n        device: Optional[torch.device] = None\n        if use_gpu:\n            use_cuda = torch.cuda.is_available()\n            if not use_cuda:\n                print(\"No GPU - not using one\")\n            device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n            self.to(device)\n\n        self.eval()\n\n        input_data = tif_to_np(\n            path_to_file,\n            add_ndvi=add_ndvi,\n            add_ndwi=add_ndwi,\n            nan=nan_fill,\n            normalizing_dict=self.normalizing_dict,\n            days_per_timestep=days_per_timestep,\n        )\n\n        if with_forecaster:\n            input_data.x = input_data.x[:, : self.hparams.input_months, :]\n\n        predictions: List[np.ndarray] = []\n        cur_i = 0\n\n        pbar = tqdm(total=input_data.x.shape[0] - 1)\n        while cur_i < (input_data.x.shape[0] - 1):\n\n            batch_x_np = input_data.x[cur_i: cur_i + batch_size]\n            if self.hparams.remove_b1_b10:\n                batch_x_np = CropDataset._remove_bands(batch_x_np)\n            batch_x = torch.from_numpy(batch_x_np).float()\n\n            if use_gpu and (device is not None):\n                batch_x = batch_x.to(device)\n\n            with torch.no_grad():\n                if with_forecaster:\n                    batch_x_next = self.forecaster(batch_x)\n                    batch_x = torch.cat((batch_x, batch_x_next), dim=1)\n\n                batch_preds = self.classifier(batch_x)\n\n                if self.hparams.multi_headed:\n                    global_preds, local_preds = batch_preds\n\n                    if local_head:\n                        batch_preds = local_preds\n                    else:\n                        batch_preds = global_preds\n\n                # back to the CPU, if necessary\n                batch_preds = batch_preds.cpu()\n\n            predictions.append(cast(torch.Tensor, batch_preds).numpy())\n            cur_i += batch_size\n            pbar.update(batch_size)\n\n        all_preds = np.concatenate(predictions, axis=0)\n        if len(all_preds.shape) == 1:\n            all_preds = np.expand_dims(all_preds, axis=-1)\n\n        return preds_to_xr(all_preds, lats=input_data.lat, lons=input_data.lon,)\n\n    def _output_metrics(\n        self, preds: np.ndarray, labels: np.ndarray, prefix: str = \"\"\n    ) -> Dict[str, float]:\n\n        if len(preds) == 0:\n            # sometimes this happens in the warmup\n            return {}\n\n        output_dict: Dict[str, float] = {}\n        if not (labels == labels[0]).all():\n            # This can happen when lightning does its warm up on a subset of the\n            # validation data\n            output_dict[f\"{prefix}roc_auc_score\"] = roc_auc_score(\n                labels, preds)\n\n        preds = (preds > PROBABILITY_THRESHOLD).astype(int)\n\n        output_dict[f\"{prefix}precision_score\"] = precision_score(\n            labels, preds)\n        output_dict[f\"{prefix}recall_score\"] = recall_score(labels, preds)\n        output_dict[f\"{prefix}f1_score\"] = f1_score(labels, preds)\n        output_dict[f\"{prefix}accuracy\"] = accuracy_score(labels, preds)\n\n        return output_dict\n\n    def add_noise(self, x: torch.Tensor, training: bool) -> torch.Tensor:\n        if (self.hparams.noise_factor == 0) or (not training):\n            return x\n\n        # expect input to be of shape [timesteps, bands]\n        # and to be normalized with mean 0, std=1\n        # if its not, it means no norm_dict was passed, so lets\n        # just assume std=1\n        noise = torch.normal(0, 1, size=x.shape).float() * \\\n            self.hparams.noise_factor\n\n        # the added noise is the same per band, so that the temporal relationships\n        # are preserved\n        # noise_per_timesteps = noise.repeat(x.shape[0], 1)\n        return x + noise\n\n    def _split_preds_and_get_loss(\n        self, batch, add_preds: bool, loss_label: str, log_loss: bool, training: bool\n    ) -> Dict:\n\n        x, label, is_global = batch\n\n        input_to_encode = x[:, : self.hparams.input_months, :]\n\n        if self.hparams.forecast:\n            # we will predict every timestep except the first one\n            output_to_predict = x[:, 1:, :]\n            encoder_output = self.forecaster(input_to_encode)\n            encoder_loss = self.forecaster_loss(\n                encoder_output, output_to_predict)\n            loss: Union[float, torch.Tensor] = encoder_loss\n\n            final_encoded_input = torch.cat(\n                (\n                    (\n                        self.add_noise(input_to_encode, training),\n                        # -1 because the encoder output has no value for the 0th\n                        # timestep\n                        encoder_output[:, self.hparams.input_months - 1:, :],\n                    )\n                ),\n                dim=1,\n            )\n\n            output_dict = {}\n            if add_preds:\n                output_dict.update(\n                    {\"encoder_prediction\": encoder_output,\n                        \"encoder_target\": output_to_predict, }\n                )\n            if log_loss:\n                output_dict[\"log\"] = {}\n\n            # we now repeat label and is_global\n            x = torch.cat((self.add_noise(x, training),\n                          final_encoded_input), dim=0)\n            label = torch.cat((label, label), dim=0)\n            is_global = torch.cat((is_global, is_global), dim=0)\n        else:\n            loss = 0\n            output_dict = {}\n            if log_loss:\n                output_dict[\"log\"] = {}\n            x = self.add_noise(input_to_encode, training=training)\n\n        if self.hparams.multi_headed:\n            org_global_preds, local_preds = self.classifier(x)\n            global_preds = org_global_preds[is_global != 0]\n            global_labels = label[is_global != 0]\n\n            local_preds = local_preds[is_global == 0]\n            local_labels = label[is_global == 0]\n\n            if local_preds.shape[0] > 0:\n                local_loss = self.local_loss_function(\n                    local_preds.squeeze(-1), local_labels,)\n                loss += local_loss\n\n            if global_preds.shape[0] > 0:\n                global_loss = self.global_loss_function(\n                    global_preds.squeeze(-1), global_labels,)\n\n                num_local_labels = local_preds.shape[0]\n                if num_local_labels == 0:\n                    alpha = 1\n                else:\n                    ratio = global_preds.shape[0] / num_local_labels\n                    alpha = ratio / self.hparams.alpha\n                loss += alpha * global_loss\n\n            output_dict[loss_label] = loss\n            if log_loss:\n                output_dict[\"log\"][loss_label] = loss\n            if add_preds:\n                output_dict.update(\n                    {\n                        \"global_pred\": global_preds,\n                        \"global_label\": global_labels,\n                        \"kenya_pred\": local_preds,\n                        \"kenya_label\": local_labels,\n                    }\n                )\n            return output_dict\n        else:\n            preds = cast(torch.Tensor, self.classifier(x))\n\n            loss += self.global_loss_function(\n                input=preds.squeeze(-1), target=label,)\n\n            output_dict = {loss_label: loss}\n            if log_loss:\n                output_dict[\"log\"][loss_label] = loss\n            if add_preds:\n                output_dict.update({\"pred\": preds, \"label\": label})\n            return output_dict\n\n    def training_step(self, batch, batch_idx):\n        return self._split_preds_and_get_loss(\n            batch, add_preds=False, loss_label=\"loss\", log_loss=True, training=True\n        )\n\n    def validation_step(self, batch, batch_idx):\n        return self._split_preds_and_get_loss(\n            batch, add_preds=True, loss_label=\"val_loss\", log_loss=True, training=False\n        )\n\n    def test_step(self, batch, batch_idx):\n        return self._split_preds_and_get_loss(\n            batch, add_preds=True, loss_label=\"test_loss\", log_loss=True, training=False\n        )\n\n    @staticmethod\n    def _split_tensor(outputs, label) -> Tuple[np.ndarray, np.ndarray]:\n        encoded_all, unencoded_all = [], []\n        for x in outputs:\n            # the first half is unencoded, the second is encoded\n            total = x[label]\n            unencoded_all.append(total[: total.shape[0] // 2])\n            encoded_all.append(total[total.shape[0] // 2:])\n        return (\n            torch.cat(unencoded_all).detach().cpu().numpy(),\n            torch.cat(encoded_all).detach().cpu().numpy(),\n        )\n\n    def _interpretable_metrics(self, outputs, input_prefix: str, output_prefix: str) -> Dict:\n\n        output_dict = {}\n\n        if self.hparams.forecast:\n            u_labels, e_labels = self._split_tensor(\n                outputs, f\"{input_prefix}label\")\n\n            u_preds, e_preds = self._split_tensor(\n                outputs, f\"{input_prefix}pred\")\n        else:\n            u_preds = torch.cat([x[f\"{input_prefix}pred\"]\n                                for x in outputs]).detach().cpu().numpy()\n            u_labels = (\n                torch.cat([x[f\"{input_prefix}label\"]\n                          for x in outputs]).detach().cpu().numpy()\n            )\n\n        output_dict.update(\n            self._output_metrics(\n                u_preds, u_labels, f\"unencoded_{output_prefix}{input_prefix}\")\n        )\n\n        if self.hparams.forecast:\n            output_dict.update(\n                self._output_metrics(\n                    e_preds, e_labels, f\"encoded_{output_prefix}{input_prefix}\")\n            )\n\n        return output_dict\n\n    def validation_epoch_end(self, outputs):\n        avg_loss = torch.stack([x[\"val_loss\"] for x in outputs]).mean()\n        logs = {\"val_loss\": avg_loss}\n        if self.hparams.forecast:\n            encoder_pred = (\n                torch.cat(\n                    [torch.flatten(x[\"encoder_prediction\"], start_dim=1) for x in outputs], dim=0,\n                )\n                .detach()\n                .cpu()\n                .numpy()\n            )\n            encoder_target = (\n                torch.cat(\n                    [torch.flatten(x[\"encoder_target\"], start_dim=1) for x in outputs], dim=0,\n                )\n                .detach()\n                .cpu()\n                .numpy()\n            )\n\n            logs[\"val_encoder_mae\"] = mean_absolute_error(\n                encoder_target, encoder_pred)\n\n        if self.hparams.multi_headed:\n            logs.update(self._interpretable_metrics(\n                outputs, \"global_\", \"val_\"))\n            logs.update(self._interpretable_metrics(outputs, \"kenya_\", \"val_\"))\n        else:\n            logs.update(self._interpretable_metrics(outputs, \"\", \"val_\"))\n        return {\"val_loss\": avg_loss, \"log\": logs}\n\n    def test_epoch_end(self, outputs):\n\n        avg_loss = torch.stack([x[\"test_loss\"] for x in outputs]).mean().item()\n        output_dict = {\"val_loss\": avg_loss}\n\n        if self.hparams.forecast:\n            encoder_pred = (\n                torch.cat(\n                    [torch.flatten(x[\"encoder_prediction\"], start_dim=1) for x in outputs], dim=0,\n                )\n                .detach()\n                .cpu()\n                .numpy()\n            )\n            encoder_target = (\n                torch.cat(\n                    [torch.flatten(x[\"encoder_target\"], start_dim=1) for x in outputs], dim=0,\n                )\n                .detach()\n                .cpu()\n                .numpy()\n            )\n\n            output_dict[\"test_encoder_mae\"] = mean_absolute_error(\n                encoder_target, encoder_pred)\n\n        if self.hparams.multi_headed:\n            output_dict.update(self._interpretable_metrics(\n                outputs, \"global_\", \"test_\"))\n            output_dict.update(self._interpretable_metrics(\n                outputs, \"kenya_\", \"test_\"))\n        else:\n            output_dict.update(\n                self._interpretable_metrics(outputs, \"\", \"test_\"))\n\n        return {\"progress_bar\": output_dict}\n\n    @staticmethod\n    def add_model_specific_args(parent_parser: ArgumentParser) -> ArgumentParser:\n\n        parser = ArgumentParser(parents=[parent_parser], add_help=False)\n\n        parser_args: Dict[str, Tuple[Type, Any]] = {\n            # assumes this is being run from \"scripts\"\n            \"--data_folder\": (str, str(Path(\"../data\"))),\n            \"--learning_rate\": (float, 0.001),\n            \"--batch_size\": (int, 64),\n            \"--input_months\": (int, 5),\n            \"--alpha\": (float, 10),\n            \"--noise_factor\": (float, 0.1),\n        }\n\n        for key, val in parser_args.items():\n            parser.add_argument(key, type=val[0], default=val[1])\n\n        parser.add_argument(\"--remove_b1_b10\",\n                            dest=\"remove_b1_b10\", action=\"store_true\")\n        parser.add_argument(\n            \"--keep_b1_b10\", dest=\"remove_b1_b10\", action=\"store_false\")\n        parser.set_defaults(remove_b1_b10=True)\n\n        parser.add_argument(\"--forecast\", dest=\"forecast\", action=\"store_true\")\n        parser.add_argument(\"--do_not_forecast\",\n                            dest=\"forecast\", action=\"store_false\")\n        parser.set_defaults(forecast=True)\n\n        parser.add_argument(\"--cache\", dest=\"cache\", action=\"store_true\")\n        parser.add_argument(\"--do_not_cache\", dest=\"cache\",\n                            action=\"store_false\")\n        parser.set_defaults(cache=True)\n\n        parser.add_argument(\"--include_geowiki\",\n                            dest=\"include_geowiki\", action=\"store_true\")\n        parser.add_argument(\"--exclude_geowiki\",\n                            dest=\"include_geowiki\", action=\"store_false\")\n        parser.set_defaults(include_geowiki=True)\n\n        parser.add_argument(\"--upsample\", dest=\"upsample\", action=\"store_true\")\n        parser.add_argument(\"--do_not_upsample\",\n                            dest=\"upsample\", action=\"store_false\")\n        parser.set_defaults(upsample=True)\n\n        classifier_parser = Classifier.add_model_specific_args(parser)\n        return Forecaster.add_model_specific_args(classifier_parser)\n",
  "history_output" : "",
  "history_begin_time" : 1647346814023,
  "history_end_time" : 1647346818127,
  "history_notes" : null,
  "history_process" : "9ardvx",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "k231f0q3922",
  "history_input" : "from argparse import ArgumentParser, Namespace\nfrom pathlib import Path\nimport numpy as np\nimport xarray as xr\nfrom tqdm import tqdm\n\nimport torch\nfrom torch.nn import functional as F\nfrom torch.utils.data import DataLoader\n\nimport pytorch_lightning as pl\n\nfrom sklearn.metrics import (\n    roc_auc_score,\n    accuracy_score,\n    precision_score,\n    recall_score,\n    f1_score,\n    mean_absolute_error,\n)\n\nfrom src_models_data import CropDataset\nfrom src_models_utils import tif_to_np, preds_to_xr\nfrom src_utils import set_seed\nfrom src_models_forecaster import Forecaster\nfrom src_models_classifier import Classifier\nfrom src_config import PROBABILITY_THRESHOLD\n\nfrom typing import cast, Callable, Tuple, Dict, Any, Type, Optional, List, Union\n\n\nclass Model(pl.LightningModule):\n    r\"\"\"\n    An model for annual and in-season crop mapping. This model consists of a\n    forecaster.Forecaster and a classifier.Classifier - it will require the arguments\n    required by those models too.\n\n    hparams\n    --------\n    The default values for these parameters are set in add_model_specific_args\n\n    :param hparams.data_folder: The path to the data. Default (assumes the model\n        is being run from the scripts directory) = \"../data\"\n    :param hparams.learning_rate: The learning rate. Default = 0.001\n    :param hparams.batch_size: The batch size. Default = 64\n    :param hparams.input_months: The number of input months to pass to the model. If\n        hparams.forecast is True, the remaining months will be forecasted. Otherwise, only the\n        partial timeseries will be passed to the classifier. Default = 5\n    :param hparams.alpha: The weight to use when adding the global and local losses. This\n        parameter is only used if hparams.multi_headed is True. Default = 10\n    :param hparams.noise_factor: The standard deviation of the random noise to add to the\n        raw inputs to the classifier. Default = 0.1\n    :param hparams.remove_b1_b10: Whether or not to remove the B1 and B10 bands. Default = True\n    :param hparams.forecast: Whether or not to forecast the partial time series. Default = True\n    :param hparams.cache: Whether to load all the data into memory during training. Default = True\n    :param hparams.include_geowiki: Whether to include the global GeoWiki dataset during\n        training. Default = True\n    :param hparams.upsample: Whether to oversample the under-represented class so that each class\n        is equally represented in the training and validation dataset. Default = True\n    \"\"\"\n\n    def __init__(self, hparams: Namespace) -> None:\n        super().__init__()\n        set_seed()\n        self.hparams = hparams\n\n        self.data_folder = Path(hparams.data_folder)\n\n        dataset = self.get_dataset(subset=\"training\", cache=False)\n        self.num_outputs = dataset.num_output_classes\n        self.num_timesteps = dataset.num_timesteps\n        self.input_size = dataset.num_input_features\n\n        # we save the normalizing dict because we calculate weighted\n        # normalization values based on the datasets we combine.\n        # The number of instances per dataset (and therefore the weights) can\n        # vary between the train / test / val sets - this ensures the normalizing\n        # dict stays constant between them\n        self.normalizing_dict = dataset.normalizing_dict\n\n        if self.hparams.forecast:\n            num_output_timesteps = self.num_timesteps - self.hparams.input_months\n            print(\n                f\"Predicting {num_output_timesteps} timesteps in the forecaster\")\n            self.forecaster = Forecaster(\n                num_bands=self.input_size, output_timesteps=num_output_timesteps, hparams=hparams,\n            )\n\n            self.forecaster_loss = F.smooth_l1_loss\n\n        self.classifier = Classifier(\n            input_size=self.input_size, hparams=hparams)\n        self.global_loss_function: Callable = F.binary_cross_entropy\n        self.local_loss_function: Callable = F.binary_cross_entropy\n\n    def forward(self, x: torch.Tensor) -> Union[torch.Tensor, Tuple[torch.Tensor, torch.Tensor]]:\n        # To keep the ABC happy\n        return self.classifier(x)\n\n    def configure_optimizers(self):\n        return torch.optim.Adam(self.parameters(), lr=self.hparams.learning_rate)\n\n    def get_dataset(\n        self, subset: str, normalizing_dict: Optional[Dict] = None, cache: Optional[bool] = None,\n    ) -> CropDataset:\n        return CropDataset(\n            data_folder=self.data_folder,\n            subset=subset,\n            remove_b1_b10=self.hparams.remove_b1_b10,\n            normalizing_dict=normalizing_dict,\n            include_geowiki=self.hparams.include_geowiki if subset != \"testing\" else False,\n            cache=self.hparams.cache if cache is None else cache,\n            upsample=self.hparams.upsample if subset != \"testing\" else False,\n            noise_factor=self.hparams.noise_factor if subset != \"testing\" else 0,\n        )\n\n    def train_dataloader(self):\n        return DataLoader(\n            self.get_dataset(subset=\"training\"), shuffle=True, batch_size=self.hparams.batch_size,\n        )\n\n    def val_dataloader(self):\n        return DataLoader(\n            self.get_dataset(subset=\"validation\",\n                             normalizing_dict=self.normalizing_dict,),\n            batch_size=self.hparams.batch_size,\n        )\n\n    def test_dataloader(self):\n        return DataLoader(\n            self.get_dataset(subset=\"testing\",\n                             normalizing_dict=self.normalizing_dict,),\n            batch_size=self.hparams.batch_size,\n        )\n\n    def predict(\n        self,\n        path_to_file: Path,\n        with_forecaster: bool,\n        batch_size: int = 64,\n        add_ndvi: bool = True,\n        add_ndwi: bool = False,\n        nan_fill: float = 0,\n        days_per_timestep: int = 30,\n        local_head: bool = True,\n        use_gpu: bool = True,\n    ) -> xr.Dataset:\n\n        # check if a GPU is available, and if it is\n        # move the model onto the GPU\n        device: Optional[torch.device] = None\n        if use_gpu:\n            use_cuda = torch.cuda.is_available()\n            if not use_cuda:\n                print(\"No GPU - not using one\")\n            device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n            self.to(device)\n\n        self.eval()\n\n        input_data = tif_to_np(\n            path_to_file,\n            add_ndvi=add_ndvi,\n            add_ndwi=add_ndwi,\n            nan=nan_fill,\n            normalizing_dict=self.normalizing_dict,\n            days_per_timestep=days_per_timestep,\n        )\n\n        if with_forecaster:\n            input_data.x = input_data.x[:, : self.hparams.input_months, :]\n\n        predictions: List[np.ndarray] = []\n        cur_i = 0\n\n        pbar = tqdm(total=input_data.x.shape[0] - 1)\n        while cur_i < (input_data.x.shape[0] - 1):\n\n            batch_x_np = input_data.x[cur_i: cur_i + batch_size]\n            if self.hparams.remove_b1_b10:\n                batch_x_np = CropDataset._remove_bands(batch_x_np)\n            batch_x = torch.from_numpy(batch_x_np).float()\n\n            if use_gpu and (device is not None):\n                batch_x = batch_x.to(device)\n\n            with torch.no_grad():\n                if with_forecaster:\n                    batch_x_next = self.forecaster(batch_x)\n                    batch_x = torch.cat((batch_x, batch_x_next), dim=1)\n\n                batch_preds = self.classifier(batch_x)\n\n                if self.hparams.multi_headed:\n                    global_preds, local_preds = batch_preds\n\n                    if local_head:\n                        batch_preds = local_preds\n                    else:\n                        batch_preds = global_preds\n\n                # back to the CPU, if necessary\n                batch_preds = batch_preds.cpu()\n\n            predictions.append(cast(torch.Tensor, batch_preds).numpy())\n            cur_i += batch_size\n            pbar.update(batch_size)\n\n        all_preds = np.concatenate(predictions, axis=0)\n        if len(all_preds.shape) == 1:\n            all_preds = np.expand_dims(all_preds, axis=-1)\n\n        return preds_to_xr(all_preds, lats=input_data.lat, lons=input_data.lon,)\n\n    def _output_metrics(\n        self, preds: np.ndarray, labels: np.ndarray, prefix: str = \"\"\n    ) -> Dict[str, float]:\n\n        if len(preds) == 0:\n            # sometimes this happens in the warmup\n            return {}\n\n        output_dict: Dict[str, float] = {}\n        if not (labels == labels[0]).all():\n            # This can happen when lightning does its warm up on a subset of the\n            # validation data\n            output_dict[f\"{prefix}roc_auc_score\"] = roc_auc_score(\n                labels, preds)\n\n        preds = (preds > PROBABILITY_THRESHOLD).astype(int)\n\n        output_dict[f\"{prefix}precision_score\"] = precision_score(\n            labels, preds)\n        output_dict[f\"{prefix}recall_score\"] = recall_score(labels, preds)\n        output_dict[f\"{prefix}f1_score\"] = f1_score(labels, preds)\n        output_dict[f\"{prefix}accuracy\"] = accuracy_score(labels, preds)\n\n        return output_dict\n\n    def add_noise(self, x: torch.Tensor, training: bool) -> torch.Tensor:\n        if (self.hparams.noise_factor == 0) or (not training):\n            return x\n\n        # expect input to be of shape [timesteps, bands]\n        # and to be normalized with mean 0, std=1\n        # if its not, it means no norm_dict was passed, so lets\n        # just assume std=1\n        noise = torch.normal(0, 1, size=x.shape).float() * \\\n            self.hparams.noise_factor\n\n        # the added noise is the same per band, so that the temporal relationships\n        # are preserved\n        # noise_per_timesteps = noise.repeat(x.shape[0], 1)\n        return x + noise\n\n    def _split_preds_and_get_loss(\n        self, batch, add_preds: bool, loss_label: str, log_loss: bool, training: bool\n    ) -> Dict:\n\n        x, label, is_global = batch\n\n        input_to_encode = x[:, : self.hparams.input_months, :]\n\n        if self.hparams.forecast:\n            # we will predict every timestep except the first one\n            output_to_predict = x[:, 1:, :]\n            encoder_output = self.forecaster(input_to_encode)\n            encoder_loss = self.forecaster_loss(\n                encoder_output, output_to_predict)\n            loss: Union[float, torch.Tensor] = encoder_loss\n\n            final_encoded_input = torch.cat(\n                (\n                    (\n                        self.add_noise(input_to_encode, training),\n                        # -1 because the encoder output has no value for the 0th\n                        # timestep\n                        encoder_output[:, self.hparams.input_months - 1:, :],\n                    )\n                ),\n                dim=1,\n            )\n\n            output_dict = {}\n            if add_preds:\n                output_dict.update(\n                    {\"encoder_prediction\": encoder_output,\n                        \"encoder_target\": output_to_predict, }\n                )\n            if log_loss:\n                output_dict[\"log\"] = {}\n\n            # we now repeat label and is_global\n            x = torch.cat((self.add_noise(x, training),\n                          final_encoded_input), dim=0)\n            label = torch.cat((label, label), dim=0)\n            is_global = torch.cat((is_global, is_global), dim=0)\n        else:\n            loss = 0\n            output_dict = {}\n            if log_loss:\n                output_dict[\"log\"] = {}\n            x = self.add_noise(input_to_encode, training=training)\n\n        if self.hparams.multi_headed:\n            org_global_preds, local_preds = self.classifier(x)\n            global_preds = org_global_preds[is_global != 0]\n            global_labels = label[is_global != 0]\n\n            local_preds = local_preds[is_global == 0]\n            local_labels = label[is_global == 0]\n\n            if local_preds.shape[0] > 0:\n                local_loss = self.local_loss_function(\n                    local_preds.squeeze(-1), local_labels,)\n                loss += local_loss\n\n            if global_preds.shape[0] > 0:\n                global_loss = self.global_loss_function(\n                    global_preds.squeeze(-1), global_labels,)\n\n                num_local_labels = local_preds.shape[0]\n                if num_local_labels == 0:\n                    alpha = 1\n                else:\n                    ratio = global_preds.shape[0] / num_local_labels\n                    alpha = ratio / self.hparams.alpha\n                loss += alpha * global_loss\n\n            output_dict[loss_label] = loss\n            if log_loss:\n                output_dict[\"log\"][loss_label] = loss\n            if add_preds:\n                output_dict.update(\n                    {\n                        \"global_pred\": global_preds,\n                        \"global_label\": global_labels,\n                        \"kenya_pred\": local_preds,\n                        \"kenya_label\": local_labels,\n                    }\n                )\n            return output_dict\n        else:\n            preds = cast(torch.Tensor, self.classifier(x))\n\n            loss += self.global_loss_function(\n                input=preds.squeeze(-1), target=label,)\n\n            output_dict = {loss_label: loss}\n            if log_loss:\n                output_dict[\"log\"][loss_label] = loss\n            if add_preds:\n                output_dict.update({\"pred\": preds, \"label\": label})\n            return output_dict\n\n    def training_step(self, batch, batch_idx):\n        return self._split_preds_and_get_loss(\n            batch, add_preds=False, loss_label=\"loss\", log_loss=True, training=True\n        )\n\n    def validation_step(self, batch, batch_idx):\n        return self._split_preds_and_get_loss(\n            batch, add_preds=True, loss_label=\"val_loss\", log_loss=True, training=False\n        )\n\n    def test_step(self, batch, batch_idx):\n        return self._split_preds_and_get_loss(\n            batch, add_preds=True, loss_label=\"test_loss\", log_loss=True, training=False\n        )\n\n    @staticmethod\n    def _split_tensor(outputs, label) -> Tuple[np.ndarray, np.ndarray]:\n        encoded_all, unencoded_all = [], []\n        for x in outputs:\n            # the first half is unencoded, the second is encoded\n            total = x[label]\n            unencoded_all.append(total[: total.shape[0] // 2])\n            encoded_all.append(total[total.shape[0] // 2:])\n        return (\n            torch.cat(unencoded_all).detach().cpu().numpy(),\n            torch.cat(encoded_all).detach().cpu().numpy(),\n        )\n\n    def _interpretable_metrics(self, outputs, input_prefix: str, output_prefix: str) -> Dict:\n\n        output_dict = {}\n\n        if self.hparams.forecast:\n            u_labels, e_labels = self._split_tensor(\n                outputs, f\"{input_prefix}label\")\n\n            u_preds, e_preds = self._split_tensor(\n                outputs, f\"{input_prefix}pred\")\n        else:\n            u_preds = torch.cat([x[f\"{input_prefix}pred\"]\n                                for x in outputs]).detach().cpu().numpy()\n            u_labels = (\n                torch.cat([x[f\"{input_prefix}label\"]\n                          for x in outputs]).detach().cpu().numpy()\n            )\n\n        output_dict.update(\n            self._output_metrics(\n                u_preds, u_labels, f\"unencoded_{output_prefix}{input_prefix}\")\n        )\n\n        if self.hparams.forecast:\n            output_dict.update(\n                self._output_metrics(\n                    e_preds, e_labels, f\"encoded_{output_prefix}{input_prefix}\")\n            )\n\n        return output_dict\n\n    def validation_epoch_end(self, outputs):\n        avg_loss = torch.stack([x[\"val_loss\"] for x in outputs]).mean()\n        logs = {\"val_loss\": avg_loss}\n        if self.hparams.forecast:\n            encoder_pred = (\n                torch.cat(\n                    [torch.flatten(x[\"encoder_prediction\"], start_dim=1) for x in outputs], dim=0,\n                )\n                .detach()\n                .cpu()\n                .numpy()\n            )\n            encoder_target = (\n                torch.cat(\n                    [torch.flatten(x[\"encoder_target\"], start_dim=1) for x in outputs], dim=0,\n                )\n                .detach()\n                .cpu()\n                .numpy()\n            )\n\n            logs[\"val_encoder_mae\"] = mean_absolute_error(\n                encoder_target, encoder_pred)\n\n        if self.hparams.multi_headed:\n            logs.update(self._interpretable_metrics(\n                outputs, \"global_\", \"val_\"))\n            logs.update(self._interpretable_metrics(outputs, \"kenya_\", \"val_\"))\n        else:\n            logs.update(self._interpretable_metrics(outputs, \"\", \"val_\"))\n        return {\"val_loss\": avg_loss, \"log\": logs}\n\n    def test_epoch_end(self, outputs):\n\n        avg_loss = torch.stack([x[\"test_loss\"] for x in outputs]).mean().item()\n        output_dict = {\"val_loss\": avg_loss}\n\n        if self.hparams.forecast:\n            encoder_pred = (\n                torch.cat(\n                    [torch.flatten(x[\"encoder_prediction\"], start_dim=1) for x in outputs], dim=0,\n                )\n                .detach()\n                .cpu()\n                .numpy()\n            )\n            encoder_target = (\n                torch.cat(\n                    [torch.flatten(x[\"encoder_target\"], start_dim=1) for x in outputs], dim=0,\n                )\n                .detach()\n                .cpu()\n                .numpy()\n            )\n\n            output_dict[\"test_encoder_mae\"] = mean_absolute_error(\n                encoder_target, encoder_pred)\n\n        if self.hparams.multi_headed:\n            output_dict.update(self._interpretable_metrics(\n                outputs, \"global_\", \"test_\"))\n            output_dict.update(self._interpretable_metrics(\n                outputs, \"kenya_\", \"test_\"))\n        else:\n            output_dict.update(\n                self._interpretable_metrics(outputs, \"\", \"test_\"))\n\n        return {\"progress_bar\": output_dict}\n\n    @staticmethod\n    def add_model_specific_args(parent_parser: ArgumentParser) -> ArgumentParser:\n\n        parser = ArgumentParser(parents=[parent_parser], add_help=False)\n\n        parser_args: Dict[str, Tuple[Type, Any]] = {\n            # assumes this is being run from \"scripts\"\n            \"--data_folder\": (str, str(Path(\"../data\"))),\n            \"--learning_rate\": (float, 0.001),\n            \"--batch_size\": (int, 64),\n            \"--input_months\": (int, 5),\n            \"--alpha\": (float, 10),\n            \"--noise_factor\": (float, 0.1),\n        }\n\n        for key, val in parser_args.items():\n            parser.add_argument(key, type=val[0], default=val[1])\n\n        parser.add_argument(\"--remove_b1_b10\",\n                            dest=\"remove_b1_b10\", action=\"store_true\")\n        parser.add_argument(\n            \"--keep_b1_b10\", dest=\"remove_b1_b10\", action=\"store_false\")\n        parser.set_defaults(remove_b1_b10=True)\n\n        parser.add_argument(\"--forecast\", dest=\"forecast\", action=\"store_true\")\n        parser.add_argument(\"--do_not_forecast\",\n                            dest=\"forecast\", action=\"store_false\")\n        parser.set_defaults(forecast=True)\n\n        parser.add_argument(\"--cache\", dest=\"cache\", action=\"store_true\")\n        parser.add_argument(\"--do_not_cache\", dest=\"cache\",\n                            action=\"store_false\")\n        parser.set_defaults(cache=True)\n\n        parser.add_argument(\"--include_geowiki\",\n                            dest=\"include_geowiki\", action=\"store_true\")\n        parser.add_argument(\"--exclude_geowiki\",\n                            dest=\"include_geowiki\", action=\"store_false\")\n        parser.set_defaults(include_geowiki=True)\n\n        parser.add_argument(\"--upsample\", dest=\"upsample\", action=\"store_true\")\n        parser.add_argument(\"--do_not_upsample\",\n                            dest=\"upsample\", action=\"store_false\")\n        parser.set_defaults(upsample=True)\n\n        classifier_parser = Classifier.add_model_specific_args(parser)\n        return Forecaster.add_model_specific_args(classifier_parser)\n",
  "history_output" : "",
  "history_begin_time" : 1647346644230,
  "history_end_time" : 1647346644315,
  "history_notes" : null,
  "history_process" : "9ardvx",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "txx4ra8ftch",
  "history_input" : "from argparse import ArgumentParser, Namespace\nfrom pathlib import Path\nimport numpy as np\nimport xarray as xr\nfrom tqdm import tqdm\n\nimport torch\nfrom torch.nn import functional as F\nfrom torch.utils.data import DataLoader\n\nimport pytorch_lightning as pl\n\nfrom sklearn.metrics import (\n    roc_auc_score,\n    accuracy_score,\n    precision_score,\n    recall_score,\n    f1_score,\n    mean_absolute_error,\n)\n\nfrom src_models_data import CropDataset\nfrom src_models_utils import tif_to_np, preds_to_xr\nfrom src_utils import set_seed\nfrom src_models_forecaster import Forecaster\nfrom src_models_classifier import Classifier\nfrom src_config import PROBABILITY_THRESHOLD\n\nfrom typing import cast, Callable, Tuple, Dict, Any, Type, Optional, List, Union\n\n\nclass Model(pl.LightningModule):\n    r\"\"\"\n    An model for annual and in-season crop mapping. This model consists of a\n    forecaster.Forecaster and a classifier.Classifier - it will require the arguments\n    required by those models too.\n\n    hparams\n    --------\n    The default values for these parameters are set in add_model_specific_args\n\n    :param hparams.data_folder: The path to the data. Default (assumes the model\n        is being run from the scripts directory) = \"../data\"\n    :param hparams.learning_rate: The learning rate. Default = 0.001\n    :param hparams.batch_size: The batch size. Default = 64\n    :param hparams.input_months: The number of input months to pass to the model. If\n        hparams.forecast is True, the remaining months will be forecasted. Otherwise, only the\n        partial timeseries will be passed to the classifier. Default = 5\n    :param hparams.alpha: The weight to use when adding the global and local losses. This\n        parameter is only used if hparams.multi_headed is True. Default = 10\n    :param hparams.noise_factor: The standard deviation of the random noise to add to the\n        raw inputs to the classifier. Default = 0.1\n    :param hparams.remove_b1_b10: Whether or not to remove the B1 and B10 bands. Default = True\n    :param hparams.forecast: Whether or not to forecast the partial time series. Default = True\n    :param hparams.cache: Whether to load all the data into memory during training. Default = True\n    :param hparams.include_geowiki: Whether to include the global GeoWiki dataset during\n        training. Default = True\n    :param hparams.upsample: Whether to oversample the under-represented class so that each class\n        is equally represented in the training and validation dataset. Default = True\n    \"\"\"\n\n    def __init__(self, hparams: Namespace) -> None:\n        super().__init__()\n        set_seed()\n        self.hparams = hparams\n\n        self.data_folder = Path(hparams.data_folder)\n\n        dataset = self.get_dataset(subset=\"training\", cache=False)\n        self.num_outputs = dataset.num_output_classes\n        self.num_timesteps = dataset.num_timesteps\n        self.input_size = dataset.num_input_features\n\n        # we save the normalizing dict because we calculate weighted\n        # normalization values based on the datasets we combine.\n        # The number of instances per dataset (and therefore the weights) can\n        # vary between the train / test / val sets - this ensures the normalizing\n        # dict stays constant between them\n        self.normalizing_dict = dataset.normalizing_dict\n\n        if self.hparams.forecast:\n            num_output_timesteps = self.num_timesteps - self.hparams.input_months\n            print(\n                f\"Predicting {num_output_timesteps} timesteps in the forecaster\")\n            self.forecaster = Forecaster(\n                num_bands=self.input_size, output_timesteps=num_output_timesteps, hparams=hparams,\n            )\n\n            self.forecaster_loss = F.smooth_l1_loss\n\n        self.classifier = Classifier(\n            input_size=self.input_size, hparams=hparams)\n        self.global_loss_function: Callable = F.binary_cross_entropy\n        self.local_loss_function: Callable = F.binary_cross_entropy\n\n    def forward(self, x: torch.Tensor) -> Union[torch.Tensor, Tuple[torch.Tensor, torch.Tensor]]:\n        # To keep the ABC happy\n        return self.classifier(x)\n\n    def configure_optimizers(self):\n        return torch.optim.Adam(self.parameters(), lr=self.hparams.learning_rate)\n\n    def get_dataset(\n        self, subset: str, normalizing_dict: Optional[Dict] = None, cache: Optional[bool] = None,\n    ) -> CropDataset:\n        return CropDataset(\n            data_folder=self.data_folder,\n            subset=subset,\n            remove_b1_b10=self.hparams.remove_b1_b10,\n            normalizing_dict=normalizing_dict,\n            include_geowiki=self.hparams.include_geowiki if subset != \"testing\" else False,\n            cache=self.hparams.cache if cache is None else cache,\n            upsample=self.hparams.upsample if subset != \"testing\" else False,\n            noise_factor=self.hparams.noise_factor if subset != \"testing\" else 0,\n        )\n\n    def train_dataloader(self):\n        return DataLoader(\n            self.get_dataset(subset=\"training\"), shuffle=True, batch_size=self.hparams.batch_size,\n        )\n\n    def val_dataloader(self):\n        return DataLoader(\n            self.get_dataset(subset=\"validation\",\n                             normalizing_dict=self.normalizing_dict,),\n            batch_size=self.hparams.batch_size,\n        )\n\n    def test_dataloader(self):\n        return DataLoader(\n            self.get_dataset(subset=\"testing\",\n                             normalizing_dict=self.normalizing_dict,),\n            batch_size=self.hparams.batch_size,\n        )\n\n    def predict(\n        self,\n        path_to_file: Path,\n        with_forecaster: bool,\n        batch_size: int = 64,\n        add_ndvi: bool = True,\n        add_ndwi: bool = False,\n        nan_fill: float = 0,\n        days_per_timestep: int = 30,\n        local_head: bool = True,\n        use_gpu: bool = True,\n    ) -> xr.Dataset:\n\n        # check if a GPU is available, and if it is\n        # move the model onto the GPU\n        device: Optional[torch.device] = None\n        if use_gpu:\n            use_cuda = torch.cuda.is_available()\n            if not use_cuda:\n                print(\"No GPU - not using one\")\n            device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n            self.to(device)\n\n        self.eval()\n\n        input_data = tif_to_np(\n            path_to_file,\n            add_ndvi=add_ndvi,\n            add_ndwi=add_ndwi,\n            nan=nan_fill,\n            normalizing_dict=self.normalizing_dict,\n            days_per_timestep=days_per_timestep,\n        )\n\n        if with_forecaster:\n            input_data.x = input_data.x[:, : self.hparams.input_months, :]\n\n        predictions: List[np.ndarray] = []\n        cur_i = 0\n\n        pbar = tqdm(total=input_data.x.shape[0] - 1)\n        while cur_i < (input_data.x.shape[0] - 1):\n\n            batch_x_np = input_data.x[cur_i: cur_i + batch_size]\n            if self.hparams.remove_b1_b10:\n                batch_x_np = CropDataset._remove_bands(batch_x_np)\n            batch_x = torch.from_numpy(batch_x_np).float()\n\n            if use_gpu and (device is not None):\n                batch_x = batch_x.to(device)\n\n            with torch.no_grad():\n                if with_forecaster:\n                    batch_x_next = self.forecaster(batch_x)\n                    batch_x = torch.cat((batch_x, batch_x_next), dim=1)\n\n                batch_preds = self.classifier(batch_x)\n\n                if self.hparams.multi_headed:\n                    global_preds, local_preds = batch_preds\n\n                    if local_head:\n                        batch_preds = local_preds\n                    else:\n                        batch_preds = global_preds\n\n                # back to the CPU, if necessary\n                batch_preds = batch_preds.cpu()\n\n            predictions.append(cast(torch.Tensor, batch_preds).numpy())\n            cur_i += batch_size\n            pbar.update(batch_size)\n\n        all_preds = np.concatenate(predictions, axis=0)\n        if len(all_preds.shape) == 1:\n            all_preds = np.expand_dims(all_preds, axis=-1)\n\n        return preds_to_xr(all_preds, lats=input_data.lat, lons=input_data.lon,)\n\n    def _output_metrics(\n        self, preds: np.ndarray, labels: np.ndarray, prefix: str = \"\"\n    ) -> Dict[str, float]:\n\n        if len(preds) == 0:\n            # sometimes this happens in the warmup\n            return {}\n\n        output_dict: Dict[str, float] = {}\n        if not (labels == labels[0]).all():\n            # This can happen when lightning does its warm up on a subset of the\n            # validation data\n            output_dict[f\"{prefix}roc_auc_score\"] = roc_auc_score(\n                labels, preds)\n\n        preds = (preds > PROBABILITY_THRESHOLD).astype(int)\n\n        output_dict[f\"{prefix}precision_score\"] = precision_score(\n            labels, preds)\n        output_dict[f\"{prefix}recall_score\"] = recall_score(labels, preds)\n        output_dict[f\"{prefix}f1_score\"] = f1_score(labels, preds)\n        output_dict[f\"{prefix}accuracy\"] = accuracy_score(labels, preds)\n\n        return output_dict\n\n    def add_noise(self, x: torch.Tensor, training: bool) -> torch.Tensor:\n        if (self.hparams.noise_factor == 0) or (not training):\n            return x\n\n        # expect input to be of shape [timesteps, bands]\n        # and to be normalized with mean 0, std=1\n        # if its not, it means no norm_dict was passed, so lets\n        # just assume std=1\n        noise = torch.normal(0, 1, size=x.shape).float() * \\\n            self.hparams.noise_factor\n\n        # the added noise is the same per band, so that the temporal relationships\n        # are preserved\n        # noise_per_timesteps = noise.repeat(x.shape[0], 1)\n        return x + noise\n\n    def _split_preds_and_get_loss(\n        self, batch, add_preds: bool, loss_label: str, log_loss: bool, training: bool\n    ) -> Dict:\n\n        x, label, is_global = batch\n\n        input_to_encode = x[:, : self.hparams.input_months, :]\n\n        if self.hparams.forecast:\n            # we will predict every timestep except the first one\n            output_to_predict = x[:, 1:, :]\n            encoder_output = self.forecaster(input_to_encode)\n            encoder_loss = self.forecaster_loss(\n                encoder_output, output_to_predict)\n            loss: Union[float, torch.Tensor] = encoder_loss\n\n            final_encoded_input = torch.cat(\n                (\n                    (\n                        self.add_noise(input_to_encode, training),\n                        # -1 because the encoder output has no value for the 0th\n                        # timestep\n                        encoder_output[:, self.hparams.input_months - 1:, :],\n                    )\n                ),\n                dim=1,\n            )\n\n            output_dict = {}\n            if add_preds:\n                output_dict.update(\n                    {\"encoder_prediction\": encoder_output,\n                        \"encoder_target\": output_to_predict, }\n                )\n            if log_loss:\n                output_dict[\"log\"] = {}\n\n            # we now repeat label and is_global\n            x = torch.cat((self.add_noise(x, training),\n                          final_encoded_input), dim=0)\n            label = torch.cat((label, label), dim=0)\n            is_global = torch.cat((is_global, is_global), dim=0)\n        else:\n            loss = 0\n            output_dict = {}\n            if log_loss:\n                output_dict[\"log\"] = {}\n            x = self.add_noise(input_to_encode, training=training)\n\n        if self.hparams.multi_headed:\n            org_global_preds, local_preds = self.classifier(x)\n            global_preds = org_global_preds[is_global != 0]\n            global_labels = label[is_global != 0]\n\n            local_preds = local_preds[is_global == 0]\n            local_labels = label[is_global == 0]\n\n            if local_preds.shape[0] > 0:\n                local_loss = self.local_loss_function(\n                    local_preds.squeeze(-1), local_labels,)\n                loss += local_loss\n\n            if global_preds.shape[0] > 0:\n                global_loss = self.global_loss_function(\n                    global_preds.squeeze(-1), global_labels,)\n\n                num_local_labels = local_preds.shape[0]\n                if num_local_labels == 0:\n                    alpha = 1\n                else:\n                    ratio = global_preds.shape[0] / num_local_labels\n                    alpha = ratio / self.hparams.alpha\n                loss += alpha * global_loss\n\n            output_dict[loss_label] = loss\n            if log_loss:\n                output_dict[\"log\"][loss_label] = loss\n            if add_preds:\n                output_dict.update(\n                    {\n                        \"global_pred\": global_preds,\n                        \"global_label\": global_labels,\n                        \"kenya_pred\": local_preds,\n                        \"kenya_label\": local_labels,\n                    }\n                )\n            return output_dict\n        else:\n            preds = cast(torch.Tensor, self.classifier(x))\n\n            loss += self.global_loss_function(\n                input=preds.squeeze(-1), target=label,)\n\n            output_dict = {loss_label: loss}\n            if log_loss:\n                output_dict[\"log\"][loss_label] = loss\n            if add_preds:\n                output_dict.update({\"pred\": preds, \"label\": label})\n            return output_dict\n\n    def training_step(self, batch, batch_idx):\n        return self._split_preds_and_get_loss(\n            batch, add_preds=False, loss_label=\"loss\", log_loss=True, training=True\n        )\n\n    def validation_step(self, batch, batch_idx):\n        return self._split_preds_and_get_loss(\n            batch, add_preds=True, loss_label=\"val_loss\", log_loss=True, training=False\n        )\n\n    def test_step(self, batch, batch_idx):\n        return self._split_preds_and_get_loss(\n            batch, add_preds=True, loss_label=\"test_loss\", log_loss=True, training=False\n        )\n\n    @staticmethod\n    def _split_tensor(outputs, label) -> Tuple[np.ndarray, np.ndarray]:\n        encoded_all, unencoded_all = [], []\n        for x in outputs:\n            # the first half is unencoded, the second is encoded\n            total = x[label]\n            unencoded_all.append(total[: total.shape[0] // 2])\n            encoded_all.append(total[total.shape[0] // 2:])\n        return (\n            torch.cat(unencoded_all).detach().cpu().numpy(),\n            torch.cat(encoded_all).detach().cpu().numpy(),\n        )\n\n    def _interpretable_metrics(self, outputs, input_prefix: str, output_prefix: str) -> Dict:\n\n        output_dict = {}\n\n        if self.hparams.forecast:\n            u_labels, e_labels = self._split_tensor(\n                outputs, f\"{input_prefix}label\")\n\n            u_preds, e_preds = self._split_tensor(\n                outputs, f\"{input_prefix}pred\")\n        else:\n            u_preds = torch.cat([x[f\"{input_prefix}pred\"]\n                                for x in outputs]).detach().cpu().numpy()\n            u_labels = (\n                torch.cat([x[f\"{input_prefix}label\"]\n                          for x in outputs]).detach().cpu().numpy()\n            )\n\n        output_dict.update(\n            self._output_metrics(\n                u_preds, u_labels, f\"unencoded_{output_prefix}{input_prefix}\")\n        )\n\n        if self.hparams.forecast:\n            output_dict.update(\n                self._output_metrics(\n                    e_preds, e_labels, f\"encoded_{output_prefix}{input_prefix}\")\n            )\n\n        return output_dict\n\n    def validation_epoch_end(self, outputs):\n        avg_loss = torch.stack([x[\"val_loss\"] for x in outputs]).mean()\n        logs = {\"val_loss\": avg_loss}\n        if self.hparams.forecast:\n            encoder_pred = (\n                torch.cat(\n                    [torch.flatten(x[\"encoder_prediction\"], start_dim=1) for x in outputs], dim=0,\n                )\n                .detach()\n                .cpu()\n                .numpy()\n            )\n            encoder_target = (\n                torch.cat(\n                    [torch.flatten(x[\"encoder_target\"], start_dim=1) for x in outputs], dim=0,\n                )\n                .detach()\n                .cpu()\n                .numpy()\n            )\n\n            logs[\"val_encoder_mae\"] = mean_absolute_error(\n                encoder_target, encoder_pred)\n\n        if self.hparams.multi_headed:\n            logs.update(self._interpretable_metrics(\n                outputs, \"global_\", \"val_\"))\n            logs.update(self._interpretable_metrics(outputs, \"kenya_\", \"val_\"))\n        else:\n            logs.update(self._interpretable_metrics(outputs, \"\", \"val_\"))\n        return {\"val_loss\": avg_loss, \"log\": logs}\n\n    def test_epoch_end(self, outputs):\n\n        avg_loss = torch.stack([x[\"test_loss\"] for x in outputs]).mean().item()\n        output_dict = {\"val_loss\": avg_loss}\n\n        if self.hparams.forecast:\n            encoder_pred = (\n                torch.cat(\n                    [torch.flatten(x[\"encoder_prediction\"], start_dim=1) for x in outputs], dim=0,\n                )\n                .detach()\n                .cpu()\n                .numpy()\n            )\n            encoder_target = (\n                torch.cat(\n                    [torch.flatten(x[\"encoder_target\"], start_dim=1) for x in outputs], dim=0,\n                )\n                .detach()\n                .cpu()\n                .numpy()\n            )\n\n            output_dict[\"test_encoder_mae\"] = mean_absolute_error(\n                encoder_target, encoder_pred)\n\n        if self.hparams.multi_headed:\n            output_dict.update(self._interpretable_metrics(\n                outputs, \"global_\", \"test_\"))\n            output_dict.update(self._interpretable_metrics(\n                outputs, \"kenya_\", \"test_\"))\n        else:\n            output_dict.update(\n                self._interpretable_metrics(outputs, \"\", \"test_\"))\n\n        return {\"progress_bar\": output_dict}\n\n    @staticmethod\n    def add_model_specific_args(parent_parser: ArgumentParser) -> ArgumentParser:\n\n        parser = ArgumentParser(parents=[parent_parser], add_help=False)\n\n        parser_args: Dict[str, Tuple[Type, Any]] = {\n            # assumes this is being run from \"scripts\"\n            \"--data_folder\": (str, str(Path(\"../data\"))),\n            \"--learning_rate\": (float, 0.001),\n            \"--batch_size\": (int, 64),\n            \"--input_months\": (int, 5),\n            \"--alpha\": (float, 10),\n            \"--noise_factor\": (float, 0.1),\n        }\n\n        for key, val in parser_args.items():\n            parser.add_argument(key, type=val[0], default=val[1])\n\n        parser.add_argument(\"--remove_b1_b10\",\n                            dest=\"remove_b1_b10\", action=\"store_true\")\n        parser.add_argument(\n            \"--keep_b1_b10\", dest=\"remove_b1_b10\", action=\"store_false\")\n        parser.set_defaults(remove_b1_b10=True)\n\n        parser.add_argument(\"--forecast\", dest=\"forecast\", action=\"store_true\")\n        parser.add_argument(\"--do_not_forecast\",\n                            dest=\"forecast\", action=\"store_false\")\n        parser.set_defaults(forecast=True)\n\n        parser.add_argument(\"--cache\", dest=\"cache\", action=\"store_true\")\n        parser.add_argument(\"--do_not_cache\", dest=\"cache\",\n                            action=\"store_false\")\n        parser.set_defaults(cache=True)\n\n        parser.add_argument(\"--include_geowiki\",\n                            dest=\"include_geowiki\", action=\"store_true\")\n        parser.add_argument(\"--exclude_geowiki\",\n                            dest=\"include_geowiki\", action=\"store_false\")\n        parser.set_defaults(include_geowiki=True)\n\n        parser.add_argument(\"--upsample\", dest=\"upsample\", action=\"store_true\")\n        parser.add_argument(\"--do_not_upsample\",\n                            dest=\"upsample\", action=\"store_false\")\n        parser.set_defaults(upsample=True)\n\n        classifier_parser = Classifier.add_model_specific_args(parser)\n        return Forecaster.add_model_specific_args(classifier_parser)\n",
  "history_output" : "",
  "history_begin_time" : 1646138298059,
  "history_end_time" : 1646138302410,
  "history_notes" : null,
  "history_process" : "9ardvx",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "8xos7eopy2g",
  "history_input" : "from argparse import ArgumentParser, Namespace\nfrom pathlib import Path\nimport numpy as np\nimport xarray as xr\nfrom tqdm import tqdm\n\nimport torch\nfrom torch.nn import functional as F\nfrom torch.utils.data import DataLoader\n\nimport pytorch_lightning as pl\n\nfrom sklearn.metrics import (\n    roc_auc_score,\n    accuracy_score,\n    precision_score,\n    recall_score,\n    f1_score,\n    mean_absolute_error,\n)\n\nfrom src_models_data import CropDataset\nfrom src_models_utils import tif_to_np, preds_to_xr\nfrom src_utils import set_seed\nfrom src_models_forecaster import Forecaster\nfrom src_models_classifier import Classifier\nfrom src_config import PROBABILITY_THRESHOLD\n\nfrom typing import cast, Callable, Tuple, Dict, Any, Type, Optional, List, Union\n\n\nclass Model(pl.LightningModule):\n    r\"\"\"\n    An model for annual and in-season crop mapping. This model consists of a\n    forecaster.Forecaster and a classifier.Classifier - it will require the arguments\n    required by those models too.\n\n    hparams\n    --------\n    The default values for these parameters are set in add_model_specific_args\n\n    :param hparams.data_folder: The path to the data. Default (assumes the model\n        is being run from the scripts directory) = \"../data\"\n    :param hparams.learning_rate: The learning rate. Default = 0.001\n    :param hparams.batch_size: The batch size. Default = 64\n    :param hparams.input_months: The number of input months to pass to the model. If\n        hparams.forecast is True, the remaining months will be forecasted. Otherwise, only the\n        partial timeseries will be passed to the classifier. Default = 5\n    :param hparams.alpha: The weight to use when adding the global and local losses. This\n        parameter is only used if hparams.multi_headed is True. Default = 10\n    :param hparams.noise_factor: The standard deviation of the random noise to add to the\n        raw inputs to the classifier. Default = 0.1\n    :param hparams.remove_b1_b10: Whether or not to remove the B1 and B10 bands. Default = True\n    :param hparams.forecast: Whether or not to forecast the partial time series. Default = True\n    :param hparams.cache: Whether to load all the data into memory during training. Default = True\n    :param hparams.include_geowiki: Whether to include the global GeoWiki dataset during\n        training. Default = True\n    :param hparams.upsample: Whether to oversample the under-represented class so that each class\n        is equally represented in the training and validation dataset. Default = True\n    \"\"\"\n\n    def __init__(self, hparams: Namespace) -> None:\n        super().__init__()\n        set_seed()\n        self.hparams = hparams\n\n        self.data_folder = Path(hparams.data_folder)\n\n        dataset = self.get_dataset(subset=\"training\", cache=False)\n        self.num_outputs = dataset.num_output_classes\n        self.num_timesteps = dataset.num_timesteps\n        self.input_size = dataset.num_input_features\n\n        # we save the normalizing dict because we calculate weighted\n        # normalization values based on the datasets we combine.\n        # The number of instances per dataset (and therefore the weights) can\n        # vary between the train / test / val sets - this ensures the normalizing\n        # dict stays constant between them\n        self.normalizing_dict = dataset.normalizing_dict\n\n        if self.hparams.forecast:\n            num_output_timesteps = self.num_timesteps - self.hparams.input_months\n            print(\n                f\"Predicting {num_output_timesteps} timesteps in the forecaster\")\n            self.forecaster = Forecaster(\n                num_bands=self.input_size, output_timesteps=num_output_timesteps, hparams=hparams,\n            )\n\n            self.forecaster_loss = F.smooth_l1_loss\n\n        self.classifier = Classifier(\n            input_size=self.input_size, hparams=hparams)\n        self.global_loss_function: Callable = F.binary_cross_entropy\n        self.local_loss_function: Callable = F.binary_cross_entropy\n\n    def forward(self, x: torch.Tensor) -> Union[torch.Tensor, Tuple[torch.Tensor, torch.Tensor]]:\n        # To keep the ABC happy\n        return self.classifier(x)\n\n    def configure_optimizers(self):\n        return torch.optim.Adam(self.parameters(), lr=self.hparams.learning_rate)\n\n    def get_dataset(\n        self, subset: str, normalizing_dict: Optional[Dict] = None, cache: Optional[bool] = None,\n    ) -> CropDataset:\n        return CropDataset(\n            data_folder=self.data_folder,\n            subset=subset,\n            remove_b1_b10=self.hparams.remove_b1_b10,\n            normalizing_dict=normalizing_dict,\n            include_geowiki=self.hparams.include_geowiki if subset != \"testing\" else False,\n            cache=self.hparams.cache if cache is None else cache,\n            upsample=self.hparams.upsample if subset != \"testing\" else False,\n            noise_factor=self.hparams.noise_factor if subset != \"testing\" else 0,\n        )\n\n    def train_dataloader(self):\n        return DataLoader(\n            self.get_dataset(subset=\"training\"), shuffle=True, batch_size=self.hparams.batch_size,\n        )\n\n    def val_dataloader(self):\n        return DataLoader(\n            self.get_dataset(subset=\"validation\",\n                             normalizing_dict=self.normalizing_dict,),\n            batch_size=self.hparams.batch_size,\n        )\n\n    def test_dataloader(self):\n        return DataLoader(\n            self.get_dataset(subset=\"testing\",\n                             normalizing_dict=self.normalizing_dict,),\n            batch_size=self.hparams.batch_size,\n        )\n\n    def predict(\n        self,\n        path_to_file: Path,\n        with_forecaster: bool,\n        batch_size: int = 64,\n        add_ndvi: bool = True,\n        add_ndwi: bool = False,\n        nan_fill: float = 0,\n        days_per_timestep: int = 30,\n        local_head: bool = True,\n        use_gpu: bool = True,\n    ) -> xr.Dataset:\n\n        # check if a GPU is available, and if it is\n        # move the model onto the GPU\n        device: Optional[torch.device] = None\n        if use_gpu:\n            use_cuda = torch.cuda.is_available()\n            if not use_cuda:\n                print(\"No GPU - not using one\")\n            device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n            self.to(device)\n\n        self.eval()\n\n        input_data = tif_to_np(\n            path_to_file,\n            add_ndvi=add_ndvi,\n            add_ndwi=add_ndwi,\n            nan=nan_fill,\n            normalizing_dict=self.normalizing_dict,\n            days_per_timestep=days_per_timestep,\n        )\n\n        if with_forecaster:\n            input_data.x = input_data.x[:, : self.hparams.input_months, :]\n\n        predictions: List[np.ndarray] = []\n        cur_i = 0\n\n        pbar = tqdm(total=input_data.x.shape[0] - 1)\n        while cur_i < (input_data.x.shape[0] - 1):\n\n            batch_x_np = input_data.x[cur_i: cur_i + batch_size]\n            if self.hparams.remove_b1_b10:\n                batch_x_np = CropDataset._remove_bands(batch_x_np)\n            batch_x = torch.from_numpy(batch_x_np).float()\n\n            if use_gpu and (device is not None):\n                batch_x = batch_x.to(device)\n\n            with torch.no_grad():\n                if with_forecaster:\n                    batch_x_next = self.forecaster(batch_x)\n                    batch_x = torch.cat((batch_x, batch_x_next), dim=1)\n\n                batch_preds = self.classifier(batch_x)\n\n                if self.hparams.multi_headed:\n                    global_preds, local_preds = batch_preds\n\n                    if local_head:\n                        batch_preds = local_preds\n                    else:\n                        batch_preds = global_preds\n\n                # back to the CPU, if necessary\n                batch_preds = batch_preds.cpu()\n\n            predictions.append(cast(torch.Tensor, batch_preds).numpy())\n            cur_i += batch_size\n            pbar.update(batch_size)\n\n        all_preds = np.concatenate(predictions, axis=0)\n        if len(all_preds.shape) == 1:\n            all_preds = np.expand_dims(all_preds, axis=-1)\n\n        return preds_to_xr(all_preds, lats=input_data.lat, lons=input_data.lon,)\n\n    def _output_metrics(\n        self, preds: np.ndarray, labels: np.ndarray, prefix: str = \"\"\n    ) -> Dict[str, float]:\n\n        if len(preds) == 0:\n            # sometimes this happens in the warmup\n            return {}\n\n        output_dict: Dict[str, float] = {}\n        if not (labels == labels[0]).all():\n            # This can happen when lightning does its warm up on a subset of the\n            # validation data\n            output_dict[f\"{prefix}roc_auc_score\"] = roc_auc_score(\n                labels, preds)\n\n        preds = (preds > PROBABILITY_THRESHOLD).astype(int)\n\n        output_dict[f\"{prefix}precision_score\"] = precision_score(\n            labels, preds)\n        output_dict[f\"{prefix}recall_score\"] = recall_score(labels, preds)\n        output_dict[f\"{prefix}f1_score\"] = f1_score(labels, preds)\n        output_dict[f\"{prefix}accuracy\"] = accuracy_score(labels, preds)\n\n        return output_dict\n\n    def add_noise(self, x: torch.Tensor, training: bool) -> torch.Tensor:\n        if (self.hparams.noise_factor == 0) or (not training):\n            return x\n\n        # expect input to be of shape [timesteps, bands]\n        # and to be normalized with mean 0, std=1\n        # if its not, it means no norm_dict was passed, so lets\n        # just assume std=1\n        noise = torch.normal(0, 1, size=x.shape).float() * \\\n            self.hparams.noise_factor\n\n        # the added noise is the same per band, so that the temporal relationships\n        # are preserved\n        # noise_per_timesteps = noise.repeat(x.shape[0], 1)\n        return x + noise\n\n    def _split_preds_and_get_loss(\n        self, batch, add_preds: bool, loss_label: str, log_loss: bool, training: bool\n    ) -> Dict:\n\n        x, label, is_global = batch\n\n        input_to_encode = x[:, : self.hparams.input_months, :]\n\n        if self.hparams.forecast:\n            # we will predict every timestep except the first one\n            output_to_predict = x[:, 1:, :]\n            encoder_output = self.forecaster(input_to_encode)\n            encoder_loss = self.forecaster_loss(\n                encoder_output, output_to_predict)\n            loss: Union[float, torch.Tensor] = encoder_loss\n\n            final_encoded_input = torch.cat(\n                (\n                    (\n                        self.add_noise(input_to_encode, training),\n                        # -1 because the encoder output has no value for the 0th\n                        # timestep\n                        encoder_output[:, self.hparams.input_months - 1:, :],\n                    )\n                ),\n                dim=1,\n            )\n\n            output_dict = {}\n            if add_preds:\n                output_dict.update(\n                    {\"encoder_prediction\": encoder_output,\n                        \"encoder_target\": output_to_predict, }\n                )\n            if log_loss:\n                output_dict[\"log\"] = {}\n\n            # we now repeat label and is_global\n            x = torch.cat((self.add_noise(x, training),\n                          final_encoded_input), dim=0)\n            label = torch.cat((label, label), dim=0)\n            is_global = torch.cat((is_global, is_global), dim=0)\n        else:\n            loss = 0\n            output_dict = {}\n            if log_loss:\n                output_dict[\"log\"] = {}\n            x = self.add_noise(input_to_encode, training=training)\n\n        if self.hparams.multi_headed:\n            org_global_preds, local_preds = self.classifier(x)\n            global_preds = org_global_preds[is_global != 0]\n            global_labels = label[is_global != 0]\n\n            local_preds = local_preds[is_global == 0]\n            local_labels = label[is_global == 0]\n\n            if local_preds.shape[0] > 0:\n                local_loss = self.local_loss_function(\n                    local_preds.squeeze(-1), local_labels,)\n                loss += local_loss\n\n            if global_preds.shape[0] > 0:\n                global_loss = self.global_loss_function(\n                    global_preds.squeeze(-1), global_labels,)\n\n                num_local_labels = local_preds.shape[0]\n                if num_local_labels == 0:\n                    alpha = 1\n                else:\n                    ratio = global_preds.shape[0] / num_local_labels\n                    alpha = ratio / self.hparams.alpha\n                loss += alpha * global_loss\n\n            output_dict[loss_label] = loss\n            if log_loss:\n                output_dict[\"log\"][loss_label] = loss\n            if add_preds:\n                output_dict.update(\n                    {\n                        \"global_pred\": global_preds,\n                        \"global_label\": global_labels,\n                        \"kenya_pred\": local_preds,\n                        \"kenya_label\": local_labels,\n                    }\n                )\n            return output_dict\n        else:\n            preds = cast(torch.Tensor, self.classifier(x))\n\n            loss += self.global_loss_function(\n                input=preds.squeeze(-1), target=label,)\n\n            output_dict = {loss_label: loss}\n            if log_loss:\n                output_dict[\"log\"][loss_label] = loss\n            if add_preds:\n                output_dict.update({\"pred\": preds, \"label\": label})\n            return output_dict\n\n    def training_step(self, batch, batch_idx):\n        return self._split_preds_and_get_loss(\n            batch, add_preds=False, loss_label=\"loss\", log_loss=True, training=True\n        )\n\n    def validation_step(self, batch, batch_idx):\n        return self._split_preds_and_get_loss(\n            batch, add_preds=True, loss_label=\"val_loss\", log_loss=True, training=False\n        )\n\n    def test_step(self, batch, batch_idx):\n        return self._split_preds_and_get_loss(\n            batch, add_preds=True, loss_label=\"test_loss\", log_loss=True, training=False\n        )\n\n    @staticmethod\n    def _split_tensor(outputs, label) -> Tuple[np.ndarray, np.ndarray]:\n        encoded_all, unencoded_all = [], []\n        for x in outputs:\n            # the first half is unencoded, the second is encoded\n            total = x[label]\n            unencoded_all.append(total[: total.shape[0] // 2])\n            encoded_all.append(total[total.shape[0] // 2:])\n        return (\n            torch.cat(unencoded_all).detach().cpu().numpy(),\n            torch.cat(encoded_all).detach().cpu().numpy(),\n        )\n\n    def _interpretable_metrics(self, outputs, input_prefix: str, output_prefix: str) -> Dict:\n\n        output_dict = {}\n\n        if self.hparams.forecast:\n            u_labels, e_labels = self._split_tensor(\n                outputs, f\"{input_prefix}label\")\n\n            u_preds, e_preds = self._split_tensor(\n                outputs, f\"{input_prefix}pred\")\n        else:\n            u_preds = torch.cat([x[f\"{input_prefix}pred\"]\n                                for x in outputs]).detach().cpu().numpy()\n            u_labels = (\n                torch.cat([x[f\"{input_prefix}label\"]\n                          for x in outputs]).detach().cpu().numpy()\n            )\n\n        output_dict.update(\n            self._output_metrics(\n                u_preds, u_labels, f\"unencoded_{output_prefix}{input_prefix}\")\n        )\n\n        if self.hparams.forecast:\n            output_dict.update(\n                self._output_metrics(\n                    e_preds, e_labels, f\"encoded_{output_prefix}{input_prefix}\")\n            )\n\n        return output_dict\n\n    def validation_epoch_end(self, outputs):\n        avg_loss = torch.stack([x[\"val_loss\"] for x in outputs]).mean()\n        logs = {\"val_loss\": avg_loss}\n        if self.hparams.forecast:\n            encoder_pred = (\n                torch.cat(\n                    [torch.flatten(x[\"encoder_prediction\"], start_dim=1) for x in outputs], dim=0,\n                )\n                .detach()\n                .cpu()\n                .numpy()\n            )\n            encoder_target = (\n                torch.cat(\n                    [torch.flatten(x[\"encoder_target\"], start_dim=1) for x in outputs], dim=0,\n                )\n                .detach()\n                .cpu()\n                .numpy()\n            )\n\n            logs[\"val_encoder_mae\"] = mean_absolute_error(\n                encoder_target, encoder_pred)\n\n        if self.hparams.multi_headed:\n            logs.update(self._interpretable_metrics(\n                outputs, \"global_\", \"val_\"))\n            logs.update(self._interpretable_metrics(outputs, \"kenya_\", \"val_\"))\n        else:\n            logs.update(self._interpretable_metrics(outputs, \"\", \"val_\"))\n        return {\"val_loss\": avg_loss, \"log\": logs}\n\n    def test_epoch_end(self, outputs):\n\n        avg_loss = torch.stack([x[\"test_loss\"] for x in outputs]).mean().item()\n        output_dict = {\"val_loss\": avg_loss}\n\n        if self.hparams.forecast:\n            encoder_pred = (\n                torch.cat(\n                    [torch.flatten(x[\"encoder_prediction\"], start_dim=1) for x in outputs], dim=0,\n                )\n                .detach()\n                .cpu()\n                .numpy()\n            )\n            encoder_target = (\n                torch.cat(\n                    [torch.flatten(x[\"encoder_target\"], start_dim=1) for x in outputs], dim=0,\n                )\n                .detach()\n                .cpu()\n                .numpy()\n            )\n\n            output_dict[\"test_encoder_mae\"] = mean_absolute_error(\n                encoder_target, encoder_pred)\n\n        if self.hparams.multi_headed:\n            output_dict.update(self._interpretable_metrics(\n                outputs, \"global_\", \"test_\"))\n            output_dict.update(self._interpretable_metrics(\n                outputs, \"kenya_\", \"test_\"))\n        else:\n            output_dict.update(\n                self._interpretable_metrics(outputs, \"\", \"test_\"))\n\n        return {\"progress_bar\": output_dict}\n\n    @staticmethod\n    def add_model_specific_args(parent_parser: ArgumentParser) -> ArgumentParser:\n\n        parser = ArgumentParser(parents=[parent_parser], add_help=False)\n\n        parser_args: Dict[str, Tuple[Type, Any]] = {\n            # assumes this is being run from \"scripts\"\n            \"--data_folder\": (str, str(Path(\"../data\"))),\n            \"--learning_rate\": (float, 0.001),\n            \"--batch_size\": (int, 64),\n            \"--input_months\": (int, 5),\n            \"--alpha\": (float, 10),\n            \"--noise_factor\": (float, 0.1),\n        }\n\n        for key, val in parser_args.items():\n            parser.add_argument(key, type=val[0], default=val[1])\n\n        parser.add_argument(\"--remove_b1_b10\",\n                            dest=\"remove_b1_b10\", action=\"store_true\")\n        parser.add_argument(\n            \"--keep_b1_b10\", dest=\"remove_b1_b10\", action=\"store_false\")\n        parser.set_defaults(remove_b1_b10=True)\n\n        parser.add_argument(\"--forecast\", dest=\"forecast\", action=\"store_true\")\n        parser.add_argument(\"--do_not_forecast\",\n                            dest=\"forecast\", action=\"store_false\")\n        parser.set_defaults(forecast=True)\n\n        parser.add_argument(\"--cache\", dest=\"cache\", action=\"store_true\")\n        parser.add_argument(\"--do_not_cache\", dest=\"cache\",\n                            action=\"store_false\")\n        parser.set_defaults(cache=True)\n\n        parser.add_argument(\"--include_geowiki\",\n                            dest=\"include_geowiki\", action=\"store_true\")\n        parser.add_argument(\"--exclude_geowiki\",\n                            dest=\"include_geowiki\", action=\"store_false\")\n        parser.set_defaults(include_geowiki=True)\n\n        parser.add_argument(\"--upsample\", dest=\"upsample\", action=\"store_true\")\n        parser.add_argument(\"--do_not_upsample\",\n                            dest=\"upsample\", action=\"store_false\")\n        parser.set_defaults(upsample=True)\n\n        classifier_parser = Classifier.add_model_specific_args(parser)\n        return Forecaster.add_model_specific_args(classifier_parser)\n",
  "history_output" : "",
  "history_begin_time" : 1646138200041,
  "history_end_time" : 1646138204126,
  "history_notes" : null,
  "history_process" : "9ardvx",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "np8x3gpzmo8",
  "history_input" : "from argparse import ArgumentParser, Namespace\nfrom pathlib import Path\nimport numpy as np\nimport xarray as xr\nfrom tqdm import tqdm\n\nimport torch\nfrom torch.nn import functional as F\nfrom torch.utils.data import DataLoader\n\nimport pytorch_lightning as pl\n\nfrom sklearn.metrics import (\n    roc_auc_score,\n    accuracy_score,\n    precision_score,\n    recall_score,\n    f1_score,\n    mean_absolute_error,\n)\n\nfrom src_models_data import CropDataset\nfrom src_models_utils import tif_to_np, preds_to_xr\nfrom src_utils import set_seed\nfrom src_models_forecaster import Forecaster\nfrom src_models_classifier import Classifier\nfrom src_config import PROBABILITY_THRESHOLD\n\nfrom typing import cast, Callable, Tuple, Dict, Any, Type, Optional, List, Union\n\n\nclass Model(pl.LightningModule):\n    r\"\"\"\n    An model for annual and in-season crop mapping. This model consists of a\n    forecaster.Forecaster and a classifier.Classifier - it will require the arguments\n    required by those models too.\n\n    hparams\n    --------\n    The default values for these parameters are set in add_model_specific_args\n\n    :param hparams.data_folder: The path to the data. Default (assumes the model\n        is being run from the scripts directory) = \"../data\"\n    :param hparams.learning_rate: The learning rate. Default = 0.001\n    :param hparams.batch_size: The batch size. Default = 64\n    :param hparams.input_months: The number of input months to pass to the model. If\n        hparams.forecast is True, the remaining months will be forecasted. Otherwise, only the\n        partial timeseries will be passed to the classifier. Default = 5\n    :param hparams.alpha: The weight to use when adding the global and local losses. This\n        parameter is only used if hparams.multi_headed is True. Default = 10\n    :param hparams.noise_factor: The standard deviation of the random noise to add to the\n        raw inputs to the classifier. Default = 0.1\n    :param hparams.remove_b1_b10: Whether or not to remove the B1 and B10 bands. Default = True\n    :param hparams.forecast: Whether or not to forecast the partial time series. Default = True\n    :param hparams.cache: Whether to load all the data into memory during training. Default = True\n    :param hparams.include_geowiki: Whether to include the global GeoWiki dataset during\n        training. Default = True\n    :param hparams.upsample: Whether to oversample the under-represented class so that each class\n        is equally represented in the training and validation dataset. Default = True\n    \"\"\"\n\n    def __init__(self, hparams: Namespace) -> None:\n        super().__init__()\n        set_seed()\n        self.hparams = hparams\n\n        self.data_folder = Path(hparams.data_folder)\n\n        dataset = self.get_dataset(subset=\"training\", cache=False)\n        self.num_outputs = dataset.num_output_classes\n        self.num_timesteps = dataset.num_timesteps\n        self.input_size = dataset.num_input_features\n\n        # we save the normalizing dict because we calculate weighted\n        # normalization values based on the datasets we combine.\n        # The number of instances per dataset (and therefore the weights) can\n        # vary between the train / test / val sets - this ensures the normalizing\n        # dict stays constant between them\n        self.normalizing_dict = dataset.normalizing_dict\n\n        if self.hparams.forecast:\n            num_output_timesteps = self.num_timesteps - self.hparams.input_months\n            print(\n                f\"Predicting {num_output_timesteps} timesteps in the forecaster\")\n            self.forecaster = Forecaster(\n                num_bands=self.input_size, output_timesteps=num_output_timesteps, hparams=hparams,\n            )\n\n            self.forecaster_loss = F.smooth_l1_loss\n\n        self.classifier = Classifier(\n            input_size=self.input_size, hparams=hparams)\n        self.global_loss_function: Callable = F.binary_cross_entropy\n        self.local_loss_function: Callable = F.binary_cross_entropy\n\n    def forward(self, x: torch.Tensor) -> Union[torch.Tensor, Tuple[torch.Tensor, torch.Tensor]]:\n        # To keep the ABC happy\n        return self.classifier(x)\n\n    def configure_optimizers(self):\n        return torch.optim.Adam(self.parameters(), lr=self.hparams.learning_rate)\n\n    def get_dataset(\n        self, subset: str, normalizing_dict: Optional[Dict] = None, cache: Optional[bool] = None,\n    ) -> CropDataset:\n        return CropDataset(\n            data_folder=self.data_folder,\n            subset=subset,\n            remove_b1_b10=self.hparams.remove_b1_b10,\n            normalizing_dict=normalizing_dict,\n            include_geowiki=self.hparams.include_geowiki if subset != \"testing\" else False,\n            cache=self.hparams.cache if cache is None else cache,\n            upsample=self.hparams.upsample if subset != \"testing\" else False,\n            noise_factor=self.hparams.noise_factor if subset != \"testing\" else 0,\n        )\n\n    def train_dataloader(self):\n        return DataLoader(\n            self.get_dataset(subset=\"training\"), shuffle=True, batch_size=self.hparams.batch_size,\n        )\n\n    def val_dataloader(self):\n        return DataLoader(\n            self.get_dataset(subset=\"validation\",\n                             normalizing_dict=self.normalizing_dict,),\n            batch_size=self.hparams.batch_size,\n        )\n\n    def test_dataloader(self):\n        return DataLoader(\n            self.get_dataset(subset=\"testing\",\n                             normalizing_dict=self.normalizing_dict,),\n            batch_size=self.hparams.batch_size,\n        )\n\n    def predict(\n        self,\n        path_to_file: Path,\n        with_forecaster: bool,\n        batch_size: int = 64,\n        add_ndvi: bool = True,\n        add_ndwi: bool = False,\n        nan_fill: float = 0,\n        days_per_timestep: int = 30,\n        local_head: bool = True,\n        use_gpu: bool = True,\n    ) -> xr.Dataset:\n\n        # check if a GPU is available, and if it is\n        # move the model onto the GPU\n        device: Optional[torch.device] = None\n        if use_gpu:\n            use_cuda = torch.cuda.is_available()\n            if not use_cuda:\n                print(\"No GPU - not using one\")\n            device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n            self.to(device)\n\n        self.eval()\n\n        input_data = tif_to_np(\n            path_to_file,\n            add_ndvi=add_ndvi,\n            add_ndwi=add_ndwi,\n            nan=nan_fill,\n            normalizing_dict=self.normalizing_dict,\n            days_per_timestep=days_per_timestep,\n        )\n\n        if with_forecaster:\n            input_data.x = input_data.x[:, : self.hparams.input_months, :]\n\n        predictions: List[np.ndarray] = []\n        cur_i = 0\n\n        pbar = tqdm(total=input_data.x.shape[0] - 1)\n        while cur_i < (input_data.x.shape[0] - 1):\n\n            batch_x_np = input_data.x[cur_i: cur_i + batch_size]\n            if self.hparams.remove_b1_b10:\n                batch_x_np = CropDataset._remove_bands(batch_x_np)\n            batch_x = torch.from_numpy(batch_x_np).float()\n\n            if use_gpu and (device is not None):\n                batch_x = batch_x.to(device)\n\n            with torch.no_grad():\n                if with_forecaster:\n                    batch_x_next = self.forecaster(batch_x)\n                    batch_x = torch.cat((batch_x, batch_x_next), dim=1)\n\n                batch_preds = self.classifier(batch_x)\n\n                if self.hparams.multi_headed:\n                    global_preds, local_preds = batch_preds\n\n                    if local_head:\n                        batch_preds = local_preds\n                    else:\n                        batch_preds = global_preds\n\n                # back to the CPU, if necessary\n                batch_preds = batch_preds.cpu()\n\n            predictions.append(cast(torch.Tensor, batch_preds).numpy())\n            cur_i += batch_size\n            pbar.update(batch_size)\n\n        all_preds = np.concatenate(predictions, axis=0)\n        if len(all_preds.shape) == 1:\n            all_preds = np.expand_dims(all_preds, axis=-1)\n\n        return preds_to_xr(all_preds, lats=input_data.lat, lons=input_data.lon,)\n\n    def _output_metrics(\n        self, preds: np.ndarray, labels: np.ndarray, prefix: str = \"\"\n    ) -> Dict[str, float]:\n\n        if len(preds) == 0:\n            # sometimes this happens in the warmup\n            return {}\n\n        output_dict: Dict[str, float] = {}\n        if not (labels == labels[0]).all():\n            # This can happen when lightning does its warm up on a subset of the\n            # validation data\n            output_dict[f\"{prefix}roc_auc_score\"] = roc_auc_score(\n                labels, preds)\n\n        preds = (preds > PROBABILITY_THRESHOLD).astype(int)\n\n        output_dict[f\"{prefix}precision_score\"] = precision_score(\n            labels, preds)\n        output_dict[f\"{prefix}recall_score\"] = recall_score(labels, preds)\n        output_dict[f\"{prefix}f1_score\"] = f1_score(labels, preds)\n        output_dict[f\"{prefix}accuracy\"] = accuracy_score(labels, preds)\n\n        return output_dict\n\n    def add_noise(self, x: torch.Tensor, training: bool) -> torch.Tensor:\n        if (self.hparams.noise_factor == 0) or (not training):\n            return x\n\n        # expect input to be of shape [timesteps, bands]\n        # and to be normalized with mean 0, std=1\n        # if its not, it means no norm_dict was passed, so lets\n        # just assume std=1\n        noise = torch.normal(0, 1, size=x.shape).float() * \\\n            self.hparams.noise_factor\n\n        # the added noise is the same per band, so that the temporal relationships\n        # are preserved\n        # noise_per_timesteps = noise.repeat(x.shape[0], 1)\n        return x + noise\n\n    def _split_preds_and_get_loss(\n        self, batch, add_preds: bool, loss_label: str, log_loss: bool, training: bool\n    ) -> Dict:\n\n        x, label, is_global = batch\n\n        input_to_encode = x[:, : self.hparams.input_months, :]\n\n        if self.hparams.forecast:\n            # we will predict every timestep except the first one\n            output_to_predict = x[:, 1:, :]\n            encoder_output = self.forecaster(input_to_encode)\n            encoder_loss = self.forecaster_loss(\n                encoder_output, output_to_predict)\n            loss: Union[float, torch.Tensor] = encoder_loss\n\n            final_encoded_input = torch.cat(\n                (\n                    (\n                        self.add_noise(input_to_encode, training),\n                        # -1 because the encoder output has no value for the 0th\n                        # timestep\n                        encoder_output[:, self.hparams.input_months - 1:, :],\n                    )\n                ),\n                dim=1,\n            )\n\n            output_dict = {}\n            if add_preds:\n                output_dict.update(\n                    {\"encoder_prediction\": encoder_output,\n                        \"encoder_target\": output_to_predict, }\n                )\n            if log_loss:\n                output_dict[\"log\"] = {}\n\n            # we now repeat label and is_global\n            x = torch.cat((self.add_noise(x, training),\n                          final_encoded_input), dim=0)\n            label = torch.cat((label, label), dim=0)\n            is_global = torch.cat((is_global, is_global), dim=0)\n        else:\n            loss = 0\n            output_dict = {}\n            if log_loss:\n                output_dict[\"log\"] = {}\n            x = self.add_noise(input_to_encode, training=training)\n\n        if self.hparams.multi_headed:\n            org_global_preds, local_preds = self.classifier(x)\n            global_preds = org_global_preds[is_global != 0]\n            global_labels = label[is_global != 0]\n\n            local_preds = local_preds[is_global == 0]\n            local_labels = label[is_global == 0]\n\n            if local_preds.shape[0] > 0:\n                local_loss = self.local_loss_function(\n                    local_preds.squeeze(-1), local_labels,)\n                loss += local_loss\n\n            if global_preds.shape[0] > 0:\n                global_loss = self.global_loss_function(\n                    global_preds.squeeze(-1), global_labels,)\n\n                num_local_labels = local_preds.shape[0]\n                if num_local_labels == 0:\n                    alpha = 1\n                else:\n                    ratio = global_preds.shape[0] / num_local_labels\n                    alpha = ratio / self.hparams.alpha\n                loss += alpha * global_loss\n\n            output_dict[loss_label] = loss\n            if log_loss:\n                output_dict[\"log\"][loss_label] = loss\n            if add_preds:\n                output_dict.update(\n                    {\n                        \"global_pred\": global_preds,\n                        \"global_label\": global_labels,\n                        \"kenya_pred\": local_preds,\n                        \"kenya_label\": local_labels,\n                    }\n                )\n            return output_dict\n        else:\n            preds = cast(torch.Tensor, self.classifier(x))\n\n            loss += self.global_loss_function(\n                input=preds.squeeze(-1), target=label,)\n\n            output_dict = {loss_label: loss}\n            if log_loss:\n                output_dict[\"log\"][loss_label] = loss\n            if add_preds:\n                output_dict.update({\"pred\": preds, \"label\": label})\n            return output_dict\n\n    def training_step(self, batch, batch_idx):\n        return self._split_preds_and_get_loss(\n            batch, add_preds=False, loss_label=\"loss\", log_loss=True, training=True\n        )\n\n    def validation_step(self, batch, batch_idx):\n        return self._split_preds_and_get_loss(\n            batch, add_preds=True, loss_label=\"val_loss\", log_loss=True, training=False\n        )\n\n    def test_step(self, batch, batch_idx):\n        return self._split_preds_and_get_loss(\n            batch, add_preds=True, loss_label=\"test_loss\", log_loss=True, training=False\n        )\n\n    @staticmethod\n    def _split_tensor(outputs, label) -> Tuple[np.ndarray, np.ndarray]:\n        encoded_all, unencoded_all = [], []\n        for x in outputs:\n            # the first half is unencoded, the second is encoded\n            total = x[label]\n            unencoded_all.append(total[: total.shape[0] // 2])\n            encoded_all.append(total[total.shape[0] // 2:])\n        return (\n            torch.cat(unencoded_all).detach().cpu().numpy(),\n            torch.cat(encoded_all).detach().cpu().numpy(),\n        )\n\n    def _interpretable_metrics(self, outputs, input_prefix: str, output_prefix: str) -> Dict:\n\n        output_dict = {}\n\n        if self.hparams.forecast:\n            u_labels, e_labels = self._split_tensor(\n                outputs, f\"{input_prefix}label\")\n\n            u_preds, e_preds = self._split_tensor(\n                outputs, f\"{input_prefix}pred\")\n        else:\n            u_preds = torch.cat([x[f\"{input_prefix}pred\"]\n                                for x in outputs]).detach().cpu().numpy()\n            u_labels = (\n                torch.cat([x[f\"{input_prefix}label\"]\n                          for x in outputs]).detach().cpu().numpy()\n            )\n\n        output_dict.update(\n            self._output_metrics(\n                u_preds, u_labels, f\"unencoded_{output_prefix}{input_prefix}\")\n        )\n\n        if self.hparams.forecast:\n            output_dict.update(\n                self._output_metrics(\n                    e_preds, e_labels, f\"encoded_{output_prefix}{input_prefix}\")\n            )\n\n        return output_dict\n\n    def validation_epoch_end(self, outputs):\n        avg_loss = torch.stack([x[\"val_loss\"] for x in outputs]).mean()\n        logs = {\"val_loss\": avg_loss}\n        if self.hparams.forecast:\n            encoder_pred = (\n                torch.cat(\n                    [torch.flatten(x[\"encoder_prediction\"], start_dim=1) for x in outputs], dim=0,\n                )\n                .detach()\n                .cpu()\n                .numpy()\n            )\n            encoder_target = (\n                torch.cat(\n                    [torch.flatten(x[\"encoder_target\"], start_dim=1) for x in outputs], dim=0,\n                )\n                .detach()\n                .cpu()\n                .numpy()\n            )\n\n            logs[\"val_encoder_mae\"] = mean_absolute_error(\n                encoder_target, encoder_pred)\n\n        if self.hparams.multi_headed:\n            logs.update(self._interpretable_metrics(\n                outputs, \"global_\", \"val_\"))\n            logs.update(self._interpretable_metrics(outputs, \"kenya_\", \"val_\"))\n        else:\n            logs.update(self._interpretable_metrics(outputs, \"\", \"val_\"))\n        return {\"val_loss\": avg_loss, \"log\": logs}\n\n    def test_epoch_end(self, outputs):\n\n        avg_loss = torch.stack([x[\"test_loss\"] for x in outputs]).mean().item()\n        output_dict = {\"val_loss\": avg_loss}\n\n        if self.hparams.forecast:\n            encoder_pred = (\n                torch.cat(\n                    [torch.flatten(x[\"encoder_prediction\"], start_dim=1) for x in outputs], dim=0,\n                )\n                .detach()\n                .cpu()\n                .numpy()\n            )\n            encoder_target = (\n                torch.cat(\n                    [torch.flatten(x[\"encoder_target\"], start_dim=1) for x in outputs], dim=0,\n                )\n                .detach()\n                .cpu()\n                .numpy()\n            )\n\n            output_dict[\"test_encoder_mae\"] = mean_absolute_error(\n                encoder_target, encoder_pred)\n\n        if self.hparams.multi_headed:\n            output_dict.update(self._interpretable_metrics(\n                outputs, \"global_\", \"test_\"))\n            output_dict.update(self._interpretable_metrics(\n                outputs, \"kenya_\", \"test_\"))\n        else:\n            output_dict.update(\n                self._interpretable_metrics(outputs, \"\", \"test_\"))\n\n        return {\"progress_bar\": output_dict}\n\n    @staticmethod\n    def add_model_specific_args(parent_parser: ArgumentParser) -> ArgumentParser:\n\n        parser = ArgumentParser(parents=[parent_parser], add_help=False)\n\n        parser_args: Dict[str, Tuple[Type, Any]] = {\n            # assumes this is being run from \"scripts\"\n            \"--data_folder\": (str, str(Path(\"../data\"))),\n            \"--learning_rate\": (float, 0.001),\n            \"--batch_size\": (int, 64),\n            \"--input_months\": (int, 5),\n            \"--alpha\": (float, 10),\n            \"--noise_factor\": (float, 0.1),\n        }\n\n        for key, val in parser_args.items():\n            parser.add_argument(key, type=val[0], default=val[1])\n\n        parser.add_argument(\"--remove_b1_b10\",\n                            dest=\"remove_b1_b10\", action=\"store_true\")\n        parser.add_argument(\n            \"--keep_b1_b10\", dest=\"remove_b1_b10\", action=\"store_false\")\n        parser.set_defaults(remove_b1_b10=True)\n\n        parser.add_argument(\"--forecast\", dest=\"forecast\", action=\"store_true\")\n        parser.add_argument(\"--do_not_forecast\",\n                            dest=\"forecast\", action=\"store_false\")\n        parser.set_defaults(forecast=True)\n\n        parser.add_argument(\"--cache\", dest=\"cache\", action=\"store_true\")\n        parser.add_argument(\"--do_not_cache\", dest=\"cache\",\n                            action=\"store_false\")\n        parser.set_defaults(cache=True)\n\n        parser.add_argument(\"--include_geowiki\",\n                            dest=\"include_geowiki\", action=\"store_true\")\n        parser.add_argument(\"--exclude_geowiki\",\n                            dest=\"include_geowiki\", action=\"store_false\")\n        parser.set_defaults(include_geowiki=True)\n\n        parser.add_argument(\"--upsample\", dest=\"upsample\", action=\"store_true\")\n        parser.add_argument(\"--do_not_upsample\",\n                            dest=\"upsample\", action=\"store_false\")\n        parser.set_defaults(upsample=True)\n\n        classifier_parser = Classifier.add_model_specific_args(parser)\n        return Forecaster.add_model_specific_args(classifier_parser)\n",
  "history_output" : "",
  "history_begin_time" : 1646138112922,
  "history_end_time" : 1646138116776,
  "history_notes" : null,
  "history_process" : "9ardvx",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "n5ws56ixox8",
  "history_input" : "from argparse import ArgumentParser, Namespace\nfrom pathlib import Path\nimport numpy as np\nimport xarray as xr\nfrom tqdm import tqdm\n\nimport torch\nfrom torch.nn import functional as F\nfrom torch.utils.data import DataLoader\n\nimport pytorch_lightning as pl\n\nfrom sklearn.metrics import (\n    roc_auc_score,\n    accuracy_score,\n    precision_score,\n    recall_score,\n    f1_score,\n    mean_absolute_error,\n)\n\nfrom src_models_data import CropDataset\nfrom src_models_utils import tif_to_np, preds_to_xr\nfrom src_utils import set_seed\nfrom src_models_forecaster import Forecaster\nfrom src_models_classifier import Classifier\nfrom src_config import PROBABILITY_THRESHOLD\n\nfrom typing import cast, Callable, Tuple, Dict, Any, Type, Optional, List, Union\n\n\nclass Model(pl.LightningModule):\n    r\"\"\"\n    An model for annual and in-season crop mapping. This model consists of a\n    forecaster.Forecaster and a classifier.Classifier - it will require the arguments\n    required by those models too.\n\n    hparams\n    --------\n    The default values for these parameters are set in add_model_specific_args\n\n    :param hparams.data_folder: The path to the data. Default (assumes the model\n        is being run from the scripts directory) = \"../data\"\n    :param hparams.learning_rate: The learning rate. Default = 0.001\n    :param hparams.batch_size: The batch size. Default = 64\n    :param hparams.input_months: The number of input months to pass to the model. If\n        hparams.forecast is True, the remaining months will be forecasted. Otherwise, only the\n        partial timeseries will be passed to the classifier. Default = 5\n    :param hparams.alpha: The weight to use when adding the global and local losses. This\n        parameter is only used if hparams.multi_headed is True. Default = 10\n    :param hparams.noise_factor: The standard deviation of the random noise to add to the\n        raw inputs to the classifier. Default = 0.1\n    :param hparams.remove_b1_b10: Whether or not to remove the B1 and B10 bands. Default = True\n    :param hparams.forecast: Whether or not to forecast the partial time series. Default = True\n    :param hparams.cache: Whether to load all the data into memory during training. Default = True\n    :param hparams.include_geowiki: Whether to include the global GeoWiki dataset during\n        training. Default = True\n    :param hparams.upsample: Whether to oversample the under-represented class so that each class\n        is equally represented in the training and validation dataset. Default = True\n    \"\"\"\n\n    def __init__(self, hparams: Namespace) -> None:\n        super().__init__()\n        set_seed()\n        self.hparams = hparams\n\n        self.data_folder = Path(hparams.data_folder)\n\n        dataset = self.get_dataset(subset=\"training\", cache=False)\n        self.num_outputs = dataset.num_output_classes\n        self.num_timesteps = dataset.num_timesteps\n        self.input_size = dataset.num_input_features\n\n        # we save the normalizing dict because we calculate weighted\n        # normalization values based on the datasets we combine.\n        # The number of instances per dataset (and therefore the weights) can\n        # vary between the train / test / val sets - this ensures the normalizing\n        # dict stays constant between them\n        self.normalizing_dict = dataset.normalizing_dict\n\n        if self.hparams.forecast:\n            num_output_timesteps = self.num_timesteps - self.hparams.input_months\n            print(\n                f\"Predicting {num_output_timesteps} timesteps in the forecaster\")\n            self.forecaster = Forecaster(\n                num_bands=self.input_size, output_timesteps=num_output_timesteps, hparams=hparams,\n            )\n\n            self.forecaster_loss = F.smooth_l1_loss\n\n        self.classifier = Classifier(\n            input_size=self.input_size, hparams=hparams)\n        self.global_loss_function: Callable = F.binary_cross_entropy\n        self.local_loss_function: Callable = F.binary_cross_entropy\n\n    def forward(self, x: torch.Tensor) -> Union[torch.Tensor, Tuple[torch.Tensor, torch.Tensor]]:\n        # To keep the ABC happy\n        return self.classifier(x)\n\n    def configure_optimizers(self):\n        return torch.optim.Adam(self.parameters(), lr=self.hparams.learning_rate)\n\n    def get_dataset(\n        self, subset: str, normalizing_dict: Optional[Dict] = None, cache: Optional[bool] = None,\n    ) -> CropDataset:\n        return CropDataset(\n            data_folder=self.data_folder,\n            subset=subset,\n            remove_b1_b10=self.hparams.remove_b1_b10,\n            normalizing_dict=normalizing_dict,\n            include_geowiki=self.hparams.include_geowiki if subset != \"testing\" else False,\n            cache=self.hparams.cache if cache is None else cache,\n            upsample=self.hparams.upsample if subset != \"testing\" else False,\n            noise_factor=self.hparams.noise_factor if subset != \"testing\" else 0,\n        )\n\n    def train_dataloader(self):\n        return DataLoader(\n            self.get_dataset(subset=\"training\"), shuffle=True, batch_size=self.hparams.batch_size,\n        )\n\n    def val_dataloader(self):\n        return DataLoader(\n            self.get_dataset(subset=\"validation\",\n                             normalizing_dict=self.normalizing_dict,),\n            batch_size=self.hparams.batch_size,\n        )\n\n    def test_dataloader(self):\n        return DataLoader(\n            self.get_dataset(subset=\"testing\",\n                             normalizing_dict=self.normalizing_dict,),\n            batch_size=self.hparams.batch_size,\n        )\n\n    def predict(\n        self,\n        path_to_file: Path,\n        with_forecaster: bool,\n        batch_size: int = 64,\n        add_ndvi: bool = True,\n        add_ndwi: bool = False,\n        nan_fill: float = 0,\n        days_per_timestep: int = 30,\n        local_head: bool = True,\n        use_gpu: bool = True,\n    ) -> xr.Dataset:\n\n        # check if a GPU is available, and if it is\n        # move the model onto the GPU\n        device: Optional[torch.device] = None\n        if use_gpu:\n            use_cuda = torch.cuda.is_available()\n            if not use_cuda:\n                print(\"No GPU - not using one\")\n            device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n            self.to(device)\n\n        self.eval()\n\n        input_data = tif_to_np(\n            path_to_file,\n            add_ndvi=add_ndvi,\n            add_ndwi=add_ndwi,\n            nan=nan_fill,\n            normalizing_dict=self.normalizing_dict,\n            days_per_timestep=days_per_timestep,\n        )\n\n        if with_forecaster:\n            input_data.x = input_data.x[:, : self.hparams.input_months, :]\n\n        predictions: List[np.ndarray] = []\n        cur_i = 0\n\n        pbar = tqdm(total=input_data.x.shape[0] - 1)\n        while cur_i < (input_data.x.shape[0] - 1):\n\n            batch_x_np = input_data.x[cur_i: cur_i + batch_size]\n            if self.hparams.remove_b1_b10:\n                batch_x_np = CropDataset._remove_bands(batch_x_np)\n            batch_x = torch.from_numpy(batch_x_np).float()\n\n            if use_gpu and (device is not None):\n                batch_x = batch_x.to(device)\n\n            with torch.no_grad():\n                if with_forecaster:\n                    batch_x_next = self.forecaster(batch_x)\n                    batch_x = torch.cat((batch_x, batch_x_next), dim=1)\n\n                batch_preds = self.classifier(batch_x)\n\n                if self.hparams.multi_headed:\n                    global_preds, local_preds = batch_preds\n\n                    if local_head:\n                        batch_preds = local_preds\n                    else:\n                        batch_preds = global_preds\n\n                # back to the CPU, if necessary\n                batch_preds = batch_preds.cpu()\n\n            predictions.append(cast(torch.Tensor, batch_preds).numpy())\n            cur_i += batch_size\n            pbar.update(batch_size)\n\n        all_preds = np.concatenate(predictions, axis=0)\n        if len(all_preds.shape) == 1:\n            all_preds = np.expand_dims(all_preds, axis=-1)\n\n        return preds_to_xr(all_preds, lats=input_data.lat, lons=input_data.lon,)\n\n    def _output_metrics(\n        self, preds: np.ndarray, labels: np.ndarray, prefix: str = \"\"\n    ) -> Dict[str, float]:\n\n        if len(preds) == 0:\n            # sometimes this happens in the warmup\n            return {}\n\n        output_dict: Dict[str, float] = {}\n        if not (labels == labels[0]).all():\n            # This can happen when lightning does its warm up on a subset of the\n            # validation data\n            output_dict[f\"{prefix}roc_auc_score\"] = roc_auc_score(\n                labels, preds)\n\n        preds = (preds > PROBABILITY_THRESHOLD).astype(int)\n\n        output_dict[f\"{prefix}precision_score\"] = precision_score(\n            labels, preds)\n        output_dict[f\"{prefix}recall_score\"] = recall_score(labels, preds)\n        output_dict[f\"{prefix}f1_score\"] = f1_score(labels, preds)\n        output_dict[f\"{prefix}accuracy\"] = accuracy_score(labels, preds)\n\n        return output_dict\n\n    def add_noise(self, x: torch.Tensor, training: bool) -> torch.Tensor:\n        if (self.hparams.noise_factor == 0) or (not training):\n            return x\n\n        # expect input to be of shape [timesteps, bands]\n        # and to be normalized with mean 0, std=1\n        # if its not, it means no norm_dict was passed, so lets\n        # just assume std=1\n        noise = torch.normal(0, 1, size=x.shape).float() * \\\n            self.hparams.noise_factor\n\n        # the added noise is the same per band, so that the temporal relationships\n        # are preserved\n        # noise_per_timesteps = noise.repeat(x.shape[0], 1)\n        return x + noise\n\n    def _split_preds_and_get_loss(\n        self, batch, add_preds: bool, loss_label: str, log_loss: bool, training: bool\n    ) -> Dict:\n\n        x, label, is_global = batch\n\n        input_to_encode = x[:, : self.hparams.input_months, :]\n\n        if self.hparams.forecast:\n            # we will predict every timestep except the first one\n            output_to_predict = x[:, 1:, :]\n            encoder_output = self.forecaster(input_to_encode)\n            encoder_loss = self.forecaster_loss(\n                encoder_output, output_to_predict)\n            loss: Union[float, torch.Tensor] = encoder_loss\n\n            final_encoded_input = torch.cat(\n                (\n                    (\n                        self.add_noise(input_to_encode, training),\n                        # -1 because the encoder output has no value for the 0th\n                        # timestep\n                        encoder_output[:, self.hparams.input_months - 1:, :],\n                    )\n                ),\n                dim=1,\n            )\n\n            output_dict = {}\n            if add_preds:\n                output_dict.update(\n                    {\"encoder_prediction\": encoder_output,\n                        \"encoder_target\": output_to_predict, }\n                )\n            if log_loss:\n                output_dict[\"log\"] = {}\n\n            # we now repeat label and is_global\n            x = torch.cat((self.add_noise(x, training),\n                          final_encoded_input), dim=0)\n            label = torch.cat((label, label), dim=0)\n            is_global = torch.cat((is_global, is_global), dim=0)\n        else:\n            loss = 0\n            output_dict = {}\n            if log_loss:\n                output_dict[\"log\"] = {}\n            x = self.add_noise(input_to_encode, training=training)\n\n        if self.hparams.multi_headed:\n            org_global_preds, local_preds = self.classifier(x)\n            global_preds = org_global_preds[is_global != 0]\n            global_labels = label[is_global != 0]\n\n            local_preds = local_preds[is_global == 0]\n            local_labels = label[is_global == 0]\n\n            if local_preds.shape[0] > 0:\n                local_loss = self.local_loss_function(\n                    local_preds.squeeze(-1), local_labels,)\n                loss += local_loss\n\n            if global_preds.shape[0] > 0:\n                global_loss = self.global_loss_function(\n                    global_preds.squeeze(-1), global_labels,)\n\n                num_local_labels = local_preds.shape[0]\n                if num_local_labels == 0:\n                    alpha = 1\n                else:\n                    ratio = global_preds.shape[0] / num_local_labels\n                    alpha = ratio / self.hparams.alpha\n                loss += alpha * global_loss\n\n            output_dict[loss_label] = loss\n            if log_loss:\n                output_dict[\"log\"][loss_label] = loss\n            if add_preds:\n                output_dict.update(\n                    {\n                        \"global_pred\": global_preds,\n                        \"global_label\": global_labels,\n                        \"kenya_pred\": local_preds,\n                        \"kenya_label\": local_labels,\n                    }\n                )\n            return output_dict\n        else:\n            preds = cast(torch.Tensor, self.classifier(x))\n\n            loss += self.global_loss_function(\n                input=preds.squeeze(-1), target=label,)\n\n            output_dict = {loss_label: loss}\n            if log_loss:\n                output_dict[\"log\"][loss_label] = loss\n            if add_preds:\n                output_dict.update({\"pred\": preds, \"label\": label})\n            return output_dict\n\n    def training_step(self, batch, batch_idx):\n        return self._split_preds_and_get_loss(\n            batch, add_preds=False, loss_label=\"loss\", log_loss=True, training=True\n        )\n\n    def validation_step(self, batch, batch_idx):\n        return self._split_preds_and_get_loss(\n            batch, add_preds=True, loss_label=\"val_loss\", log_loss=True, training=False\n        )\n\n    def test_step(self, batch, batch_idx):\n        return self._split_preds_and_get_loss(\n            batch, add_preds=True, loss_label=\"test_loss\", log_loss=True, training=False\n        )\n\n    @staticmethod\n    def _split_tensor(outputs, label) -> Tuple[np.ndarray, np.ndarray]:\n        encoded_all, unencoded_all = [], []\n        for x in outputs:\n            # the first half is unencoded, the second is encoded\n            total = x[label]\n            unencoded_all.append(total[: total.shape[0] // 2])\n            encoded_all.append(total[total.shape[0] // 2:])\n        return (\n            torch.cat(unencoded_all).detach().cpu().numpy(),\n            torch.cat(encoded_all).detach().cpu().numpy(),\n        )\n\n    def _interpretable_metrics(self, outputs, input_prefix: str, output_prefix: str) -> Dict:\n\n        output_dict = {}\n\n        if self.hparams.forecast:\n            u_labels, e_labels = self._split_tensor(\n                outputs, f\"{input_prefix}label\")\n\n            u_preds, e_preds = self._split_tensor(\n                outputs, f\"{input_prefix}pred\")\n        else:\n            u_preds = torch.cat([x[f\"{input_prefix}pred\"]\n                                for x in outputs]).detach().cpu().numpy()\n            u_labels = (\n                torch.cat([x[f\"{input_prefix}label\"]\n                          for x in outputs]).detach().cpu().numpy()\n            )\n\n        output_dict.update(\n            self._output_metrics(\n                u_preds, u_labels, f\"unencoded_{output_prefix}{input_prefix}\")\n        )\n\n        if self.hparams.forecast:\n            output_dict.update(\n                self._output_metrics(\n                    e_preds, e_labels, f\"encoded_{output_prefix}{input_prefix}\")\n            )\n\n        return output_dict\n\n    def validation_epoch_end(self, outputs):\n        avg_loss = torch.stack([x[\"val_loss\"] for x in outputs]).mean()\n        logs = {\"val_loss\": avg_loss}\n        if self.hparams.forecast:\n            encoder_pred = (\n                torch.cat(\n                    [torch.flatten(x[\"encoder_prediction\"], start_dim=1) for x in outputs], dim=0,\n                )\n                .detach()\n                .cpu()\n                .numpy()\n            )\n            encoder_target = (\n                torch.cat(\n                    [torch.flatten(x[\"encoder_target\"], start_dim=1) for x in outputs], dim=0,\n                )\n                .detach()\n                .cpu()\n                .numpy()\n            )\n\n            logs[\"val_encoder_mae\"] = mean_absolute_error(\n                encoder_target, encoder_pred)\n\n        if self.hparams.multi_headed:\n            logs.update(self._interpretable_metrics(\n                outputs, \"global_\", \"val_\"))\n            logs.update(self._interpretable_metrics(outputs, \"kenya_\", \"val_\"))\n        else:\n            logs.update(self._interpretable_metrics(outputs, \"\", \"val_\"))\n        return {\"val_loss\": avg_loss, \"log\": logs}\n\n    def test_epoch_end(self, outputs):\n\n        avg_loss = torch.stack([x[\"test_loss\"] for x in outputs]).mean().item()\n        output_dict = {\"val_loss\": avg_loss}\n\n        if self.hparams.forecast:\n            encoder_pred = (\n                torch.cat(\n                    [torch.flatten(x[\"encoder_prediction\"], start_dim=1) for x in outputs], dim=0,\n                )\n                .detach()\n                .cpu()\n                .numpy()\n            )\n            encoder_target = (\n                torch.cat(\n                    [torch.flatten(x[\"encoder_target\"], start_dim=1) for x in outputs], dim=0,\n                )\n                .detach()\n                .cpu()\n                .numpy()\n            )\n\n            output_dict[\"test_encoder_mae\"] = mean_absolute_error(\n                encoder_target, encoder_pred)\n\n        if self.hparams.multi_headed:\n            output_dict.update(self._interpretable_metrics(\n                outputs, \"global_\", \"test_\"))\n            output_dict.update(self._interpretable_metrics(\n                outputs, \"kenya_\", \"test_\"))\n        else:\n            output_dict.update(\n                self._interpretable_metrics(outputs, \"\", \"test_\"))\n\n        return {\"progress_bar\": output_dict}\n\n    @staticmethod\n    def add_model_specific_args(parent_parser: ArgumentParser) -> ArgumentParser:\n\n        parser = ArgumentParser(parents=[parent_parser], add_help=False)\n\n        parser_args: Dict[str, Tuple[Type, Any]] = {\n            # assumes this is being run from \"scripts\"\n            \"--data_folder\": (str, str(Path(\"../data\"))),\n            \"--learning_rate\": (float, 0.001),\n            \"--batch_size\": (int, 64),\n            \"--input_months\": (int, 5),\n            \"--alpha\": (float, 10),\n            \"--noise_factor\": (float, 0.1),\n        }\n\n        for key, val in parser_args.items():\n            parser.add_argument(key, type=val[0], default=val[1])\n\n        parser.add_argument(\"--remove_b1_b10\",\n                            dest=\"remove_b1_b10\", action=\"store_true\")\n        parser.add_argument(\n            \"--keep_b1_b10\", dest=\"remove_b1_b10\", action=\"store_false\")\n        parser.set_defaults(remove_b1_b10=True)\n\n        parser.add_argument(\"--forecast\", dest=\"forecast\", action=\"store_true\")\n        parser.add_argument(\"--do_not_forecast\",\n                            dest=\"forecast\", action=\"store_false\")\n        parser.set_defaults(forecast=True)\n\n        parser.add_argument(\"--cache\", dest=\"cache\", action=\"store_true\")\n        parser.add_argument(\"--do_not_cache\", dest=\"cache\",\n                            action=\"store_false\")\n        parser.set_defaults(cache=True)\n\n        parser.add_argument(\"--include_geowiki\",\n                            dest=\"include_geowiki\", action=\"store_true\")\n        parser.add_argument(\"--exclude_geowiki\",\n                            dest=\"include_geowiki\", action=\"store_false\")\n        parser.set_defaults(include_geowiki=True)\n\n        parser.add_argument(\"--upsample\", dest=\"upsample\", action=\"store_true\")\n        parser.add_argument(\"--do_not_upsample\",\n                            dest=\"upsample\", action=\"store_false\")\n        parser.set_defaults(upsample=True)\n\n        classifier_parser = Classifier.add_model_specific_args(parser)\n        return Forecaster.add_model_specific_args(classifier_parser)\n",
  "history_output" : "",
  "history_begin_time" : 1646137797752,
  "history_end_time" : 1646137801618,
  "history_notes" : null,
  "history_process" : "9ardvx",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "mfsluw79jw4",
  "history_input" : "from argparse import ArgumentParser, Namespace\nfrom pathlib import Path\nimport numpy as np\nimport xarray as xr\nfrom tqdm import tqdm\n\nimport torch\nfrom torch.nn import functional as F\nfrom torch.utils.data import DataLoader\n\nimport pytorch_lightning as pl\n\nfrom sklearn.metrics import (\n    roc_auc_score,\n    accuracy_score,\n    precision_score,\n    recall_score,\n    f1_score,\n    mean_absolute_error,\n)\n\nfrom src_models_data import CropDataset\nfrom src_models_utils import tif_to_np, preds_to_xr\nfrom src_utils import set_seed\nfrom src_models_forecaster import Forecaster\nfrom src_models_classifier import Classifier\nfrom src_config import PROBABILITY_THRESHOLD\n\nfrom typing import cast, Callable, Tuple, Dict, Any, Type, Optional, List, Union\n\n\nclass Model(pl.LightningModule):\n    r\"\"\"\n    An model for annual and in-season crop mapping. This model consists of a\n    forecaster.Forecaster and a classifier.Classifier - it will require the arguments\n    required by those models too.\n\n    hparams\n    --------\n    The default values for these parameters are set in add_model_specific_args\n\n    :param hparams.data_folder: The path to the data. Default (assumes the model\n        is being run from the scripts directory) = \"../data\"\n    :param hparams.learning_rate: The learning rate. Default = 0.001\n    :param hparams.batch_size: The batch size. Default = 64\n    :param hparams.input_months: The number of input months to pass to the model. If\n        hparams.forecast is True, the remaining months will be forecasted. Otherwise, only the\n        partial timeseries will be passed to the classifier. Default = 5\n    :param hparams.alpha: The weight to use when adding the global and local losses. This\n        parameter is only used if hparams.multi_headed is True. Default = 10\n    :param hparams.noise_factor: The standard deviation of the random noise to add to the\n        raw inputs to the classifier. Default = 0.1\n    :param hparams.remove_b1_b10: Whether or not to remove the B1 and B10 bands. Default = True\n    :param hparams.forecast: Whether or not to forecast the partial time series. Default = True\n    :param hparams.cache: Whether to load all the data into memory during training. Default = True\n    :param hparams.include_geowiki: Whether to include the global GeoWiki dataset during\n        training. Default = True\n    :param hparams.upsample: Whether to oversample the under-represented class so that each class\n        is equally represented in the training and validation dataset. Default = True\n    \"\"\"\n\n    def __init__(self, hparams: Namespace) -> None:\n        super().__init__()\n        set_seed()\n        self.hparams = hparams\n\n        self.data_folder = Path(hparams.data_folder)\n\n        dataset = self.get_dataset(subset=\"training\", cache=False)\n        self.num_outputs = dataset.num_output_classes\n        self.num_timesteps = dataset.num_timesteps\n        self.input_size = dataset.num_input_features\n\n        # we save the normalizing dict because we calculate weighted\n        # normalization values based on the datasets we combine.\n        # The number of instances per dataset (and therefore the weights) can\n        # vary between the train / test / val sets - this ensures the normalizing\n        # dict stays constant between them\n        self.normalizing_dict = dataset.normalizing_dict\n\n        if self.hparams.forecast:\n            num_output_timesteps = self.num_timesteps - self.hparams.input_months\n            print(\n                f\"Predicting {num_output_timesteps} timesteps in the forecaster\")\n            self.forecaster = Forecaster(\n                num_bands=self.input_size, output_timesteps=num_output_timesteps, hparams=hparams,\n            )\n\n            self.forecaster_loss = F.smooth_l1_loss\n\n        self.classifier = Classifier(\n            input_size=self.input_size, hparams=hparams)\n        self.global_loss_function: Callable = F.binary_cross_entropy\n        self.local_loss_function: Callable = F.binary_cross_entropy\n\n    def forward(self, x: torch.Tensor) -> Union[torch.Tensor, Tuple[torch.Tensor, torch.Tensor]]:\n        # To keep the ABC happy\n        return self.classifier(x)\n\n    def configure_optimizers(self):\n        return torch.optim.Adam(self.parameters(), lr=self.hparams.learning_rate)\n\n    def get_dataset(\n        self, subset: str, normalizing_dict: Optional[Dict] = None, cache: Optional[bool] = None,\n    ) -> CropDataset:\n        return CropDataset(\n            data_folder=self.data_folder,\n            subset=subset,\n            remove_b1_b10=self.hparams.remove_b1_b10,\n            normalizing_dict=normalizing_dict,\n            include_geowiki=self.hparams.include_geowiki if subset != \"testing\" else False,\n            cache=self.hparams.cache if cache is None else cache,\n            upsample=self.hparams.upsample if subset != \"testing\" else False,\n            noise_factor=self.hparams.noise_factor if subset != \"testing\" else 0,\n        )\n\n    def train_dataloader(self):\n        return DataLoader(\n            self.get_dataset(subset=\"training\"), shuffle=True, batch_size=self.hparams.batch_size,\n        )\n\n    def val_dataloader(self):\n        return DataLoader(\n            self.get_dataset(subset=\"validation\",\n                             normalizing_dict=self.normalizing_dict,),\n            batch_size=self.hparams.batch_size,\n        )\n\n    def test_dataloader(self):\n        return DataLoader(\n            self.get_dataset(subset=\"testing\",\n                             normalizing_dict=self.normalizing_dict,),\n            batch_size=self.hparams.batch_size,\n        )\n\n    def predict(\n        self,\n        path_to_file: Path,\n        with_forecaster: bool,\n        batch_size: int = 64,\n        add_ndvi: bool = True,\n        add_ndwi: bool = False,\n        nan_fill: float = 0,\n        days_per_timestep: int = 30,\n        local_head: bool = True,\n        use_gpu: bool = True,\n    ) -> xr.Dataset:\n\n        # check if a GPU is available, and if it is\n        # move the model onto the GPU\n        device: Optional[torch.device] = None\n        if use_gpu:\n            use_cuda = torch.cuda.is_available()\n            if not use_cuda:\n                print(\"No GPU - not using one\")\n            device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n            self.to(device)\n\n        self.eval()\n\n        input_data = tif_to_np(\n            path_to_file,\n            add_ndvi=add_ndvi,\n            add_ndwi=add_ndwi,\n            nan=nan_fill,\n            normalizing_dict=self.normalizing_dict,\n            days_per_timestep=days_per_timestep,\n        )\n\n        if with_forecaster:\n            input_data.x = input_data.x[:, : self.hparams.input_months, :]\n\n        predictions: List[np.ndarray] = []\n        cur_i = 0\n\n        pbar = tqdm(total=input_data.x.shape[0] - 1)\n        while cur_i < (input_data.x.shape[0] - 1):\n\n            batch_x_np = input_data.x[cur_i: cur_i + batch_size]\n            if self.hparams.remove_b1_b10:\n                batch_x_np = CropDataset._remove_bands(batch_x_np)\n            batch_x = torch.from_numpy(batch_x_np).float()\n\n            if use_gpu and (device is not None):\n                batch_x = batch_x.to(device)\n\n            with torch.no_grad():\n                if with_forecaster:\n                    batch_x_next = self.forecaster(batch_x)\n                    batch_x = torch.cat((batch_x, batch_x_next), dim=1)\n\n                batch_preds = self.classifier(batch_x)\n\n                if self.hparams.multi_headed:\n                    global_preds, local_preds = batch_preds\n\n                    if local_head:\n                        batch_preds = local_preds\n                    else:\n                        batch_preds = global_preds\n\n                # back to the CPU, if necessary\n                batch_preds = batch_preds.cpu()\n\n            predictions.append(cast(torch.Tensor, batch_preds).numpy())\n            cur_i += batch_size\n            pbar.update(batch_size)\n\n        all_preds = np.concatenate(predictions, axis=0)\n        if len(all_preds.shape) == 1:\n            all_preds = np.expand_dims(all_preds, axis=-1)\n\n        return preds_to_xr(all_preds, lats=input_data.lat, lons=input_data.lon,)\n\n    def _output_metrics(\n        self, preds: np.ndarray, labels: np.ndarray, prefix: str = \"\"\n    ) -> Dict[str, float]:\n\n        if len(preds) == 0:\n            # sometimes this happens in the warmup\n            return {}\n\n        output_dict: Dict[str, float] = {}\n        if not (labels == labels[0]).all():\n            # This can happen when lightning does its warm up on a subset of the\n            # validation data\n            output_dict[f\"{prefix}roc_auc_score\"] = roc_auc_score(\n                labels, preds)\n\n        preds = (preds > PROBABILITY_THRESHOLD).astype(int)\n\n        output_dict[f\"{prefix}precision_score\"] = precision_score(\n            labels, preds)\n        output_dict[f\"{prefix}recall_score\"] = recall_score(labels, preds)\n        output_dict[f\"{prefix}f1_score\"] = f1_score(labels, preds)\n        output_dict[f\"{prefix}accuracy\"] = accuracy_score(labels, preds)\n\n        return output_dict\n\n    def add_noise(self, x: torch.Tensor, training: bool) -> torch.Tensor:\n        if (self.hparams.noise_factor == 0) or (not training):\n            return x\n\n        # expect input to be of shape [timesteps, bands]\n        # and to be normalized with mean 0, std=1\n        # if its not, it means no norm_dict was passed, so lets\n        # just assume std=1\n        noise = torch.normal(0, 1, size=x.shape).float() * \\\n            self.hparams.noise_factor\n\n        # the added noise is the same per band, so that the temporal relationships\n        # are preserved\n        # noise_per_timesteps = noise.repeat(x.shape[0], 1)\n        return x + noise\n\n    def _split_preds_and_get_loss(\n        self, batch, add_preds: bool, loss_label: str, log_loss: bool, training: bool\n    ) -> Dict:\n\n        x, label, is_global = batch\n\n        input_to_encode = x[:, : self.hparams.input_months, :]\n\n        if self.hparams.forecast:\n            # we will predict every timestep except the first one\n            output_to_predict = x[:, 1:, :]\n            encoder_output = self.forecaster(input_to_encode)\n            encoder_loss = self.forecaster_loss(\n                encoder_output, output_to_predict)\n            loss: Union[float, torch.Tensor] = encoder_loss\n\n            final_encoded_input = torch.cat(\n                (\n                    (\n                        self.add_noise(input_to_encode, training),\n                        # -1 because the encoder output has no value for the 0th\n                        # timestep\n                        encoder_output[:, self.hparams.input_months - 1:, :],\n                    )\n                ),\n                dim=1,\n            )\n\n            output_dict = {}\n            if add_preds:\n                output_dict.update(\n                    {\"encoder_prediction\": encoder_output,\n                        \"encoder_target\": output_to_predict, }\n                )\n            if log_loss:\n                output_dict[\"log\"] = {}\n\n            # we now repeat label and is_global\n            x = torch.cat((self.add_noise(x, training),\n                          final_encoded_input), dim=0)\n            label = torch.cat((label, label), dim=0)\n            is_global = torch.cat((is_global, is_global), dim=0)\n        else:\n            loss = 0\n            output_dict = {}\n            if log_loss:\n                output_dict[\"log\"] = {}\n            x = self.add_noise(input_to_encode, training=training)\n\n        if self.hparams.multi_headed:\n            org_global_preds, local_preds = self.classifier(x)\n            global_preds = org_global_preds[is_global != 0]\n            global_labels = label[is_global != 0]\n\n            local_preds = local_preds[is_global == 0]\n            local_labels = label[is_global == 0]\n\n            if local_preds.shape[0] > 0:\n                local_loss = self.local_loss_function(\n                    local_preds.squeeze(-1), local_labels,)\n                loss += local_loss\n\n            if global_preds.shape[0] > 0:\n                global_loss = self.global_loss_function(\n                    global_preds.squeeze(-1), global_labels,)\n\n                num_local_labels = local_preds.shape[0]\n                if num_local_labels == 0:\n                    alpha = 1\n                else:\n                    ratio = global_preds.shape[0] / num_local_labels\n                    alpha = ratio / self.hparams.alpha\n                loss += alpha * global_loss\n\n            output_dict[loss_label] = loss\n            if log_loss:\n                output_dict[\"log\"][loss_label] = loss\n            if add_preds:\n                output_dict.update(\n                    {\n                        \"global_pred\": global_preds,\n                        \"global_label\": global_labels,\n                        \"kenya_pred\": local_preds,\n                        \"kenya_label\": local_labels,\n                    }\n                )\n            return output_dict\n        else:\n            preds = cast(torch.Tensor, self.classifier(x))\n\n            loss += self.global_loss_function(\n                input=preds.squeeze(-1), target=label,)\n\n            output_dict = {loss_label: loss}\n            if log_loss:\n                output_dict[\"log\"][loss_label] = loss\n            if add_preds:\n                output_dict.update({\"pred\": preds, \"label\": label})\n            return output_dict\n\n    def training_step(self, batch, batch_idx):\n        return self._split_preds_and_get_loss(\n            batch, add_preds=False, loss_label=\"loss\", log_loss=True, training=True\n        )\n\n    def validation_step(self, batch, batch_idx):\n        return self._split_preds_and_get_loss(\n            batch, add_preds=True, loss_label=\"val_loss\", log_loss=True, training=False\n        )\n\n    def test_step(self, batch, batch_idx):\n        return self._split_preds_and_get_loss(\n            batch, add_preds=True, loss_label=\"test_loss\", log_loss=True, training=False\n        )\n\n    @staticmethod\n    def _split_tensor(outputs, label) -> Tuple[np.ndarray, np.ndarray]:\n        encoded_all, unencoded_all = [], []\n        for x in outputs:\n            # the first half is unencoded, the second is encoded\n            total = x[label]\n            unencoded_all.append(total[: total.shape[0] // 2])\n            encoded_all.append(total[total.shape[0] // 2:])\n        return (\n            torch.cat(unencoded_all).detach().cpu().numpy(),\n            torch.cat(encoded_all).detach().cpu().numpy(),\n        )\n\n    def _interpretable_metrics(self, outputs, input_prefix: str, output_prefix: str) -> Dict:\n\n        output_dict = {}\n\n        if self.hparams.forecast:\n            u_labels, e_labels = self._split_tensor(\n                outputs, f\"{input_prefix}label\")\n\n            u_preds, e_preds = self._split_tensor(\n                outputs, f\"{input_prefix}pred\")\n        else:\n            u_preds = torch.cat([x[f\"{input_prefix}pred\"]\n                                for x in outputs]).detach().cpu().numpy()\n            u_labels = (\n                torch.cat([x[f\"{input_prefix}label\"]\n                          for x in outputs]).detach().cpu().numpy()\n            )\n\n        output_dict.update(\n            self._output_metrics(\n                u_preds, u_labels, f\"unencoded_{output_prefix}{input_prefix}\")\n        )\n\n        if self.hparams.forecast:\n            output_dict.update(\n                self._output_metrics(\n                    e_preds, e_labels, f\"encoded_{output_prefix}{input_prefix}\")\n            )\n\n        return output_dict\n\n    def validation_epoch_end(self, outputs):\n        avg_loss = torch.stack([x[\"val_loss\"] for x in outputs]).mean()\n        logs = {\"val_loss\": avg_loss}\n        if self.hparams.forecast:\n            encoder_pred = (\n                torch.cat(\n                    [torch.flatten(x[\"encoder_prediction\"], start_dim=1) for x in outputs], dim=0,\n                )\n                .detach()\n                .cpu()\n                .numpy()\n            )\n            encoder_target = (\n                torch.cat(\n                    [torch.flatten(x[\"encoder_target\"], start_dim=1) for x in outputs], dim=0,\n                )\n                .detach()\n                .cpu()\n                .numpy()\n            )\n\n            logs[\"val_encoder_mae\"] = mean_absolute_error(\n                encoder_target, encoder_pred)\n\n        if self.hparams.multi_headed:\n            logs.update(self._interpretable_metrics(\n                outputs, \"global_\", \"val_\"))\n            logs.update(self._interpretable_metrics(outputs, \"kenya_\", \"val_\"))\n        else:\n            logs.update(self._interpretable_metrics(outputs, \"\", \"val_\"))\n        return {\"val_loss\": avg_loss, \"log\": logs}\n\n    def test_epoch_end(self, outputs):\n\n        avg_loss = torch.stack([x[\"test_loss\"] for x in outputs]).mean().item()\n        output_dict = {\"val_loss\": avg_loss}\n\n        if self.hparams.forecast:\n            encoder_pred = (\n                torch.cat(\n                    [torch.flatten(x[\"encoder_prediction\"], start_dim=1) for x in outputs], dim=0,\n                )\n                .detach()\n                .cpu()\n                .numpy()\n            )\n            encoder_target = (\n                torch.cat(\n                    [torch.flatten(x[\"encoder_target\"], start_dim=1) for x in outputs], dim=0,\n                )\n                .detach()\n                .cpu()\n                .numpy()\n            )\n\n            output_dict[\"test_encoder_mae\"] = mean_absolute_error(\n                encoder_target, encoder_pred)\n\n        if self.hparams.multi_headed:\n            output_dict.update(self._interpretable_metrics(\n                outputs, \"global_\", \"test_\"))\n            output_dict.update(self._interpretable_metrics(\n                outputs, \"kenya_\", \"test_\"))\n        else:\n            output_dict.update(\n                self._interpretable_metrics(outputs, \"\", \"test_\"))\n\n        return {\"progress_bar\": output_dict}\n\n    @staticmethod\n    def add_model_specific_args(parent_parser: ArgumentParser) -> ArgumentParser:\n\n        parser = ArgumentParser(parents=[parent_parser], add_help=False)\n\n        parser_args: Dict[str, Tuple[Type, Any]] = {\n            # assumes this is being run from \"scripts\"\n            \"--data_folder\": (str, str(Path(\"../data\"))),\n            \"--learning_rate\": (float, 0.001),\n            \"--batch_size\": (int, 64),\n            \"--input_months\": (int, 5),\n            \"--alpha\": (float, 10),\n            \"--noise_factor\": (float, 0.1),\n        }\n\n        for key, val in parser_args.items():\n            parser.add_argument(key, type=val[0], default=val[1])\n\n        parser.add_argument(\"--remove_b1_b10\",\n                            dest=\"remove_b1_b10\", action=\"store_true\")\n        parser.add_argument(\n            \"--keep_b1_b10\", dest=\"remove_b1_b10\", action=\"store_false\")\n        parser.set_defaults(remove_b1_b10=True)\n\n        parser.add_argument(\"--forecast\", dest=\"forecast\", action=\"store_true\")\n        parser.add_argument(\"--do_not_forecast\",\n                            dest=\"forecast\", action=\"store_false\")\n        parser.set_defaults(forecast=True)\n\n        parser.add_argument(\"--cache\", dest=\"cache\", action=\"store_true\")\n        parser.add_argument(\"--do_not_cache\", dest=\"cache\",\n                            action=\"store_false\")\n        parser.set_defaults(cache=True)\n\n        parser.add_argument(\"--include_geowiki\",\n                            dest=\"include_geowiki\", action=\"store_true\")\n        parser.add_argument(\"--exclude_geowiki\",\n                            dest=\"include_geowiki\", action=\"store_false\")\n        parser.set_defaults(include_geowiki=True)\n\n        parser.add_argument(\"--upsample\", dest=\"upsample\", action=\"store_true\")\n        parser.add_argument(\"--do_not_upsample\",\n                            dest=\"upsample\", action=\"store_false\")\n        parser.set_defaults(upsample=True)\n\n        classifier_parser = Classifier.add_model_specific_args(parser)\n        return Forecaster.add_model_specific_args(classifier_parser)\n",
  "history_output" : "",
  "history_begin_time" : 1646137705562,
  "history_end_time" : 1646137709719,
  "history_notes" : null,
  "history_process" : "9ardvx",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "mnzgx9ex5xa",
  "history_input" : "from argparse import ArgumentParser, Namespace\nfrom pathlib import Path\nimport numpy as np\nimport xarray as xr\nfrom tqdm import tqdm\n\nimport torch\nfrom torch.nn import functional as F\nfrom torch.utils.data import DataLoader\n\nimport pytorch_lightning as pl\n\nfrom sklearn.metrics import (\n    roc_auc_score,\n    accuracy_score,\n    precision_score,\n    recall_score,\n    f1_score,\n    mean_absolute_error,\n)\n\nfrom src_models_data import CropDataset\nfrom src_models_utils import tif_to_np, preds_to_xr\nfrom src_utils import set_seed\nfrom src_models_forecaster import Forecaster\nfrom src_models_classifier import Classifier\nfrom src_config import PROBABILITY_THRESHOLD\n\nfrom typing import cast, Callable, Tuple, Dict, Any, Type, Optional, List, Union\n\n\nclass Model(pl.LightningModule):\n    r\"\"\"\n    An model for annual and in-season crop mapping. This model consists of a\n    forecaster.Forecaster and a classifier.Classifier - it will require the arguments\n    required by those models too.\n\n    hparams\n    --------\n    The default values for these parameters are set in add_model_specific_args\n\n    :param hparams.data_folder: The path to the data. Default (assumes the model\n        is being run from the scripts directory) = \"../data\"\n    :param hparams.learning_rate: The learning rate. Default = 0.001\n    :param hparams.batch_size: The batch size. Default = 64\n    :param hparams.input_months: The number of input months to pass to the model. If\n        hparams.forecast is True, the remaining months will be forecasted. Otherwise, only the\n        partial timeseries will be passed to the classifier. Default = 5\n    :param hparams.alpha: The weight to use when adding the global and local losses. This\n        parameter is only used if hparams.multi_headed is True. Default = 10\n    :param hparams.noise_factor: The standard deviation of the random noise to add to the\n        raw inputs to the classifier. Default = 0.1\n    :param hparams.remove_b1_b10: Whether or not to remove the B1 and B10 bands. Default = True\n    :param hparams.forecast: Whether or not to forecast the partial time series. Default = True\n    :param hparams.cache: Whether to load all the data into memory during training. Default = True\n    :param hparams.include_geowiki: Whether to include the global GeoWiki dataset during\n        training. Default = True\n    :param hparams.upsample: Whether to oversample the under-represented class so that each class\n        is equally represented in the training and validation dataset. Default = True\n    \"\"\"\n\n    def __init__(self, hparams: Namespace) -> None:\n        super().__init__()\n        set_seed()\n        self.hparams = hparams\n\n        self.data_folder = Path(hparams.data_folder)\n\n        dataset = self.get_dataset(subset=\"training\", cache=False)\n        self.num_outputs = dataset.num_output_classes\n        self.num_timesteps = dataset.num_timesteps\n        self.input_size = dataset.num_input_features\n\n        # we save the normalizing dict because we calculate weighted\n        # normalization values based on the datasets we combine.\n        # The number of instances per dataset (and therefore the weights) can\n        # vary between the train / test / val sets - this ensures the normalizing\n        # dict stays constant between them\n        self.normalizing_dict = dataset.normalizing_dict\n\n        if self.hparams.forecast:\n            num_output_timesteps = self.num_timesteps - self.hparams.input_months\n            print(\n                f\"Predicting {num_output_timesteps} timesteps in the forecaster\")\n            self.forecaster = Forecaster(\n                num_bands=self.input_size, output_timesteps=num_output_timesteps, hparams=hparams,\n            )\n\n            self.forecaster_loss = F.smooth_l1_loss\n\n        self.classifier = Classifier(\n            input_size=self.input_size, hparams=hparams)\n        self.global_loss_function: Callable = F.binary_cross_entropy\n        self.local_loss_function: Callable = F.binary_cross_entropy\n\n    def forward(self, x: torch.Tensor) -> Union[torch.Tensor, Tuple[torch.Tensor, torch.Tensor]]:\n        # To keep the ABC happy\n        return self.classifier(x)\n\n    def configure_optimizers(self):\n        return torch.optim.Adam(self.parameters(), lr=self.hparams.learning_rate)\n\n    def get_dataset(\n        self, subset: str, normalizing_dict: Optional[Dict] = None, cache: Optional[bool] = None,\n    ) -> CropDataset:\n        return CropDataset(\n            data_folder=self.data_folder,\n            subset=subset,\n            remove_b1_b10=self.hparams.remove_b1_b10,\n            normalizing_dict=normalizing_dict,\n            include_geowiki=self.hparams.include_geowiki if subset != \"testing\" else False,\n            cache=self.hparams.cache if cache is None else cache,\n            upsample=self.hparams.upsample if subset != \"testing\" else False,\n            noise_factor=self.hparams.noise_factor if subset != \"testing\" else 0,\n        )\n\n    def train_dataloader(self):\n        return DataLoader(\n            self.get_dataset(subset=\"training\"), shuffle=True, batch_size=self.hparams.batch_size,\n        )\n\n    def val_dataloader(self):\n        return DataLoader(\n            self.get_dataset(subset=\"validation\",\n                             normalizing_dict=self.normalizing_dict,),\n            batch_size=self.hparams.batch_size,\n        )\n\n    def test_dataloader(self):\n        return DataLoader(\n            self.get_dataset(subset=\"testing\",\n                             normalizing_dict=self.normalizing_dict,),\n            batch_size=self.hparams.batch_size,\n        )\n\n    def predict(\n        self,\n        path_to_file: Path,\n        with_forecaster: bool,\n        batch_size: int = 64,\n        add_ndvi: bool = True,\n        add_ndwi: bool = False,\n        nan_fill: float = 0,\n        days_per_timestep: int = 30,\n        local_head: bool = True,\n        use_gpu: bool = True,\n    ) -> xr.Dataset:\n\n        # check if a GPU is available, and if it is\n        # move the model onto the GPU\n        device: Optional[torch.device] = None\n        if use_gpu:\n            use_cuda = torch.cuda.is_available()\n            if not use_cuda:\n                print(\"No GPU - not using one\")\n            device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n            self.to(device)\n\n        self.eval()\n\n        input_data = tif_to_np(\n            path_to_file,\n            add_ndvi=add_ndvi,\n            add_ndwi=add_ndwi,\n            nan=nan_fill,\n            normalizing_dict=self.normalizing_dict,\n            days_per_timestep=days_per_timestep,\n        )\n\n        if with_forecaster:\n            input_data.x = input_data.x[:, : self.hparams.input_months, :]\n\n        predictions: List[np.ndarray] = []\n        cur_i = 0\n\n        pbar = tqdm(total=input_data.x.shape[0] - 1)\n        while cur_i < (input_data.x.shape[0] - 1):\n\n            batch_x_np = input_data.x[cur_i: cur_i + batch_size]\n            if self.hparams.remove_b1_b10:\n                batch_x_np = CropDataset._remove_bands(batch_x_np)\n            batch_x = torch.from_numpy(batch_x_np).float()\n\n            if use_gpu and (device is not None):\n                batch_x = batch_x.to(device)\n\n            with torch.no_grad():\n                if with_forecaster:\n                    batch_x_next = self.forecaster(batch_x)\n                    batch_x = torch.cat((batch_x, batch_x_next), dim=1)\n\n                batch_preds = self.classifier(batch_x)\n\n                if self.hparams.multi_headed:\n                    global_preds, local_preds = batch_preds\n\n                    if local_head:\n                        batch_preds = local_preds\n                    else:\n                        batch_preds = global_preds\n\n                # back to the CPU, if necessary\n                batch_preds = batch_preds.cpu()\n\n            predictions.append(cast(torch.Tensor, batch_preds).numpy())\n            cur_i += batch_size\n            pbar.update(batch_size)\n\n        all_preds = np.concatenate(predictions, axis=0)\n        if len(all_preds.shape) == 1:\n            all_preds = np.expand_dims(all_preds, axis=-1)\n\n        return preds_to_xr(all_preds, lats=input_data.lat, lons=input_data.lon,)\n\n    def _output_metrics(\n        self, preds: np.ndarray, labels: np.ndarray, prefix: str = \"\"\n    ) -> Dict[str, float]:\n\n        if len(preds) == 0:\n            # sometimes this happens in the warmup\n            return {}\n\n        output_dict: Dict[str, float] = {}\n        if not (labels == labels[0]).all():\n            # This can happen when lightning does its warm up on a subset of the\n            # validation data\n            output_dict[f\"{prefix}roc_auc_score\"] = roc_auc_score(\n                labels, preds)\n\n        preds = (preds > PROBABILITY_THRESHOLD).astype(int)\n\n        output_dict[f\"{prefix}precision_score\"] = precision_score(\n            labels, preds)\n        output_dict[f\"{prefix}recall_score\"] = recall_score(labels, preds)\n        output_dict[f\"{prefix}f1_score\"] = f1_score(labels, preds)\n        output_dict[f\"{prefix}accuracy\"] = accuracy_score(labels, preds)\n\n        return output_dict\n\n    def add_noise(self, x: torch.Tensor, training: bool) -> torch.Tensor:\n        if (self.hparams.noise_factor == 0) or (not training):\n            return x\n\n        # expect input to be of shape [timesteps, bands]\n        # and to be normalized with mean 0, std=1\n        # if its not, it means no norm_dict was passed, so lets\n        # just assume std=1\n        noise = torch.normal(0, 1, size=x.shape).float() * \\\n            self.hparams.noise_factor\n\n        # the added noise is the same per band, so that the temporal relationships\n        # are preserved\n        # noise_per_timesteps = noise.repeat(x.shape[0], 1)\n        return x + noise\n\n    def _split_preds_and_get_loss(\n        self, batch, add_preds: bool, loss_label: str, log_loss: bool, training: bool\n    ) -> Dict:\n\n        x, label, is_global = batch\n\n        input_to_encode = x[:, : self.hparams.input_months, :]\n\n        if self.hparams.forecast:\n            # we will predict every timestep except the first one\n            output_to_predict = x[:, 1:, :]\n            encoder_output = self.forecaster(input_to_encode)\n            encoder_loss = self.forecaster_loss(\n                encoder_output, output_to_predict)\n            loss: Union[float, torch.Tensor] = encoder_loss\n\n            final_encoded_input = torch.cat(\n                (\n                    (\n                        self.add_noise(input_to_encode, training),\n                        # -1 because the encoder output has no value for the 0th\n                        # timestep\n                        encoder_output[:, self.hparams.input_months - 1:, :],\n                    )\n                ),\n                dim=1,\n            )\n\n            output_dict = {}\n            if add_preds:\n                output_dict.update(\n                    {\"encoder_prediction\": encoder_output,\n                        \"encoder_target\": output_to_predict, }\n                )\n            if log_loss:\n                output_dict[\"log\"] = {}\n\n            # we now repeat label and is_global\n            x = torch.cat((self.add_noise(x, training),\n                          final_encoded_input), dim=0)\n            label = torch.cat((label, label), dim=0)\n            is_global = torch.cat((is_global, is_global), dim=0)\n        else:\n            loss = 0\n            output_dict = {}\n            if log_loss:\n                output_dict[\"log\"] = {}\n            x = self.add_noise(input_to_encode, training=training)\n\n        if self.hparams.multi_headed:\n            org_global_preds, local_preds = self.classifier(x)\n            global_preds = org_global_preds[is_global != 0]\n            global_labels = label[is_global != 0]\n\n            local_preds = local_preds[is_global == 0]\n            local_labels = label[is_global == 0]\n\n            if local_preds.shape[0] > 0:\n                local_loss = self.local_loss_function(\n                    local_preds.squeeze(-1), local_labels,)\n                loss += local_loss\n\n            if global_preds.shape[0] > 0:\n                global_loss = self.global_loss_function(\n                    global_preds.squeeze(-1), global_labels,)\n\n                num_local_labels = local_preds.shape[0]\n                if num_local_labels == 0:\n                    alpha = 1\n                else:\n                    ratio = global_preds.shape[0] / num_local_labels\n                    alpha = ratio / self.hparams.alpha\n                loss += alpha * global_loss\n\n            output_dict[loss_label] = loss\n            if log_loss:\n                output_dict[\"log\"][loss_label] = loss\n            if add_preds:\n                output_dict.update(\n                    {\n                        \"global_pred\": global_preds,\n                        \"global_label\": global_labels,\n                        \"kenya_pred\": local_preds,\n                        \"kenya_label\": local_labels,\n                    }\n                )\n            return output_dict\n        else:\n            preds = cast(torch.Tensor, self.classifier(x))\n\n            loss += self.global_loss_function(\n                input=preds.squeeze(-1), target=label,)\n\n            output_dict = {loss_label: loss}\n            if log_loss:\n                output_dict[\"log\"][loss_label] = loss\n            if add_preds:\n                output_dict.update({\"pred\": preds, \"label\": label})\n            return output_dict\n\n    def training_step(self, batch, batch_idx):\n        return self._split_preds_and_get_loss(\n            batch, add_preds=False, loss_label=\"loss\", log_loss=True, training=True\n        )\n\n    def validation_step(self, batch, batch_idx):\n        return self._split_preds_and_get_loss(\n            batch, add_preds=True, loss_label=\"val_loss\", log_loss=True, training=False\n        )\n\n    def test_step(self, batch, batch_idx):\n        return self._split_preds_and_get_loss(\n            batch, add_preds=True, loss_label=\"test_loss\", log_loss=True, training=False\n        )\n\n    @staticmethod\n    def _split_tensor(outputs, label) -> Tuple[np.ndarray, np.ndarray]:\n        encoded_all, unencoded_all = [], []\n        for x in outputs:\n            # the first half is unencoded, the second is encoded\n            total = x[label]\n            unencoded_all.append(total[: total.shape[0] // 2])\n            encoded_all.append(total[total.shape[0] // 2:])\n        return (\n            torch.cat(unencoded_all).detach().cpu().numpy(),\n            torch.cat(encoded_all).detach().cpu().numpy(),\n        )\n\n    def _interpretable_metrics(self, outputs, input_prefix: str, output_prefix: str) -> Dict:\n\n        output_dict = {}\n\n        if self.hparams.forecast:\n            u_labels, e_labels = self._split_tensor(\n                outputs, f\"{input_prefix}label\")\n\n            u_preds, e_preds = self._split_tensor(\n                outputs, f\"{input_prefix}pred\")\n        else:\n            u_preds = torch.cat([x[f\"{input_prefix}pred\"]\n                                for x in outputs]).detach().cpu().numpy()\n            u_labels = (\n                torch.cat([x[f\"{input_prefix}label\"]\n                          for x in outputs]).detach().cpu().numpy()\n            )\n\n        output_dict.update(\n            self._output_metrics(\n                u_preds, u_labels, f\"unencoded_{output_prefix}{input_prefix}\")\n        )\n\n        if self.hparams.forecast:\n            output_dict.update(\n                self._output_metrics(\n                    e_preds, e_labels, f\"encoded_{output_prefix}{input_prefix}\")\n            )\n\n        return output_dict\n\n    def validation_epoch_end(self, outputs):\n        avg_loss = torch.stack([x[\"val_loss\"] for x in outputs]).mean()\n        logs = {\"val_loss\": avg_loss}\n        if self.hparams.forecast:\n            encoder_pred = (\n                torch.cat(\n                    [torch.flatten(x[\"encoder_prediction\"], start_dim=1) for x in outputs], dim=0,\n                )\n                .detach()\n                .cpu()\n                .numpy()\n            )\n            encoder_target = (\n                torch.cat(\n                    [torch.flatten(x[\"encoder_target\"], start_dim=1) for x in outputs], dim=0,\n                )\n                .detach()\n                .cpu()\n                .numpy()\n            )\n\n            logs[\"val_encoder_mae\"] = mean_absolute_error(\n                encoder_target, encoder_pred)\n\n        if self.hparams.multi_headed:\n            logs.update(self._interpretable_metrics(\n                outputs, \"global_\", \"val_\"))\n            logs.update(self._interpretable_metrics(outputs, \"kenya_\", \"val_\"))\n        else:\n            logs.update(self._interpretable_metrics(outputs, \"\", \"val_\"))\n        return {\"val_loss\": avg_loss, \"log\": logs}\n\n    def test_epoch_end(self, outputs):\n\n        avg_loss = torch.stack([x[\"test_loss\"] for x in outputs]).mean().item()\n        output_dict = {\"val_loss\": avg_loss}\n\n        if self.hparams.forecast:\n            encoder_pred = (\n                torch.cat(\n                    [torch.flatten(x[\"encoder_prediction\"], start_dim=1) for x in outputs], dim=0,\n                )\n                .detach()\n                .cpu()\n                .numpy()\n            )\n            encoder_target = (\n                torch.cat(\n                    [torch.flatten(x[\"encoder_target\"], start_dim=1) for x in outputs], dim=0,\n                )\n                .detach()\n                .cpu()\n                .numpy()\n            )\n\n            output_dict[\"test_encoder_mae\"] = mean_absolute_error(\n                encoder_target, encoder_pred)\n\n        if self.hparams.multi_headed:\n            output_dict.update(self._interpretable_metrics(\n                outputs, \"global_\", \"test_\"))\n            output_dict.update(self._interpretable_metrics(\n                outputs, \"kenya_\", \"test_\"))\n        else:\n            output_dict.update(\n                self._interpretable_metrics(outputs, \"\", \"test_\"))\n\n        return {\"progress_bar\": output_dict}\n\n    @staticmethod\n    def add_model_specific_args(parent_parser: ArgumentParser) -> ArgumentParser:\n\n        parser = ArgumentParser(parents=[parent_parser], add_help=False)\n\n        parser_args: Dict[str, Tuple[Type, Any]] = {\n            # assumes this is being run from \"scripts\"\n            \"--data_folder\": (str, str(Path(\"../data\"))),\n            \"--learning_rate\": (float, 0.001),\n            \"--batch_size\": (int, 64),\n            \"--input_months\": (int, 5),\n            \"--alpha\": (float, 10),\n            \"--noise_factor\": (float, 0.1),\n        }\n\n        for key, val in parser_args.items():\n            parser.add_argument(key, type=val[0], default=val[1])\n\n        parser.add_argument(\"--remove_b1_b10\",\n                            dest=\"remove_b1_b10\", action=\"store_true\")\n        parser.add_argument(\n            \"--keep_b1_b10\", dest=\"remove_b1_b10\", action=\"store_false\")\n        parser.set_defaults(remove_b1_b10=True)\n\n        parser.add_argument(\"--forecast\", dest=\"forecast\", action=\"store_true\")\n        parser.add_argument(\"--do_not_forecast\",\n                            dest=\"forecast\", action=\"store_false\")\n        parser.set_defaults(forecast=True)\n\n        parser.add_argument(\"--cache\", dest=\"cache\", action=\"store_true\")\n        parser.add_argument(\"--do_not_cache\", dest=\"cache\",\n                            action=\"store_false\")\n        parser.set_defaults(cache=True)\n\n        parser.add_argument(\"--include_geowiki\",\n                            dest=\"include_geowiki\", action=\"store_true\")\n        parser.add_argument(\"--exclude_geowiki\",\n                            dest=\"include_geowiki\", action=\"store_false\")\n        parser.set_defaults(include_geowiki=True)\n\n        parser.add_argument(\"--upsample\", dest=\"upsample\", action=\"store_true\")\n        parser.add_argument(\"--do_not_upsample\",\n                            dest=\"upsample\", action=\"store_false\")\n        parser.set_defaults(upsample=True)\n\n        classifier_parser = Classifier.add_model_specific_args(parser)\n        return Forecaster.add_model_specific_args(classifier_parser)\n",
  "history_output" : "",
  "history_begin_time" : 1646137596494,
  "history_end_time" : 1646137601100,
  "history_notes" : null,
  "history_process" : "9ardvx",
  "host_id" : "100001",
  "indicator" : "Done"
},]
